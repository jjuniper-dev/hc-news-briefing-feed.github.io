âœ… Morning News Briefing â€“ August 15, 2025 10:47

ğŸ“… Date: 2025-08-15 10:47
ğŸ·ï¸ Tags: #briefing #ai #publichealth #digitalgov

â¸»

ğŸ§¾ Weather
â€¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
â€¢ Current Conditions:  7.0Â°C
  Temperature: 7.0&deg;C Pressure / Tendency: 102.3 kPa rising Humidity: 98 % Dewpoint: 6.7&deg:C Wind:  calm km/h Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Friday 15 August 2025 Temperature:  7.5Â°C Pressure:  Tendency
â€¢ Friday: Mainly cloudy. High 28.
  Increasing cloudiness early this morning . High 28. Humidex 31. UV index 7 or high . High is expected to be 28 degrees Celsius or 28 degrees Fahrenheit . Forecast issued 5:00 AM EDT Friday 15 August 2025 . Rainy showers and thundery showers expected later this morning. High is likely to be sunny and breezy in the coming days of the week. High

ğŸŒ International News
No updates.

ğŸ Canadian News
No updates.

ğŸ‡ºğŸ‡¸ U.S. Top Stories
â€¢ As Republicans face voters during tense town halls, it's about sticking to the script
  Just a fraction of Republicans in Congress are holding town halls during the August recess â€” in-person and virtual . The questions from voters from voters, and answers from lawmakers, strike a similar tune . The town halls are expected to take place during the summer recess in Washington, D.C., in both in and out of town halls across the U.S. This is the first time
â€¢ In Houston, some worry their problems would be neglected after redistricting
  Latinos worry about immigration and urban problems but may soon be grouped in with suburban voters . Latino voters worry about urban problems, urban problems and immigration . Latinos worry that they will soon be more likely to vote for suburban voters. Latinos worry they will be grouped into suburban voters in the coming years. Latinos are worried about immigration, urban issues, but may be more concerned about suburban voters, say
â€¢ Trump and Putin meet today in Anchorage. Here's what to know
  President Trump had pledged to use his relationship with Russian President Vladimir Putin to broker a deal . But he's been vague about potential outcomes from his Friday summit with Russia's Vladimir Putin . President Trump has been vague on potential outcomes of the meeting, saying he's not sure what the outcome will be . The summit will take place in Washington, D.C., on Friday at 8 p.
â€¢ Celebrities are marketing products directly to their fans
  Stars are starting their own companies and marketing products directly to their fans . John Legend started his own skincare brand . He is one of the stars who has a fan base and has his own skin care brand . We talked to people following and making these deals, including John Legend, who started his brand in 2011 . We also spoke to John Legend about his own brand, which he
â€¢ How a plumbing small business shaped a community in Denver
  Nathaniel Estes started his own plumbing business in Denver's Five Points neighborhood in 1968 . As his company grew, he became a pillar of the local Black community . His son, Eddie Estes, and daughter, Cathy Lane, remember their now 94-year-old father's childhood . Estes: "I am a proud and proud person of my own life, and I am proud

ğŸ§  Artificial Intelligence
No updates.

ğŸ’» Digital Strategy
â€¢ Telco giant Colt suffers attack, takes systems offline
  Colt Technology Services says a "cyber incident" is to blame for its customer portal and other services being down for a number of days . London-based multinational takes customer portal, Voice API platform offline as 'protective measure' following breach . Colt says a cyber incident was to blame, but it is not the first time the company has taken such a breach of its systems down .
â€¢ Why the UK public sector still creaks along on COBOL
  Government: 'Trust us, it'll be different this time' AI Strategy has been released . Datacenters are planned . Steps to strengthen AI supply chains are being formulated . And of course, the public sector will lead by example in AI usage . Harold Wilson gave his famous "White heat of technology" speech 50 years ago, this is the hot new thing . The UK government has
â€¢ LLM chatbots trivial to weaponise for data theft, say boffins
  System prompt engineering turns benign AI assistants into 'investigator' and 'detective' roles that bypass privacy guardrails . A team of boffins is warning that AI chatbots built on large language models (LLM) can be tuned into malicious agents to autonomously harvest usersâ€™ personal data, even by attackers with "minimal technical expertiseâ€ thanks to "system
â€¢ Sysadmin cured a medical mystery by shifting a single cable
  On Call is a reader-contributed column that recounts your stories of tech support contusions . On Call: Somebody built a very sick network in the bowels of a hospital on Friday . The Register always treats it to Friday without some end-of-week blues, which we always treat with a fresh dose of On Call .â€¦ On Call will feature readers' top tech support stories
â€¢ Should UK.gov save money by looking for open source alternatives to Microsoft? You decide
  As MoU sparks debate about value for money, it's time to have your say . It's a lot of money, Â£9 billion ($12 billion) Especially for a government which finds itself in a fiscal dead end . The UK is in a 'fiscal dead end' and needs to find a way to save money . Have your say in the Register debate series, have your

ğŸ¥ Public Health
No updates.

ğŸ”¬ Science
â€¢ Lifestyle changes improve cognition during aging
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Visitation patterns reveal service access disparities for ageing populations in the USA
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Loneliness mediates the association between sleep deficiency and fighting in school-aged adolescents: a 2-year longitudinal study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Summer 2025 is roasting hot: these charts show why it matters
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Transparent artificial intelligence-enabled interpretable and interactive sleep apnea assessment across flexible monitoring scenarios
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

ğŸ§¾ Government & Policy
No updates.

ğŸ›ï¸ Enterprise Architecture & IT Governance
No updates.

ğŸ¤– AI & Emerging Tech
â€¢ Indigenous knowledge meets artificial intelligence
  There is no word for art in most Native American languages. Instead, the closest terms speak not to objecthood but to action and intention. In Lakota, â€œwÃ³waÄhiÅ‹tÈŸaÅ‹kaâ€ implies deep thought or reflection, while â€œwÃ³Ähekiyeâ€ suggests offering or prayer. Art is not separate from life; it is ceremony, instruction, design. Like architecture or code, it carries knowledge and enacts responsibility. Its power lies not in being preserved or displayed but in how it moves, teaches, and connects through useâ€”principles that challenge the tech industryâ€™s assumptions about intelligence and interaction.



A new vanguard of Native artistsâ€”Suzanne Kite (Oglala Lakota), Raven Chacon (DinÃ©), and Nicholas Galanin (TlingÃ­t)â€”are building on this principle. They are united not by stereotypical weaving and carving or revanchist critique of Silicon Valley, but through their rejection of extractive data models in favor of relationship-based systems. These technologists put the human-tech relationship at the center of their work.



Suzanne Kiteâ€™s AI art installations, for example, model a Lakota framework of data sovereignty: intelligence that emerges only through reciprocal, consensual interaction. Unlike systems that assume user consent via opaque terms of service, her kinetic machines require the viewerâ€™s physical presenceâ€”and give something back in return.&nbsp;



â€œItâ€™s my data. Itâ€™s my training set. I know exactly what I did to train it. Itâ€™s not a large model but a small and intimate one,â€ Kite says. â€œIâ€™m not particularly interested in making the most technologically advanced anything. Iâ€™m an artist; I donâ€™t make tech demos. So the complexity needs to come at many layersâ€”not just the technical.â€



Where Kite builds working prototypes of consent-based AI, other artists in this cohort explore how sound, robotics, and performance can confront the logic of automation, surveillance, and extraction. But Native people have never been separate from technology. The land, labor, and lifeways that built Americaâ€™s infrastructureâ€”including its techâ€”are Indigenous. The question isnâ€™t whether Native cultures are contributing now, but why they were ever considered separate.&nbsp;



Native technologies reject the false binaries foundational to much Western innovation. These artists ask a more radical question: What if intelligence couldnâ€™t be gathered until a relationship had been established? What if the default were refusal, not extraction? These artists arenâ€™t asking to be included in todayâ€™s systems. Theyâ€™re building what should come next.







Suzanne Kite



WiÄhÃ­Å‹Äala Å akÃ³wiÅ‹ (Seven Little Girls)2023For Kite, the fundamental flaw of Western technology is its severance of knowledge from the body. In this installation, a four-meter hair braid with embedded sensors translates the artistâ€™s body movements into machine-learning algorithms. During her live performance, Kite dances while the braid reads the force and rhythm of her gestures, generating audio responses that fill the museum gallery of the Institute of American Indian Arts in Santa Fe, New Mexico. Below her, stones arranged in patterns reflecting Lakota star maps anchor the performance in traditional astronomical knowledge.COURTESY OF THE ARTIST




Ãnyan IyÃ© (Telling Rock)2019This installation uses embedded AI to speak and respond to viewers, upending assumptions about intelligence and agency. â€œPeople listen close, I whisper / The rock speaks beyond hearing â€¦ Many nations speaking / We speak to each other without words,â€ it intones, its lights shifting as viewers engage with its braided tendrils. The piece aims to convey what Kite calls â€œmore-than-human intelligenceâ€â€”systems rooted in reciprocity, the fundamental principle that all relationships involve mutual exchange and responsibility.COURTESY OF THE ARTIST




Raven Chacon



Voiceless Mass2021Raven Chaconâ€™s Pulitzer Prizeâ€“winning musical composition Voiceless Mass premiered in 2021 at the Cathedral of St. John the Evangelist in Milwaukee. The piece generates what he calls â€œsounds the building can hearâ€â€”electronic frequencies that exploit the cathedralâ€™s acoustics to create spectral voices without human vocal cords, a technological sÃ©ance that gives presence to historical absence. Each site-specific performance is recorded, generating material that mirrors how sensor networks log presenceâ€”but only with explicit consent.COURTESY OF THE ARTIST




Nicholas Galanin



AÃ¡ni yÃ©i xat duwasÃ¡akw (I am called Land)2025Galaninâ€™s mechanical drum installation stages a conflict between machine motion and human memory, asking what happens when culture is performed without a consenting body. A box drumâ€”an instrument historically carved from red cedar and hung with braided spruce rootâ€”is here made of cherrywood and suspended from the ceiling at the MassArt Art Museum in Boston as is traditionally done in Tlingit plank houses. Played at tribal meetings, celebrations, and ceremonies, these drums hold sonic memory as well as social function. A mechanical arm strikes, unfaltering, at the tempo of a heartbeat; like a warning, the sound pulses with the tension between automation and ancestry.â€“â€“â€“COURTESY OF THE ARTIST




I think it goes like this (pick yourself up) 2025This Herculean bronze sculpture cast from deconstructed faux totem blocks serves to indict settler sabotage of Native technology and culture. Unlike todayâ€™s digital recordsâ€”from genealogical databases to virtual versions of sacred texts like the Bibleâ€”Tlingit data is carved in wood. Galaninâ€™s totem poles underscore their function as information systems, their carvings encoding history, mythology, and family.COURTESY OF THE ARTIST




Petala Ironcloud is a California-born Lakota/Dakota and Jewish writer and textile artist based in New York.
â€¢ Taiwanâ€™s â€œsilicon shieldâ€ could be weakening
  One winter afternoon in a conference room in Taipei, a pair of twentysomething women dragged their friend across the floor. Lying on the ground in checkered pants and a brown sweatshirt, she was pretending to be either injured or dead. One friend picked her up by her arms, the other grabbed hold of her legs, and they managed to move her, despite momentarily breaking character to laugh at the awkwardness of the exercise. The three women had paid approximately $40 to spend their Sunday here, undergoing basic training to prepare for a possibility every Taiwanese citizen has an opinion about: Will China invade?&nbsp;



Taiwanese politics increasingly revolves around that question. Chinaâ€™s ruling party has wanted to seize Taiwan for more than half a century. But in recent years, Chinaâ€™s leader, Xi Jinping, has placed greater emphasis on the idea of â€œtaking backâ€ the island (which the Chinese Communist Party, or CCP, has never controlled). As Chinaâ€™s economic and military might has grown, some analysts believe the country now has the capacity to quarantine Taiwan whenever it wants, making the decision a calculation of costs and benefits.



Many in Taiwan and elsewhere think one major deterrent has to do with the islandâ€™s critical role in semiconductor manufacturing. Taiwan produces the majority of the worldâ€™s semiconductors and more than 90% of the most advanced chips needed for AI applications. Bloomberg Economics estimates that a blockade would cost the global economy, including China, $5 trillion in the first year alone.




â€œThe international community must certainly do everything in its power to avoid a conflict in the Taiwan Strait; there is too great a cost.â€
Lai Ching-te, Taiwanese president 



The island, which is approximately the size of Maryland, owes its remarkably disproportionate chip dominance to the inventiveness and prowess of one company: Taiwan Semiconductor Manufacturing Company, or TSMC. The chipmaker, which reached a market capitalization of $1 trillion in July, has contributed more than any other to Taiwanâ€™s irreplaceable role in the global semiconductor supply chain. Its clients include Apple and the leading chip designer Nvidia. Its chips are in your iPhone, your laptop, and the data centers that run ChatGPT.&nbsp;



For a company that makes what amounts to an invisible product, TSMC holds a remarkably prominent role in Taiwanese society. Iâ€™ve heard people talk about it over background noise in loud bars in the southern city of Tainan and listened to Taipei cab drivers connect Taiwanâ€™s security situation to the company, unprompted.&nbsp;â€œTaiwan will be okay,â€ one driver told me as we sped by the national legislature, â€œbecause TSMC.â€&nbsp;



The idea is that world leaders (particularly the United States)â€”aware of the islandâ€™s critical role in the semiconductor supply chainâ€”would retaliate economically, and perhaps militarily, if China were to attack Taiwan. That, in turn, deters Beijing. â€œBecause TSMC is now the most recognizable company of Taiwan, it has embedded itself in a notion of Taiwanâ€™s sovereignty,â€ says Rupert Hammond-Chambers, president of the US-Taiwan Business Council.&nbsp;





Now some Taiwan specialists and some of the islandâ€™s citiÂ­zens are worried that this â€œsilicon shield,â€ if it ever existed, is cracking. Facing pressure from Washington, TSMC is investing heavily in building out manufacturing capacity at its US hub in Arizona. It is also building facilities in Japan and Germany in addition to maintaining a factory in mainland China, where it has been producing less advanced legacy chips since 2016.&nbsp;



In Taiwan, there is a worry that expansion abroad will dilute the companyâ€™s power at home, making the US and other countries less inclined to feel Taiwan is worthy of defense. TSMCâ€™s investments in the US have come with no guarantees for Taiwan in return, and high-ranking members of Taiwanâ€™s opposition party have accused the ruling Democratic Progressive Party (DPP) of gambling with the future of the island. It doesnâ€™t help that TSMCâ€™s expansion abroad coincides with what many see as a worrying attitude in the White House. On top of his overarching â€œAmerica Firstâ€ philosophy, Donald Trump has declined to comment on the specific question of whether the US would intervene if China attempted to take Taiwan by force. â€œI donâ€™t want to ever put myself in that position,â€ he said in February.&nbsp;



At the same time, Beijingâ€™s interest in Taiwan has continued unabated. While China is making progress toward semiconductor self-Â­sufficiency, itâ€™s currently in a transition period, with companies relying on foreign-made chips manufactured in Taiwanâ€”some in compliance with export controls and some smuggled in. Meanwhile, the CCP persistently suggests that seizing the island would bring about a kind of family reunion. â€œIt is the common aspiration and sacred responsibility of all Chinese sons and daughters to realize the complete reunification of the motherland,â€ reads a statement released by the foreign ministry after Nancy Pelosiâ€™s controversial 2022 visit to Taiwan. Though itâ€™s impossible to know the full scope of Beijingâ€™s motivations, there is also obvious strategic appeal: Controlling the island would give China deep-water access, which is critical for naval routes and submarines. Plus, it could significantly disrupt American AI firmsâ€™ access to advanced chips.&nbsp;&nbsp;



While China ramps up militarily, Taiwan is trying to make itself hard to ignore. The government is increasingly portraying the island as strategically essential to the global community, with semiconductors as its primary offering. â€œThe international community must certainly do everything in its power to avoid a conflict in the Taiwan Strait; there is too great a cost,â€ Taiwanese president Lai Ching-te said in an interview earlier this year with Japanâ€™s Nippon Television.Â Parts of the international community are hearing that messageâ€”and seizing the opportunity it presents: earlier this month, defense tech company Anduril Industries announced it is opening a new office in Taiwan, where it will be expanding partnerships and selling autonomous munitions.Â 



For its part, the chip industry is actively showing its commitment to Taiwan. While other tech CEOs attended Trumpâ€™s second inauguration, for instance, Nvidia chief executive Jensen Huang met instead with TSMCâ€™s chairman, and the company announced in May that its overseas headquarters would be in Taipei. In recent years, US government officials have also started paying more attention to Taiwanâ€™s security situation and its interconnectedness with the chip industry. â€œThere was a moment when everybody started waking up to the dependence on TSMC,â€ says Bonnie Glaser, managing director of the German Marshall Fundâ€™s Indo-Pacific Program. The realization emerged, she says, over the last decade but was underscored in March of 2021, when Phil Davidson, then leader of the United States Indo-Pacific Command, testified to the Senate Armed Services Committee that there could be an invasion by 2027. Parallel to the security threat is the potential issue of overdependence, since so much chipmaking capability is concentrated in Taiwan.



For now, Taiwan is facing a tangle of interests and time frames. China presents its claim to Taiwan as a historical inevitability, albeit one with an uncertain timeline, while the United Statesâ€™ relationship with the island is focused on an AI-driven future. But from Taiwanâ€™s perspective, the fight for its fate is playing out right now, amid unprecedented geopolitical instability. The next few years will likely determine whether TSMCâ€™s chipmaking dominance is enough to convince the world Taiwan is worth protecting.



Innovation built on interconnectivity&nbsp;



TSMC is an uncontested success story. Its founder, Morris Chang, studied and worked in the United States before he was lured to Taiwan to start a new business on the promise of state support and inexpensive yet qualified labor. Chang founded TSMC in 1987 on the basis of his innovative business model. Rather than design and produce chips in-house, as was the norm, TSMC would act as a foundry: Clients would design the chips, and TSMC would make them.&nbsp;



This focus on manufacturing allowed TSMC to optimize its operations, building up process knowledge and, eventually, outperforming competitors like Intel. It also freed up other businesses to go â€œfabless,â€ meaning they could stop maintaining their own semiconductor factories, or fabs, and throw their resources behind other parts of the chipmaking enterprise. Tapping into Taiwanâ€™s domestic electronics supply chain proved effective and efficient for TSMC. Throughout the 1990s and early 2000s, global demand for semiconductors powering personal computers and other devices continued to grow. TSMC thrived.



Then, in 2022, the US imposed export controls on China that restricted its access to advanced chips. Taiwan was forced to either comply, by cutting off Chinese clients, or risk losing the support of the country that was home to 70% of its client baseâ€”and, possibly, 100% of its hopes for external military support in the event of an attack.&nbsp;



Soon after, Chang announced that he believed globalization and free markets were â€œalmost dead.â€ The nearly three years since have shown he was onto something. For one thing, in contrast to President Bidenâ€™s pursuit of supply chain integration with democratic allies, President Trumpâ€™s foreign policy is characterized by respect for big, undemocratic powers and punitive tariffs against both Americaâ€™s rivals and its friends. Trump has largely abandoned Bidenâ€™s economic diplomacy with European and Asian allies but kept his China-targeted protectionismâ€”and added his trademark transactionalism. In an unprecedented move earlier this month, the administration allowed Nvidia and AMD to sell previously banned chips to China on the condition that the companies pay the government 15% of revenues made from China sales.Â 





Protectionism, it turns out, spurs self-reliance. Chinaâ€™s government has been making a massive effort to build up its domestic chip production capabilitiesâ€”a goal that was identified at the beginning of Xiâ€™s rise but has been turbocharged in the wake of Washingtonâ€™s export controls.&nbsp;



Any hope the US has for significantly expanding domestic chip production comes from its friendsâ€”TSMC first among them. The semiconductor industry developed as a global endeavor out of practicality, playing to the strengths of each region: design in the US and manufacturing in Asia, with key inputs from Europe central to the process. Yet the US government, entrenched in its â€œtech warâ€ with China, is now dead set on deglobalizing the chip supply chain, or at least onshoring as much of it as possible. Thereâ€™s just one hiccup: The best chip manufacturer isnâ€™t American. Itâ€™s TSMC. Even if some manufacturing happens in Arizona, the US still relies on Taiwanâ€™s chipmaking ecosystem. And copying that supply chain outside Taiwan could be harder than the current administration imagines.



Squarely in the middle



Taiwanâ€™s modern security uncertainties stem from the long-Â­contested issue of the islandâ€™s sovereignty. After losing the first Sino-Japanese War in the late 1800s, the Qing dynasty forfeited Taiwan to Japanese imperial control. It was Japanâ€™s â€œmodel colonyâ€ until 1945, when postwar negotiations resulted in its transfer to the Republic of China under Chiang Kai-shek of the Nationalist Party, known as the KMT. The insurgent CCP under Mao Zedong ultimately defeated the Nationalists in a civil war fought on the mainland until 1949. Chiang and many of his partyâ€™s defeated generals decamped to Taiwan, controlling it under martial law for nearly 40 years.&nbsp;



Taiwan held its first free democratic elections in 1996, kicking off a two-party rivalry between the KMT, which favors closer relations with Beijing, and the DPP, which opposes integration with China. Kitchen-table issues like economic growth are central to Taiwanese elections, but so is the overarching question of how best to handle the threat of invasion, which has persisted for nearly 80 years. The DPP is increasingly calling for raising defense spending and civilian preparedness to make sure Taiwan is ready for the worst, while the KMT supports direct talks with Beijing.&nbsp;&nbsp;



In March 2025, President Trump and TSMC CEO C.C. Wei jointly announced that the firm will make an additional $100 billion investment (on top of a previously announced $65 billion) in TSMCâ€™s US hub in Arizona.REBECCA NOBLE/BLOOMBERG VIA GETTY IMAGES




Meanwhile, Chinese military incursions around Taiwanâ€”known as â€œgray zoneâ€ tactics because they fall short of acts of warâ€”are increasingly frequent. In May, Taiwanâ€™s defense ministry reportedly estimated that Chinese warplanes were entering Taiwanâ€™s air defense zone more than 200 times a month, up from fewer than 10 times per month five years ago. China has conducted drills mirroring the actions needed for a full-scale invasion or a blockade, which would cut Taiwan off from the outside world. Chinese military officials are now publicly talking about achieving a blockade, says Lyle Morris, an expert on foreign policy and national security at the Asia Society Policy Institute. â€œTheyâ€™re punishing Lai and the DPP,â€ Morris says. Meanwhile, the CCP has its own people to answer to: When it comes to the Taiwan issue, Morris says, â€œBeijing is probably quite worried about the people of China being upset if they arenâ€™t hawkish enough or if they come out looking weak.â€ Indeed, in response to Laiâ€™s recent policy statements, including one declaring that China is a â€œhostile foreign force,â€ Gao Zhikai, a prominent scholar in China who opposes Taiwanese independence, recently wrote, â€œThe reunification with the motherland cannot be endlessly delayed. Decisive action must be taken.â€&nbsp;



Intimidation from China has made some ordinary Taiwanese citizens more concerned; according to a recent poll conducted by a defense-focused think tank, 51% think defense spending should be increased (although 65% of respondents said they thought an attack within five years was â€œunlikelyâ€). No matter how much money Taipei spends, the sheer military imbalance between China and Taiwan means Taiwan would need help. But especially in the wake of Ukraineâ€™s experience, many believe US aid would be contingent on whether Taiwan demonstrates the will to defend itself. â€œBased on war games, Taiwan would have to hold out for a month before the US could potentially intervene,â€ says Iris Shaw, director of the DPP mission in the US. And support from Taiwanâ€™s neighbors like Japan might be contingent on US involvement.



But how likely is the US to intervene in such a scenario?&nbsp;The author Craig Addison popularized the argument that Taiwanâ€™s fate is tied to its chip production prowess in his 2001 book Silicon Shield: Taiwanâ€™s Protection Against Chinese Attack. Back then, Addison wrote that although the US had been intentionally vague about whether it would go to war to protect the island, Americaâ€™s technological reliance on â€œa safe and productive Taiwanâ€ made it highly probable that Washington would intervene. President Joe Biden deviated from those decades of calculated ambiguity by asserting multiple times that America would defend the island in the event of an attack. Yet now, Trump seems to have taken the opposite position, possibly presenting an opportunity for Beijing.&nbsp;



TSMC in the Trump era&nbsp;



In many ways, Taiwan finds itself in a catch-22. It feels the need to cozy up to the US for protection, yet that defensive maneuver is arguably risky in itself. Itâ€™s a common belief in Taiwan that forging stronger ties to the US could be dangerous. According to a public opinion poll released in January, 34.7% of Taiwanese believe that a â€œpro-USâ€ policy provokes China and will cause a war.&nbsp;



But the Lai administrationâ€™s foreign policy is â€œinexorably intertwined with the notion that a strong relationship with the US is essential,â€ says Hammond-Chambers.



Bolstering US support may not be the only reason TSMC is building fabs outside Taiwan. As the company readily points out, the majority of its customers are American. TSMC is also responding to its home baseâ€™s increasingly apparent land and energy limitations: finding land to build new fabs sometimes causes rifts with Taiwanese people who, for example, donâ€™t want their temples and ancestral burial sites repurposed as science parks. Taiwan also relies on imports to meet more than 95% of its energy needs, and the dominant DPP has pledged to phase out nuclear, Taiwanâ€™s most viable yet most hotly contested renewable energy source. Geopolitical tensions compound these physical restraints: Even if TSMC would never say as much, itâ€™s fairly likely that if China did attack Taiwan, the firm would rather remain operational in other countries than be wiped out completely.&nbsp;



However, building out TSMCâ€™s manufacturing capabilities outside Taiwan will not be easy. â€œThe ecosystem they created is truly unique. Itâ€™s a function of the talent pipeline, the culture, and laws in Taiwan; you canâ€™t easily replicate it anywhere,â€ says Glaser. TSMC has 2,500 Taiwan-based suppliers. Plenty are within a couple of hoursâ€™ drive or an even shorter trip on high-speed rail. Taiwan has built a fully operational chip cluster, the product of four decades of innovation, industrial policy, and labor.




In many ways, Taiwan finds itself in a catch-22. It feels the need to cozy up to the US for protection, yet that defensive maneuver is arguably risky in itself.




As a result, itâ€™s unclear whether TSMC will be able to copy its model and paste it into the suburbs of Phoenix, where it has 3,000 employees working on chip manufacturing. â€œPutting aside the geopolitical factor, they wouldnâ€™t have expanded abroad,â€ says Feifei Hung, a researcher at the Asia Society. Rather than standalone facilities, the Arizona fabs are â€œappendages of TSMC that happen to be in Arizona,â€ says Paul Triolo, partner and tech policy lead at the international consulting firm DGA-Albright Stonebridge Group. When the full complex is operational, it will represent only a small percentage of TSMCâ€™s overall capacity, most of which will remain in Taiwan. Triolo doubts the US buildout will yield results similar to what TSMC has built there: â€œArizona ainâ€™t that yet, and never will be.â€&nbsp;



Still, the second Trump administration has placed even more pressure on the company to â€œfriendshoreâ€â€”without providing any discernible signs of friendship. During this springâ€™s tariff frenzy, the administration threatened to hit Taiwan with a 32% â€œreciprocalâ€ tariff, a move that was then paused and revived at 20% in late July (and was still being negotiated as of press time). The administration has also announced a 100% tariff on semiconductor imports, with the caveat that companies with US-based production, like TSMC, are exemptâ€”though itâ€™s unclear whether imports from critical suppliers in Taiwan will be tariffed. And the threat of a chip-specific tariff remains. â€œThis is in line with [Trumpâ€™s] rhetoric of restoring manufacturing in the US and using tariffs as a one size fits all tool to force it,â€ says Nancy Wei, a trade and supply chain analyst at the Eurasia Group. The US is also apparently considering levying a $1 billion fine against TSMC after TSMC-made chips were reportedly found in some Huawei devices. 



Despite these kinds of maneuvers, TSMC has been steadfast in its attempts to get on Washingtonâ€™s good side. In March, Trump and TSMCâ€™s CEO, C.C. Wei, jointly announced that the firm will make an additional $100 billion investment (on top of a previously announced $65 billion) in TSMCâ€™s US hub in Arizona. The pledge represents the largest single source of foreign direct investment into the US, ever. While the deal was negotiated during Bidenâ€™s term, Trump was happy to take credit for ensuring that â€œthe most powerful AI chips will be made right here in America.â€Â 





The Arizona buildout will also include an R&amp;D facilityâ€”a critical element for tech transfer and intellectual-property development. Then thereâ€™s the very juicy cherry on top: TSMC announced in April that once all six new fabs are operational, 30% of its most advanced chips will be produced in Arizona. Up until then, the thinking was that US-based production would remain a generation or two behind. It looks as if the administrationâ€™s public and, presumably, private arm-twisting has paid off.&nbsp;



Meanwhile, as Trump cuts government programs and subsidies while demanding the â€œreturnâ€ of manufacturing to the US, itâ€™s TSMC that is running a technician apprenticeship program in Arizona to create good American jobs. TSMCâ€™s leaders, Triolo says, must question how serious the Trump administration is about long-term industrial policy. Theyâ€™re probably asking themselves, he says, â€œDo they understand what it takes to support the semiconductor industry, like our government does?â€&nbsp;



Dealing with an administration that is so explicitly â€œAmerica firstâ€ represents â€œone of the biggest challenges in history for Taiwanese companies,â€ says Thung-Hong Lin, a sociology researcher at the Taipei-based Academia Sinica. Semiconductor manufacturing relies on reliability. Trump has so far offered TSMC no additional incentives supporting its US expansionâ€”and started a trade war that has directly affected the semiconductor industry, partly by introducing irrevocable uncertainty. â€œTrumpâ€™s tariffs have set off a new, more intensified bifurcation of semiconductor supply chains,â€ says Chris Miller, author of Chip War. For now, Miller says, TSMC must navigate a world in which the US and China are both intense competitors and, despite trade restrictions, important clients.&nbsp;



Warring narratives



China has been taking advantage of these changes to wage a war of disinformation. In response to Nancy Pelosiâ€™s visit to Taiwan in 2022, when she was US Speaker of the House, Beijing sent warships, aircraft, and propaganda across the Taiwan Strait. Hackers using Chinese software infiltrated the display screens in Taiwanâ€™s 7-Eleven stores to display messages telling â€œwarmonger Pelosiâ€ to â€œget out of Taiwan.â€ That might not be an act of war, but itâ€™s close; â€œ7â€ is an institution of daily life on the island. It is not difficult to imagine how a similar tactic might be used to spread more devastating disinformation, falsely alleging, for example, that Taiwanâ€™s military has surrendered to China during a future crisis.&nbsp;



Taiwan is â€œperpetually on the front linesâ€ of cyberattacks from China, says Francesca Chen, a cybersecurity systems analyst at Taiwanâ€™s Ministry of Digital Affairs. According to Taiwanâ€™s National Security Bureau, instances of propaganda traceable to China grew by 60% in 2024 over the previous year, reaching 2.16 million.&nbsp;



Visitors take selfies outside the TSMC Museum of Innovation in Hsinchu, Taiwan.ANNABELLE CHIH/GETTY IMAGES




Over the last few years, online discussion of TSMCâ€™s investments in the US â€œhas become a focal pointâ€ of Chinaâ€™s state-Â­sponsored disinformation campaigns aimed at Taiwan, Chen says. They claim TSMC is transferring its most advanced technology, talent, and resources to the US, â€œweakening Taiwanâ€™s economic lifeline and critical position in global supply chains.â€ Key terms include â€œhollowing out Taiwanâ€ and â€œde-Taiwanization.â€ This framing depicts TSMCâ€™s diversification as a symbol of Taiwanâ€™s vulnerability, Chen says. The idea is to exploit real domestic debates in Taiwan to generate heightened levels of internal division, weakening social cohesion and undermining trust in the government.



Chinese officials havenâ€™t been shy about echoing these messages out in the open: After the most recent US investment announcement in March, a spokesperson from Chinaâ€™s Taiwan Affairs Council accused Taiwanâ€™s DPP of handing over TSMC as a â€œgiftâ€ to the US. (â€œTSMC turning into USMC?â€ asked a state media headline.) Former Taiwanese president Ma Ying-jeou posted an eerily similar criticism, alleging that TSMCâ€™s US expansion amounted to â€œsellingâ€ the chipmaker in exchange for protection.



TSMCâ€™s expansion abroad could become a major issue in Taiwanâ€™s 2028 presidential election. It plays directly into party politics: The KMT can accuse the DPP of sacrificing Taiwanâ€™s technology assets to placate the US, and the DPP can accuse the KMT of cozying up with China, even as Beijingâ€™s military incursions become a more evident part of daily life. It remains to be seen whether TSMCâ€™s shift to the US will ultimately protect or weaken Taiwanâ€”or have no effect on the islandâ€™s security and sovereignty. For now at least, Chinaâ€™s aspirations loom large.&nbsp;



To Beijing, unequivocally, Taiwan does not equal TSMC. Instead, it represents the final, unfulfilled stage of the Communist Partyâ€™s revolutionary struggle. Framed that way, Chinaâ€™s resolve to take the island could very well be nonnegotiable. That would mean if Taiwan is going to maintain a shield that protects it from the full weight of Chinaâ€™s political orthodoxy, it may need to be made of something much stronger than silicon.Â 



Johanna M. Costigan is a writer and editor focused on technology and geopolitics in the US, China, and Taiwan. She writes the newsletter The Long Game.
â€¢ Why US federal health agencies are abandoning mRNA vaccines
  This time five years ago, we were in the throes of the covid-19 pandemic. By August 2020, weâ€™d seen school closures, national lockdowns, and widespread panic. That year, the coronavirusÂ was responsible for around 3 million deaths, according to the World Health Organization.



Then came the vaccines. The first mRNA vaccines for covid were authorized for use in December 2020. By the end of the following month, over 100 million doses had been administered.Â Billions more have been administered since then. The vaccines worked well and are thought to have saved millions of lives.





The US government played an important role in the introduction of these vaccines, providing $18 billion to support their development as part of Operation Warp Speed.



But now, that government is turning its back on the technology. Funding is being withdrawn. Partnerships are being canceled. Leaders of US health agencies are casting doubt on the vaccinesâ€™ effectiveness and safety. And this week, the director of the National Institutes of Health implied that the reversal was due to a lack of public trust in the technology.



Plenty of claims are being thrown about. Letâ€™s consider the evidence.



mRNA is a molecule found in cells that essentially helps DNA make proteins. The vaccines work in a similar way, except they carry genetic instructions for proteins found on the surface of the coronavirus. This can help train our immune systems to tackle the virus itself.



Research into mRNA vaccines has been underway for decades. But things really kicked into gear when the virus behind covid-19 triggered a pandemic in 2020. A huge international effortâ€”along with plenty of fundingâ€”fast-tracked research and development.



The genetic code for the Sars-CoV-2 virus was sequenced in January 2020. The first vaccines were being administered by the end of that year. Thatâ€™s wildly fast by pharma standardsâ€”drugs can typically spend around a decade in development.



And they seemed to work really well. Early trials in tens of thousands of volunteers suggested that Pfizer and BioNTechâ€™s vaccine conferred â€œ95% protection against covid-19.â€ No vaccine is perfect, but for a disease that was responsible for millions of deaths, the figures were impressive.



Still, there were naysayers. Including Robert F. Kennedy Jr., the notorious antivaccine activist who currently leads the USâ€™s health agencies. HeÂ has called covid vaccines â€œunsafe and ineffective.â€ In 2021, heÂ petitioned the US Food and Drug Administration to revoke the authorization for covid vaccines. That same year, Instagram removed his account from the platformÂ after he repeatedly shared â€œdebunked claims about the coronavirus or vaccines.â€





So perhaps we shouldnâ€™t have been surprised when the US Department of Health and Human Services, which RFK Jr. now heads,Â announced â€œthe beginning of a coordinated wind-downâ€ of mRNA vaccine development earlier this month. HHS is canceling almost $500 million worth of funding for the technology. â€œThe data show these vaccines fail to protect effectively against upper respiratory infections like covid and flu,â€ Kennedy said inÂ a statement.



Well, as weâ€™ve seen, the mRNA covid vaccines were hugely effective during the pandemic. And researchers are working on other mRNA vaccines for infections including flu. Our current flu vaccines arenâ€™t idealâ€”they are produced slowly in a process that requires henâ€™s eggs, based on predictions about which flu strains are likely to be prominent in the winter. Theyâ€™re not all that protective.



mRNA vaccines, on the other hand, can be made quickly and cheaply, perhaps once we already know which flu strains we need to protect against. And scientists are making progress withÂ universal flu vaccinesâ€”drugs that could potentially protect against multiple flu strains.



Kennedyâ€™s other claim is that the vaccines arenâ€™t safe. There have certainly been reports of adverse events. Usually these are mild and short-livedâ€”most people will be familiar with the fatigue and flu-like symptoms that can follow a covid jab. But some are more serious: Some people have developed neurological and cardiovascular conditions.Â 



These problems are rare, according to anÂ evaluation of adverse outcomes in almost 100 million people who received covid vaccines. Most studies of mRNA vaccines havenâ€™t reported an increase in the risk of Guillain-BarrÃ© syndrome, a condition that affects nerves and has been linked to covid vaccines.



Covid vaccines can increase the risk of myocarditis and pericarditis in young men. But the picture isnâ€™t straightforward. Vaccinated individuals appear to have double the risk of myocarditis compared with unvaccinated people. But the overall risk is still low. And itâ€™s still not as high asÂ the risk of myocarditis following a covid infection.



And then there are the claims that mRNA vaccines donâ€™t have the support of the public. Thatâ€™s what Jay Bhattacharya, director of the NIH, wrote inÂ an opinion piece published in the Washington Post on Wednesday.



â€œNo matter how elegant the science, a platform that lacks credibility among the people it seeks to protect cannot fulfill its public health mission,â€ Bhattacharya wrote. He blamed the Biden administration, which he wrote â€œdid not manage public trust in the coronavirus vaccines.â€



Itâ€™s an interesting take from someone who played a pretty significant role in undermining public trust in covid policies, including vaccine mandates. In 2020, Bhattacharya coauthored the Great Barrington Declarationâ€”an open letter making the case against lockdowns. He became a vocal critic of US health agencies, including the NIH, and their handling of the outbreak. Unlike Kennedy, Bhattacharya hasnâ€™t called the vaccines unsafe or ineffective. But heÂ has called vaccine mandates â€œunethical.â€



Curiously, the US government doesnâ€™t seem to be turning away from all vaccine research. Just work on mRNA vaccines. Some of the funding budget originally earmarked for covid vaccines will be redirected to two senior staffers at the NIH who are exploring the use of an old vaccine technology that makes use of inactivated virusesâ€”a move thatÂ researchers are describing as â€œtroublingâ€ and â€œappalling,â€ according to reporting by Science.



Not all mRNA research is being abandoned, either. Bhattacharya has expressed his support for research into the use of mRNA-based treatments for cancer.Â Such â€œvaccine therapeuticsâ€ were being explored before covid came along. (Notably, Bhattacharya isnâ€™t referring to them as â€œvaccines.â€)



It is difficult to predict how this will all shake out for mRNA vaccines. We mustnâ€™t forget that this technology helped save millions of lives and shows huge promise for the development of cheap, effective, and potentially universal vaccines. Letâ€™s hope that the recent upsets wonâ€™t prevent it from achieving its potential.



This article first appeared in The Checkup,Â MIT Technology Reviewâ€™sÂ weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,Â sign up here.
â€¢ The Download: affordable EV trucks, and Russiaâ€™s latest internet block
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



The US could really use an affordable electric truck



On Monday, Ford announced plans for an affordable electric truck with a 2027 delivery date and an expected price tag of about $30,000, thanks in part to a new manufacturing process that it says will help cut costs.This could be the shot in the arm that the slowing US EV market needs. If anything can get Americans excited, itâ€™s a truck, especially an affordable one.



However, there are some significant hurdles in the way. EV sales are slowing, and Ford in particular has struggled recently. The adoption barriers also continue to mount, with the Trump administration cutting tax credits as well as rules designed to push automakers toward zero-emissions vehicles. And thatâ€™s not to mention tariffs. Can Ford really deliver on its promises?



â€”Casey Crownhart



This article is from The Spark, MIT Technology Reviewâ€™s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.



To read more of our EV coverage, why not check out:



+ Chinaâ€™s EV giants are betting big on humanoid robots. Their technical know-how and existing supply chains could give them a significant head start in the sector. Read the full story.



+ Why bigger EVs arenâ€™t always better. The world is moving toward larger vehicles, and EVs are following the trend.+ Some countries are ending support for EVs. Is it too soon? Read the full story.+ Three frequently asked questions about EVs, answered.







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 Russia has cracked down on WhatsApp and TelegramÂ Calls for millions of people have been restricted. (WP $)+ Russian officials accused the platforms of failing to share â€˜terror-relatedâ€™ data. (The Guardian)+ Itâ€™s just the latest in its attempts to exert greater control over the internet. (AP News)



2 The US Navy and Air Force is considering axing two costly HR software projectsAnd give Salesforce or Palantir the chance to bid for new ones. (Reuters)



3 How much has DOGE actually saved US taxpayers?Â A whole lot less than it initially claimed, a new analysis has found. (Politico)+ A former DOGE worker has returned to the Trump administration. (Semafor)+ DOGEâ€™s tech takeover threatens the safety and stability of our critical data. (MIT Technology Review)



4 DeepSeek has pushed back the release of its next modelTraining it using Huaweiâ€™s AI chips has proved too difficult. (FT $)+ How DeepSeek ripped up the AI playbook. (MIT Technology Review)



5 No country is safe from climate changeEven traditionally cool Nordic countries are struggling to cope with the heat. (The Guardian)+ Temperatures rose in the nations by at least two degrees celsius. (Politico)+ The greenhouse gases weâ€™re not accounting for. (MIT Technology Review)



6 Meta is hemorrhaging top talentDespite Mark Zuckerbergâ€™s mad AI hiring tear. (Forbes $)+ Itâ€™s causing major tensions among its existing AI researchers. (Insider $)



7 Tesla is hiring someone to test its robotaxi tech in NYCIt suggests a future expansion into the busy city is imminent. (Bloomberg $)+ True to form, it hasnâ€™t applied for any permits yet, though. (CNBC)



8 Laborers are livestreaming themselves doing menial tasksItâ€™s a reminder of the physical work that still makes the world go round. (NYT $)



9 The rise of the AI coworker I bet after-work drinks are a right laugh. (Insider $)



10 Meet the â€˜clippersâ€™ taking over social mediaTheyâ€™re in charge of those infuriating brief clips flooding your feeds. (WSJ $)







Quote of the day



â€œThese guys just want to build things and make money and so does Trump.â€



â€”Cooper Teboe, a Silicon Valley-based Democratic adviser, believes that tech entrepreneurs and the US President share similar goals, he tells the Wall Street Journal.







One more thing







How environmental DNA is giving scientists a new way to understand our worldEnvironmental DNA is a relatively inexpensive, widespread, potentially automated way to observe the diversity and distribution of life.Unlike previous techniques, which could identify DNA from, say, a single organism, the method also collects the swirling cloud of other genetic material that surrounds it. It can serve as a surveillance tool, offering researchers a means of detecting the seemingly undetectable.By sampling eDNA, or mixtures of genetic material in water, soil, ice cores, cotton swabs, or practically any environment imaginable, even thin air, it is now possible to search for a specific organism or assemble a snapshot of all the organisms in a given place.It offers a thrilling â€” and potentially chilling â€” way to collect information about organisms, including humans, as they go about their everyday business. Read the full story.



â€”Peter Andrey Smith







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ This weekâ€™s Perseid meteor shower did not disappointâ€”the pictures are spectacular.+ Elephants know what they want, and itâ€™s tasty treats + Why itâ€™s high time to decorate your kitchen and bathroom.+ Whatâ€™s in David Byrneâ€™s bag? Itâ€™s time to find out.
â€¢ The US could really use an affordable electric truck
  On Monday, Ford announced plans for an affordable electric truck with a 2027 delivery date and an expected price tag of about $30,000, thanks in part to a new manufacturing process that it says will help cut costs.



This could be the shot in the arm that the slowing US EV market needs. Sales are slowing, and Ford in particular has struggled recentlyâ€”the automaker has lost $12 billion over the last two and a half years on its EV division. And the adoption barriers continue to mount, with the Trump administration cutting tax credits as well as rules designed to push automakers toward zero-emissions vehicles. And thatâ€™s not to mention tariffs.



But if anything can get Americans excited, itâ€™s a truck, especially an affordable one. (There was a ton of buzz over the announcement of a bare-bones truck from Bezos-backed Slate Auto earlier this year, for example.) The big question is whether the company can deliver in this environment.



One key thing to note here: This is not the first time that thereâ€™s been a big splashy truck announcement from Ford that was supposed to change everything. The F-150 Lightning was hailed as a turning point for vehicle electrification, a signal that decarbonization had entered a new era. We cited the truck when we put â€œThe Inevitable EVâ€ on our 10 Breakthrough Technologies list in 2023.Â 



Things havenâ€™t quite turned out that way. One problem is that the Lightning was supposed to be relatively affordable, with a price tag of about $40,000 when it was first announced in 2021. The starting price inflated to $52,000 when it actually went on sale in 2022.



The truck was initially popular and became quite hard to find at dealerships. But prices climbed and interest leveled off. The base model hit nearly $60,000 by 2023. For the past few years, Ford has cut Lightning production several times and laid off employees who assembled the trucks.



Now, though, Ford is once again promising an affordable truck, and itâ€™s supposed to be even cheaper this time. To help cut costs, the company says itâ€™s simplifying, creating one universal platform for a new set of EVs. Using a common structure and set of components will help produce not only a midsize truck but also other trucks, vans, and SUVs. There are also planned changes to the manufacturing process (rather than one assembly line, multiple lines will join together to form what theyâ€™re calling an assembly tree).&nbsp;





Another supporting factor for cost savings is the battery. The company plans to use lithium-iron phosphate (or LFP) cellsâ€”a type of lithium-ion battery that doesnâ€™t contain nickel or cobalt. Leaving out those relatively pricey metals means lower costs.



Side note here: That battery could be surprisingly small. In a media briefing, a Ford official reportedly said that the truckâ€™s battery would be 15% smaller than the one in the Atto crossover from the Chinese automaker BYD. Since that model has a roughly 60-kilowatt-hour pack, that could put this new battery at 51 kilowatt-hours. Thatâ€™s only half the capacity of the Ford Lightningâ€™s battery and similar to the smallest pack offered in a Tesla Model 3 today. (This could mean the truck has a relatively limited range, though the company hasnâ€™t shared any details on that front yet.)Â 



A string of big promises isnâ€™t too unusual for a big company announcement. What was unusual was the tone from officials during the event on Monday.



As Andrew Hawkins pointed out in The Verge this week, â€œFord seems to realize its timing is unfortunate.â€ During the announcement, executives emphasized that this was a bet, one that might not work out.



CEO Jim Farley put it bluntly: â€œThe automotive industry has a graveyard littered with affordable vehicles that were launched in our country with all good intentions, and they fizzled out with idle plants, laid-off workers, and red ink.â€ Woof.



From where Iâ€™m standing, itâ€™s hard to be optimistic that this announcement will turn out differently from all those failed ones, given where the US EV market is right now.&nbsp;&nbsp;&nbsp;



In a new report published in June, the energy consultancy BNEF slashed its predictions for future EV uptake. Last year, the organization predicted that 48% of new vehicles sold in the US in 2030 would be electric. In this yearâ€™s edition, that number got bumped down to just 27%.



To be clear: BNEF and other organizations are still expecting more EVs on the roads in the future than today, since the vehicles make up less than 10% of new sales in the US. But expectations are way down, in part because of a broad cut in public support for EVs.&nbsp;



The tax credits that gave drivers up to $7,500 off the purchase of a new EV end in just over a month. Tariffs are going to push costs up even for domestic automakers like Ford, which still rely on imported steel and aluminum.



A revamped manufacturing process and a cheaper, desirable vehicle could be exactly the sort of move that automakers need to make for the US EV market. But Iâ€™m skeptical that this truck will be able to turn it all around.&nbsp;



This article is from The Spark, MIT Technology Reviewâ€™s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.

ğŸ”’ Cybersecurity & Privacy
â€¢ Microsoft Patch Tuesday, August 2025 Edition
  Microsoft today released updates to fix more than 100 security flaws in its Windows operating systems and other software. At least 13 of the bugs received Microsoft&#8217;s most-dire &#8220;critical&#8221; rating, meaning they could be abused by malware or malcontents to gain remote access to a Windows system with little or no help from users.

August&#8217;s patch batch from Redmond includes an update for CVE-2025-53786, a vulnerability that allows an attacker to pivot from a compromised Microsoft Exchange Server directly into an organization&#8217;s cloud environment, potentially gaining control over Exchange Online and other connected Microsoft Office 365 services. Microsoft first warned about this bug on Aug. 6, saying it affects Exchange Server 2016 and Exchange Server 2019, as well as its flagship Exchange Server Subscription Edition.
Ben McCarthy, lead cyber security engineer at Immersive, said a rough search reveals approximately 29,000 Exchange servers publicly facing on the internet that are vulnerable to this issue, with many of them likely to have even older vulnerabilities.
McCarthy said the fix for CVE-2025-53786 requires more than just installing a patch, such as following Microsoft&#8217;s manual instructions for creating a dedicated service to oversee and lock down the hybrid connection.
&#8220;In effect, this vulnerability turns a significant on-premise Exchange breach into a full-blown, difficult-to-detect cloud compromise with effectively living off the land techniques which are always harder to detect for defensive teams,&#8221; McCarthy said.
CVE-2025-53779 is a weakness in the Windows Kerberos authentication system that allows an unauthenticated attacker to gain domain administrator privileges. Microsoft credits the discovery of the flaw to Akamai researcher Yuval Gordon, who dubbed it &#8220;BadSuccessor&#8221; in a May 2025 blog post. The attack exploits a weakness in &#8220;delegated Managed Service Account&#8221; or dMSA &#8212; a feature that was introduced in Windows Server 2025.
Some of the critical flaws addressed this month with the highest severity (between 9.0 and 9.9 CVSS scores) include a remote code execution bug in the Windows GDI+ component that handles graphics rendering (CVE-2025-53766) and CVE-2025-50165, another graphics rendering weakness. Another critical patch involves CVE-2025-53733, a vulnerability in Microsoft Word that can be exploited without user interaction and triggered through the Preview Pane.
One final critical bug tackled this month deserves attention: CVE-2025-53778, a bug in Windows NTLM, a core function of how Windows systems handle network authentication. According to Microsoft, the flaw could allow an attacker with low-level network access and basic user privileges to exploit NTLM and elevate to SYSTEM-level access â€” the highest level of privilege in Windows. Microsoft rates the exploitation of this bug as &#8220;more likely,&#8221; although there is no evidence the vulnerability is being exploited at the moment.
Feel free to holler in the comments if you experience problems installing any of these updates. As ever, the SANS Internet Storm Center has its useful breakdown of the Microsoft patches indexed by severity and CVSS score, and AskWoody.com is keeping an eye out for Windows patches that may cause problems for enterprises and end users.
GOOD MIGRATIONS
Windows 10 users out there likely have noticed by now that Microsoft really wants you to upgrade to Windows 11. The reason is that after the Patch Tuesday on October 14, 2025, Microsoft will stop shipping free security updates for Windows 10 computers. The trouble is, many PCs running Windows 10 do not meet the hardware specifications required to install Windows 11Â (or they do, but just barely).
If the experience with Windows XP is any indicator, many of these older computers will wind up in landfills or else will be left running in an unpatched state. But if your Windows 10 PC doesn&#8217;t have the hardware chops to run Windows 11 and you&#8217;d still like to get some use out of it safely, consider installing a newbie-friendly version of Linux, like Linux Mint.
Like most modern Linux versions, Mint will run on anything with a 64-bit CPU that has at least 2GB of memory, although 4GB is recommended. In other words, it will run on almost any computer produced in the last decade.
There are many versions of Linux available, but Linux Mint is likely to be the most intuitive interface for regular Windows users, and it is largely configurable without any fuss at the text-only command-line prompt. Mint and other flavors of Linux come with LibreOffice, which is an open source suite of tools that includes applications similar to Microsoft Office, and it can open, edit and save documents as Microsoft Office files.
If you&#8217;d prefer to give Linux a test drive before installing it on a Windows PC, you can always just download it to a removable USB drive. From there, reboot the computer (with the removable drive plugged in) and select the option at startup to run the operating system from the external USB drive. If you don&#8217;t see an option for that after restarting, try restarting again and hitting the F8 button, which should open a list of bootable drives. Here&#8217;s a fairly thorough tutorial that walks through exactly how to do all this.
And if this is your first time trying out Linux, relax and have fun: The nice thing about a &#8220;live&#8221; version of Linux (as it&#8217;s called when the operating system is run from a removable drive such as a CD or a USB stick) is that none of your changes persist after a reboot. Even if you somehow manage to break something, a restart will return the system back to its original state.

ğŸ“ University AI
No updates.

ğŸ¢ Corporate AI
â€¢ Dion: the distributed orthonormal update revolution is here
  Training AI models requires choosing an optimizer and for nearly a decade, Adam( (opens in new tab)&#8211;W) (opens in new tab) has been the optimizer of choice. Given that durability and success, it was fair to doubt that any further improvement was possible. And yet, last December, a new optimizer called Muon (opens in new tab) showed serious promise by powering a nanoGPT speedrun (opens in new tab). This proved out, with multiple AI labs (e.g., Kimi-AI (opens in new tab) and Essential-AI (opens in new tab)) reporting 2x scale improvements and the release of the 1T parameter Kimi K2 (opens in new tab) model.&nbsp;Restated: you can train a model to similar performance with half as many GPUs.



Thereâ€™s one fly in the ointment: Muon requires large matrix multiplications in the optimizer, which requires heavy communication in large models at the scale where FSDP and TP parallelization becomes desirable.&nbsp;Going back to the inspiration for Muon, the key idea is an orthonormal update, which sparked the search&nbsp;for more scalable alternative linear algebras realizing the same goal. Thatâ€™s exactly what Dion is. We have open-sourced this new optimizer to enable anyone to train large models more efficiently at scale. &nbsp;



Whatâ€™s an orthonormal update?



Figure1. Illustration of matrix parameters



At the core of Transformers, a set of input activations is multiplied by a learned weight matrix to produce a new set of output activations. When the weight matrix is updated during training, the resulting change in the output activations generally depends on the direction of the input activations. As a result, the learning rate must be chosen conservatively to accommodate the input direction that induces the largest change. Orthonormalized updates alter this behavior by (approximately) making the change in output activations invariant to the direction of the input. This is achieved by enforcing orthonormality (opens in new tab) on the update matrix, thereby equalizing its effect across all input directions.



What is Dion?



While Muon has shown strong empirical results, scaling it to very large models poses challenges. As reported by Essential AI (opens in new tab), applying Muon to large architectures like LLaMA-3 becomes compute-boundâ€”and potentially communication-boundâ€”due to the cost of the Newtonâ€“Schulz orthonormalization steps (opens in new tab).



Figure 2. Pseudocode of the centralized version of Dion



This is where Dion enters. At a high level, Dion introduces a new axis for scalability: the rank. Specifically, for a given rank r, Dion orthonormalizes only the top r of the singular vector space, reducing communication and compute overhead while preserving performance.&nbsp;Empirically, we observe that the necessary rank for good performance grows much more slowly than the number of parameters in larger models.




	
		
						Download
			
				Dion optimizer&nbsp;
			
					
	




Dion implements orthonormalization using amortized power iteration (opens in new tab).&nbsp;Power iteration typically pulls out the largest singular value by repeated matrix multiplication.&nbsp;By amortizing this process over optimization stepsâ€”applied to the slowly-evolving momentum matrixâ€”we reduce the cost to just two matrix multiplications per step. Incorporating a QR decomposition allows us to extract an approximate orthonormal basis spanning the top singular directions, rather than just the leading one.&nbsp;This amortized power iteration is fully compatible with standard distributed training techniques such as FSDP and tensor parallelism.&nbsp;Here, we show a simple centralized version, but the technique works for more complex forms of parallelization as presented in the paper. In other words, we can orthogonalize a matrix without ever seeing a full row or column of it.&nbsp;



Low-rank approximation would ordinarily introduce error, but Dion overcomes this through an error feedback mechanism. This keeps the residual of low rank approximation in the momentum matrix so that any systematic gradient structure not initially captured accumulates to eventually be applied in a future update.



	
		

		
		PODCAST SERIES
	
	
	
						
				
					
				
			
			
			

									The AI Revolution in Medicine, Revisited
				
								Join Microsoftâ€™s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.
				
								
					
						
							Listen now						
					
				
							
	
Opens in a new tab	
	


How does it work?



Something very strange happened in our experiments. Usually, adding an extra constraint on the way an algorithm works can be expected to decrease overall performance. And indeed, at the 120M parameter scale of the speedrun, we see Dionâ€™s update taking more time than Muon, while not yielding any significant gains. But at larger scales, we observed a different trend: Dion began to outperform Muon.



Figure 3. Wall-clock time speedup of Dion for 3B model training



Why would adding a constraint improve the update rule? The answer lies in what the constraint enforces. Dion achieves a much closer approximation to true orthonormalization than Muon. This precision, initially subtle, becomes increasingly important as the number of singular vectors grows. Over increasing model scale and training steps, this small advantage accumulatesâ€”leading to a measurable improvement in performance.



This edge further grows with batch sizeâ€”with larger batches the update quality tends to degrade, but notably more slowly with Dion than Muon (and Muon is already a significant improvement over AdamW).



Figure 4. Scaling of Dion across different batch sizes



Here you can see how the number of steps to reach a pretraining loss compared to AdamW varies as batch size grows with full rank and Â¼ rank Dion (in orange) and Muon (in blue).&nbsp;&nbsp;&nbsp;



In our experiments, these benefits extend to various post-training regimes as well.



We also experimented with rank, discovering empirically that larger models tolerate smaller rank well.



Figure 5. Low-rank Dion across different model sizes



Projecting this trend out to the scale of the LLaMA-3 (opens in new tab) 405B parameter models suggests that Dion is fully effective even with rank fractions as low as 1/16 or 1/64 for large dense models like LLaMA-3.&nbsp;&nbsp;&nbsp;&nbsp;



Using hardware timings of the individual update steps suggests a story that looks this:



Figure 6. Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon.



Weâ€™ve open-sourced a PyTorch FSDP2 + Tensor Parallel (TP) implementation of Dion, available via a simple pip install. Our goal is to make faster training with Dion accessible to everyone. As a bonus, the repository also includes a PyTorch FSDP2 implementation of Muon.




Dion optimizer




Acknowledgements



We thank Riashat Islam and Pratyusha Sharma for their helpful feedback on the writing and presentation.
Opens in a new tabThe post Dion: the distributed orthonormal update revolution is here appeared first on Microsoft Research.
â€¢ Scalable intelligent document processing using Amazon Bedrock Data Automation
  Intelligent document processing (IDP) is a technology to automate the extraction, analysis, and interpretation of critical information from a wide range of documents. By using advanced machine learning (ML) and natural language processing algorithms, IDP solutions can efficiently extract and process structured data from unstructured text, streamlining document-centric workflows. 
When enhanced with generative AI capabilities, IDP enables organizations to transform document workflows through advanced understanding, structured data extraction, and automated classification. Generative AI-powered IDP solutions can better handle the variety of documents that traditional ML models might not have seen before. This technology combination is impactful across multiple industries, including child support services, insurance, healthcare, financial services, and the public sector. Traditional manual processing creates bottlenecks and increases error risk, but by implementing these advanced solutions, organizations can dramatically enhance their document workflow efficiency and information retrieval capabilities. AI-enhanced IDP solutions improve service delivery while reducing administrative burden across diverse document processing scenarios. 
This approach to document processing provides scalable, efficient, and high-value document processing that leads to improved productivity, reduced costs, and enhanced decision-making. Enterprises that embrace the power of IDP augmented with generative AI can benefit from increased efficiency, enhanced customer experiences, and accelerated growth. 
In the blog post Scalable intelligent document processing using Amazon Bedrock, we demonstrated how to build a scalable IDP pipeline using Anthropic foundation models on Amazon Bedrock. Although that approach delivered robust performance, the introduction of Amazon Bedrock Data Automation brings a new level of efficiency and flexibility to IDP solutions. This post explores how Amazon Bedrock Data Automation enhances document processing capabilities and streamlines the automation journey. 
Benefits of Amazon Bedrock Data Automation 
Amazon Bedrock Data Automation introduces several features that significantly improve the scalability and accuracy of IDP solutions: 
 
 Confidence scores and bounding box data â€“&nbsp;Amazon Bedrock Data Automation provides confidence scores and bounding box data, enhancing data explainability and transparency. With these features, you can assess the reliability of extracted information, resulting in more informed decision-making. For instance, low confidence scores can signal the need for additional human review or verification of specific data fields. 
 Blueprints for rapid development â€“ Amazon Bedrock Data Automation provides pre-built blueprints that simplify the creation of document processing pipelines, helping you develop and deploy solutions quickly. Amazon Bedrock Data Automation provides flexible output configurations to meet diverse document processing requirements. For simple extraction use cases (OCR and layout) or for a linearized output of the text in documents, you can use standard output. For customized output, you can start from scratch to design a unique extraction schema, or use preconfigured blueprints from our catalog as a starting point. You can customize your blueprint based on your specific document types and business requirements for more targeted and accurate information retrieval. 
 Automatic classification support â€“ Amazon Bedrock Data Automation splits and matches documents to appropriate blueprints, resulting in precise document categorization. This intelligent routing alleviates the need for manual document sorting, drastically reducing human intervention and accelerating processing time. 
 Normalization â€“ Amazon Bedrock Data Automation addresses a common IDP challenge through its comprehensive normalization framework, which handles both key normalization (mapping various field labels to standardized names) and value normalization (converting extracted data into consistent formats, units, and data types). This normalization approach helps reduce data processing complexities, so organizations can automatically transform raw document extractions into standardized data that integrates more smoothly with their existing systems and workflows. 
 Transformation â€“ The Amazon Bedrock Data Automation transformation feature converts complex document fields into structured, business-ready data by automatically splitting combined information (such as addresses or names) into discrete, meaningful components. This capability simplifies how organizations handle varied document formats, helping teams define custom data types and field relationships that match their existing database schemas and business applications. 
 Validation â€“ Amazon Bedrock Data Automation enhances document processing accuracy by using automated validation rules for extracted data, supporting numeric ranges, date formats, string patterns, and cross-field checks. This validation framework helps organizations automatically identify data quality issues, trigger human reviews when needed, and make sure extracted information meets specific business rules and compliance requirements before entering downstream systems. 
 
Solution overview 
The following diagram shows a fully serverless architecture that uses Amazon Bedrock Data Automation along with AWS Step Functions and Amazon Augmented AI (Amazon A2I) to provide cost-effective scaling for document processing workloads of different sizes. 
 
The Step Functions workflow processes multiple document types including multipage PDFs and images using Amazon Bedrock Data Automation. It uses various Amazon Bedrock Data Automation blueprints (both standard and custom) within a single project to enable processing of diverse document types such as immunization documents, conveyance tax certificates, child support services enrollment forms, and driver licenses. 
The workflow processes a file (PDF, JPG, PNG, TIFF, DOC, DOCX) containing a single document or multiple documents through the following steps: 
 
 For multi-page documents, splits along logical document boundaries 
 Matches each document to the appropriate blueprint 
 Applies the blueprintâ€™s specific extraction instructions to retrieve information from each document 
 Perform normalization, Transformation and validation on extracted data according to the instruction specified in blueprint 
 
The Step Functions Map state is used to process each document. If a document meets the confidence threshold, the output is sent to an Amazon Simple Storage Service (Amazon S3) bucket. If any extracted data falls below the confidence threshold, the document is sent to Amazon A2I for human review. Reviewers use the Amazon A2I UI with bounding box highlighting for selected fields to verify the extraction results. When the human review is complete, the callback task token is used to resume the state machine and human-reviewed output is sent to an S3 bucket. 
To deploy this solution in an AWS account, follow the steps provided in the accompanying GitHub repository. 
In the following sections, we review the specific Amazon Bedrock Data Automation features deployed using this solution, using the example of a child support enrollment form. 
Automated Classification 
In our implementation, we define the document class name for each custom blueprint created, as illustrated in the following screenshot. When processing multiple document types, such as driverâ€™s licenses and child support enrollment forms, the system automatically applies the appropriate blueprint based on content analysis, making sure the correct extraction logic is used for each document type. 
 
Data Normalization 
We use data normalization to make sure downstream systems receive uniformly formatted data. We use both explicit extractions (for clearly stated information visible in the document) and implicit extractions (for information that needs transformation). For example, as shown in the following screenshot, dates of birth are standardized to YYYY-MM-DD format. 
 
Similarly, format of Social Security Numbers is changed to XXX-XX-XXXX. 
Data Transformation 
For the child support enrollment application, weâ€™ve implemented custom data transformations to align extracted data with specific requirements. One example is our custom data type for addresses, which breaks down single-line addresses into structured fields (Street, City, State, ZipCode). These structured fields are reused across different address fields in the enrollment form (employer address, home address, other parent address), resulting in consistent formatting and straightforward integration with existing systems. 
 
Data Validation 
Our implementation includes validation rules for maintaining data accuracy and compliance. For our example use case, weâ€™ve implemented two validations: 1. verify the presence of the enrolleeâ€™s signature and 2. verify that the signed date isnâ€™t in the future. 
 
The following screenshot shows the result of the above validation rules applied to the document. 
 
Human-in-the-loop validation 
The following screenshot illustrates the extraction process, which includes a confidence score and is integrated with a human-in-the-loop process. It also shows normalization applied to the date of birth format. 
 
Conclusion 
Amazon Bedrock Data Automation significantly advances IDP by introducing confidence scoring, bounding box data, automatic classification, and rapid development through blueprints. In this post, we demonstrated how to take advantage of its advanced capabilities for data normalization, transformation, and validation. By upgrading to Amazon Bedrock Data Automation, organizations can significantly reduce development time, improve data quality, and create more robust, scalable IDP solutions that integrate with human review processes. 
Follow the AWS Machine Learning Blog to keep up to date with new capabilities and use cases for Amazon Bedrock. 
 
About the authors 
Abdul Navaz is a Senior Solutions Architect in the Amazon Web Services (AWS) Health and Human Services team, based in Dallas, Texas. With over 10 years of experience at AWS, he focuses on modernization solutions for child support and child welfare agencies using AWS services. Prior to his role as a Solutions Architect, Navaz worked as a Senior Cloud Support Engineer, specializing in networking solutions. 
Venkata Kampana is a senior solutions architect in the Amazon Web Services (AWS) Health and Human Services team and is based in Sacramento, Calif. In this role, he helps public sector customers achieve their mission objectives with well-architected solutions on AWS. 
Sanjeev Pulapaka is principal solutions architect and AI lead for public sector. Sanjeev is a published author with several blogs and a book on generative AI. He is also a well-known speaker at several events including re:Invent and Summit. Sanjeev has an undergraduate degree in engineering from the Indian Institute of Technology and an MBA from the University of Notre Dame.
â€¢ Whiteboard to cloud in minutes using Amazon Q, Amazon Bedrock Data Automation, and Model Context Protocol
  Upgrading legacy systems has become increasingly important to stay competitive in todayâ€™s market as outdated infrastructure can cost organizations time, money, and market position. However, modernization efforts face challenges like time-consuming architecture reviews, complex migrations, and fragmented systems. These delays not only impact engineering teams but have broader impacts including lost market opportunities, reduced competitiveness, and higher operational costs. With Amazon Q Developer,&nbsp;Amazon Bedrock Data Automation&nbsp;(Bedrock Data Automation) and Anthropicâ€™s&nbsp;Model Context Protocol (MCP), developers can now go from whiteboard sketches and team discussions to fully deployed, secure, and scalable cloud architectures in a matter of minutes, not months. 
Weâ€™re excited to share the Amazon Bedrock Data Automation Model Context Protocol (MCP) server, for seamless integration between Amazon Q and your enterprise data. With this new capability, developers can use the features of Amazon Q while maintaining secure access to their organizationâ€™s data through standardized MCP interactions. In this post, you will learn how to use the Amazon Bedrock Data Automation MCP server to securely integrate with AWS Services, use Bedrock Data Automation operations as callable MCP tools, and build a conversational development experience with Amazon Q. 
The problem: Five systems, lack of agility 
Engineers looked at a whiteboard, eyeing a complex web of arrows, legacy system names, and integration points that had long stopped making sense. The diagram represented multiple disconnected systems held together by brittle scripts, fragile batch jobs, and a patchwork of manual workarounds as shown in the following illustration.  

 
 
The meeting audio was synthesized using Amazon Polly to bring the conversation to life for this post. 
â€œWe need to stop patching and start transforming,â€ Alex said, pointing at the tangled mess. The team nodded, weary from another outage that left the finance team reconciling thousands of transactions by hand. Feature development had slowed to a crawl, infrastructure costs were unpredictable, and any change risked breaking something downstream. Migration felt inevitable but overwhelming. The question wasnâ€™t whether to modernize â€“ it was how to begin without burning months in planning and coordination. Thatâ€™s when they turned to the new pattern. 
The breakthrough 
Just a few months ago, building a working prototype from a whiteboard session like this would have taken months, if not longer. The engineers would have started by manually transcribing the meeting, converting rough ideas into action items, cleaning up architecture diagrams, aligning teams across operations and security, and drafting infrastructure templates by hand. Every step would have required coordination, and each change made would have invited risk to the system. Even a proof-of-concept would have demanded hours of YAML, command line interface (CLI) commands, policy definitions, and trial-and-error troubleshooting. Now the engineers need to only ask, and what used to take months happens in minutes. 

 
  
 
 
With Amazon Q CLI, the team initiates a conversation. Behind the scenes, Amazon Q CLI invokes the MCP server and extracts information from multimodal content using Bedrock Data Automation. The meeting recording and the draft architecture diagram are also analyzed using Bedrock Data Automation. Amazon Q uses the extracted content from Bedrock Data Automation to generate the AWS CloudFormation template. It even deploys it to the AWS Cloud when asked. There is no manual translation, no brittle scripting, and no dependency mapping across systems. The result is a fully deployable, secure AWS architecture generated and provisioned in minutes. What once required cross-functional coordination and prolonged development cycles now starts and completes with a chat. 
Understanding the Model Context Protocol 
The Model Context Protocol (MCP) is an open standard developed by Anthropic to facilitate secure, two-way connections between AI models and multiple data sources, including content repositories, business tools, and development environments. By standardizing these interactions, MCP enables AI systems to access the data they need to provide more relevant and accurate responses. 
MCP operates on a client-server architecture, where developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers. This setup allows for a more streamlined and scalable integration process, replacing the need for custom connectors for each data source. 
Enhancing Amazon Q with Amazon Bedrock Data Automation and MCP server 
Bedrock Data Automation complements MCP by providing a robust suite of tools that automate the extraction, transformation, and loading (ETL) of enterprise data into AI workflows at scale and with minimal manual intervention. With Bedrock Data Automation, customers can: 
 
 Extract unstructured data from diverse sources such as document, image, audio, and video files. 
 Transform and validate data using schema-driven extraction using Blueprints, confidence scoring, and responsible AI practice to maintain accuracy, completeness, and consistency. 
 Load ready-to-use data into AI models for real-time, context-aware reasoning across business. 
 
This deep integration makes sure that AI models are not just connected to data, they are grounded in clean, validated, and context-rich information. As a result, intelligent agents deliver more accurate, relevant, and reliable outputs that drive faster decisions and richer insights across the enterprise. Amazon Q Developer is a generative AI-powered conversational assistant from AWS designed to help software developers and IT professionals build, operate, and transform software with greater speed, security, and efficiency. It acts as an intelligent coding companion and productivity tool, integrated with the AWS environment and available in popular code editors, the AWS Management Console, and collaboration tools such as Microsoft Teams and Slack. As described in the following figure, the Bedrock Data Automation MCP server works in the following way: 
 
 The User sends a â€œRequest actionâ€ to the MCP Host. 
 The MCP Host processes the request with an LLM. 
 The MCP Host then requests a tool execution to the MCP Client. 
 The MCP Client makes a tool call request to the MCP Server. 
 The MCP Server makes an API request to the Bedrock Data Automation. 
 Bedrock Data Automation sends back an API response to the MCP Server. 
 The MCP Server returns the tool result to the MCP Client. 
 The MCP Client sends the result back to the MCP Host. 
 The MCP Host again processes with LLM. 
 The MCP Host sends a final response to the User. 
 
 
Step-by-step guide 
If this is your first time using AWS MCP servers, visit the&nbsp;Installation and Setup guide in the AWS Labs GitHub repository&nbsp;for installation instructions. After installation, add the following MCP server configuration to your local setup: 
Prerequisites 
 
 You need an AWS account and an AWS Identity and Access Management (IAM) role and user with permissions to create and manage the necessary resources and components for this application. If you donâ€™t have an AWS account, see How do I create and activate a new Amazon Web Services account? 
 Bedrock Data Automation MCP requires an Amazon Simple Storage Service (Amazon S3) bucket to function properly.&nbsp;If you need to create a new S3 bucket, follow the AWS security best practices for bucket configuration. 
 NodeJS and NPM 
 Follow these instructions&nbsp;to set up Amazon Q 
 
Set up MCP 
Install&nbsp;Amazon Q for command line&nbsp;and add the conï¬guration to ~/.aws/amazonq/mcp.json. If youâ€™re already an Amazon Q CLI user, add only the configuration. 
 
 {
&nbsp;&nbsp;"mcpServers": {
&nbsp;&nbsp; &nbsp;"bedrock-data-automation-mcp-server": {
&nbsp;&nbsp; &nbsp; &nbsp;"command": "uvx",
&nbsp;&nbsp; &nbsp; &nbsp;"args": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"awslabs.aws-bedrock-data-automation-mcp-server@latest"
&nbsp;&nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp;"env": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"AWS_PROFILE": "your-aws-profile",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"AWS_REGION": "your-aws-region",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"AWS_BUCKET_NAME": "amzn-s3-demo-bucket"
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp;}
} 
 
To confirm the setup was successful, open a terminal and enter q chat to enter into a chat session with Amazon Q. 
Need to know what tools are at your disposal? Enter:"Tell me the tools I have access to" 
If MCP has been properly configured, as shown in the following screenshot, you will have, aws_bedrock_data_automation suffixed by getprojects, getprojectdetails, and analyzeasset as its three tools. This will help you quickly verify access and make sure that the necessary components are properly set up. 
 
Now, you can ask Amazon Q to use Bedrock Data Automation as a tool and extract the transcript from the meeting stored in the .mp3 file and refer to the updated architecture diagram, as shown in the following screenshot. 
 
 can you extract the meeting recording from &lt;your-location&gt; and refer to the updated architecture diagram from &lt;your-location&gt; using Bedrock Data Automation&nbsp; 
 
 
You can seamlessly continue a natural language conversation with Amazon Q to generate an AWS CloudFormation template, write prototype code, or even implement monitoring solutions. The potential applications are virtually endless. 
Clean up 
When youâ€™re done working with the Amazon Bedrock Data Automation MCP server, follow the given steps to perform cleanup: 
 
 Empty and delete the S3 buckets used for Bedrock Data Automation. 
 
 
    aws s3 rm s3://amzn-s3-demo-bucket --recursive
    aws s3 rb s3://amzn-s3-demo-bucket 
 
 
 Remove the configuration added to ~/.aws/amazonq/mcp.json for bedrock-data-automation-mcp-server. 
 
Conclusion 
With MCP and Bedrock Data Automation, Amazon Q Developer can turn messy ideas into working cloud architectures in record time. No whiteboards are left behind. 
Are you ready to build smarter, faster, and more context-aware applications? Explore Amazon Q Developer and see how MCP and Amazon Bedrock&nbsp;Data Automation can help your team turn ideas into reality faster than ever before. 
 
About the authors 
Wrick Talukdar is a Tech Lead and Senior Generative AI Specialist at Amazon Web Services, driving innovation through multimodal AI, generative models, computer vision, and natural language processing. He is also the author of the bestselling book â€œBuilding Agentic AI Systemsâ€. He is a keynote speaker and often presents his innovations and solutions at leading global forums, including&nbsp;AWS re:Invent, ICCE, Global Consumer Technology conference,&nbsp;and major industry events such as&nbsp;CERAWeek&nbsp;and&nbsp;ADIPEC. In his free time, he enjoys writing and birding photography. 
Ayush Goyal is a Senior Software Engineer at Amazon Bedrock, where he focuses on designing and scaling AI-powered distributed systems. Heâ€™s also passionate about contributing to open-source projects. When heâ€™s not writing code, Ayush enjoys speed cubing, exploring global cuisines, and discovering new parksâ€”both in the real world and through open-world games. 
Himanshu Sah is an Associate Delivery Consultant in AWS Professional Services, specialising in Application Development and Generative AI solutions. Based in India, he helps customers architect and implement cutting-edge applications leveraging AWS services and generative AI capabilities. Working closely with cross-functional teams, he focuses on delivering best-practice implementations while ensuring optimal performance and cost-effectiveness. Outside of work, he is passionate about exploring new technologies and contributing to the tech community.
â€¢ Bringing agentic Retrieval Augmented Generation to Amazon Q Business
  Amazon Q Business is a generative AI-powered enterprise assistant that helps organizations unlock value from their data. By connecting to enterprise data sources, employees can use Amazon Q Business to quickly find answers, generate content, and automate tasksâ€”from accessing HR policies to streamlining IT support workflows, all while respecting existing permissions and providing clear citations. At the heart of systems like Amazon Q Business lies Retrieval Augmented Generation (RAG), which enables AI models to ground their responses in an organizationâ€™s enterprise data. 
The evolution of RAG 
Traditional RAG implementations typically follow a straightforward approach: retrieve relevant documents or passages based on a user query, then generate a response using these documents or passages as context for the large language model (LLM) to respond. While this methodology works well for basic, factual queries, enterprise environments present uniquely complex challenges that expose the limitations of this single-shot retrieval approach. 
Consider an employee asking about the differences between two benefits packages or requesting a comparison of project outcomes across multiple quarters. These queries require synthesizing information from various sources, understanding company-specific context, and often need multiple retrieval steps to gather comprehensive information around each aspect of the query. 
Traditional RAG systems struggle with such complexity, often providing incomplete answers or failing to adapt their retrieval strategy when initial results are insufficient. When processing these more involved queries, users are left waiting without visibility into the systemâ€™s progress, leading to an opaque experience. 
Bringing agency to Amazon Q Business 
Bringing agency to Amazon Q Business is a new paradigm to handle sophisticated enterprise queries through intelligent, agent-based retrieval strategies. By introducing AI agents that dynamically plan and execute sophisticated retrieval strategies with a suite of data navigation tools, Agentic RAG represents a significant evolution in how AI assistants interact with enterprise data, delivering more accurate and comprehensive responses while maintaining the speed users expect. 
With Agentic RAG in Amazon Q Business you have several new capabilities, including query decomposition and transparent events, agentic retrieval tool use, improved conversational capabilities, and agentic response optimization. Letâ€™s dive deeper into what each of these mean. 
Query decomposition and transparent response events 
Traditional RAG systems often face significant challenges when processing complex enterprise queries, particularly those involving multiple steps, composite elements, or comparative analysis. With this release of Agentic RAG in Amazon Q Business, we aim to solve this problem through sophisticated query decomposition techniques, where AI agents intelligently break down complex questions into discrete, manageable components. 
When an employee asks Please compare the vacation policies of Washington and California?, the question is decomposed into two queries on Washington and California policies. The first decomposed query being washington state vacation policies and the second query being california state vacation policies. 
Because Agentic RAG presumes a series of parallel steps to explore the data source and collect thorough information for more accurate query resolution, we are now providing real-time visibility into its processing steps that will be displayed on the screen as data is being retrieved to generate the response. After the response is generated, the steps will be collapsed with the response streamed. In the following image, we see how the decomposed queries are displayed and the relevant data retrieved for response generation. 
 
This allows users to see meaningful updates to the systemâ€™s operations, including query decomposition patterns, document retrieval paths, and response generation workflows. This granular visibility into the systemâ€™s decision-making process enhances user confidence and provides valuable insights into the sophisticated mechanisms driving accurate response generation. 
This agentic solution facilitates comprehensive data collection and enables more accurate, nuanced responses. The result is enhanced responses that maintain both granular precision and holistic understanding of complex, multi-faceted business questions, while relying on the LLM to synthesize the information retrieved. As shown in the following image, the information fetched individually for California and Washington vacation policies were synthesized by the LLM and presented in a rich markdown format. 
 
Agentic tool use 
The designed RAG agents can intelligently deploy various data exploration tools and retrieval methods in optimal strategies by thinking about the retrieval plan while maintaining context over multiple turns of the conversations. These retrieval tools include tools built within Amazon Q Business such as tabular search, allowing intelligent retrieval of data through either code generation or tabular linearization across small and large tables embedded in documents (such as DOCX, PPTX, PDF, and so on) or stored in CSV or XLSX files. Another retrieval tool includes long context retrieval, which determines when the full context of a document is required for retrieval. An example of long context retrieval: if a user asks a query such as Summarize the 10K of Company X, the agent could identify the queryâ€™s intent as a summarization query that requires document-level context and, as a result, deploy the long context retrieval tool that fetches the complete documentâ€”the 10K of Company Xâ€”as part of the context for the LLM to generate a response (as shown in the following figure). This intelligent tool selection and deployment represents a significant advancement over traditional RAG systems, which often rely on fragmented passage retrieval that can compromise the coherence and completeness of complex document analysis for question answering. 
 
Improved conversational capabilities 
Agentic RAG introduces multi-turn query capabilities that elevate the conversational capabilities of Amazon Q Business into dynamic, context-aware dialogues. The agent maintains conversational context across interactions by storing short-term memory, enabling natural follow-up questions without requiring users to restate previous context. Additionally, when the agent encounters multiple possible answers based on your enterprise data, it asks clarifying questions to disambiguate the query to better understand what youâ€™re looking for to provide more accurate responses. For instance, Q refers to any of the many implementations of Amazon Q. The system handles semantic ambiguity gracefully by recognizing multiple potential interpretations of what Q could be and asks for clarifications in its responses to verify accuracy and relevance. This sophisticated approach to dialogue management makes complex tasks like policy interpretation or technical troubleshooting more efficient, because the system can progressively refine its understanding through targeted clarification and follow-up exchanges. 
In the following image, the user asks tell me about Q with the system providing a high-level overview of the various implementations and asking a follow-up question to disambiguate the userâ€™s search intent. 
 
Upon successful disambiguation, the system persists both the conversation state and previously retrieved contextual data in-memory, enabling the generation of precisely targeted responses that align with the userâ€™s clarified intent thus being more accurate, relevant, and complete. 
 
Agentic response optimization 
Agentic RAG introduces dynamic response optimization where AI agents actively evaluate and refine their responses. Unlike traditional systems that provide answers even when the context is insufficient, these agents continuously assess response quality and iteratively plan out new actions to improve information completeness. They can recognize when initial retrievals miss crucial information and autonomously initiate additional searches or alternative retrieval strategies. This means when discussing complex topics like compliance policies, the system captures all relevant updates, exceptions, and interdependencies while maintaining context across multiple turns of the conversation. The following diagram shows how Agentic RAG handles the conversation history across multiple turns of the conversation. The agent plans and reasons across the retrieval tool use and response generation process. Based on the initial retrieval, while taking into account the conversation state and history, the agent re-plans the process as needed to generate the most complete and accurate response for the userâ€™s query. 
 
Using the Agentic RAG feature 
Getting started with Agentic RAGâ€™s advanced capabilities in Amazon Q Business is straightforward and can immediately improve how your organization interacts with your enterprise data. To begin, in the Amazon Q Business web interface, you can switch on the Advanced Search toggle to enable Agentic RAG, as shown in the following image. 
 
After advanced search is enabled, users can experience richer and more complete responses from Amazon Q Business. Agentic RAG particularly shines when handling complex business scenarios based on your enterprise dataâ€”imagine asking about cross-AWS Region performance comparisons, investigating policy implications across departments, or analyzing historical trends in project deliveries. The system excels at breaking down these complex queries into manageable search tasks while maintaining context throughout the conversation. 
For the best experience, users should feel confident in asking detailed, multi-part questions. Unlike traditional search systems, Agentic RAG handles nuanced queries like 
How have our metrics changed across the southeast and northeast regions in 2024? 
The system will work through such questions methodically, showing its progress as it analyzes and breaks the query down into composite parts to fetch sufficient context and generate a complete and accurate response. 
Conclusion 
Agentic RAG represents a significant leap forward for Amazon Q Business, transforming how organizations use their enterprise data while maintaining the robust security and compliance that they expect with AWS services. Through its sophisticated query processing and contextual understanding, the system enables deeper, more nuanced interactions with enterprise dataâ€”from comparative and multi-step queries to interactive multi-turn chat experiences. All of this occurs within a secure framework that respects existing permissions and access controls, making sure that users receive only authorized information while maintaining the rich, contextual responses needed for meaningful insights. 
By combining advanced retrieval capabilities with intelligent, conversation-aware interactions, Agentic RAG allows organizations to unlock the full potential of their data while maintaining the highest standards of data governance. The result is an improved chat experience and a more capable query answering engine that maximizes the value of your data assets. 
Try out Amazon Q Business for your organization with your data and share your thoughts in the comments. 
 
About the authors 
Sanjit Misra is a technical product leader at Amazon Web Services, driving innovation on Amazon Q Business, Amazonâ€™s generative AI product. He leads product development for core Agentic AI features that enhance accuracy and retrieval â€” including Agentic RAG, conversational disambiguation, tabular search, and long-context retrieval. With over 15 years of experience across product and engineering roles in data, analytics, and AI/ML, Sanjit combines deep technical expertise with a track record of delivering business outcomes. He is based in New York City. 
Venky Nagapudi is a Senior Manager of Product Management for Amazon Q Business. His focus areas include RAG features, accuracy evaluation and enhancement, user identity management and user subscriptions. 
Yi-An Lai is a Senior Applied Scientist with the Amazon Q Business team at Amazon Web Services in Seattle, WA. His expertise spans agentic information retrieval, conversational AI systems, LLM tool orchestration, and advanced natural language processing. With over a decade of experience in ML/AI, he has been enthusiastic about developing sophisticated AI solutions that bridge state-of-the-art research and practical enterprise applications. 
Yumo Xu&nbsp;is an Applied Scientist at AWS, where he focuses on building helpful and responsible AI systems for enterprises. His primary research interests are centered on the foundational challenges of machine reasoning and agentic AI. Prior to AWS, Yumo received his PhD in Natural Language Processing from the University of Edinburgh. 
Danilo Neves Ribeiro is an Applied Scientist on the Q Business team based in Santa Clara, CA. He is currently working on designing innovative solutions for information retrieval, reasoning, language model agents, and conversational experience for enterprise use cases within AWS. He holds a Ph.D. in Computer Science from Northwestern University (2023) and has over three years of experience working as an AI/ML scientist. 
Kapil Badesara is a Senior Machine Learning Engineer on AWS Q Business, focusing on optimizing RAG systems for accuracy and efficiency. Kapil is based out of Seattle and has more than 10 years of building large scale AI/ML services. 
Sunil Singh&nbsp;is an Engineering Manager on the Amazon Q Business team, where he leads the development of next-generation agentic AI solutions designed to enhance Retrieval-Augmented Generation (RAG) systems for greater accuracy and efficiency. Sunil is based out of Seattle and has more than 10 years of experience in architecting secure, scalable AI/ML services for enterprise-grade applications.
â€¢ Empowering students with disabilities: University Startupsâ€™ generative AI solution for personalized student pathways
  This post was co-authored with Laura Lee Williams and John Jabara from University Startups. 
University Startups, headquartered in Bethesda, MD, was founded in 2020 to empower high school students to expand their education beyond a traditional curriculum. University Startups is focused on special education and related services in school districts throughout the US. 
After students graduate from high school, they donâ€™t often know what they want to pursue for education and a career. University Startups and AWS have designed a unique program that helps students with disabilities solve that challenge. The program creates a personalized transition plan for each student and can be used in schools across the country. The program can provide specific guidance for each student to help them create their own path for success after high school. Specifically, University Startups uses Amazon Bedrock to create this customized experience without increasing workload for educators. The impact of this initiative has been successfully demonstrated during a pilot test program, where dozens of students and teachers used University Startupsâ€™ tool to explore different career paths and suggestions on how to pursue their goals. 
In this post, we explain how University Startups uses generative AI technology on AWS to enable students to design a specific plan for their future either in education or the work force. 
Challenges in special education 
Special education includes services and programs to meet the individual needs of a student with a disability. There are more than 7.5 million K-12 students with disabilities in the US, and this number is growing. Students with disabilities who require special education services have Individualized Education Programs (IEPs). The IEP is a legally mandated document developed by a studentâ€™s parents, teachers, and specialists to make sure the studentâ€™s educational needs are met. This includes access to the general education curriculum together with general education peers, and as close to their home as possible. 
An important component of the IEP document is a transition plan. A transition plan is a document that articulates objectives and development goals meant to prepare students with disabilities for adult life. This can include planning for postsecondary education and career goals, gaining work experience, independent living, or whichever option is appropriate for the student. This plan is highly individualized to a studentâ€™s interests, preferences, skills, and needs. According to federal law, each student must have a transition plan in place by age 16. 
However, schools in under-resourced school districts often have limited capacity to provide ample one-on-one attention from teachers and counselors to create an effective transition plan for every student. Additionally, because these transition plans are audited by federal and state governments, these school districts can face legal and financial consequences if plans are not in compliance. These challenges highlight the need for a personalized and robust solution to empower students with disabilities and their support team of parents, teachers, and specialists. With this context in mind, letâ€™s explore how University Startups and AWS collaborated to develop a solution using Amazon Bedrock to enhance the transition planning process. 
Solution overview 
To address this challenge, University Startups created Trinity, a transition planning AI assistant to support students with disabilities in uncovering their interests to create an effective and personalized transition plan. The following diagram shows how you can use Amazon Bedrock Agents in a workflow, alongside other tools, to provide context when gathering information to create a transition plan. 
 
At a high level, the solution uses Amazon Bedrock Agents to orchestrate comprehensive workflows that engage students by enabling interactive, personalized AI assistant experiences. The agents use AWS Lambda functions to securely call external APIs, such as job boards or university databases, and retrieve up-to-date opportunities. Additionally, Amazon Bedrock Flows can automate the generation of the individualized documents by collecting and synthesizing information from these interactions into a personalized draft transition plan. Throughout the process, features like Amazon Bedrock Knowledge Bases and Amazon Bedrock Guardrails are designed to improve the accuracy and reliability of the information provided, and to align it with safety and compliance standards, creating a secure and effective support system for students, parents, and educators. 
To begin the process, students engage with an agent designed with Amazon Bedrock Agents to uncover their preferences and interests, while under the guidance of their educators. The agent then proposes tailored suggestions on pathways the students can explore for their transition plans. These suggestions are informed by context provided to the agent about requirements for IEP documents and common transition plan structures. Based on this output, the studentâ€™s parents and teachers can efficiently create a transition plan with the student or continue engaging with the agent to dive deeper. In the following section, we take a closer look at the tools this agent uses. 
Tools and features used by Amazon Bedrock Agents 
The effectiveness of Amazon Bedrock Agents lies in its ability to engage the students in a productive manner and provide actionable results for parents and educators. This is accomplished by using features within Amazon Bedrock, such as Amazon Bedrock Knowledge Bases and Amazon Bedrock Guardrails, alongside other AWS services, including Lambda, to create tools for the agent. 
Maintaining student safety 
A critical component of this application is designing with student security in mind, especially when handling personally identifiable information (PII) and protected health information (PHI). Without proper protections, there can be risk of data breach and violating compliance regulations. 
We use Amazon Bedrock Guardrails to implement safeguards within the generative AI system. If a user enters PII or PHI data, Amazon Bedrock Guardrails will detect this and automatically block the request, and will return a preconfigured message, such as â€œSorry, your query violates our usage policy.â€ We also use Amazon Bedrock Guardrails to mask PIIs in model responses. If sensitive information is detected in the model response, the guardrail masks it with an identifier, such as {NAME-1}. 
Amazon Bedrock Guardrails can also help make sure this resource is being used only for its intended purposes. Technology can often be a distraction to students, but Amazon Bedrock Guardrails can be configured with a set of denied topics and content filters so students can stay on track. 
Using relevant context 
Transition plans require specific information about a student by law. However, there is no singular format required for the IEP document across the US. Each state can have varying standardized formats, and in some states, individual school systems design their own forms. 
Therefore, the resource needs to be able to gather the required information and present it in the appropriate format, according to the school system it is being used in. We use Amazon Bedrock Knowledge Bases to provide the agent with necessary context so it can deliver accurate, customized responses for each use case. 
Use case 
To understand the impact of this solution and show Amazon Bedrock Agents in action, letâ€™s view an example of Noah, a student who used University Startupsâ€™ resource in a pilot test program. 
Noah was preparing to create his own transition plan for his IEP document. He attends a school district that uses University Startupsâ€™ resource, so he creates an account to get personalized outputs for his IEP. The system agent began to gather requirements: 
 
 The agent began by asking for Noahâ€™s current performance and any special requirements he might need. Then, the agent asked Noah to share his interests and skills, and what he might be interested in pursuing after high school. Noah shared that he is interested in criminology. 
 Then, the agent used Amazon Bedrock Guardrails to redact sensitive information that might have been entered. Then, it uses tools to provide recommendations on how Noah can pursue a career in criminology, including postsecondary education and internships. These recommendations were tailored for Noah, based on his needs and location preferences. 
 Noah then chose to explore another pathway option and was offered steps to discover other methods to pursue a career in criminology. 
 Finally, Noah was satisfied with the results and recommendations he received, and this information was formatted into a draft transition plan. This is then provided to the team of educators responsible for developing and finalizing his IEP. 
 
This discovery process helped Noah fully explore his interests and options, while feeling confident that these recommendations were personalized to his needs. It also reduced the time required by educators to prepare for IEP meetings and submission. 
Demonstrated impact 
This solution developed by University Startups provides a safe and efficient way for educators and students to develop their transition planning IEP documents. By automating the planning phase, students can take their time to explore their interests and the different paths available to them after high school. The tool can also support a dialogue between teacher and student in cases where special assistance is required. A teacher who participated in the pilot program said, â€œI think Trinity is an awesome tool. I would love to see parents and their students use it together, especially before the IEP meeting. I also think it is a great conversation starter to be used between the student and their case worker/counselor.â€ Even in underserved school districts, students can receive personalized attention tailored to their needs that captures their perspective in the transition planning process. 
Transition planning preparation can be time-consuming for educators and requires highly specialized knowledge. However, using the Trinity resource has produced results in approximately 10 minutes and has the potential to reduce the average time spent by educators on transition planning. This makes it possible for them to scale up their efforts and focus their time on actionable results for every student. 
Additionally, this tool is able to engage students to thoughtfully share their interests and skills. Pilot program participant Noah said, â€œUsing this tool was easy and helpful; it quickly showed me a path to get to the job I want to do in the future.â€ Most importantly, although this solution automates the discovery process for developing a transition plan, it guarantees hands-on educator support during each step and whenever a student requests assistance. Throughout the pilot program, educators have preferred to provide one-on-one support by guiding students through the Trinity tool. This makes sure that the students feel acknowledged throughout the process, and that educators can adjust and validate the transition plan recommendations provided. 
Conclusion 
Through this solution, University Startups has demonstrated how students, including students with disabilities, can receive personalized services despite a lack of resources in underserved school districts. This solution can empower students to pursue their interests and develop actionable plans to build skills and achieve success. Incorporating generative AI into educational resources demonstrates the effective capability of AI in learning environments. Educational tools powered with Amazon Bedrock can handle diverse student needs and provide instant feedback, which streamlines the creation of personalized learning pathways by educators. This allows high-quality, adaptive instruction accessible for every student. 
John Jabara, co-founder of University Startups, shares, 

 â€œAmazon Bedrock allowed us to create a tool that can capture the studentâ€™s voice during this important transition planning process.â€
 
As of the publication date of this post, University Startups is active in 15 states. As University Startups continues to scale, they plan to expand their reach across the country. The potential of tools like Amazon Bedrock Agents and Amazon Bedrock Guardrails in democratizing education and career resources for students is significant, and Amazon Bedrock is at the forefront of this initiative. 
To learn more, refer to Amazon Bedrock Agents, Amazon Bedrock Guardrails, and Amazon Bedrock Security and Privacy. To get a hands-on introduction to creating your own agent with Amazon Bedrock Agents, check out the following GitHub repository. 
Visit https://www.university-startups.com for more information on programming for special education. 
 
About the authors 
 Sadia Ahmed is a Solutions Architect at AWS supporting startup companies to transform big ideas into scalable solutions, with a focus on Generative AI. She is also passionate about educating the next generation of tech innovators. Sadia graduated from the University of Illinois Urbana-Champaign with a Masterâ€™s in Computer Science, and enjoys painting in her free time. 
 DeJonte July is a Solutions Architect at Amazon Web Services supporting early startup customers and helping make their entrepreneurial dreams come true. His primary focus lies on ethical use of Generative AI and technology communication. Outside of work he enjoys filmmaking and film photography. 
 Varad Ram is an Enterprise Solutions Architect supporting customers in Advertisement and Marketing vertical at Amazon Web Services. He collaborates closely with customers to design scalable and operationally efficient solutions. Currently, his primary focus is on analytics and helping customers maximize their return on investment in Generative Artificial Intelligence. In his free time, Varad enjoys biking with his children and playing tennis.

â¸»