âœ… Morning News Briefing â€“ October 15, 2025 10:46

ğŸ“… Date: 2025-10-15 10:46
ğŸ·ï¸ Tags: #briefing #ai #publichealth #digitalgov

â¸»

ğŸ§¾ Weather
â€¢ Current Conditions:  6.5Â°C
  Temperature: 6.5&deg;C Pressure / Tendency: 102.4 kPa rising Humidity: 62 % Dewpoint: -0.2&deg:C Wind: NNW 14 km/h Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Wednesday 15 October 2025 Temperature: . Temperature: Â 6.5/
â€¢ Wednesday: Mainly sunny. High 11.
  Clearing. Clearing . Wind northwest 20 km/h gusting to 40 . High 11. UV index 3 or moderate . Clearing and sunny sunny skies. Wind gusts to 40 mph in some areas . Forecast issued 5:00 AM EDT Wednesday 15 October 2025 . Weather forecast: Thursday, Friday, Saturday, Sunday, October 15, and Friday, October 16, 2025
â€¢ Wednesday night: Clear. Low zero.
  Clear. Clear . Wind north 30 km/h becoming light after midnight . Low zero. Clear. Low zero . Clear. High winds north 30km/h . Low winds will be windy. Low winds north to 40km/hr . Forecast issued 5:00 AM EDT Wednesday 15 October 2025. Low wind gusts could gust up to 40 km/hr. Forecast

ğŸŒ International News
No updates.

ğŸ Canadian News
No updates.

ğŸ‡ºğŸ‡¸ U.S. Top Stories
â€¢ Israel keeps Gaza border crossing closed while reducing aid deliveries
  The ceasefire on Wednesday was largely holding, although Hamas described Israeli attacks in Gaza as violations of the agreement . Hamas described Israel's attack in Gaza in violation of the ceasefire agreement . The ceasefire is largely holding despite Hamas describing Israeli attacks on Gaza as violating the agreement, according to Hamas . Hamas says Israeli strikes in Gaza violate the ceasefire, but Israel says it is not violating the ceasefire deal .
â€¢ U.S. charges Cambodian tycoon in massive alleged cryptocurrency scam
  U.S. prosecutors charge the founder of a Cambodian conglomerate in a massive cryptocurrency scam . The scam bilked would-be investors out of billions of dollars, prosecutors say . The indictment was unsealed in federal court in an indictment unsealed by federal prosecutors in a federal court . The Cambodian businessman is accused of bilking people out of millions of dollars by scamming them out
â€¢ Thousands of federal employees are getting laid off. Will a judge intervene?
  Unions representing federal employees have asked a federal judge in San Francisco to halt the Trump administration's latest round of layoffs . The layoffs are coming amid the government shutdown, which is currently being affected by the shutdown . Unions represent federal employees in the U.S. have asked for a halt of the layoffs . A federal judge is expected to hear the case in a San Francisco court on
â€¢ Scientists are modifying wildlife DNA. Should these species be released into nature?
  Scientists are researching ways to genetically modify plants and animals to be more resistant to threats like climate change . The IUCN is voting on whether those species should be allowed in nature . Scientists are working on genetically modified species to be resistant to climate change threats . The vote will be held in the U.S. and the world's largest conservation group, the International Union of Conservationists,
â€¢ 'Broadcasting' has its roots in agriculture. Here's how it made its way into media
  The word 'broadcasting' dates back centuries, and originally described a method of sowing seeds . But it took on a new meaning with the rise of radio in the 1920s . 'Broadcasting' was originally used to refer to a method that was used to sow seeds . It took on new meaning when radio was first used in broadcasting in 1920s, when it was first

ğŸ§  Artificial Intelligence
No updates.

ğŸ’» Digital Strategy
â€¢ Schleswig-Holstein waves auf Wiedersehen to Microsoft stack
  Germany's northernmost state bins Outlook â€“ and tens of thousands of Redmond licenses . Schleswig-Holstein has finally concluded one element of a long-running project to eject Microsoft from its infrastructure by giving Exchange Server the boot . Exchange Server is the latest in a series of Microsoft products to be thrown out of Germany's IT infrastructure by the state . The state has given up tens of
â€¢ Trump's anti-sustainability agenda comes to Eurozone
  US President Donald Trump released a wrecking ball that smashed through environmental, social, and governance (ESG) policies stateside â€“ and it's now swinging across the Atlantic, analysts say . ESG kicked like a 'toxic political football' amid greenwashing Canalys Forums 2025, Canalys Forum 2025 . Canalys forums 2025: Canalys. 2025: US President Trump released wreck
â€¢ UK government's Â£45B AI savings pitch built on broad-brush guesswork, MPs told
  Think tank cautions that without job cuts or capital savings, the math doesn't add up . UK government's plans to save Â£45 billion through the application of AI in the public sector lack clarity and are based on broad-brush assumptions, Members of Parliament have heard . Without job cuts, capital savings or job cuts the math isn't adding up, the think tank says . Think tank
â€¢ AI is the flying car of the mind: An irresistible idea nobody knows how to land or manage
  Steve Jobs described a personal computer as a "bicycle for the mind" Jobs' point was that both tools help us to go further, faster, with just a little extra effort . And which will crash, repeatedly, until users learn how to handle it safely, will crash again if they learn to use it safely . Steve Jobs: Both tools can help us go further and faster,
â€¢ Salesforce pumps the dream of AI agents as helpers, not replacements
  Salesforce CEO Marc Benioff heralded the arrival of the agentic era during his keynote at the CRM giant's annual Dreamforce conference . In the Agentic Enterprise, 'AI doesnâ€™t replace people, it elevates them,' he said . Salesforce: In the future, AI doesn't replace people. It's the future of the 'agentic enterprise'

ğŸ¥ Public Health
No updates.

ğŸ”¬ Science
â€¢ Germanyâ€™s national genomDE strategy
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Effects of scarcity on womenâ€™s cognitive ability to manage mental health and substance use after prison release
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Japan declares a flu epidemic â€” what this means for other nations
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Adverse drug reaction profiles of histone deacetylase inhibitors
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ A health and economic evaluation of the spatial spillover effect from measles resurgence
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

ğŸ§¾ Government & Policy
No updates.

ğŸ›ï¸ Enterprise Architecture & IT Governance
No updates.

ğŸ¤– AI & Emerging Tech
â€¢ The quest to find out how our bodies react to extreme temperatures
  Itâ€™s the 25th of June and Iâ€™m shivering in my lab-issued underwear in Fort Worth, Texas. Libby Cowgill, an anthropologist in a furry parka, has wheeled me and my cot into a metal-walled room set to 40 Â°F. A loud fan pummels me from above and siphons the dregs of my body heat through the cotâ€™s mesh from below. A large respirator fits snug over my nose and mouth. The device tracks carbon dioxide in my exhalesâ€”a proxy for how my metabolism speeds up or slows down throughout the experiment. Eventually Cowgill will remove my respirator to slip a wire-thin metal temperature probe several pointy inches into my nose.



Cowgill and a graduate student quietly observe me from the corner of their so-called â€œclimate chamber.â€ Just a few hours earlier Iâ€™d sat beside them to observe as another volunteer, a 24-year-old personal trainer, endured the cold. Every few minutes, they measured his skin temperature with a thermal camera, his core temperature with a wireless pill, and his blood pressure and other metrics that hinted at how his body handles extreme cold. He lasted almost an hour without shivering; when my turn comes, I shiver aggressively on the cot for nearly an hour straight.



Iâ€™m visiting Texas to learn about this experiment on how different bodies respond to extreme climates. â€œWhatâ€™s the record for fastest to shiver so far?â€ I jokingly ask Cowgill as she tapes biosensing devices to my chest and legs. After I exit the cold, she surprises me: â€œYou, believe it or not, were not the worst person weâ€™ve ever seen.â€




Climate change forces us to reckon with the knotty science of how our bodies interact with the environment.




Cowgill is a 40-something anthropologist at the University of Missouri who powerlifts and teaches CrossFit in her spare time. Sheâ€™s small and strong, with dark bangs and geometric tattoos. Since 2022, sheâ€™s spent the summers at the University of North Texas Health Science Center tending to these uncomfortable experiments. Her team hopes to revamp the science of thermoregulation.&nbsp;



While we know in broad strokes how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. â€œWe have the general picture. We donâ€™t have a lot of the specifics for vulnerable groups,â€ says Kristie Ebi, an epidemiologist with the University of Washington who has studied heat and health for over 30 years. â€œHow does thermoregulation work if youâ€™ve got heart disease?â€&nbsp;





â€œEpidemiologists have particular tools that theyâ€™re applying for this question,â€ Ebi continues. â€œBut we do need more answers from other disciplines.â€



Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. Thatâ€™s heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.&nbsp;



Extreme temperatures already threaten large stretches of the world. Populations across the Middle East, Asia, and sub-Â­Saharan Africa regularly face highs beyond widely accepted levels of human heat tolerance. Swaths of the southern US, northern Europe, and Asia now also endure unprecedented lows: The 2021 Texas freeze killed at least 246 people, and a 2023 polar vortex sank temperatures in Chinaâ€™s northernmost city to a hypothermic record of â€“63.4 Â°F.&nbsp;



This change is here, and more is coming. Climate scientists predict that limiting emissions can prevent lethal extremes from encroaching elsewhere. But if emissions keep course, fierce heat and even cold will reach deeper into every continent. About 2.5 billion people in the worldâ€™s hottest places donâ€™t have air-Â­conditioning. When people do, it can make outdoor temperatures even worse, intensifying the heat island effect in dense cities. And neither AC nor radiators are much help when heat waves and cold snaps capsize the power grid.



COURTESY OF MAX G. LEVY







COURTESY OF MAX G. LEVY






COURTESY OF MAX G. LEVY






â€œYou, believe it or not, were not the worst person weâ€™ve ever seen,â€ the author was told after enduring Cowgillâ€™s â€œclimate chamber.â€




Through experiments like Cowgillâ€™s, researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and coldâ€”and how to survive in a new world.&nbsp;



Embodied change



Archaeologists have known for some time that we once braved colder temperatures than anyone previously imagined. Humans pushed into Eurasia and North America well before the last glacial period ended about 11,700 years ago. We were the only hominins to make it out of this era. Neanderthals, Denisovans, and Homo floresiensis all went extinct. We donâ€™t know for certain what killed those species. But we do know that humans survived thanks to protection from clothing, large social networks, and physiological flexibility. Human resilience to extreme temperature is baked into our bodies, behavior, and genetic code. We wouldnâ€™t be here without it.&nbsp;



â€œOur bodies are constantly in communication with the environment,â€ says Cara Ocobock, an anthropologist at the University of Notre Dame who studies how we expend energy in extreme conditions. She has worked closely with Finnish reindeer herders and Wyoming mountaineers.&nbsp;



But the relationship between bodies and temperature is surprisingly still a mystery to scientists. In 1847, the anatomist Carl Bergmann observed that animal species grow larger in cold climates. The zoologist Joel Asaph Allen noted in 1877 that cold-dwellers had shorter appendages. Then thereâ€™s the nose thing: In the 1920s, the British anthropologist Arthur Thomson theorized that people in cold places have relatively long, narrow noses, the better to heat and humidify the air they take in. These theories stemmed from observations of animals like bears and foxes, and others that followed stemmed from studies comparing the bodies of cold-accustomed Indigenous populations with white male control groups. Some, like those having to do with optimization of surface area, do make sense: It seems reasonable that a tall, thin body increases the amount of skin available to dump excess heat. The problem is, scientists have never actually tested this stuff in humans.&nbsp;




â€œOur bodies are constantly in communication with the environment.â€
Cara Ocobock, anthropologist, University of Notre Dame



Some of what we know about temperature tolerance thus far comes from century-old race science or assumptions that anatomy controls everything. But science has evolved. Biology has matured. Childhood experiences, lifestyles, fat cells, and wonky biochemical feedback loops can contribute to a picture of the body as more malleable than anything imagined before. And thatâ€™s prompting researchers to change how they study it.



â€œIf you take someone whoâ€™s super long and lanky and lean and put them in a cold climate, are they gonna burn more calories to stay warm than somebody whoâ€™s short and broad?â€ Ocobock says. â€œNo oneâ€™s looked at that.â€



Ocobock and Cowgill teamed up with Scott Maddux and Elizabeth Cho at the Center for Anatomical Sciences at the University of North Texas Health Fort Worth. All four are biological anthropologists who have also puzzled over whether the rules Bergmann, Allen, and Thomson proposed are actually true.&nbsp;



For the past four years, the team has been studying how factors like metabolism, fat, sweat, blood flow, and personal history control thermoregulation.&nbsp;





Your native climate, for example, may influence how you handle temperature extremes. In a unique study of mortality statistics from 1980s Milan, Italians raised in warm southern Italy were more likely to survive heat waves in the northern part of the country.&nbsp;



Similar trends have appeared in cold climes. Researchers often measure cold tolerance by a personâ€™s â€œbrown adipose,â€ a type of fat that is specialized for generating heat (unlike white fat, which primarily stores energy). Brown fat is a cold adaptation because it delivers heat without the mechanism of shivering. Studies have linked it to living in cold climates, particularly at young ages. Wouter van Marken Lichtenbelt, the physiologist at Maastricht University who with colleagues discovered brown fat in adults, has shown that this tissue can further activate with cold exposure and even help regulate blood sugar and influence how the body burns other fat.&nbsp;



That adaptability served as an early clue for the Texas team. They want to know how a personâ€™s response to hot and cold correlates with height, weight, and body shape. What is the difference, Maddux asks, between â€œa male whoâ€™s 6 foot 6 and weighs 240 poundsâ€ and someone else in the same environment â€œwhoâ€™s 4 foot 10 and weighs 89 poundsâ€? But the team also wondered if shape was only part of the story.&nbsp;



Their multi-year experiment uses tools that anthropologists couldnâ€™t have imagined a century agoâ€”devices that track metabolism in real time and analyze genetics. Each participant gets a CT scan (measuring body shape), a DEXA scan (estimating percentages of fat and muscle), high-resolution 3D scans, and DNA analysis from saliva to examine ancestry genetically.&nbsp;



Volunteers lie on a cot in underwear, as I did, for about 45 minutes in each climate condition, all on separate days. Thereâ€™s dry cold, around 40 Â°F, akin to braving a walk-in refrigerator. Then dry heat and humid heat: 112 Â°F with 15% humidity and 98&nbsp;Â°F with 85% humidity. They call it â€œgoing to Vegasâ€ and â€œgoing to Houston,â€ says Cowgill. The chamber session is long enough to measure an effect, but short enough to be safe.&nbsp;



Before I traveled to Texas, Cowgill told me she suspected the old rules would fall. Studies linking temperature tolerance to race and ethnicity, for example, seemed tenuous because biological anthropologists today reject the concept of distinct races. Itâ€™s a false premise, she told me: â€œNo one in biological anthropology would argue that human beings do not vary across the globeâ€”thatâ€™s obvious to anyone with eyes. [But] you canâ€™t draw sharp borders around populations.â€&nbsp;



She added, â€œI think thereâ€™s a substantial possibility that we spend four years testing this and find out that really, limb length, body mass, surface area [â€¦] are not the primary things that are predicting how well you do in cold and heat.â€&nbsp;



Adaptable to a degree



In July 1995, a week-long heat wave pushed Chicago above 100 Â°F, killing roughly 500 people. Thirty years later, Ollie Jay, a physiologist at the University of Sydney, can duplicate the conditions of that exceptionally humid heat wave in a climate chamber at his laboratory.&nbsp;



â€œWe can simulate the Chicago heat wave of â€™95. The Paris heat wave of 2003. The heat wave [in early July of this year]&nbsp; in Europe,â€ Jay says. â€œAs long as weâ€™ve got the temperature and humidity information, we can re-create those conditions.â€



â€œEverybody has quite an intimate experience of feeling hot, so weâ€™ve got 8 billion experts on how to keep cool,â€ he says. Yet our internal sense of when heat turns deadly is unreliable. Even professional athletes overseen by experienced medics have died after missing dangerous warning signs. And little research has been done to explore how vulnerable populations such as elderly people, those with heart disease, and low-income communities with limited access to cooling respond to extreme heat.&nbsp;



Jayâ€™s team researches the most effective strategies for surviving it. He lambastes air-conditioning, saying it demands so much energy that it can aggravate climate change in â€œa vicious cycle.â€ Instead, he has monitored peopleâ€™s vital signs while they use fans and skin mists to endure three hours in humid and dry heat. In results published last year, his research found that fans reduced cardiovascular strain by 86% for people with heart disease in the type of humid heat familiar in Chicago.&nbsp;





Dry heat was a different story. In that simulation, fans not only didnâ€™t help but actually doubled the rate at which core temperatures rose in healthy older people.



Heat kills. But not without a fight. Your body must keep its internal temperature in a narrow window flanking 98 Â°F by less than two degrees. The simple fact that youâ€™re alive means you are producing heat. Your body needs to export that heat without amassing much more. The nervous system relaxes narrow blood vessels along your skin. Your heart rate increases, propelling more warm blood to your extremities and away from your organs. You sweat. And when that sweat evaporates, it carries a torrent of body heat away with it.&nbsp;



This thermoregulatory response can be trained. Studies by van Marken Lichtenbelt have shown that exposure to mild heat increases sweat capacity, decreases blood pressure, and drops resting heart rate. Long-term studies based on Finnish saunas suggest similar correlations.&nbsp;



The body may adapt protectively to cold, too. In this case, body heat is your lifeline. Shivering and exercise help keep bodies warm. So can clothing. Cardiovascular deaths are thought to spike in cold weather. But people more adapted to cold seem better able to reroute their blood flow in ways that keep their organs warm without dropping their temperature too many degrees in their extremities.&nbsp;



Earlier this year, the biological anthropologist Stephanie B. Levy (no relation) reported that New Yorkers who experienced lower average temperatures had more productive brown fat, adding evidence for the idea that the inner workings of our bodies adjust to the climate throughout the year and perhaps even throughout our lives. â€œDo our bodies hold a biological memory of past seasons?â€ Levy wonders. â€œThatâ€™s still an open question. Thereâ€™s some work in rodent models to suggest that thatâ€™s the case.â€



Although people clearly acclimatize with enough strenuous exposures to either cold or heat, Jay says, â€œyou reach a ceiling.â€ Consider sweat: Heat exposure can increase the amount you sweat only until your skin is completely saturated. Itâ€™s a nonÂ­negotiable physical limit. Any additional sweat just means leaking water without carrying away any more heat. â€œIâ€™ve heard people say weâ€™ll just find a way of evolving out of thisâ€”weâ€™ll biologically adapt,â€ Jay says. â€œUnless weâ€™re completely changing our body shape, then thatâ€™s not going to happen.â€



And body shape may not even sway thermoregulation as much as previously believed. The subject I observed, a personal trainer, appeared outwardly adapted for cold: his broad shoulders didnâ€™t even fit in a single CT scan image. Cowgill supposed that this muscle mass insulated him. When he emerged from his session in the 40 Â°F environment, though, he had finally started shiveringâ€”intensely. The researchers covered him in a heated blanket. He continued shivering. Driving to lunch over an hour later in a hot car, he still mentioned feeling cold. An hour after that, a finger prick drew no blood, a sign that blood vessels in his extremities remained constricted. His body temperature fell about half a degree C in the cold sessionâ€”a significant dropâ€”and his wider build did not appear to shield him from the cold as well as my involuntary shivering protected me.Â 



I asked Cowgill if perhaps there is no such thing as being uniquely predisposed to hot or cold. â€œAbsolutely,â€ she said.&nbsp;



A hot mess



So if body shape doesnâ€™t tell us much about how a person maintains body temperature, and acclimation also runs into limits, then how do we determine how hot is too hot?&nbsp;



In 2010 two climate change researchers, Steven Sherwood and Matthew Huber, argued that regions around the world become uninhabitable at wet-bulb temperatures of 35 Â°C, or 95 Â°F. (Wet-bulb measurements are a way to combine air temperature and relative humidity.) Above 35 Â°C, a person simply wouldnâ€™t be able to dissipate heat quickly enough. But it turns out that their estimate was too optimistic.&nbsp;



Researchers â€œran withâ€ that number for a decade, says Daniel Vecellio, a bioclimatologist at the University of Nebraska, Omaha. â€œBut the number had never been actually empirically tested.â€ In 2021 a Pennsylvania State University physiologist, W. Larry Kenney, worked with Vecellio and others to test wet-bulb limits in a climate chamber. Kenneyâ€™s lab investigates which combinations of temperature, humidity, and time push a personâ€™s body over the edge.&nbsp;



Not long after, the researchers came up with their own wet-bulb limit of human tolerance: below 31 Â°C in warm, humid conditions for the youngest cohort, people in their thermoregulatory prime. Their research suggests that a day reaching 98â€¯Â°F and 65% humidity, for example, poses danger in a matter of hours, even for healthy people.&nbsp;



JUSTIN CLEMONS







JUSTIN CLEMONS






JUSTIN CLEMONS






Cowgill and her colleagues Elizabeth Cho (top) and Scott Maddux prepare graduate student Joanna Bui for a â€œroom-temperature test.â€




In 2023, Vecellio and Huber teamed up, combining the growing arsenal of lab data with state-of-the-art climate simulations to predict where heat and humidity most threatened global populations: first the Middle East and South Asia, then sub-Saharan Africa and eastern China. And assuming that warming reaches 3 to 4 Â°C over preindustrial levels this century, as predicted, parts of North America, South America, and northern and central Australia will be next.&nbsp;



Last June, Vecellio, Huber, and Kenney co-published an article revising the limits that Huber had proposed in 2010. â€œWhy not 35 Â°C?â€ explained why the human limits have turned out to be lower than expected. Those initial estimates overlooked the fact that our skin temperature can quickly jump above 101 Â°F in hot weather, for example, making it harder to dump internal heat.



The Penn State team has published deep dives on how heat tolerance changes with sex and age. Older participantsâ€™ wet-bulb limits wound up being even lowerâ€”between 27 and 28 Â°C in warm, humid conditionsâ€”and varied more from person to person than they did in young people. â€œThe conditions that we experience nowâ€”especially here in North America and Europe, places like thatâ€”are well below the limits that we found in our research,â€ Vecellio says. â€œWe know that heat kills now.â€ &nbsp;



What this fast-growing body of research suggests, Vecellio stresses, is that you canâ€™t define heat risk by just one or two numbers. Last year, he and researchers at Arizona State University pulled up the hottest 10% of hours between 2005 and 2020 for each of 96 US cities. They wanted to compare recent heat-health research with historical weather data for a new perspective: How frequently is it so hot that peopleâ€™s bodies canâ€™t compensate for it? Over 88% of those â€œhot hoursâ€ met that criterion for people in full sun. In the shade, most of those heat waves became meaningfully less dangerous.&nbsp;



â€œThereâ€™s really almost no one who â€˜needsâ€™ to die in a heat wave,â€ says Ebi, the epidemiologist. â€œWe have the tools. We have the understanding. Essentially all [those] deaths are preventable.â€



More than a number



A year after visiting Texas, I called Cowgill to hear what she was thinking after four summers of chamber experiments. She told me that the only rule about hot and cold she currently stands behind is â€¦ well, none.



She recalled a recent participantâ€”the smallest man in the study, weighing 114 pounds. â€œHe shivered like a leaf on a tree,â€ Cowgill says. Normally, a strong shiverer warms up quickly. Core temperature may even climb a little. â€œThis [guy] was just shivering and shivering and shivering and not getting any warmer,â€ she says. She doesnâ€™t know why this happened. â€œEvery time I think I get a picture of whatâ€™s going on in there, weâ€™ll have one person come in and just kind of be a complete exception to the rule,â€ she says, adding that you canâ€™t just gloss over how much human bodies vary inside and out.






The same messiness complicates physiology studies.&nbsp;



Jay looks to embrace bodily complexities by improving physiological simulations of heat and the human strain it causes. Heâ€™s piloted studies that input a personâ€™s activity level and type of clothing to predict core temperature, dehydration, and cardiovascular strain based on the particular level of heat. One can then estimate the personâ€™s risk on the basis of factors like age and health. Heâ€™s also working on physiological models to identify vulnerable groups, inform early-warning systems ahead of heat waves, and possibly advise cities on whether interventions like fans and mists can help protect residents. â€œHeat is an all-of-Â­society issue,â€ Ebi says. Officials could better prepare the public for cold snaps this way too.




â€œDeath is not the only thing weâ€™re concerned about,â€ Jay adds.&nbsp; Extreme temperatures bring morbidity and sickness and strain hospital systems: â€œThereâ€™s all these community-level impacts that weâ€™re just completely missing.â€



Climate change forces us to reckon with the knotty science of how our bodies interact with the environment. Predicting the health effects is a big and messy matter.&nbsp;



The first wave of answers from Fort Worth will materialize next year. The researchers will analyze thermal images to crunch data on brown fat. Theyâ€™ll resolve whether, as Cowgill suspects, your body shape may not sway temperature tolerance as much as previously assumed. â€œHuman variation is the rule,â€ she says, â€œnot the exception.â€&nbsp;



Max G. Levy is an independent journalist who writes about chemistry, public health, and the environment.
â€¢ AI is changing how we quantify pain
  For years at Orchard Care Homes, a 23â€‘facility dementia-care chain in northern England, Cheryl Baird watched nurses fill out the Abbey Pain Scale, an observational methodology used to evaluate pain in those who canâ€™t communicate verbally. Baird, a former nurse who was then the facilityâ€™s director of quality, describes it as â€œa tickâ€‘box exercise where people werenâ€™t truly considering pain indicators.â€



As a result, agitated residents were assumed to have behavioral issues, since the scale does not always differentiate well between pain and other forms of suffering or distress. They were often prescribed psychotropic sedatives, while the pain itself went untreated.



Then, in January 2021, Orchard Care Homes began a trial of PainChek, a smartphone app that scans a residentâ€™s face for microscopic muscle movements and uses artificial intelligence to output an expected pain score. Within weeks, the pilot unit saw fewer prescriptions and had calmer corridors. â€œWe immediately saw the benefits: ease of use, accuracy, and identifying pain that wouldnâ€™t have been spotted using the old scale,â€ Baird recalls.




In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain into something a camera or sensor can score as reliably as blood pressure.




This kind of technology-assisted diagnosis hints at a bigger trend. In nursing homes, neonatal units, and ICU wards, researchers are racing to turn painâ€”medicineâ€™s most subjective vital signâ€”into something a camera or sensor can score as reliably as blood pressure. The push has already produced PainChek, which has been cleared by regulators on three continents and has logged more than 10 million pain assessments. Other startups are beginning to make similar inroads in care settings.



The way we assess pain may finally be shifting, but when algorithms measure our suffering, does that change the way we understand and treat it?



Science already understands certain aspects of pain. We know that when you stub your toe, for example, microscopic alarm bells called nociceptors send electrical impulses toward your spinal cord on â€œexpressâ€ wires, delivering the first stab of pain, while a slower convoy follows with the dull throb that lingers. At the spinal cord, the signal meets a microscopic switchboard scientists call the gate. Flood that gate with friendly touchesâ€”say, by rubbing the bruiseâ€”or let the brain return an instruction born of panic or calm, and the gate might muffle or magnify the message before you even become aware of it.





The gate can either let pain signals pass through or block them, depending on other nerve activity and instructions from your brain. Only the signals that succeed in getting past this gate travel up to your brainâ€™s sensory map to help locate the damage, while others branch out to emotion centers that decide how bad it feels. Within milliseconds, those same hubs in the brain shoot fresh orders back down the line, releasing built-in painkillers or stoking the alarm. In other words, pain isnâ€™t a straightforward translation of damage or sensation but a live negotiation between the body and the brain.



But much of how that negotiation plays out is still a mystery. For instance, scientists cannot predict what causes someone to slip from a routine injury into years-long hypersensitivity; the molecular shift from acute to chronic pain is still largely unknown. Phantom-limb pain remains equally puzzling: About two-thirds of amputees feel agony in a part of their body that no longer exists, yet competing theoriesâ€”cortical remapping, peripheral neuromas, body-schema mismatchâ€”do not explain why they suffer while the other third feel nothing.



The first serious attempt at a system for quantifying pain was introduced in 1921. Patients marked their degree of pain as a point on a blank 10â€‘centimeter line and clinicians scored the distance in millimeters, converting lived experience into a 0â€“100 ladder. By 1975, psychologist Ronaldâ€¯Melzackâ€™s McGill Pain Questionnaire offered 78 adjectives like â€œburning,â€ â€œstabbing,â€ and â€œthrobbing,â€ so that painâ€™s texture could join intensity in the chart. Over the past few decades, hospitals have ultimately settled on the 0â€“10 Numeric Rating Scale.



Yet pain is stubbornly subjective. Feedback from the brain in the form of your reaction can send instructions back down the spinal cord, meaning that expectation and emotion can change how much the same injury hurts. In one trial, volunteers who believed they had received a pain relief cream reported a stimulus as 22% less painful than those who knew the cream was inactiveâ€”and a functional magnetic resonance image of their brains showed that the drop corresponded with decreased activity in the parts of the brain that report pain, meaning they really did feel less hurt.



Whatâ€™s more, pain can also be affected by a slew of external factors. In one study, experimenters applied the same calibrated electrical stimulus to volunteers from Italy, Sweden, and Saudi Arabia, and the ratings varied dramatically. Italian women recorded the highest scores on the 0â€“10 scale, while Swedish and Saudi participants judged the identical burn several points lower, implying that culture can amplify or dampen the felt intensity of the same experience.



Bias inside the clinic can drive different responses even to the same pain score. A 2024 analysis of discharge notes found that womenâ€™s scores were recorded 10% less often than menâ€™s. At a large pediatric emergency department, Black children presenting with limb fractures were roughly 39% less likely to receive an opioid analgesic than their white non-Hispanic peers, even after the researchers controlled for pain score and other clinical factors. Together these studies make clear that an â€œ8 out of 10â€ does not always result in the same reaction or treatment. And many patients cannot self-report their pain at allâ€”for example, a review of bedside studies concludes that about 70% of intensive-care patients have pain that goes unrecognized or undertreated, a problem the authors link to their impaired communication due to sedation or intubation.



These issues have prompted a search for a better, more objective way to understand and assess pain. Progress in artificial intelligence has brought a new dimension to that hunt.



Research groups are pursuing two broad routes. The first listens underneath the skin. Electrophysiologists strap electrode nets to volunteers and look for neural signatures that rise and fall with administered stimuli. A 2024 machine-learning study reported that one such algorithm could tell with over 80% accuracy, using a few minutes of resting-state EEG, which subjects experienced chronic pain and which were pain-free control participants. Other researchers combine EEG with galvanic skin response and heart-rate variability, hoping a multisignal â€œpain fingerprintâ€ will provide more robust measurements.





One example of this method is the PMD-200 patient monitor from Medasense, which uses AI-based tools to output pain scores. The device uses physiological patterns like heart rate, sweating, or peripheral temperature changes as the input and focuses on surgical patients, with the goal of helping anesthesiologists adjust doses during operations. In a 2022 study of 75 patients undergoing major abdominal surgery, use of the monitor resulted in lower self-reported pain scores after the operationâ€”a median score of 3 out of 10, versus 5 out of 10 in controlsâ€”without an increase in opioid use. The device is authorized by the US Food and Drug Administration and is in use in the United States, the European Union, Canada, and elsewhere.



The second path is behavioral. A grimace, a guarded posture, or a sharp intake of breath correlates with various levels of pain. Computer-vision teams have fed high-speed video of patientsâ€™ changing expressions into neural networks trained on the Face Action Coding System (FACS), which was introduced in the late 1970s with the goal of creating an objective and universal system to analyze such expressionsâ€”itâ€™s the Rosetta stone of 44 facial micro-movements. In lab tests, those models can flag frames indicating pain from the data set with over 90% accuracy, edging close to the consistency of expert human assessors. Similar approaches mine posture and even sentence fragments in clinical notes, using natural-language processing, to spot phrases like â€œcurling knees to chestâ€ that often correlate with high pain.



PainChek is one of these behavioral models, and it acts like a cameraâ€‘based thermometer, but for pain: A care worker opens the app and holds a phone 30â€¯centimeters from a personâ€™s face. For three seconds, a neural network looks for nine particular microscopic movementsâ€”upperâ€‘lip raise, brow pinch, cheek tension, and so onâ€”that research has linked most strongly to pain. Then the screen flashes a score ofâ€¯0 toâ€¯42. â€œThereâ€™s a catalogue of â€˜actionâ€‘unit codesâ€™â€”facial expressions common to all humans. Nine of those are associated with pain,â€ explains Kreshnikâ€¯Hoti, a senior research scientist with PainChek and a co-inventor of the device. This system is built directly on the foundation of FACS. After the scan, the app walks the user through a yesâ€‘orâ€‘no checklist of other signs, like groaning, â€œguarding,â€ and sleep disruption, and stores the result on a cloud dashboard that can show trends.



Linking the scan to a humanâ€‘filled checklist was, Hoti admits, a late design choice. â€œInitially, we thought AI should automate everything, but now we see [that] hybrid useâ€”AI plus human inputâ€”is our major strength,â€ he says. Care aides, not nurses, complete most assessments, freeing clinicians to act on the data rather than gather it.



PainChek was cleared by Australiaâ€™s Therapeutic Goods Administration in 2017, and national rollout funding from Canberra helped embed it in hundreds of nursing homes in the country. The system has also won authorization in the UKâ€”where expansion began just before covid-19 started spreading and resumed as lockdowns easedâ€”and in Canada and Newâ€¯Zealand, which are running pilot programs. In the US, itâ€™s currently awaiting an FDA decision. Companyâ€‘wide data show â€œabout a 25% drop in antiÂ­psychotic use and, in Scotland, a 42% reduction in falls,â€ Hoti says.



PainChek is a mobile app that estimates pain scores by applying artificial intelligence to facial scans.COURTESY OF PAINCHEK




Orchard Care Homes is one of its early adopters. Baird, then the facilityâ€™s director of quality, remembers the preâ€‘AI routine that was largely done â€œto prove compliance,â€ she says.



PainChek added an algorithm to that workflow, and the hybrid approach has paid off. Orchardâ€™s internal study of four care homes tracked monthly pain scores, behavioral incidents, and prescriptions. Within weeks, psychotropic scripts fell and residentsâ€™ behavior calmed. The ripple effects went beyond pharmacy tallies. Residents who had skipped meals because of undetected dental pain â€œbegan eating again,â€ Baird notes, and â€œthose who were isolated due to pain began socializing.â€



Inside Orchard facilities, a cultural shift is underway. When Baird trained new staff, she likened pain â€œto measuring blood pressure or oxygen,â€ she says. â€œWe wouldnâ€™t guess those, so why guess pain?â€ The analogy lands, but getting people fully on board is still a slog. Some nurses insist their clinical judgment is enough; others balk at another login and audit trail. â€œThe sector has been slow to adopt technology, but itâ€™s changing,â€ Baird says. Thatâ€™s helped by the fact that administering a full Abbey Pain Scale takes 20â€¯minutes, while a PainChek scan and checklist take less than five.



Engineers at PainChek are now adapting the code for the very youngest patients. PainChekâ€¯Infant targets babies under one year, whose grimaces flicker faster than adultsâ€™. The algorithm, retrained on neonatal faces, detects six validated facial action units based on the well-established Baby Facial Action Coding System. PainChek Infant is starting limited testing in Australia while the company pursues a separate regulatory pathway.



Skeptics raise familiar red flags about these devices. Facialâ€‘analysis AI has a history of skinâ€‘tone bias, for example. Facial analysis may also misread grimaces stemming from nausea or fear. The tool is only as good as the yesâ€‘orâ€‘no answers that follow the scan; sloppy data entry can skew results in either direction. Results lack the broader clinical and interpersonal context a caregiver is likely to have from interacting with individual patients regularly and understanding their medical history. Itâ€™s also possible that clinicians might defer too strongly to the algorithm, over-relying on outside judgment and eroding their own.



If PainChek is approved by the FDA this fall, it will be part of a broader effort to create a system of new pain measurement technology. Other startups are pitching EEG headbands for neuropathic pain, galvanic skin sensors that flag breakthrough cancer pain, and even language models that comb nursing notes for evidence of hidden distress. Still, quantifying pain with an external device could be rife with hidden issues, like bias or inaccuracies, that we will uncover only after significant use.



For Baird, the issue is fairly straightforward nonetheless. â€œIâ€™ve lived with chronic pain and had a hard time getting people to believe me. [PainChek] would have made a huge difference,â€ she says. If artificial intelligence can give silent sufferers a numerical voiceâ€”and make clinicians listenâ€”then adding one more line to the vitalâ€‘sign chart might be worth the screen time.



Deena Mousa is a researcher, grantmaker, and journalist focused on global health, economic development, and scientific and technological progress.



Mousa is employed as lead researcher by Open Philanthropy, a funder and adviser focused on high-impact causes, including global health and the potential risks posed by AI. The research team investigates new causes of focus and is not involved in work related to pain management. Mousa has not been involved with any grants related to pain management, although Open Philanthropy has funded research in this area in the past.
â€¢ Big Techâ€™s big bet on a controversial carbon removal tactic
  Over the last century, much of the US pulp and paper industry crowded into the southeastern corner of the nation, setting up mills amid sprawling timber forests to strip the fibers from juvenile loblolly, long leaf, and slash pine trees.



Today, after the factories chip the softwood and digest it into pulp, the leftover lignin, spent chemicals, and remaining organic matter form a dark, syrupy by-product known as black liquor. Itâ€™s then concentrated into a biofuel and burned, which heats the towering boilers that power the facilityâ€”and releases carbon dioxide into the air.



Microsoft, JP MorganChase, and a tech company consortium that includes Alphabet, Meta, Shopify, and Stripe have all recently struck multimillion-dollar deals to pay paper mill owners to capture at least hundreds of thousands of tons of this greenhouse gas by installing carbon scrubbing equipment in their facilities.



The captured carbon dioxide will then be piped down into saline aquifers more than a mile underground, where it should be sequestered permanently.



Big Tech is suddenly betting big on this form of carbon removal, known as bioenergy with carbon capture and storage, or BECCS. The sector also includes biomass-fueled power plants, waste incinerators, and biofuel refineries that add carbon capturing equipment to their facilities.Since trees and other plants absorb carbon dioxide through photosynthesis and these factories will trap emissions that would have gone into the air, together they can theoretically remove more greenhouse gas from the atmosphere than was released, achieving whatâ€™s known as â€œnegative emissions.â€



The companies that pay for this removal can apply that reduction in carbon dioxide to cancel out a share of their own corporate pollution. BECCS now accounts for nearly 70% of the announced contracts in carbon removal, a popularity due largely to the fact that it can be tacked onto industrial facilities already operating on large scales.



â€œIf weâ€™re balancing cost, time to market, and ultimate scale potential, BECCS offers a really attractive value proposition across all three of those,â€ says Brian Marrs, senior director of energy and carbon removal at Microsoft, which has become by far the largest buyer of carbon removal credits as it races to balance out its ongoing emissions by the end of the decade.



But experts have raised a number of concerns about various approaches to BECCS, stressing they may inflate the climate benefits of the projects, conflate prevented emissions with carbon removal, and extend the life of facilities that pollute in other ways. It could also create greater financial incentives to log forests or convert them to agricultural land.&nbsp;



When greenhouse-gas sources and sinks are properly tallied across all the fields, forests, and factories involved, itâ€™s highly difficult to achieve negative emissions with many approaches to BECCS, says Tim Searchinger, a senior research scholar at Princeton University. That undermines the logic of dedicating more of the worldâ€™s limited land, crops, and woods to such projects, he argues.



â€œI call it a â€˜BECCS and switch,â€™â€ he says, adding later: â€œItâ€™s folly at some level.â€



The logic of BECCS



For a biomass-fueled power plant, BECCS works like this:A tree captures carbon dioxide from the atmosphere as it grows, sequestering the carbon in its bark, trunk, branches, and roots while releasing the oxygen. Someone then cuts it down, converts it into wood pellets, and delivers it to a power plant that, in turn, burns the wood to produce heat or electricity.



Usually, that facility will produce carbon dioxide as the wood incinerates. But under both European Union and US rules, the burning of the wood is generally treated as carbon neutral, so long as the timber forests are managed in sustainable ways and the various operations abide by other regulations. The argument is that the tree pulled CO2 out of the air in the first place, and new plant growth will bring that emissions debt back into balance over time.&nbsp;



If that same power plant now captures a significant share of the greenhouse gas produced in the process and pumps it underground, the process can potentially go from carbon neutral to carbon negative.



But the starting assumption that biomass is carbon neutral is fundamentally flawed, because it doesnâ€™t fully take into account other ways that emissions are released throughout the process, according to Searchinger.



Among other things, a proper analysis must also ask: How much carbon is left behind in roots or branches on the forest floor that will begin to decompose and release greenhouse gases after the plant is removed? How much fossil fuel was burned in the process of cutting, collecting, and distributing the biomass? How much greenhouse gas was produced while converting timber into wood pellets and shipping them elsewhere? And how long will it take to grow back the trees or plants that would have otherwise continued capturing and storing carbon?



â€œIf youâ€™re harvesting wood, itâ€™s essentially impossible to get negative emissions,â€ Searchinger says.



Burning biomass, or the biofuels created from it, can also produce other forms of pollution that can harm human health, including particulate matter, volatile organic compounds, sulfur dioxide, and carbon monoxide.



Preventing carbon dioxide emissions at a given factory may necessitate capturing certain other pollutants as well, notably sulfur dioxide. But it doesnâ€™t necessarily filter out all the other pollution floating out of the flue stack, notes Emily Grubert, an associate professor of sustainable energy policy at the University of Notre Dame who focuses on carbon management issues and the transition away from fossil fuels.&nbsp;



Driving demand



The idea that we might be able to use biomass to generate energy and suck down carbon dates back decades. But as global temperatures and emissions both continued to rise, climate modelers found that more and more BECCS or other types of carbon removal would be needed to prevent the planet from tipping past increasingly dangerous warming thresholds.



In addition to dramatic cuts in emissions, the world may need to suck down 11 billion tons of carbon dioxide per year by 2050 and 20 billion by 2100 to limit warming to 2 Â°C over preindustrial levels, according to a 2022 UN climate panel report. Thatâ€™s a threshold weâ€™re increasingly likely to blow past.



These grave climate warnings sparked growing interest and investments in ways to draw carbon dioxide out of the atmosphere. Companies sprang up offering to sink seaweed, bury biomass, develop carbon-sucking direct air capture factories, and add alkaline substances to agricultural fields or the oceans.&nbsp;



But BECCS purchases have dwarfed those other approaches.







For companies with fast-approaching climate deadlines, BECCS is one of the few options for removing hundreds of thousands of tons over the next few years, says Robert HÃ¶glund, who cofounded CDR.fyi, â€‹â€‹a public-benefit corporation that analyzes the carbon removal sector.



â€œIf you have a target you want to meet in 2030 and you want durable carbon removal, thatâ€™s the thing you can buy,â€ he says.



Thatâ€™s chiefly because these projects can harness the infrastructure of existing industries. At least for now, you donâ€™t have to finance, permit, and develop new facilities.



â€œTheyâ€™re not that hard to build, because itâ€™s often a retrofitting of an existing plant,â€ HÃ¶glund says.&nbsp;



BECCS is also substantially less expensive for buyers than, say, direct air capture, with weighted average prices of $210 a ton compared with $490 among the deals to date, according to CDR.fyi. Thatâ€™s in part because capturing the carbon dioxide from, say, a pulp and paper mill, where it makes up around 15% of flue gas, takes far less energy than plucking CO2 molecules out of the open air, where they account for just 0.04%.



Microsoftâ€™s big BECCS bet



In 2020, Microsoft announced plans to become carbon negative by the end of this decade and, by midcentury, to remove all the emissions the company generated directly and from electricity use throughout its corporate history.&nbsp;



Itâ€™s leaning particularly heavily on BECCS to meet those climate commitments, with the category accounting for 76% of its known carbon removal purchases to date.



In April, the company announced it would purchase 3.7 million tons of carbon dioxide that a paper and pulp mill, located at some unspecified site in the southern US, will eventually capture and store over a 12-year period. It reached the deal through CO280, a startup based in Vancouver, British Columbia, that is forming joint ventures with paper and pulp mill companies in the US and Canada, to finance, develop, and operate the projects.&nbsp;



It was the biggest carbon removal purchase on recordâ€”until four days later, when Microsoft revealed it had agreed to buy 6.75 million tons of carbon removal from AtmosClear, CDR.fyi noted. That company is building a biomass power plant at the Port of Greater Baton Rouge in Louisiana, which will run largely on sugarcane bagasse (a by-product of sugar production) and forest trimmings. AtmosClear says the facility will be able to capture 680,000 tons of carbon dioxide per year.



â€œWhat weâ€™ve seen is a lot of these BECCS projects have been very helpful, if not transformational, for providing investment in rural economies,â€ Marrs says. â€œWe look at our BECCS deals, in Louisiana with AtmosClear and some other Gulf State providers, like CO280, as a real means of helping support these economies, while at the same time promoting sustainable forestry practices.â€



In earlier quarters, Microsoft also made substantial purchases from Orsted, which operates power plants that burn wood pellets; Gaia, which runs facilities that convert municipal waste into energy; and Arbor, whose plants are fueled by â€œovergrown brush, crop residues, and food waste.â€&nbsp;



Donâ€™t let waste go to waste



Notably, at least three of these projects rely on some form of waste, a category distinct from fresh-cut timber or crops grown for the purpose of fueling BECCS projects. Solid waste, agricultural residues, logging leftovers, and plant material removed from forests to prevent fires present some of the ripest opportunities for BECCSâ€”as well as some difficult questions of carbon accounting.



A 2019 report from the National Academy of Sciences estimated that the US could achieve more than 500 million tons of carbon removal a year through BECCS by 2040, while the world could exceed 3.5 billion tons, by relying just on agricultural by-products, logging residues, and organic wasteâ€”without needing to grow crops dedicated to energy.



Roger Aines, chief scientist of the energy program at Lawrence Livermore National Laboratory, argues we should at least be putting these sources to use rather than burning them or leaving them to decompose in fields. (Aines coauthored a similar analysis focused on Californiaâ€™s waste biomass and contributed to a 2022 lab report prepared for Microsoft to evaluate costs and options for carbon removal purchases.)



He stresses that the BECCS sector can learn a lot from using that waste material. For example, it should help to provide a sharper sense of whether the carbon math will work if more land, forests, and crops are dedicated to these sorts of purposes.



â€œThe point is you wonâ€™t grow new material to do this in most cases, and wonâ€™t have to for a very long time, because thereâ€™s so much waste available,â€ Aines says. â€œIf we get to that point, long into the future, we can address that then.â€



Wonky accounting



But the critical question that emerges with waste is: Would it otherwise have been burned or allowed to decompose, or might some of it have been used in some other way that kept the carbon out of the atmosphere?&nbsp;



Sugarcane bagasse, for instance, is or could also be used to produce recyclable packaging and paper, biodegradable food packaging and cutlery, building materials, or soil amendments that add nutrients back to agricultural fields.



â€œA lot of the time those materials are being used for something else already, so the accounting gets wonky really quickly,â€ Grubert says.&nbsp;



Some fear that the financial incentives to pursue BECCS could also compel companies to trim away more trees and plants than is truly necessary to, say, manage forests or prevent firesâ€”particularly as more and more BECCS plants create greater and greater demand for the limited supplies of such materials.



â€œOnce you start capturing waste, you create an incentive to produce waste, so you have to be very careful about the perverse incentives,â€ says Danny Cullenward, a researcher and senior fellow at the Kleinman Center for Energy Policy at the University of Pennsylvania who studies carbon markets.



Due diligence&nbsp;



Like other big tech companies, Microsoft has lost some momentum when it comes to its climate goals, in large part because of the surging energy demands of its AI data centers.&nbsp;



But the company has generally earned a reputation for striving to clean up its direct emissions where possible and for seeking out high-quality approaches to carbon removal. It has consulted extensively with critically minded researchers at advisory firms like Carbon Direct and demonstrated a willingness to pay higher prices to support more credible projects.



Marrs says the company has extended that scrutiny to its BECCS deals.



â€œWe want as much positive environmental impact as possible from every project,â€ he says.



â€œWeâ€™re doing months and months of technical due diligence with teams that visit the site, that interview stakeholders, that produce a report for us that we go through in depth with a third-party engineering provider or technical perspective provider,â€ he adds.



In a follow-up statement, Microsoft stressed that it strives to validate that every BECCS project it supports will achieve negative emissions, whatever the fuel source.



â€œAcross all of these projects, we conducted substantial due diligence to ensure that BECCS feedstocks would otherwise return carbon to the atmosphere in a few years,â€ the company said.&nbsp;



Likewise, Jonathan Rhone, the cofounder and chief executive of CO280, stresses that theyâ€™ve worked with consultants, carbon market registries, and pulp and paper mills â€œto make sure weâ€™re adopting the best standards.â€ He says they strive to conservatively assess the release and uptake of greenhouse gases across the supply chain of the mills they work with, taking into account the type of biomass used by a given plant, the growth rate of the forests itâ€™s harvested from, the distance trucks drive to ship the timber or sawmill residues, the total emissions of the facility, and more.



Rhone says its typical projects will capture and store away on the order of 850,000 to 900,000 tons of carbon dioxide per year. How much that would make up of the plantâ€™s total emissions would vary, based in part on how much of the facilityâ€™s energy comes from by-product biomatter and how much comes from fossil fuels. For its first projects, the company will aim to capture 50% to 65% of the CO2 emissions at the pulp and paper mills, but it eventually hopes to exceed 90%.&nbsp;



In a follow-up email, Rhone said the carbon capture equipment at the mills it works with will also prevent â€œsubstantial levelsâ€ of particulate matter and sulfur dioxide emissions and might reduce emissions of other pollutants as well.



The company is in active discussions with 10 pulp and paper mills in the Gulf Coast and Canada. Each carbon capture and storage project could cost hundreds of millions of dollars.&nbsp;



â€œWhat weâ€™re trying to do at CO280 is show and demonstrate that we can create a stable, repeatable playbook for developing projects that are low risk and provide the market with what it wants, with what it needs,â€ Rhone says.&nbsp;



Proponents of BECCS say we could leverage biomass to deliver substantial volumes of carbon removal, so long as appropriate industry standards are put in place to prevent, or at least minimize, bad behavior.



The question is whether that will be the caseâ€”or whether, as the BECCS sector matures, it will veer closer to the pattern of carbon offset markets.&nbsp;



Studies and investigations have consistently shown that loosely regulated or poorly designed carbon credit and offset programs have allowed, if not invited, companies to significantly exaggerate the climate benefits of tree planting, forest preservation, and similar projects.&nbsp;



â€œIt appears to me to be something that will be manageable but that weâ€™ll always have to keep an eye on,â€ Aines says.&nbsp;



Magic



Even with all these carbon accounting complexities, BECCS projects can often deliver climate benefits, particularly for existing plants.



Adding carbon capture to an operating paper and pulp mill, power plant, or refinery is at least an improvement over the status quo from a climate perspective, insofar as it prevents emissions that would otherwise have continued.



But ambitions for BECCS are already growing beyond existing plants: Last year Drax, the controversial UK power giant, announced plans to launch a Houston-based division tasked with developing enough new BECCS projects to deliver 6 million tons of carbon removal per year, in the US or elsewhere.



Numerous other companies have also built or proposed biomass power plants in recent years, with or without carbon capture systemsâ€”decisions driven in part by policies that classify them as carbon neutral.But if biomass isnâ€™t carbon neutral, as Searchinger and others argue it canâ€™t be in many applications, then these new unfiltered power plants are just adding more emissions to the atmosphereâ€”and BECCS projects arenâ€™t drawing any out of the air. And if thatâ€™s the case, it raises tough questions about corporate climate claims that depend on its doing so and the societal trade-offs involved in building lots of new plants dedicated to these purposes.



Thatâ€™s because crops grown for energy require land, fertilizer, insecticides, and human labor that might otherwise go toward producing food for an expanding global population. And greater demand for wood invites the timber industry to chop down more and more of the worldâ€™s forests, which are already sucking up and storing away vast amounts of carbon dioxide and providing homes for immense varieties of plants and animals.



If these projects are merely preventing greenhouse gas from floating into the atmosphere but not drawing any down, weâ€™re better off adding carbon capture and storage (CCS) equipment to an existing natural-gas plant instead, Searchinger argues.



Companies may think that harnessing nature to draw carbon dioxide out of the sky sounds better than cutting the emissions of a fossil-fuel turbine. But the electricity from the latter plant would cost dramatically less, the carbon capture system would reduce emissions more for the amount of same energy generated, and it would avoid the added pressures to cut down trees, he says.



â€œPeople think some magic happensâ€”this magic combination of using biomass and CCS creates something bigger than its parts,â€ Searchinger says. â€œBut itâ€™s not magic; itâ€™s simply the sum of the two.â€
â€¢ The Download: aging clocks, and repairing the internet
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



How aging clocks can help us understand why we ageâ€”and if we can reverse it



Wrinkles and gray hairs aside, it can be difficult to know how wellâ€”or poorlyâ€”someoneâ€™s body is truly aging. A person who develops age-related diseases earlier in life, or has other biological changes associated with aging, might be considered â€œbiologically olderâ€ than a similar-age person who doesnâ€™t have those changes. Some 80-year-olds will be weak and frail, while others are fit and active.Over the past decade, scientists have been uncovering new methods of looking at the hidden ways our bodies are aging. And what theyâ€™ve found is changing our understanding of aging itself. Read the full story.



â€”Jessica Hamzelou







Can we repair the internet?



From addictive algorithms to exploitative apps, data mining to misinformation, the internet today can be a hazardous place. New books by three influential figuresâ€”the intellect behind â€œnet neutrality,â€ a former Meta executive, and the webâ€™s own inventorâ€”propose radical approaches to fixing it. But are these luminaries the right people for the job? Read the full story.



â€”Nathan Smith



Both these stories are from our forthcoming print issue, which is all about the body. If you havenâ€™t already, subscribe now to receive future issues once they land. Plus, you&#8217;ll also receive a free digital report on nuclear power.







2025 climate tech companies to watch: Cyclic Materials and its rare earth recycling tech



Rare earth magnets are essential for clean energy, but only a tiny fraction of the metals inside them are ever recycled. Cyclic Materials aims to change that by opening one of the largest rare earth magnet recycling operations outside of China next year.&nbsp;



By collecting a wide range of devices and recycling multiple metals, the company seeks to overcome the economic challenges that have long held back such efforts. Read the full story.



â€”Maddie Stone



Cyclic Materials is one of our 10 climate tech companies to watchâ€”our annual list of some of the most promising climate tech firms on the planet. Check out the rest of the list here.







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 Californiaâ€™s AI safety bill has been signed into lawÂ Â Â It holds AI companies legally accountable if their chatbots fail to protect users. (TechCrunch)+ It also requires chatbots to remind young users that theyâ€™re not human. (The Verge)+ Gavin Newsom also green-lit measures for social media warning labels. (The Hill)



2 Satellites are leaking unencrypted dataIncluding civilian text messages, plus military and law enforcement communications. (Wired $)+ Itâ€™s getting mighty crowded up there too. (Space)3 Defense startups are reviving manufacturing in quiet US townsThe weapons of the future are being built in Delaware, Michigan and Ohio. (NYT $)+ Phase two of military AI has arrived. (MIT Technology Review)



4 Europe is worried about becoming an AI â€œcolonyâ€The bloc is too dependent on US tech, experts fear. (FT $)+ The US is locked in a bind with China. (Rest of World)5 Vast chunks of human knowledge are missing from the webÂ And AI is poised to make the problem even worse. (Aeon)+ How AI and Wikipedia have sent vulnerable languages into a doom spiral. (MIT Technology Review)



6 How mega batteries are unlocking an energy revolutionVast battery units are helping to shore up grids and extend the use of clean power. (FT $)+ This startup wants to use the Earth as a massive battery. (MIT Technology Review)



7 A new chemical detection technique reveals whatâ€™s making wildlife illItâ€™s a small step toward a healthier future for all animalsâ€”including humans. (Knowable Magazine)+ Weâ€™re inhaling, eating, and drinking toxic chemicals. Now we need to figure out how theyâ€™re affecting us. (MIT Technology Review)



8 The world is growing more food crops than ever beforeBut hunger still hasnâ€™t been eradicated. (Vox)+ Africa fights rising hunger by looking to foods of the past. (MIT Technology Review)



9 Google is starting to hide sponsored search resultsOnly after youâ€™ve seen them first. (The Verge)+ Is Google playing catchup on search with OpenAI? (MIT Technology Review)



10 Indonesiaâ€™s film industry is embracing AITo the detriment of artists and storyboarders. (Rest of World)







Quote of the day



â€œIt is attempting to solve a problem that wasnâ€™t a problem before AI showed up, or before big tech showed up.â€



â€”Greg Loudon, a certified beer judge and brewery sales manager, tells 404 Media why heâ€™s so unimpressed by a prominent competition using AI to judge the quality of beer.







One more thing







The lucky break behind the first CRISPR treatmentThe worldâ€™s first commercial gene-editing treatment is set to start changing the lives of people with sickle-cell disease. Itâ€™s called Casgevy, and it was approved in November 2022 in the UK.The treatment, which will be sold in the US by Vertex Pharmaceuticals, employs CRISPR, which can be easily programmed by scientists to cut DNA at precise locations they choose.But where do you aim CRISPR, and how did the researchers know what DNA to change? Thatâ€™s the lesser-known story of the sickle-cell breakthrough. Read more about it.



â€”Antonio Regalado







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Why you should consider adopting a â€œcoffee name.â€+ Where does your favorite Star Wars character rank in this ultimate list? (Number one is correct.)+ Steve McQueen, you will always be cool.+ The compelling argument for adopting an ethical diet.
â€¢ How aging clocks can help us understand why we ageâ€”and if we can reverse it
  Be honest: Have you ever looked up someone from your childhood on social media with the sole intention of seeing how theyâ€™ve aged?&nbsp;



One of my colleagues, who shall remain nameless, certainly has. He recently shared a photo of a former classmate. â€œCan you believe weâ€™re the same age?â€ he asked, with a hint of glee in his voice. A relative also delights in this pastime. â€œWow, she looks like an old woman,â€ sheâ€™ll say when looking at a picture of someone she has known since childhood. The years certainly are kinder to some of us than others.



But wrinkles and gray hairs aside, it can be difficult to know how wellâ€”or poorlyâ€”someoneâ€™s body is truly aging, under the hood. A person who develops age-related diseases earlier in life, or has other biological changes associated with aging (such as elevated cholesterol or markers of inflammation), might be considered â€œbiologically olderâ€ than a similar-age person who doesnâ€™t have those changes. Some 80-year-olds will be weak and frail, while others are fit and active.&nbsp;





Doctors have long used functional tests that measure their patientsâ€™ strength or the distance they can walk, for example, or simply â€œeyeballâ€ them to guess whether they look fit enough to survive some treatment regimen, says Tamir Chandra, who studies aging at the Mayo Clinic.&nbsp;



But over the past decade, scientists have been uncovering new methods of looking at the hidden ways our bodies are aging. What theyâ€™ve found is changing our understanding of aging itself.&nbsp;



â€œAging clocksâ€ are new scientific tools that can measure how our organs are wearing out, giving us insight into our mortality and health. They hint at our biological age. While chronological age is simply how many birthdays weâ€™ve had, biological age is meant to reflect something deeper. It measures how our bodies are handling the passing of time andâ€”perhapsâ€”lets us know how much more of it we have left. And while you canâ€™t change your chronological age, you just might be able to influence your biological age.



Itâ€™s not just scientists who are using these clocks. Longevity influencers like Bryan Johnson often use them to make the case that they are aging backwards. â€œMy telomeres say Iâ€™m 10 years old,â€ Johnson posted on X in April. The Kardashians have tried them too (KhloÃ© was told on TV that her biological age was 12 years below her chronological age). Even my local health-food store offers biological age testing. Some are pushing the use of clocks even further, using them to sell unproven â€œanti-agingâ€ supplements.



The science is still new, and few experts in the fieldâ€”some of whom affectionately refer to it as â€œclock worldâ€â€”would argue that an aging clock can definitively reveal an individualâ€™s biological age.&nbsp;



But their work is revealing that aging clocks can offer so much more than an insta-brag, a snake-oil pitchâ€”or even just an eye-catching number. In fact, they are helping scientists unravel some of the deepest mysteries in biology: Why do we age? How do we age? When does aging begin? What does it even mean to age?



Ultimately, and most importantly, they might soon tell us whether we can reverse the whole process.



Clocks kick off



The way your genes work can change. Molecules called methyl groups can attach to DNA, controlling the way genes make proteins. This process is called methylation, and it can potentially occur at millions of points along the genome. These epigenetic markers, as they are known, can switch genes on or off, or increase or decrease how much protein they make. Theyâ€™re not part of our DNA, but they influence how it works.



In 2011, Steve Horvath, then a biostatistician at the University of California, Los Angeles, took part in a study that was looking for links between sexual orientation and these epigenetic markers. Steve is straight; he says his twin brother, Markus, who also volunteered, is gay.



That study didnâ€™t find a link between DNA methylÂ­ation and sexual orientation. But when Horvath looked at the data, he noticed a different trendâ€”a very strong link between age and methylation at around 88 points on the genome. He once told me he fell off his chair when he saw it.Â 



Many of the affected genes had already been linked to age-related brain and cardiovascular diseases, but it wasnâ€™t clear how methylation might be related to those diseases.&nbsp;




If a model could work out what average aging looks like, it could potentially estimate whether someone was aging unusually fast or slowly. It could transform medicine and fast-track the search for an anti-aging drug. It could help us understand what aging is, and why it happens at all.




In 2013, Horvath collected methylation data from 8,000 tissue and cell samples to create what he called the Horvath clockâ€”essentially a mathematical model that could estimate age on the basis of DNA methylation at 353 points on the genome. From a tissue sample, it was able to detect a personâ€™s age within a range of 2.9 years.



That clock changed everything. Its publication in 2013 marked the birth of â€œclock world.â€ To some, the possibilities were almost endless. If a model could work out what average aging looks like, it could potentially estimate whether someone was aging unusually fast or slowly. It could transform medicine and fast-track the search for an anti-aging drug. It could help us understand what aging is, and why it happens at all.



The epigenetic clock was a success story in â€œa field that, frankly, doesnâ€™t have a lot of success stories,â€ says JoÃ£o Pedro de MagalhÃ£es, who researches aging at the University of Birmingham, UK.



It took a few years, but as more aging researchers heard about the clock, they began incorporating it into their research and even developing their own clocks. Horvath became a bit of a celebrity. Scientists started asking for selfies with him at conferences, he says. Some researchers even made T-shirts bearing the front page of his 2013 paper.





Some of the many other aging clocks developed since have become notable in their own right. Examples include the PhenoAge clock, which incorporates health data such as blood cell counts and signs of inflammation along with methylÂ­ation, and the Dunedin Pace of Aging clock, which tells you how quickly or slowly a person is aging rather than pointing to a specific age. Many of the clocks measure methylation, but some look at other variables, such as proteins in blood or certain carbohydrate molecules that attach to such proteins.



Today, there are hundreds or even thousands of clocks out there, says Chiara Herzog, who researches aging at Kingâ€™s College London and is a member of the Biomarkers of Aging Consortium. Everyone has a favorite. Horvath himself favors his GrimAge clock, which was named after the Grim Reaper because it is designed to predict time to death.



That clock was trained on data collected from people who were monitored for decades, many of whom died in that period. Horvath wonâ€™t use it to tell people when they might die of old age, he stresses, saying that it wouldnâ€™t be ethical. Instead, it can be used to deliver a biological age that hints at how long a person might expect to live. Someone who is 50 but has a GrimAge of 60 can assume that, compared with the average 50-year-old, they might be a bit closer to the end.



GrimAge is not perfect. While it can strongly predict time to death given the health trajectory someone is on, no aging clock can predict if someone will start smoking or get a divorce (which generally speeds aging) or suddenly take up running (which can generally slow it). â€œPeople are complicated,â€ Horvath tells MIT Technology Review. â€œThereâ€™s a huge error bar.â€



On the whole, the clocks are pretty good at making predictions about health and lifespan. Theyâ€™ve been able to predict that people over the age of 105 have lower biological ages, which tracks given how rare it is for people to make it past that age. A higher epigenetic age has been linked to declining cognitive function and signs of Alzheimerâ€™s disease, while better physical and cognitive fitness has been linked to a lower epigenetic age.



Black-box clocks



But accuracy is a challenge for all aging clocks. Part of the problem lies in how they were designed. Most of the clocks were trained to link age with methylation. The best clocks will deliver an estimate that reflects how far a personâ€™s biology deviates from the average. Aging clocks are still judged on how well they can predict a personâ€™s chronological age, but you donâ€™t want them to be too close, says Lucas Paulo de Lima Camillo, head of machine learning at Shift Bioscience, who was awarded $10,000 by the Biomarkers of Aging Consortium for developing a clock that could estimate age within a range of 2.55 years.



None of the clocks are precise enough to predict the biological age of a single person. Putting the same biological sample through five different clocks will give you five wildly different results.LEON EDLER




â€œThereâ€™s this paradox,â€ says Camillo. If a clock is really good at predicting chronological age, thatâ€™s all it will tell youâ€”and it probably wonâ€™t reveal much about your biological age. No one needs an aging clock to tell them how many birthdays theyâ€™ve had. Camillo says heâ€™s noticed that when the clocks get too close to â€œperfectâ€ age prediction, they actually become less accurate at predicting mortality.



Therein lies the other central issue for scientists who develop and use aging clocks: What is the thing they are really measuring? It is a difficult question for a field whose members notoriously fail to agree on the basics. (Everything from the definition of aging to how it occurs and why is up for debate among the experts.)



They do agree that aging is incredibly complex. A methylation-based aging clock might tell you about how that collection of chemical markers compares across individuals, but at best, itâ€™s only giving you an idea of their â€œepigenetic age,â€ says Chandra. There are probably plenty of other biological markers that might reveal other aspects of aging, he says: â€œNone of the clocks measure everything.â€&nbsp;



We donâ€™t know why some methyl groups appear or disappear with age, either. Are these changes causing damage? Or are they a by-product of it? Are the epigenetic patterns seen in a 90-year-old a sign of deterioration? Or have they been responsible for keeping that person alive into very old age?



To make matters even more complicated, two different clocks can give similar answers by measuring methylation at entirely different regions of the genome. No one knows why, or which regions might be the best ones to focus on.



â€œThe biomarkers have this black-box quality,â€ says Jesse Poganik at Brigham and Womenâ€™s Hospital in Boston. â€œSome of them are probably causal, some of them may be adaptive â€¦ and some of them may just be neutralâ€: either â€œthereâ€™s no reason for them not to happenâ€ or â€œthey just happen by random chance.â€



What we know is that, as things stand, none of the clocks are precise enough to predict the biological age of a single person (sorry, KhloÃ©). Putting the same biological sample through five different clocks will give you five wildly different results.



Even the same clock can give you different answers if you put a sample through it more than once. â€œTheyâ€™re not yet individually predictive,â€ says Herzog. â€œWe donâ€™t know what [a clock result] means for a person, [or if] theyâ€™re more or less likely to develop disease.â€



And itâ€™s why plenty of aging researchersâ€”even those who regularly use the clocks in their workâ€”havenâ€™t bothered to measure their own epigenetic age. â€œLetâ€™s say I do a clock and it says that my biological age â€¦ is five years older than it should be,â€ says MagalhÃ£es. â€œSo what?â€ He shrugs. â€œI donâ€™t see much point in it.â€



You might think this lack of clarity would make aging clocks pretty useless in a clinical setting. But plenty of clinics are offering them anyway. Some longevity clinics are more careful, and will regularly test their patients with a range of clocks, noting their results and tracking them over time. Others will simply offer an estimate of biological age as part of a longevity treatment package.



And then there are the people who use aging clocks to sell supplements. While no drug or supplement has been definitively shown to make people live longer, that hasnâ€™t stopped the lightly regulated wellness industry from pushing a range of â€œtreatmentsâ€ that range from lotions to herbal pills all the way through to stem-cell injections.



Some of these people come to aging meetings. I was in the audience at an event when one CEO took to the stage to claim he had reversed his own biological age by 18 yearsâ€”thanks to the supplement he was selling. Tom Weldon of Ponce de Leon Health told us his gray hair was turning brown. His biological age was supposedly reversing so rapidly that he had reached â€œlongevity escape velocity.â€





But if the people who buy his supplements expect some kind of Benjamin Button effect, they might be disappointed. His company hasnâ€™t yet conducted a randomized controlled trial to demonstrate any anti-aging effects of that supplement, called Rejuvant. Weldon says that such a trial would take years and cost millions of dollars, and that heâ€™d â€œhave to increase the price of our product more than four timesâ€ to pay for one. (The company has so far tested the active ingredient in mice and carried out a provisional trial in people.)



More generally, Horvath says he â€œgets a bad taste in [his] mouthâ€ when people use the clocks to sell products and â€œmake a quick buck.â€ But he thinks that most of those sellers have genuine faith in both the clocks and their products. â€œPeople truly believe their own nonsense,â€ he says. â€œThey are so passionate about what they discovered, they fall into this trap of believing [their] own prejudices.â€&nbsp;



The accuracy of the clocks is at a level that makes them useful for research, but not for individual predictions. Even if a clock did tell someone they were five years younger than their chronological age, that wouldnâ€™t necessarily mean the person could expect to live five years longer, says MagalhÃ£es. â€œThe field of aging has long been a rich ground for snake-oil salesmen and hype,â€ he says. â€œIt comes with the territory.â€ (Weldon, for his part, says Rejuvant is the only product that has â€œclinically meaningfulâ€ claims.)&nbsp;



In any case, MagalhÃ£es adds that he thinks any publicity is better than no publicity.



And thereâ€™s the rub. Most people in the longevity field seem to have mixed feelings about the trendiness of aging clocks and how they are being used. Theyâ€™ll agree that the clocks arenâ€™t ready for consumer prime time, but they tend to appreciate the attention. Longevity research is expensive, after all. With a surge in funding and an explosion in the number of biotech companies working on longevity, aging scientists are hopeful that innovation and progress will follow.&nbsp;



So they want to be sure that the reputation of aging clocks doesnâ€™t end up being tarnished by association. Because while influencers and supplement sellers are using their â€œbiological agesâ€ to garner attention, scientists are now using these clocks to make some remarkable discoveries. Discoveries that are changing the way we think about aging.



How to be young again



Two little mice lie side by side, anesthetized and unconscious, as Jim White prepares his scalpel. The animals are of the same breed but look decidedly different. One is a youthful three-month-old, its fur thick, black, and glossy. By comparison, the second mouse, a 20-month-old, looks a little the worse for wear. Its fur is graying and patchy. Its whiskers are short, and it generally looks kind of frail.



But the two mice are about to have a lot more in common. White, with some help from a colleague, makes incisions along the side of each mouseâ€™s body and into the upper part of an arm and leg on the same side. He then carefully stitches the two animals togetherâ€”membranes, fascia, and skin.&nbsp;



The procedure takes around an hour, and the mice are then roused from their anesthesia. At first, the two still-groggy animals pull away from each other. But within a few days, they seem to have accepted that they now share their bodies. Soon their circulatory systems will fuse, and the animals will share a blood flow too.



â€œPeople are complicated. Thereâ€™s a huge error bar.â€ â€” Steve Horvath, former biostatistician at the University of California, Los AngelesLEON EDLER




White, who studies aging at Duke University, has been stitching mice together for years; he has performed this strange procedure, known as heterochronic parabiosis, more than a hundred times. And heâ€™s seen a curious phenomenon occur. The older mice appear to benefit from the arrangement. They seem to get younger.



Experiments with heterochronic parabiosis have been performed for decades, but typically scientists keep the mice attached to each other for only a few weeks, says White. In their experiment, he and his colleagues left the mice attached for three monthsâ€”equivalent to around 10 human years. The team then carefully separated the animals to assess how each of them had fared. â€œYouâ€™d think that theyâ€™d want to separate immediately,â€ says White. â€œBut when you detach them â€¦ they kind of follow each other around.â€



The most striking result of that experiment was that the older mice who had been attached to a younger mouse ended up living longer than other mice of a similar age. â€œ[They lived] around 10% longer, but [they] also maintained a lot of [their] function,â€ says White. They were more active and maintained their strength for longer, he adds.



When his colleagues, including Poganik, applied aging clocks to the mice, they found that their epigenetic ages were lower than expected. â€œThe young circulation slowed aging in the old mice,â€ says White. The effect seemed to last, tooâ€”at least for a little while. â€œIt preserved that youthful state for longer than we expected,â€ he says.



The young mice went the other way and appeared biologically older, both while they were attached to the old mice and shortly after they were detached. But in their case, the effect seemed to be short-lived, says White: â€œThe young mice went back to being young again.â€&nbsp;



To White, this suggests that something about the â€œyouthful stateâ€ might be programmed in some way. That perhaps it is written into our DNA. Maybe we donâ€™t have to go through the biological process of aging.&nbsp;



This gets at a central debate in the aging field: What is aging, and why does it happen? Some believe itâ€™s simply a result of accumulated damage. Some believe that the aging process is programmed; just as we grow limbs, develop a brain, reach puberty, and experience menopause, we are destined to deteriorate. Others think programs that play an important role in our early development just turn out to be harmful later in life by chance. And there are some scientists who agree with all of the above.



Whiteâ€™s theory is that being old is just â€œa loss of youth,â€ he says. If thatâ€™s the case, thereâ€™s a silver lining: Knowing how youth is lost might point toward a way to somehow regain it, perhaps by restoring those youthful programs in some way.&nbsp;



Dogs and dolphins



Horvathâ€™s eponymous clock was developed by measuring methylation in DNA samples taken from tissues around the body. It seems to represent aging in all these tissues, which is why Horvath calls it a pan-tissue clock. Given that our organs are thought to age differently, it was remarkable that a single clock could measure aging in so many of them.



But Horvath had ambitious plans for an even more universal clock: a pan-species model that could measure aging in all mammals. He started out, in 2017, with an email campaign that involved asking hundreds of scientists around the world to share samples of tissues from animals they had worked with. He tried zoos, too.&nbsp; &nbsp;




The pan-mammalian clock suggests that there is something universal about agingâ€”not just that all mammals experience it in a similar way, but that a similar set of genetic or epigenetic factors might be responsible for it.




â€œI learned that people had spent careers collecting [animal] tissues,â€ he says. â€œThey had freezers full of [them].â€ Amenable scientists would ship those frozen tissues, or just DNA, to Horvathâ€™s lab in California, where he would use them to train a new model.



Horvath says he initially set out to profile 30 different species. But he ended up receiving around 15,000 samples from 200 scientists, representing 348 speciesâ€”including everything from dogs to dolphins. Could a single clock really predict age in all of them?



â€œI truly felt it would fail,â€ says Horvath. â€œBut it turned out that I was completely wrong.â€ He and his colleagues developed a clock that assessed methylation at 36,000 locations on the genome. The result, which was published in 2023 as the pan-mammalian clock, can estimate the age of any mammal and even the maximum lifespan of the species. The data set is open to anyone who wants to download it, he adds: â€œI hope people will mine the data to find the secret of how to extend a healthy lifespan.â€



The pan-mammalian clock suggests that there is something universal about agingâ€”not just that all mammals experience it in a similar way, but that a similar set of genetic or epigenetic factors might be responsible for it.



Comparisons between mammals also support the idea that the slower methylation changes occur, the longer the lifespan of the animal, says Nelly Olova, an epigeneticist who researches aging at the University of Edinburgh in the UK. â€œDNA methylation slowly erodes with age,â€ she says. â€œWe still have the instructions in place, but they become a little messier.â€ The research in different mammals suggests that cells can take only so much change before they stop functioning.



â€œThereâ€™s a finite amount of change that the cell can tolerate,â€ she says. â€œIf the instructions become too messy and noisy â€¦ it cannot support life.â€



Olova has been investigating exactly when aging clocks first begin to tickâ€”in other words, the point at which aging starts. Clocks can be trained on data from volunteers, and by matching the patterns of methylation on their DNA to their chronological age. The trained clocks are then typically used to estimate the biological age of adults. But they can also be used on samples from children. Or babies. They can be used to work out the biological age of cells that make up embryos.&nbsp;



In her research, Olova used adult skin cells, whichâ€”thanks to Nobel Prizeâ€“winning research in the 2000sâ€”can be â€œreprogrammedâ€ back to a state resembling that of the pluripotent stem cells found in embryos. When Olova and her colleagues used a â€œpartial reprogrammingâ€ approach to take cells close to that state, they found that the closer they got to the entirely reprogrammed state, the â€œyoungerâ€ the cells were.&nbsp;





It was around 20 days after the cells had been reprogrammed into stem cells that they reached the biological age of zero according to the clock used, says Olova. â€œIt was a bit surreal,â€ she says. â€œThe pluripotent cells measure as minus 0.5; theyâ€™re slightly below zero.â€



Vadim Gladyshev, a prominent aging researcher at Harvard University, has since proposed that the same negative level of aging might apply to embryos. After all, some kind of rejuvenation happens during the early stages of embryo formationâ€”an aged egg cell and an aged sperm cell somehow create a brand-new cell. The slate is wiped clean.



Gladyshev calls this point â€œground zero.â€ He posits that itâ€™s reached sometime during the â€œmid-embryonic state.â€ At this point, aging begins. And so does â€œorganismal life,â€ he argues. â€œItâ€™s interesting how this coincides with philosophical questions about when life starts,â€ says Olova.Â 



Some have argued that life begins when sperm meets egg, while others have suggested that the point when embryonic cells start to form some kind of unified structure is what counts. The ground zero point is when the body plan is set out and cells begin to organize accordingly, she says. â€œBefore that, itâ€™s just a bunch of cells.â€



This doesnâ€™t mean that life begins at the embryonic state, but it does suggest that this is when aging beginsâ€”perhaps as the result of â€œa generational clearance of damage,â€ says Poganik.



It is early daysâ€”no pun intendedâ€”for this research, and the science is far from settled. But knowing when aging begins could help inform attempts to rewind the clock. If scientists can pinpoint an ideal biological age for cells, perhaps they can find ways to get old cells back to that state. There might be a way to slow aging once cells reach a certain biological age, too.&nbsp;



â€œPresumably, there may be opportunities for targeting aging before â€¦ youâ€™re full of gray hair,â€ says Poganik. â€œIt could mean that there is an ideal window for intervention which is much earlier than our current geriatrics-based approach.â€



When young meets old



When White first started stitching mice together, he would sit and watch them for hours. â€œI was like, look at them go! Theyâ€™re together, and they donâ€™t even care!â€ he says. Since then, heâ€™s learned a few tricks. He tends to work with female mice, for instanceâ€”the males tend to bicker and nip at each other, he says. The females, on the other hand, seem to get on well.&nbsp;



The effect their partnership appears to have on their biological ages, if only temporarily, is among the ways aging clocks are helping us understand that biological age is plastic to some degree. White and his colleagues have also found, for instance, that stress seems to increase biological age, but that the effect can be reversed once the stress stops. Both pregnancy and covid-19 infections have a similar reversible effect.



Poganik wonders if this finding might have applications for human organ transplants. Perhaps thereâ€™s a way to measure the biological age of an organ before it is transplanted and somehow rejuvenate organs before surgery.&nbsp;



But new data from aging clocks suggests that this might be more complicated than it sounds. Poganik and his colleagues have been using methylation clocks to measure the biological age of samples taken from recently transplanted hearts in living people.&nbsp;




If being old is simply a case of losing our youthfulness, then that might give us a clue to how we can somehow regain it.




Young hearts do well in older bodies, but the biological age of these organs eventually creeps up to match that of their recipient. The same is true for older hearts in younger bodies, says Poganik, who has not yet published his findings. â€œAfter a few months, the tissue may assimilate the biological age of the organism,â€ he says.&nbsp;



If thatâ€™s the case, the benefits of young organs might be short-lived. It also suggests that scientists working on ways to rejuvenate individual organs may need to focus their anti-aging efforts on more systemic means of rejuvenationâ€”for example, stem cells that repopulate the blood. Reprogramming these cells to a youthful state, perhaps one a little closer to â€œground zero,â€ might be the way to go.



Whole-body rejuvenation might be some way off, but scientists are still hopeful that aging clocks might help them find a way to reverse aging in people.



â€œWe have the machinery to reset our epigenetic clock to a more youthful state,â€ says White. â€œThat means we have the ability to turn the clock backwards.â€

ğŸ”’ Cybersecurity & Privacy
â€¢ Patch Tuesday, October 2025 â€˜End of 10â€™ Edition
  Microsoft today released software updates to plug a whopping 172 security holes in its Windows operating systems, including at least two vulnerabilities that are already being actively exploited. October&#8217;s Patch Tuesday also marks the final month that Microsoft will ship security updates for Windows 10 systems. If you&#8217;re running a Windows 10 PC and you&#8217;re unable or unwilling to migrate to Windows 11, read on for other options.

The first zero-day bug addressed this month (CVE-2025-24990) involves a third-party modem driver called Agere Modem that&#8217;s been bundled with Windows for the past two decades. Microsoft responded to active attacks on this flaw by completely removing the vulnerable driver from Windows.
The other zero-day is CVE-2025-59230, an elevation of privilege vulnerability in Windows Remote Access Connection Manager (also known as RasMan), a service used to manage remote network connections through virtual private networks (VPNs) and dial-up networks.
&#8220;While RasMan is a frequent flyer on Patch Tuesday, appearing more than 20 times since January 2022, this is the first time we&#8217;ve seen it exploited in the wild as a zero day,&#8221; said Satnam Narang, senior staff research engineer at Tenable.
Narang notes that Microsoft Office users should also take note of CVE-2025-59227 and CVE-2025-59234, a pair of remote code execution bugs that take advantage of &#8220;Preview Pane,â€ meaning that the target doesnâ€™t even need to open the file for exploitation to occur. To execute these flaws, an attacker would social engineer a target into previewing an email with a malicious Microsoft Office document.
Speaking of Office, Microsoft quietly announced this week that Microsoft Word will now automatically save documents to OneDrive, Microsoft&#8217;s cloud platform. Users who are uncomfortable saving all of their documents to Microsoft&#8217;s cloud can change this in Word&#8217;s settings; ZDNet has a useful how-to on disabling this feature.
Kev Breen, senior director of threat research at Immersive, called attention to CVE-2025-59287, a critical remote code execution bug in the Windows Server Update ServiceÂ  (WSUS) &#8212; the very same Windows service responsible for downloading security patches for Windows Server versions. Microsoft says there are no signs this weakness is being exploited yet. But with a threat score of 9.8 out of possible 10 and marked &#8220;exploitation more likely,&#8221; CVE-2025-59287 can be exploited without authentication and is an easy &#8220;patch now&#8221; candidate.
&#8220;Microsoft provides limited information, stating that an unauthenticated attacker with network access can send untrusted data to the WSUS server, resulting in deserialization and code execution,&#8221; Breen wrote. &#8220;As WSUS is a trusted Windows service that is designed to update privileged files across the file system, an attacker would have free rein over the operating system and could potentially bypass some EDR detections that ignore or exclude the WSUS service.&#8221;
For more on other fixes from Redmond today, check out the SANS Internet Storm Center monthly roundup, which indexes all of the updates by severity and urgency.
Windows 10 isn&#8217;t the only Microsoft OS that is reaching end-of-life today;Â Exchange Server 2016, Exchange Server 2019, Skype for Business 2016, Windows 11 IoT Enterprise Version 22H2, and Outlook 2016 are some of the other products that Microsoft is sunsetting today.

If you&#8217;re running any Windows 10 systems, you&#8217;ve probably already determined whether your PC meets the technical hardware specs recommended for the Windows 11 OS. If you&#8217;re reluctant or unable to migrate a Windows 10 system to Windows 11, there are alternatives to simply continuing to use Windows 10 without ongoing security updates.
One option is to pay for another year&#8217;s worth of security updates through Microsoft&#8217;s Extended Security Updates (ESU) program. The cost is just $30 if you don&#8217;t have a Microsoft account, and apparently free if you register the PC to a Microsoft account. This video breakdown from Ask Your Computer Guy does a good job of walking Windows 10 users through this process. Microsoft emphasizes that ESU enrollment does not provide other types of fixes, feature improvements or product enhancements. It also does not come with technical support.
If your Windows 10 system is associated with a Microsoft account and signed in when you visit Windows Update, you should see an option to enroll in extended updates. Image: https://www.youtube.com/watch?v=SZH7MlvOoPM
Windows 10 users also have the option of installing some flavor of Linux instead. Anyone seriously considering this option should check out the website endof10.org, which includes a plethora of tips and a DIY installation guide.
Linux Mint is a great option for Linux newbies. Like most modern Linux versions, Mint will run on anything with a 64-bit CPU that has at least 2GB of memory, although 4GB is recommended. In other words, it will run on almost any computer produced in the last decade.
Linux Mint also is likely to be the most intuitive interface for regular Windows users, and it is largely configurable without any fuss at the text-only command-line prompt. Mint and other flavors of Linux come with LibreOffice, which is an open source suite of tools that includes applications similar to Microsoft Office, and it can open, edit and save documents as Microsoft Office files.
If youâ€™d prefer to give Linux a test drive before installing it on a Windows PC, you can always just download it to a removable USB drive. From there, reboot the computer (with the removable drive plugged in) and select the option at startup to run the operating system from the external USB drive. If you donâ€™t see an option for that after restarting, try restarting again and hitting the F8 button, which should open a list of bootable drives.Â Hereâ€™s a fairly thorough tutorialÂ that walks through exactly how to do all this.
And if this is your first time trying out Linux, relax and have fun: The nice thing about a â€œliveâ€ version of Linux (as itâ€™s called when the operating system is run from a removable drive such as a CD or a USB stick) is that none of your changes persist after a reboot. Even if you somehow manage to break something, a restart will return the system back to its original state.
As ever, if you experience any difficulties during or after applying this month&#8217;s batch of patches, please leave a note about it in the comments below.
â€¢ DDoS Botnet Aisuru Blankets US ISPs in Record DDoS
  The world&#8217;s largest and most disruptive botnet is now drawing a majority of its firepower from compromised Internet-of-Things (IoT) devices hosted on U.S. Internet providers like AT&amp;T, Comcast and Verizon, new evidence suggests. Experts say the heavy concentration of infected devices at U.S. providers is complicating efforts to limit collateral damage from the botnet&#8217;s attacks, which shattered previous records this week with a brief traffic flood that clocked in at nearly 30 trillion bits of data per second.
Since its debut more than a year ago, the Aisuru botnet has steadily outcompeted virtually all other IoT-based botnets in the wild, with recent attacks siphoning Internet bandwidth from an estimated 300,000 compromised hosts worldwide.
The hacked systems that get subsumed into the botnet are mostly consumer-grade routers, security cameras, digital video recorders and other devices operating with insecure and outdated firmware, and/or factory-default settings. Aisuru&#8217;s owners are continuously scanning the Internet for these vulnerable devices and enslaving them for use in distributed denial-of-service (DDoS) attacks that can overwhelm targeted servers with crippling amounts of junk traffic.
As Aisuru&#8217;s size has mushroomed, so has its punch. In May 2025, KrebsOnSecurity was hit with a near-record 6.35 terabits per second (Tbps) attack from Aisuru, which was then the largest assault that Google&#8217;s DDoS protection service Project Shield had ever mitigated. Days later, Aisuru shattered that record with a data blast in excess of 11 Tbps.
By late September, Aisuru was publicly flexing DDoS capabilities topping 22 Tbps. Then on October 6, its operators heaved a whopping 29.6 terabits of junk data packets each second at a targeted host. Hardly anyone noticed because it appears to have been a brief test or demonstration of Aisuru&#8217;s capabilities: The traffic flood lasted less only a few seconds and was pointed at an Internet server that was specifically designed to measure large-scale DDoS attacks.
A measurement of an Oct. 6 DDoS believed to have been launched through multiple botnets operated by the owners of the Aisuru botnet. Image: DDoS Analyzer Community on Telegram.
Aisuru&#8217;s overlords aren&#8217;t just showing off. Their botnet is being blamed for a series of increasingly massive and disruptive attacks. Although recent assaults from Aisuru have targeted mostly ISPs that serve online gaming communities like Minecraft, those digital sieges often result in widespread collateral Internet disruption.
For the past several weeks, ISPs hosting some of the Internet&#8217;s top gaming destinations have been hit with a relentless volley of gargantuan attacks that experts say are well beyond the DDoS mitigation capabilities of most organizations connected to the Internet today.
Steven Ferguson is principal security engineer at Global Secure Layer (GSL), an ISP in Brisbane, Australia. GSL hosts TCPShield, which offers free or low-cost DDoS protection to more than 50,000 Minecraft servers worldwide. Ferguson told KrebsOnSecurity that on October 8, TCPShield was walloped with a blitz from Aisuru that flooded its network with more than 15 terabits of junk data per second.
Ferguson said that after the attack subsided, TCPShield was told by its upstream provider OVH that they were no longer welcome as a customer.
&#8220;This was causing serious congestion on their Miami external ports for several weeks, shown publicly via their weather map,&#8221; he said, explaining that TCPShield is now solely protected by GSL.
Traces from the recent spate of crippling Aisuru attacks on gaming servers can be still seen at the website blockgametracker.gg, which indexes the uptime and downtime of the top Minecraft hosts. In the following example from a series of data deluges on the evening of September 28, we can see an Aisuru botnet campaign briefly knocked TCPShield offline.
An Aisuru botnet attack on TCPShield (AS64199) on Sept. 28Â  can be seen in the giant downward spike in the middle of this uptime graphic. Image: grafana.blockgametracker.gg.
Paging through the same uptime graphs for other network operators listed shows almost all of them suffered brief but repeated outages around the same time. Here is the same uptime tracking for Minecraft servers on the network provider Cosmic (AS30456), and it shows multiple large dips that correspond to game server outages caused by Aisuru.
Multiple DDoS attacks from Aisuru can be seen against the Minecraft host Cosmic on Sept. 28. The sharp downward spikes correspond to brief but enormous attacks from Aisuru. Image: grafana.blockgametracker.gg.
BOTNETS R US
Ferguson said he&#8217;s been tracking Aisuru for about three months, and recently he noticed the botnet&#8217;s composition shifted heavily toward infected systems at ISPs in the United States. Ferguson shared logs from an attack on October 8 that indexed traffic by the total volume sent through each network provider, and the logs showed that 11 of the top 20 traffic sources were U.S. based ISPs.
AT&amp;T customers were by far the biggest U.S. contributors to that attack, followed by botted systems on Charter Communications, Comcast, T-Mobile and Verizon, Ferguson found. He said the volume of data packets per second coming from infected IoT hosts on these ISPs is often so high that it has started to affect the quality of service that ISPs are able to provide to adjacent (non-botted) customers.
&#8220;The impact extends beyond victim networks,&#8221; Ferguson said. &#8220;For instance we have seen 500 gigabits of traffic via Comcast&#8217;s network alone. This amount of egress leaving their network, especially being so US-East concentrated, will result in congestion towards other services or content trying to be reached while an attack is ongoing.&#8221;
Roland Dobbins is principal engineer at Netscout. Dobbins said Ferguson is spot on, noting that while most ISPs have effective mitigations in place to handle large incoming DDoS attacks, many are far less prepared to manage the inevitable service degradation caused by large numbers of their customers suddenly using some or all available bandwidth to attack others.
&#8220;The outbound and cross-bound DDoS attacks can be just as disruptive as the inbound stuff,&#8221; Dobbin said. &#8220;We&#8217;re now in a situation where ISPs are routinely seeing terabit-per-second plus outbound attacks from their networks that can cause operational problems.&#8221;
&#8220;The crying need for effective and universal outbound DDoS attack suppression is something that is really being highlighted by these recent attacks,&#8221; Dobbins continued. &#8220;A lot of network operators are learning that lesson now, and there&#8217;s going to be a period ahead where there&#8217;s some scrambling and potential disruption going on.&#8221;
KrebsOnSecurity sought comment from the ISPs named in Ferguson&#8217;s report. Charter Communications pointed to a recent blog post on protecting its network, stating that Charter actively monitors for both inbound and outbound attacks, and that it takes proactive action wherever possible.
&#8220;In addition to our own extensive network security, we also aim to reduce the risk of customer connected devices contributing to attacks through our Advanced WiFi solution that includes Security Shield, and we make Security Suite available to our Internet customers,&#8221; Charter wrote in an emailed response to questions. &#8220;With the ever-growing number of devices connecting to networks, we encourage customers to purchase trusted devices with secure development and manufacturing practices, use anti-virus and security tools on their connected devices, and regularly download security patches.&#8221;
A spokesperson for Comcast responded, &#8220;Currently our network is not experiencing impacts and we are able to handle the traffic.&#8221;
9 YEARS OF MIRAI
Aisuru is built on the bones of malicious code that was leaked in 2016Â by the original creators of the Mirai IoT botnet. Like Aisuru, Mirai quickly outcompeted all other DDoS botnets in its heyday, and obliterated previous DDoS attack records with a 620 gigabit-per-second siege that sidelined this website for nearly four days in 2016.
The Mirai botmasters likewise used their crime machine to attack mostly Minecraft servers, but with the goal of forcing Minecraft server owners to purchase a DDoS protection service that they controlled. In addition, they rented out slices of the Mirai botnet to paying customers, some of whom used it to mask the sources of other types of cybercrime, such as click fraud.
A depiction of the outages caused by the Mirai botnet attacks against the internet infrastructure firm Dyn on October 21, 2016. Source: Downdetector.com.
Dobbins said Aisuru&#8217;s owners also appear to be renting out their botnet as a distributed proxy network that cybercriminal customers anywhere in the world can use to anonymize their malicious traffic and make it appear to be coming from regular residential users in the U.S.
&#8220;The people who operate this botnet are also selling (it as) residential proxies,&#8221; he said. &#8220;And that&#8217;s being used to reflect application layer attacks through the proxies on the bots as well.&#8221;
The Aisuru botnet harkens back to its predecessor Mirai in another intriguing way. One of its owners is using the Telegram handle &#8220;9gigsofram,&#8221; which corresponds to the nickname used by the co-owner of a Minecraft server protection service called Proxypipe that was heavily targeted in 2016 by the original Mirai botmasters.
Robert Coelho co-ran Proxypipe back then along with his business partner Erik &#8220;9gigsofram&#8221; Buckingham, and has spent the past nine years fine-tuning various DDoS mitigation companies that cater to Minecraft server operators and other gaming enthusiasts. Coelho said he has no idea why one of Aisuru&#8217;s botmasters chose Buckingham&#8217;s nickname, but added that it might say something about how long this person has been involved in the DDoS-for-hire industry.
&#8220;The Aisuru attacks on the gaming networks these past seven day have been absolutely huge, and you can see tons of providers going down multiple times a day,&#8221; Coelho said.
Coelho said the 15 Tbps attack this week against TCPShield was likely only a portion of the total attack volume hurled by Aisuru at the time, because much of it would have been shoved through networks that simply couldn&#8217;t process that volume of traffic all at once. Such outsized attacks, he said, are becoming increasingly difficult and expensive to mitigate.
&#8220;It&#8217;s definitely at the point now where you need to be spending at least a million dollars a month just to have the network capacity to be able to deal with these attacks,&#8221; he said.
RAPID SPREAD
Aisuru has long been rumored to use multiple zero-day vulnerabilities in IoT devices to aid its rapid growth over the past year. XLab, the Chinese security company that was the first to profile Aisuru&#8217;s rise in 2024, warned last month that one of the Aisuru botmasters had compromised the firmware distribution website for Totolink, a maker of low-cost routers and other networking gear.
&#8220;Multiple sources indicate the group allegedly compromised a router firmware update server in April and distributed malicious scripts to expand the botnet,&#8221; XLab wrote on September 15. &#8220;The node count is currently reported to be around 300,000.&#8221;
A malicious script implanted into a Totolink update server in April 2025. Image: XLab.
Aisuru&#8217;s operators received an unexpected boost to their crime machine in August when the U.S. Department JusticeÂ charged the alleged proprietor of Rapper Bot, a DDoS-for-hire botnet that competed directly with Aisuru for control over the global pool of vulnerable IoT systems.
Once Rapper Bot was dismantled, Aisuru&#8217;s curators moved quickly to commandeer vulnerable IoT devices that were suddenly set adrift by the government&#8217;s takedown, Dobbins said.
&#8220;Folks were arrested and Rapper Bot control servers were seized and that&#8217;s great, but unfortunately the botnet&#8217;s attack assets were then pieced out by the remaining botnets,&#8221; he said. &#8220;The problem is, even if those infected IoT devices are rebooted and cleaned up, they will still get re-compromised by something else generally within minutes of being plugged back in.&#8221;
A screenshot shared by XLabs showing the Aisuru botmasters recently celebrating a record-breaking 7.7 Tbps DDoS. The user at the top has adopted the name &#8220;Ethan J. Foltz&#8221; in a mocking tribute to the alleged Rapper Bot operator who was arrested and charged in August 2025.
BOTMASTERS AT LARGE
XLab&#8217;s September blog post cited multiple unnamed sources saying Aisuru is operated by three cybercriminals: &#8220;Snow,&#8221; who&#8217;s responsible for botnet development; &#8220;Tom,&#8221; tasked with finding new vulnerabilities; and &#8220;Forky,&#8221; responsible for botnet sales.
KrebsOnSecurity interviewed Forky in our May 2025 story about the record 6.3 Tbps attack from Aisuru. That story identified Forky as a 21-year-old man from Sao Paulo, Brazil who has been extremely active in the DDoS-for-hire scene since at least 2022. The FBI has seized Forky&#8217;s DDoS-for-hire domains several times over the years.

Like the original Mirai botmasters, Forky also operates a DDoS mitigation service called Botshield. Forky declined to discuss the makeup of his ISPâ€™s clientele, or to clarify whether Botshield was more of a hosting provider or a DDoS mitigation firm. However, Forky has posted on Telegram about Botshield successfully mitigating large DDoS attacks launched against other DDoS-for-hire services.
In our previous interview, Forky acknowledged being involved in the development and marketing of Aisuru, but denied participating in attacks launched by the botnet.
Reached for comment earlier this month, Forky continued to maintain his innocence, claiming that he also is still trying to figure out who the current Aisuru botnet operators are in real life (Forky said the same thing in our May interview).
But after a week of promising juicy details, Forky came up empty-handed once again. Suspecting that Forky was merely being coy, I asked him how someone so connected to the DDoS-for-hire world could still be mystified on this point, and suggested that his inability or unwillingness to blame anyone else for Aisuru would not exactly help his case.
At this, Forky verbally bristled at being pressed for more details, and abruptly terminated our interview.
&#8220;I&#8217;m not here to be threatened with ignorance because you are stressed,&#8221; Forky replied. &#8220;They&#8217;re blaming me for those new attacks. Pretty much the whole world (is) due to your blog.&#8221;

ğŸ“ University AI
No updates.

ğŸ¢ Corporate AI
â€¢ Build a device management agent with Amazon Bedrock AgentCore
  The proliferation of Internet of Things (IoT) devices has transformed how we interact with our environments, from homes to industrial settings. However, as the number of connected devices grows, so does the complexity of managing them. Traditional device management interfaces often require navigating through multiple applications, each with its own UI and learning curve. This fragmentation creates friction for users trying to monitor and control their IoT environment. 
In this post, we explore how to build a conversational device management system using Amazon Bedrock AgentCore. With this solution, users can manage their IoT devices through natural language, using a UI for tasks like checking device status, configuring WiFi networks, and monitoring user activity. To learn more about how Amazon Bedrock AgentCore enables deploying and operating highly effective agents securely at scale using a variety of frameworks and models, refer to Enabling customers to deliver production-ready AI agents at scale. 
The challenge of device management 
Managing a modern IoT environment involves navigating numerous challenges that can hinder user experience and technology adoption. Interface fragmentation forces users to juggle multiple applications and management tools for different devices, and technical complexity can make even basic configuration tasks intimidating for non-specialists. Adding to these difficulties are visibility limitations that prevent comprehensive monitoring of device status, and inadequate user management capabilities that make it difficult to track device usage patterns. 
Together, these pain points create significant friction for users trying to implement and maintain IoT solutions effectively. 
Solution overview 
The conversational AI solution using agents offers a comprehensive approach to IoT complexity through its unified conversational interface that consolidates device management tasks into a single access point. Users can perform sophisticated operations through natural language interaction instead of navigating technical menus, while gaining comprehensive visibility across connected devices and transforming complex configuration tasks into straightforward conversations. The system delivers essential capabilities, including device management for inventory control and status monitoring, WiFi network management for simplified network configuration, user management for access control, and activity tracking for temporal analysis of user interactions. This seamless management experience minimizes monitoring vulnerabilities and provides valuable insights into usage patterns and potential security concerns, effectively removing the typical barriers to successful IoT implementation while maintaining appropriate system authorization throughout the network. 
Architecture overview 
 
The device management system follows a modular architecture that uses several AWS services. The architecture consists of the following components: 
 
 User and application interface â€“ Users interact with the system through a web application that serves as the frontend interface. 
 Foundation models â€“ This system uses various foundation models (FMs) in Amazon Bedrock to power natural language understanding and generation capabilities. 
 Amazon Bedrock AgentCore Gateway â€“ This feature acts as the secure entry point for authenticated requests, validating bearer tokens before routing requests to the appropriate target. 
 Amazon Bedrock AgentCore Identity â€“ This feature manages agent identity and permissions, controlling what actions the agent can perform on behalf of users. 
 Amazon Bedrock AgentCore Memory â€“ This feature supports both short-term and long-term memory, maintaining immediate conversation context within a session and storing persistent insights and preferences across sessions. This enables agents to provide consistent, context-aware responses without developers needing to manage complex memory infrastructure. 
 Amazon Bedrock AgentCore Observability â€“ This feature monitors agent performance, tracks metrics, and provides insights into system usage and behavior for debugging and optimization. 
 Amazon Bedrock AgentCore Runtime â€“ This secure, serverless environment supports AI agents built with open source frameworks. It maintains complete session isolation by dedicating isolated containers per user session, enabling scalable and secure management of long-running, stateful interactions. 
 Amazon Cognito â€“ Amazon Cognito handles user authentication through bearer token generation and validation, facilitating secure access to the system. 
 Amazon DynamoDB â€“ Amazon DynamoDB stores system data across five tables. 
 AWS Lambda â€“ The solution connects the gateway to AWS Lambda functions that execute specific device management operations. Lambda contains the business logic for device management, implementing seven core tools. 
 
This architecture enables a seamless flow from user query to response: the user submits a natural language request through the application, which is authenticated through Amazon Cognito and processed by Amazon Bedrock AgentCore Runtime. The runtime determines the appropriate tool to invoke and sends the request through the gateway to the Lambda function, which queries or updates DynamoDB as needed. The result flows back through the same path, with the runtime generating a natural language response based on the data retrieved. 
Refer to the GitHub repository for detailed deployment instructions. 
Key functionalities of the device management agent 
The device management system uses Lambda to implement seven essential tools for device management, including listing devices, retrieving settings, managing WiFi networks, and monitoring user activity, all invoked by the agent as needed. This functionality is supported by our flexible NoSQL database architecture in DynamoDB, which comprises five distinct tablesâ€”Devices, DeviceSettings, WifiNetworks, Users, and UserActivitiesâ€”storing specialized data to maintain comprehensive system records. Together, these components create a robust foundation that enables efficient device management while maintaining detailed audit trails of system activities. 
Key features showcase 

 
  
 
 
Performance and security considerations 
The solution balances robust concurrent processing capabilities with comprehensive protection measures. The device management system efficiently handles multiple simultaneous requests through automatically scaling Lambda functions, consistent DynamoDB performance regardless of data volume, and intelligent retry logic with exponential backoff when encountering rate limitations. To scale across hundreds of tools, the semantic search capability in Amazon Bedrock AgentCore Gateway enables efficient and relevant discovery of tools by meaning, facilitating quick and accurate responses even at large scale. 
The system implements industry-leading security practices, including Amazon Cognito authentication, Amazon Bedrock AgentCore Identity, layered access control through gateway and Lambda level permission verification, comprehensive data encryption at rest and in transit, and Amazon Bedrock Guardrails to help prevent prompt injection attacks while maintaining interaction safety. 
Conclusion 
The device management system presented in this post uses Amazon Bedrock AgentCore to transform IoT management through conversational AI, creating an intuitive interface where complex device operations become simple dialogue. Its composable, reusable, and decoupled agentic architecture alleviates undifferentiated heavy lifting by providing built-in features for secure, scalable deployment and seamless integration. By combining large language models with an AWS infrastructure, the solution provides enterprise-grade capabilities without burdening developers with infrastructure management. Key benefits include simplified user experiences through natural language interaction, operational efficiency with unified interfaces, comprehensive device visibility, and future-proof architecture that evolves with AI advancements. The systemâ€™s model-agnostic approach supports continuous improvement as new FMs emerge, and robust security and observability features help organizations confidently deploy scalable, next-generation device management solutions tailored to their specific IoT environments. 
To implement this solution, refer to the GitHub repository. 
 
About the Author 
Godwin Sahayaraj Vincent is an Enterprise Solutions Architect at AWS who is passionate about Machine Learning and providing guidance to customers to design, deploy and manage their AWS workloads and architectures. In his spare time, he loves to play cricket with his friends and tennis with his three kids. 
Ramesh Kumar Venkatraman is a Senior Solutions Architect at AWS who is passionate about Generative AI, Containers and Databases. He works with AWS customers to design, deploy and manage their AWS workloads and architectures. In his spare time, he loves to play with his two kids and follows cricket. 
Chhavi Kaushik is an AWS Solutions Architect specializing in cloud-native architectures and digital transformation. She is passionate about helping customers harness the power of Generative AI, designing and implementing enterprise-scale solutions that combine AWSâ€™s cutting-edge AI/ML services. Outside of her professional life, Chhavi enjoys exploring the California outdoors, making the most of the Bay Areaâ€™s beautiful weather and lifestyle.
â€¢ How Amazon Bedrock Custom Model Import streamlined LLM deployment for Salesforce
  This post is cowritten by Salesforceâ€™s AI Platform team members Srikanta Prasad, Utkarsh Arora, Raghav Tanaji, Nitin Surya, Gokulakrishnan Gopalakrishnan, and Akhilesh Deepak Gotmare. 
Salesforceâ€™s Artificial Intelligence (AI) platform team runs customized large language models (LLMs)â€”fine-tuned versions of Llama, Qwen, and Mistralâ€”for agentic AI applications like Agentforce. Deploying these models creates operational overheads: teams spend months optimizing instance families, serving engines, and configurations. This process is time-consuming, hard to maintain with frequent releases, and expensive due to GPU capacity reservations for peak usage. 
Salesforce solved this by adopting Amazon Bedrock Custom Model Import. With Amazon Bedrock Custom Model Import, teams can import and deploy customized models through a unified API, minimizing infrastructure management while integrating with Amazon Bedrock features like Amazon Bedrock Knowledge Bases, Amazon Bedrock Guardrails, and Amazon Bedrock Agents. This shift lets Salesforce focus on models and business logic instead of infrastructure. 
This post shows how Salesforce integrated Amazon Bedrock Custom Model Import into their machine learning operations (MLOps) workflow, reused existing endpoints without application changes, and benchmarked scalability. We share key metrics on operational efficiency and cost optimization gains, and offer practical insights for simplifying your deployment strategy. 
Integration approach 
Salesforceâ€™s transition from Amazon SageMaker Inference to Amazon Bedrock Custom Model Import required careful integration with their existing MLOps pipeline to avoid disrupting production workloads. The teamâ€™s primary goal was to maintain their current API endpoints and model serving interfaces, keeping zero downtime and no required changes to downstream applications. With this approach, they could use the serverless capabilities of Amazon Bedrock while preserving the investment in their existing infrastructure and tooling. The integration strategy focused on creating a seamless bridge between their current deployment workflows and Amazon Bedrock managed services, enabling gradual migration without additional operational risk. 
As shown in the following deployment flow diagram, Salesforce enhanced their existing model delivery pipeline with a single additional step to use Amazon Bedrock Custom Model Import. After their continuous integration and continuous delivery (CI/CD) process saves model artifacts to their model store (an Amazon Simple Storage Service (Amazon S3) bucket), they now call the Amazon Bedrock Custom Model Import API to register the model with Amazon Bedrock. This control plane operation is lightweight because Amazon Bedrock pulls the model directly from Amazon S3, adding minimal overhead (5â€“7 mins, depending on model size) to their deployment timelineâ€”their overall model release process remains at approximately 1 hour. The integration delivered an immediate performance benefit: SageMaker no longer needs to download weights at container startup because Amazon Bedrock preloads the model. The main configuration changes involved granting Amazon Bedrock permissions to allow cross-account access to their S3 model bucket and updating AWS Identity and Access Management (IAM) policies to allow inference clients to invoke Amazon Bedrock endpoints. 
 
The following inference flow diagram illustrates how Salesforce maintained their existing application interfaces while using Amazon Bedrock serverless capabilities. Client requests flow through their established preprocessing layer for business logic like prompt formatting before reaching Amazon Bedrock, with postprocessing applied to the raw model output. To handle complex processing requirements, they deployed lightweight SageMaker CPU containers that act as intelligent proxiesâ€”running their custom model.py logic while forwarding the actual inference to Amazon Bedrock endpoints. This hybrid architecture preserves their existing tooling framework: their prediction service continues calling SageMaker endpoints without routing changes, and they retain mature SageMaker monitoring and logging for preprocessing and postprocessing logic. The trade-off involves an additional network hop adding 5â€“10 millisecond latency and the cost of always-on CPU instances, but this approach delivers backward-compatibility with existing integrations while keeping the GPU-intensive inference fully serverless through Amazon Bedrock. 
 
Scalability benchmarking 
To validate the performance capabilities of Amazon Bedrock Custom Model Import, Salesforce conducted comprehensive load testing across various concurrency scenarios. Their testing methodology focused on measuring how the transparent auto scaling behavior of Amazon Bedrockâ€”where the service automatically spins up model copies on-demand and scales out under heavy loadâ€”would impact real-world performance. Each test involved sending standardized payloads containing model IDs and input data through their proxy containers to Amazon Bedrock endpoints, measuring latency and throughput under different load patterns. Results (see the following table) show that at low concurrency, Amazon Bedrock achieved 44% lower latency than the ml.g6e.xlarge baseline (bf16 precision). Under higher loads, Amazon Bedrock Custom Model Import maintained consistent throughput with acceptable latency (less than 10 milliseconds), demonstrating the serverless architectureâ€™s ability to handle production workloads without manual scaling. 
 
  
   
   Concurrency (Count) 
   P95 Latency (in Seconds) 
   Throughput (Request per Minute) 
   
   
   1 
   7.2 
   11 
   
   
   4 
   7.96 
   41 
   
   
   16 
   9.35 
   133 
   
   
   32 
   10.44 
   232 
   
  
 
The results show P95 latency and throughput performance of the ApexGuru model (fine-tuned QWEN-2.5 13B) at varying concurrency levels. Amazon Bedrock Custom Model Import auto scaled from one to three copies as concurrency reached 32. Each model copy used 1 model unit. 
Results and metrics 
Beyond scalability improvements, Salesforce evaluated Amazon Bedrock Custom Model Import across two critical business dimensions: operational efficiency and cost optimization. The operational efficiency gains were substantialâ€”the team achieved a 30% reduction in time to iterate and deploy models to production. This improvement stemmed from alleviating complex decision-making around instance selection, parameter tuning, and choosing between serving engines like vLLM vs. TensorRT-LLM. The streamlined deployment process allowed developers to focus on model performance rather than infrastructure configuration. 
Cost optimization delivered even more dramatic results, with Salesforce achieving up to 40% cost reduction through Amazon Bedrock. This savings was primarily driven by their diverse traffic patterns across generative AI applicationsâ€”ranging from low to high production trafficâ€”where they previously had to reserve GPU capacity for peak workloads. The pay-per-use model proved especially beneficial for development, performance testing, and staging environments that only required GPU resources during active development cycles, avoiding the need for round-the-clock reserved capacity that often sat idle. 
Lessons learned 
Salesforceâ€™s journey with Amazon Bedrock Custom Model Import revealed several key insights that can guide other organizations considering a similar approach. First, although Amazon Bedrock Custom Model Import supports popular open source model architectures (Qwen, Mistral, Llama) and expands its portfolio frequently based on demand, teams working with cutting-edge architectures might need to wait for support. However, organizations fine-tuning with the latest model architectures should verify compatibility before committing to the deployment timeline. 
For pre- and post-inference processing, Salesforce evaluated alternative approaches using Amazon API Gateway and AWS Lambda functions, which offer complete serverless scaling and pay-per-use pricing down to milliseconds of execution. However, they found this approach less backward-compatible with existing integrations and observed cold start impacts when using larger libraries in their processing logic. 
Cold start latency emerged as a critical consideration, particularly for larger (over 7B parameter) models. Salesforce observed cold start delays of a couple of minutes with 26B parameter models, with latency varying based on model size. For latency-sensitive applications that canâ€™t tolerate such delays, they recommend keeping endpoints warm by maintaining at least one model copy active through health check invocations every 14 minutes. This approach balances cost-efficiency with performance requirements for production workloads. 
Conclusion 
Salesforceâ€™s adoption of Amazon Bedrock Custom Model Import shows how to simplify LLM deployment without sacrificing scalability or performance. They achieved 30% faster deployments and 40% cost savings while maintaining backward-compatibility through their hybrid architecture using SageMaker proxy containers alongside Amazon Bedrock serverless inference. For highly customized models or unsupported architectures, Salesforce continues using SageMaker AI as a managed ML solution. 
Their success came from methodical execution: thorough load testing, and gradual migration starting with non-critical workloads. The results prove serverless AI deployment works for production, especially with variable traffic patterns. ApexGuru is now deployed in their production environment. 
For teams managing LLMs at scale, this case study provides a clear blueprint. Check your model architecture compatibility, plan for cold starts with larger models, and preserve existing interfaces. Amazon Bedrock Custom Model Import offers a proven path to serverless AI that can reduce overhead, speed deployment, and cut costs while meeting performance requirements. 
To learn more about pricing for Amazon Bedrock, refer to Optimizing cost for using foundational models with Amazon Bedrock and Amazon Bedrock pricing. 
For help choosing between Amazon Bedrock and SageMaker AI, see Amazon Bedrock or Amazon SageMaker AI? 
For more information about Amazon Bedrock Custom Model Import, see How to configure cross-account model deployment using Amazon Bedrock Custom Model Import. 
For more details about ApexGuru, refer to Get AI-Powered Insights for Your Apex Code with ApexGuru. 
 
About the authors 
Srikanta Prasad is a Senior Manager in Product Management specializing in generative AI solutions at Salesforce. He leads Model Hosting and Inference initiatives, focusing on LLM inference serving, LLMOps, and scalable AI deployments.  
Utkarsh Arora is an Associate Member of Technical Staff at Salesforce, combining strong academic grounding from IIIT Delhi with early career contributions in ML engineering and research.&nbsp;  
Raghav Tanaji is a Lead Member of Technical Staff at Salesforce, specializing in machine learning, pattern recognition, and statistical learning. He holds an M.Tech from IISc Bangalore. 
Akhilesh Deepak Gotmare is a Senior Research Staff Member at Salesforce Research, based in Singapore. He is an AI Researcher focusing on deep learning, natural language processing, and code-related applications 
Gokulakrishnan Gopalakrishnan is a Principal Software Engineer at Salesforce, where he leads engineering efforts on ApexGuru. With 15+ years of experience, including at Microsoft, he specializes in building scalable software systems 
Nitin Surya is a Lead Member of Technical Staff at Salesforce with 8+ years in software/ML engineering. He holds a B.Tech in CS from VIT University and MS in CS (AI/ML focus) from University of Illinois Chicago. 
Hrushikesh Gangur is a Principal Solutions Architect at AWS based in San Francisco, California. He specializes in generative and agentic AI, helping startups and ISVs build and deploy AI applications.
â€¢ Transforming the physical world with AI: the next frontier in intelligent automation
  The convergence of artificial intelligence with physical systems marks a pivotal moment in technological evolution. Physical AI, where algorithms transcend digital boundaries to perceive, understand, and manipulate the tangible world, will fundamentally transform how enterprises operate across industries. These intelligent systems bridge the gap between digital intelligence and physical reality, unlocking unprecedented opportunities for efficiency and innovation. For many organizations, this opens the door to entirely new ways to delight their customers and, in turn, transform entire industries. 
To accelerate this transformation, the AWS Generative AI Innovation Center, MassRobotics, and NVIDIA launched the Physical AI Fellowship, providing crucial support to startups developing next-generation robotics and automation solutions. We are pleased to be working with our first cohort fellows: 
 
 Bedrock Robotics â€“ provides same-day hardware and software installation to provide autonomy to existing construction equipment fleets 
 Blue Water Autonomy â€“ integrating hardware, software, and AI to enable uncrewed ships to operate on the open ocean for months at a time 
 Diligent Robotics â€“ develop foundation models for autonomous humanoid robots in dynamic, human-facing environments 
 Generalist AI â€“ developing end-to-end AI foundation models toward general-purpose robots, starting with a focus on dexterity 
 RobCo â€“ offering modular hardware and a no-code system to automate tasks such as machine tending, palletizing, dispensing, or welding without upfront investment or specialist expertise 
 Tutor Intelligence â€“ building AI-powered robots to help manufacturers and warehouses obtain immediate returns on investment 
 Wandercraft â€“ developing exoskeletons to help with rehabilitation and restoring walking ability at home and in outpatient centers 
 Zordi â€“ combining AI, robotics, and machine learning to innovate greenhouse agriculture 
 
For businesses and public sector organizations, this convergence of AI and physical systems goes beyond incremental improvements, fundamentally rethinking whatâ€™s possible in their operations and customer experiences. 
The Physical AI spectrum: from automation to true intelligence 
 
As organizations evaluate their Physical AI initiatives, understanding where different solutions fall on the capability spectrum is crucial for strategic planning. Each level represents a distinct leap in autonomy and sophistication: 
 
 Level 1: Basic Physical Automation:&nbsp;This foundational stage involves systems that perform predefined tasks in tightly controlled environments. Think of industrial robots on assembly linesâ€”highly efficient, but rigid and entirely dependent on human programming and oversight. 
 Level 2: Adaptive Physical Automation:&nbsp;At this stage, systems gain flexibility in task sequencing. While individual actions are still preprogrammed, they can adjust their order based on real-time environmental cues. Collaborative robots that change behavior when humans are nearby is a prime example. 
 Level 3: Partially Autonomous Physical AI:&nbsp;Here, systems demonstrate intelligent behavior, including planning, executing, and adapting tasks with limited human input. Robots that learn new processes through demonstration highlight this emerging autonomy. 
 Level 4: Fully Autonomous Physical AI:&nbsp;The most advanced level features systems capable of operating across varied domains with minimal supervision. These systems adapt fluidly to new scenarios and environmental changes. Although most commercial solutions remain at Levels 1 or 2, momentum toward full autonomy is accelerating. 
 
Enabling technologies: the building blocks of Physical AI 
The progression from basic automation to full autonomy requires sophisticated technological foundations. Several key innovations are driving this evolution: 
 
 Advanced control theory facilitates precise and reliable actuation. 
 High-fidelity perception models, powered by multimodal sensors, enable machines to interpret complex environments. 
 Edge AI accelerators support real-time inference at the point of action, crucial for latency-sensitive tasks. 
 Foundation models, trained on multimodal datasets, help provide generalizable intelligence across domains. 
 Digital twin systems play a pivotal role in enabling simulation, validation, and optimization of physical systems before real-world deployment, significantly accelerating development cycles. 
 
Industry forces and investment momentum 
Physical AI sits at the intersection of multiple high-growth industries, with the AI Robots sector alone projected to reach a staggering $124.26 billion by 2034. Alongside this, the closely related Digital Twin Technology industry is set to hit an even more impressive $379 billion in the same timeframe. These projections signal a fundamental shift in how enterprises approach automation, efficiency, and digital transformation. 
Investors are keenly aware of this potential, focusing their attention on several key themes within the Physical AI space. Humanoid robotics has emerged as a particularly exciting frontier, with startups securing substantial funding rounds to develop general-purpose robotic workers capable of seamlessly operating in environments designed for humans. Simultaneously, thereâ€™s growing interest in foundation models for robotics â€“ the development of sophisticated â€œrobot brainsâ€ that can adapt to various tasks and control diverse robotic systems. This push towards more flexible, intelligent systems is complemented by continued investment in vertical-specific applications, where companies are leveraging Physical AI to address acute industry challenges, from streamlining warehouse logistics to revolutionizing agricultural practices. The breadth of Physical AIâ€™s potential is further demonstrated by emerging applications in fields as diverse as surgical robotics, autonomous delivery systems, and advanced defense technologies. This expansion into new domains underscores the versatility and transformative power of Physical AI across sectors. 
Real-world impact: quantifying the Physical AI transformation 
While investment trends signal strong future potential, Physical AI is already delivering concrete results across industries. For example, Amazonâ€™s&nbsp;supply chain has boosted efficiency by 25% through intelligent automation, while Foxconn cut manufacturing deployment times by 40%. In healthcare, AI-assisted procedures have led to 30% fewer complications and 25% shorter surgery durations, showcasing transformative outcomes. 
According to a 2024 AI in manufacturing &amp; energy report, 64% of manufacturers using AI in production already report positive ROI, with nearly one-third expecting returns of $2 to $5 for every dollar invested. These gains translate into efficiency improvements between 20-40%, cost savings of 15-30%, and the rise of innovative business models like Robot-as-a-Service. 
In retail, digital twins are being used to explore the impact of different store layouts on shopper behavior and to test the integration of Physical AI with autonomous inventory management systems, helping retailers optimize their physical spaces and operations. Meanwhile, agriculture benefits from advancements in precision farming, crop monitoring, and automated harvestingâ€”further highlighting Physical AIâ€™s broad and growing impact. 
The next frontier 
The impact of Physical AI is already evident across industries, with organizations moving well beyond proofs-of-concept to delivering measurable business value. For participating cohorts, the Physical AI Fellowship will play a key role in helping innovative startups accelerate the path from research to commercial applications of this emerging technology. For enterprises of different sizes and sectors, successful integration of AI with physical systems will define industry leaders in the decade to come. 
Learn more:&nbsp; 
Contact us to learn more about evaluating if your organization is set up to work as teammates, or if youâ€™d like to dive deeper into skill development and risk posture for your physical AI plans. 
Learn more about the Generative AI Innovation Center and how we provide expert tailored support from experimentation to production. 
 
About the authors 
Sri Elaprolu is a technology leader with over 25 years of experience spanning artificial intelligence, machine learning, and software engineering. As Director of the AWS Generative AI Innovation Center, Sri leads a global team of ML scientists and engineers applying the latest advances in generative AI to solve complex challenges for enterprises and the public sector. 
Alla Simoneau is a technology and commercial leader with over 15 years of experience, currently serving as the Emerging Technology Physical AI Lead at Amazon Web Services (AWS), where she drives global innovation at the intersection of AI and real-world applications. With over a decade at Amazon, Alla is a recognized leader in strategy, team building, and operational excellence, specializing in turning cutting-edge technologies into real-world transformations for startups and enterprise customers. 
Paul Amadeo is a seasoned technology leader with over 30 years of experience spanning artificial intelligence, machine learning, IoT systems, RF design, optics, semiconductor physics, and advanced engineering. As Technical Lead for Physical AI in the AWS Generative AI Innovation Center, Paul specializes in translating AI capabilities into tangible physical systems, guiding enterprise customers through complex implementations from concept to production. His diverse background includes architecting computer vision systems for edge environments, designing robotic smart card manufacturing technologies that have produced billions of devices globally, and leading cross-functional teams in both commercial and defense sectors. Paul holds an MS in Applied Physics from the University of California, San Diego, a BS in Applied Physics from Caltech, and holds six patents spanning optical systems, communication devices, and manufacturing technologies. 
Randi Larson bridges the gap between AI innovation and executive strategy at the AWS Generative AI Innovation Center, shaping how organizations understand and translate technical breakthroughs into business value. She combines strategic storytelling with data-driven insight through global keynotes, Amazonâ€™s first tech-for-good podcast, and conversations with industry and Amazon leaders on AI transformation. Before Amazon, Randi refined her analytical precision as a Bloomberg journalist and advisor to economic institutions, think tanks, and family offices on technology initiatives. Randi holds an MBA from Duke Universityâ€™s Fuqua School of Business and a B.S. in Journalism and Spanish from Boston University.
â€¢ Medical reports analysis dashboard using Amazon Bedrock, LangChain, and Streamlit
  In healthcare, the ability to quickly analyze and interpret medical reports is crucial for both healthcare providers and patients. While medical reports contain valuable information, they often remain underutilized due to their complex nature and the time-intensive process of analysis. This complexity manifests in several ways: the interpretation of multiple parameters and their relationships (such as various blood cell counts), the comparison of test results against standard reference ranges, and the need to analyze trends in health parameters over time. To address this challenge, weâ€™ve conceptualized a medical reports analysis dashboard that illustrates how healthcare providers could enhance their interaction with medical data through a sample implementation 
In this post, the created dashboard represents a convergent solution that brings together the power of Amazon Bedrock advanced AI capabilities, LangChainâ€˜s document processing, and Streamlitâ€˜s intuitive user interface. By using these technologies, weâ€™ve created a system that not only stores and displays medical reports, but actively helps interpret them through natural language interactions and dynamic visualizations. 
Solution overview 
At the solutionâ€™s foundation are various large language models available through Amazon Bedrock, including Anthropicâ€™s Claude series and Amazon Nova Foundation Models. You can select from options such as Claude Opus 4.1, Claude 3.7 Sonnet, Amazon Nova Pro, and others, each optimized for different performance and capability requirements. The chosen model processes natural language queries with medical context awareness, enabling detailed interpretation of healthcare data. With this flexibility, you can balance factors like accuracy, speed, and cost based on your specific needs. This is enhanced by LangChainâ€™s document processing capabilities, which manage the retrieval system and maintain conversation context, facilitating accurate and relevant responses. 
The solutionâ€™s data flow begins with medical reports securely stored in Amazon Simple Storage Service (Amazon S3), which are then processed through LangChainâ€™s document handling system. When you interact with the Streamlit frontend, your queries are analyzed by Amazon Bedrock, while LangChain maintains the conversation context and manages document retrieval. The system processes this information and presents results through an intuitive interface featuring interactive visualizations. 
These visualizations, powered by Plotly, include range comparison charts that clearly display normal versus actual values, bar charts for parameter comparisons, and trend lines for tracking changes over time. The Streamlit interface ties everything together, providing real-time interaction with the AI system while managing user session state and conversation history. This comprehensive approach helps ensure that medical professionals can quickly access, analyze, and interpret their medical reports through natural language queries while viewing supporting visual data. 
The following is the architecture diagram of the solution that has four layers: 
 
 User Interface Layer: Streamlit Web App, Chat interface, Plotly data visualizations 
 Processing Layer: LangChain document processing, Conversation retrieval chain, Data parsing 
 AI/ML Layer: Amazon Bedrock, Amazon Bedrock embeddings, In-memory vector store 
 Storage Layer: Amazon S3 for medical reports, Conversation buffer memory 
 
 
Prerequisites 
Before deploying the Medical Reports Analysis Dashboard, you need: 
 
 An AWS account with Amazon Bedrock access enabled 
 AWS Identity and Access Management (IAM) permission for Amazon Bedrock and Amazon S3 
 AWS Command Line Interface (AWS CLI) installed and configured 
 An Amazon S3 bucket for storing medical reports in csv format 
   
   Follow Creating a general purpose bucket to create a bucket. 
   Sample reports provided are in the following repository. The command needed to upload reports is in the deployment section. 
    
 Python 3.9 or later with pip 
 Access to Amazon Bedrock Models. The solution supports multiple models including: 
   
   Anthropicâ€™s Claude series (Opus 4.1, 3.7 Sonnet, Sonnet 4, and so on.) 
   Amazon Nova foundation model series (Nova Pro and Nova Lite) 
    
 
Weâ€™ll be using a Python virtual environment (venv) for this project to provide a clean, isolated environment. Virtual environments help avoid package conflicts between projects and make dependency management more straightforward. While weâ€™re using Pythonâ€™s built-in venv, you could alternatively use miniconda or other environment managers. 
Deployment 
To get started with deployment, install the necessary packages on a local machine. 
 
 Clone the repository: 
 
 
 git clone https://github.com/aws-samples/sample-medical-analysis-dashboard.git 
 
 
 Navigate to the project directory. 
 Create and activate a virtual environment (recommended): 
 
For Mac/Linux: 
 
 python3 -m venv venv
source venv/bin/activate 
 
For Windows: 
 
 python3 -m venv venv
venv\Scripts\activate 
 
 
 Update pip to the latest version: 
 
 
 python3 -m pip install --upgrade pip 
 
 
 Install required packages: 
 
 
 pip install -r requirements.txt 
 
Projectâ€™s dependencies are listed in requirements.txt: 
 
 boto3 
 streamlit 
 unstructured 
 langchain-aws 
 langchain-community 
 pandas 
 plotly 
 numpy 
 docarray 
 
These packages will handle AWS integration, web interface, data processing, and visualizations. Theyâ€™ll be installed in our virtual environment during the deployment process. This setup helps ensure that the components are properly installed and isolated in a virtual environment for optimal performance. 
 
 Follow Configuring environment variables for the AWS CLI to configure AWS credentials. 
 
 
 export AWS_ACCESS_KEY_ID='your-access-key'
export AWS_SECRET_ACCESS_KEY='your-secret-key' 
 
 
 Upload sample CSV files to the S3 bucket created in prerequisites section: 
 
Our repository contains two sample files: 
 
 basic_test.csv: Complete blood work with 15 parameters 
 blood_test.csv with basic parameters 
 
The following is the content of basic_test.csv: 
 
 Parameter,Value,Reference_Range,Unit
Hemoglobin,13.8,13.5-17.5,g/dL
RBC,4.8,4.5-5.9,million/ÂµL
WBC,8500,4000-11000,cells/ÂµL
Glucose,92,70-100,mg/dL
Creatinine,1.0,0.7-1.3,mg/dL 
 
Run the following commands to upload sample files to the S3 bucket: 
 
 aws s3 cp basic_test.csv s3://BUCKET_NAME/

aws s3 cp blood_test.csv s3://BUCKET_NAME/ 
 
Go to app.py line 68 and update the S3 bucket name in app.py to match your actual S3 bucket name. 
 
 BUCKET_NAME = "your-bucket-name" 
 
 
 Run the application: 
 
 
 streamlit run app.py 
 
The dashboard will be available at http://localhost:8501. You can now interact with your medical reports through the web interface. 
Using the dashboard 
This section walks through the key features and demonstrates how to effectively use the dashboard for medical data analysis. 
Dashboard interface overview 
The following figures show the complete dashboard where the selected medical report is blood_test.csv from the repo showing the navigation pane and main content. The first figure also shows the first two graphs. 
 
The following figure shows the second graph of the three that are included in this dashboard. 
 
The dashboard interface is organized into three main sections for medical report analysis: 
 
 Document selection and model choice (navigation pane) 
   
   Selection of Amazon Bedrock model (for example: Claude Opus 4.1, Claude 3.7 Sonnet, or Amazon Nova Pro) 
   List of available medical reports in a dropdown menu 
   Currently analyzing blood_test.csv 
   Token usage display (input, output, and total tokens) 
    
 Chat analysis section 
   
   Clean chat interface for natural language queries 
   History of conversation maintained 
   Clear response formatting 
    
 Visualization area 
   
   Range comparison chart showing normal compared to actual values 
   Bar chart displaying the parameters 
   Trend lines for multiple parameters 
    
 
Context-aware query system 
The dashboardâ€™s AI-powered query system demonstrates sophisticated understanding of medical reports through natural conversations. Hereâ€™s a sequence of interactions showing the systemâ€™s capabilities. 
Question 1: Initial query about hemoglobin: 
 
 What is the hemoglobin level in report? 
 
 
Question 2: Follow-up question demonstrating context awareness: 
 
 How does this compare to other parameters in the report? Are there any that stand out? 
 
 
Question 3: Complex analysis request: 
 
 Can you analyze the distribution patterns of percentage-based measurements versus absolute values in this report, and identify any notable patterns in their reference ranges? 
 
 
The system maintains conversation context while providing detailed insights from the medical reports, supporting responses with relevant data visualizations. 
The solution can be further enhanced by fine-tuning the foundational model on organization-specific medical data, clinical questions, and domain expertise. This specialized training helps the model better understand medical terminology, standard protocols, and institution-specific practices. Additionally, organizations can use pre-trained medical LLMs available in AWS Marketplace, which are specifically optimized for healthcare use cases. When combined with the systemâ€™s existing capabilities, these specialized models can provide contextually relevant responses to medical queries while maintaining compliance with healthcare data governance requirements. 
Amazon Bedrock guardrails should be configured to restrict the model from providing medical advice, prescriptions, or diagnoses, making sure responses are limited to data analysis and interpretation only. 
Security considerations 
While our current deployment uses dummy medical data for demonstration purposes, itâ€™s crucial to consider security and compliance measures for real-world healthcare applications. Here are recommendations for enhancing security in a production environment: 
Data privacy: 
 
 HIPAA compliance: Implement HIPAA-compliant practices, including access controls and audit trails. 
 Encryption: Use Amazon S3 server-side encryption (SSE-S3) for data at rest and TLS for data in transit. 
 Personally identifiable information (PII) protection: 
   
   Apply data masking for PII fields. 
   Control data access through role-based permissions. 
   Monitor model invocation using CloudWatch Logs and Amazon S3. 
   Configure Amazon Bedrock Guardrails. You can use guardrails to also restrict the model from providing medical advice, prescriptions, or diagnoses, limiting responses to data analysis and interpretation only. 
    
 Amazon S3 Configuration: Secure your medical data storage with the following S3 bucket settings 
   
   Enable versioning to maintain a complete audit trail and protect against accidental deletions or modifications 
   Block public access at both bucket and account levels 
   Implement strict bucket policies that limit access to specific IAM roles and enforce encryption in transit 
   Configure encryption (AES-256 or KMS) for all objects uploaded to the bucket 
    
 
Recommended AWS security implementation: 
 
 IAM roles: Create specific IAM roles following the principle of least for each service 
 S3 bucket encryption: Enable default AES-256 encryption for all objects 
 Amazon Bedrock API access: Secure access using IAM roles and proper API key management 
 Audit logging: Activate AWS CloudTrail for comprehensive API call logging. 
   
   Log data access events on S3 buckets, Amazon Bedrock API calls, and IAM user and role activities 
   Monitor and record management events for S3 bucket configuration changes and policy updates 
    
 
These are general recommendations. For a production healthcare application, consult with security experts and conduct a risk assessment to make sure all relevant compliance standards are met. 
Clean up 
To avoid ongoing AWS charges, follow these steps to clean up the resources created: 
 
 Delete the created Amazon S3 bucket 
 Delete the created local resources: 
 
 
 # Deactivate virtual environment
deactivate
# Remove project directory and virtual environment
rm -rf medical-analysis-dashboard/ 
 
Conclusion 
In this post, we demonstrated the development of a conceptual Medical Reports Analysis Dashboard that combines Amazon Bedrock AI capabilities, LangChainâ€™s document processing, and Streamlitâ€™s interactive visualization features. The solution transforms complex medical data into accessible insights through a context-aware chat system powered by large language models available through Amazon Bedrock and dynamic visualizations of health parameters. 
This project showcases how cloud and AI technologies can be applied to healthcare analytics, making medical report interpretation more intuitive and efficient. While our implementation uses dummy data for demonstration purposes, the architecture provides a foundation for building secure, compliance-aligned healthcare applications that can be enhanced to meet healthcare organizational requirements and security protocols. 
 
About the authors 
Aditya Ranjan is a Delivery Consultant with AWS, specializing in distributed systems architecture and cloud-native solutions. He collaborates with customers to design and implement well-architected technical solutions using AWSâ€™s latest technologies, including generative AI services, enabling them to achieve their business goals and objectives. 
Shubham Tiwari is a Solutions Architect at AWS specializing in Modernisation, containers and Security. He has been helping customers in deploying highly scalable, resilient and cost optimised architecture on AWS.
â€¢ Kitsa transforms clinical trial site selection with Amazon Quick Automate
  This post was written with Ajay Nyamati from Kitsa. 
The clinical trial industry conducts medical research studies to evaluate the safety, efficacy, and effectiveness of new drugs, treatments, or medical devices before they reach the market. The industry is a cornerstone of medical innovation, yet it continues to face a fundamental bottleneck: selection of the right trial sites based on the requirement by clinical trial sponsors and contract research organizations (CROs). 
Although there are tens of thousands of potential research sites worldwide, the decision-making process is still heavily influenced by personal networks, limited visibility, and incomplete data. The result is delayed trial launches, underutilized site capacity, and missed opportunities for both sponsors and research centers. 
Key challenges in site selection include: 
 
 Data fragmentation: Site performance and operational data are scattered across siloed systems, inconsistent formats, and unstructured online sources. 
 Manual effort and low coverage: Sponsors and CROs often review only a fraction of the available sites due to the time and cost of manual analysis. 
 Over-reliance of Key Opinion Leaders (KOLs): Personal preference and relationships often outweigh objective performance metrics. 
 Missed opportunities for capable sites: Many high-quality sites are overlooked because they lack a centralized platform to showcase their capabilities. 
 Knowledge hoarding: Organizations with large datasets often keep them proprietary, limiting industry-wide progress. 
 
In this post, weâ€™ll show how Kitsa used Amazon Quick Automate to transform their clinical trial site selection solution. Amazon Quick Automate, a capability of Amazon Quick Suite, enables enterprises to build, deploy and maintain resilient workflow automations at scale. Amazon Quick Suite helps business users make better decisions faster and act on them by unifying AI agents for research, business insights, and automation into a single experience. 
Kitsa, a health-tech company specializing in AI-driven clinical trial recruitment and site selection, is tackling the challenge in site selection. By combining demographic data, disease prevalence insights, historical trial performance, and operational site metrics, Kitsa has developed an agentic analytics engine that matches sponsors with the most suitable sites for their studies. This approach requires consolidating and analyzing data from hundreds of fragmented sources, including websites of clinical trial sites, clinical trial registries, investigator resumes, regulatory filings, publications, and conference abstracts. Traditionally, this has been a slow, manual process that pushed trial start dates by months. 
To address this, Kitsa turned to Amazon Web Services (AWS) to build a scalable, secure, and compliant automation pipeline that unifies this data into a single decision-making engine. Using Quick Automate, a generative AIâ€“powered workflow automation capability of Amazon Quick Suite, Kitsa can rapidly extract, normalize, and analyze site data at scale. With an advanced multi-agent automation architecture engineered for enterprise-scale deployment, Quick Automate combines UI automation, API integrations, and workflow orchestration in a single, fully managed solution. 
Quick Automate uses generative AI to analyze inputs from the user and suggests a workflow that can be modified and extended to take action across business systems and UIs, engaging a human when needed. Through specialized AI agents, Quick Automate helps organizations to automate complex processes across applications and departments. It also reduces operational costs through usage-based pricing. 
By using AWS services, Kitsa is transforming site selection from a slow, relationship-driven process into a fast, data-driven, and globally scalable system. 
Solution overview and details 
Kitsa required a process automation solution capable of navigating websites, extracting over 50 distinct data points, and compiling the results in a structured format. The solution needed to be highly reliable, scalable to hundreds of thousands of websites, and accurate. Given that Kitsa operates in the life sciences and healthcare sector, which is heavily regulated, they also needed a secure, compliant solution that meets the industryâ€™s strict standards. 
The automation was built using Quick Automate, designed for enterprise-scale workflow automation. A key component of the solution is a state-of-the-art UI Agent, configured to autonomously perform website navigation and data extraction. The UI Agent is part of Quick Automate, enabling complex browser-based workflows. 
The UI Agent takes natural language input and produces structured outputsâ€”essential for reliably capturing more than 50 data points from each website. It was configured to extract information efficiently and consistently, maintaining both accuracy and compliance. The AWS team collaborated closely with the Kitsa team to design and refine specialized prompts, helping the automation perform optimally for the customerâ€™s needs. The following architecture diagram illustrates the workflow. 
 
Workflow architecture and implementation 
The automation workflow uses the following: 
Case initialization and parallel processing 
The automation begins by fetching cases, where each case contains the URL that needs information extraction. The case management functionality enables parallelization of website processing and evaluation, reducing processing time through concurrent execution of multiple cases. 
Intelligent data extraction 
For each case, the UI Agent navigates to the specified URL and extracts required information while applying AI reasoning concerning the content. The information extraction process utilizes natural language instructions provided to the UI Agent task. It then delivers results in a structured output format, so downstream workflow steps can consume them without extra parsing. 
Human-in-the-loop integration 
When website information extraction shows lower confidence, the system can automatically route cases to human reviewers for manual assessment. This human-in-the-loop (HILO) approach maintains quality control while allowing automated processing. 
Data persistence and storage 
Processed cases are systematically saved and written to an Excel spreadsheet within the workflow. The completed files are then uploaded to an Amazon Simple Storage Service (Amazon S3) bucket through integrated S3 connectors, providing secure and accessible data storage. 
Robust exception handling 
The workflow incorporates exception handling mechanisms to gracefully manage scenarios where websites are not found, under construction, or otherwise inaccessible. The workflow returns accurate error messages and continues processing subsequent websites without interrupting the overall workflow execution, resulting in operational continuity and reliability. 
Results 
With Quick Automate powering the Kitsa large-scale data extraction and integration workflow solution, the impact was immediate and measurable: 
 
 91% cost savings: Compared to the legacy manual process it lowered operational expenses while dramatically expanding the number of sites analyzed. 
 96% faster data acquisition: Kitsa is able to process in days what previously took months, accelerating the entire site feasibility process. 
 96% coverage in data extraction: Surpasses manual review while maintaining consistency across hundreds of thousands of processed websites. 
 Full regulatory compliance: Meets all data security, privacy, and auditability standards required in life sciences and healthcare. 
 
The solution now directly powers the Kitsa Site Finder Agent, which evaluates hundreds of site-specific parameters (from past recruitment speed to infrastructure readiness), and ranks them with a trial-specific algorithm. Sponsors can now compare sites on hard evidence rather than subjective impressions, and eligible sites can showcase their capabilities to pharma companies for the first time in a structured, data-rich format. 
As Rohit Banga, Co-Founder &amp; CTO of Kitsa, explains: 

 â€œWith Amazon Quick Automate, we were able to break through one of the biggest bottlenecks in site selection â€” collecting and unifying high-quality data at scale. This allowed our Site Finder Agent to evaluate more sites, more fairly, and with more precision than ever before. Our results show 96% coverage in data extraction, 91% cost savings compared to legacy manual processes, and 96% faster data acquisition â€“ processing in days what previously took months.â€
 
Conclusion 
Clinical trial site selection has long been a critical bottleneck in medical research, with fragmented data and manual processes causing significant delays and missed opportunities. Kitsa addressed this challenge by using the Automate capability of Amazon Quick Suite in their automated site selection solution. 
With the solution Kitsa can automatically extract and analyze over 50 distinct data points from hundreds of thousands of websites. They are achieving remarkable results with 96% coverage in data extraction and 91% cost savings compared to manual processes. Kitsa also reduced their data acquisition time by 96% while maintaining full regulatory compliance in the heavily regulated healthcare sector. 
Their Site Finder Agent now evaluates hundreds of site-specific parameters objectively, helping pharmaceutical companies to make evidence-based decisions and allowing trial sites to showcase their capabilities in a structured format. This transformation demonstrates how Quick Automate can solve complex industry challenges while significantly improving efficiency, accuracy, and fairness in clinical trial site selection. 
Contact an AWS Representative to know how we can help accelerate your business. 
 
About the authors 
Chethan Shriyan is a Principal Product Manager â€“ Technical at AWS. He has 12+ years of experience in product and business management. Chethan is passionate about building and delivering technology products that create meaningful impact in customersâ€™ lives. 
Ajay Nyamati is the co-founder and CEO of Kitsa â€“ a healthtech company using AI and data automation to transform clinical trials. With 20+ years of Sales &amp; Strategy in global companies, Ajay has spent 10+ years in the Digital Health space across payors, providers and pharma. Before co-founding Kitsa, he was the business leader for clinical trials solutions in Amazon Web Services. 
Reagan Rosario brings over a decade of technical expertise to his role as a Sr. Specialist Solutions Architect in Generative AI at AWS. Reagan transforms enterprise systems through strategic implementation of AI-powered cloud solutions, automated workflows, and innovative architecture design. His specialty lies in guiding organizations through digital evolutionâ€”preserving core business value while implementing cutting-edge generative AI capabilities that dramatically enhance operations and create new possibilities.

â¸»