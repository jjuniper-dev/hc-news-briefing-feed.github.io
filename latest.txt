‚úÖ Morning News Briefing ‚Äì November 12, 2025 10:48

üìÖ Date: 2025-11-12 10:48
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions:  -1.8¬∞C
  Temperature: -1.8&deg;C Pressure / Tendency: 100.1 kPa falling Humidity: 92 % Wind Chill: -3 . Dewpoint: -2.9&deg:C Wind: SE 4 km/h Air Quality Health Index: n/a . Pembroke 5:00 AM EST Wednesday 12 November 2025 Temperature: 1.8
‚Ä¢ Wednesday: Rain or snow. High plus 3.
  Snowfall amount 2 cm over higher terrain . Snow changing to rain near noon . Wind becoming west 30 km/h this afternoon . High plus 3. UV index 1 or low . Snowfall amounts 2cm over high terrain . Rain expected to change to rain in the morning of Wednesday 12 November 2025 . Forecast issued 5:00 AM EST Wednesday 12 Nov 2025. For confidential support call

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ It's harder to get home insurance. That's changing communities across the U.S.
  Home insurance is getting less affordable, and less available, as insurers raise prices and pull back from areas with extreme weather . That's forcing families across the country to make tough choices . Insurance companies are raising prices and pulling back from those areas with severe weather . Families across the U.S. are making tough choices as they face tough choices in their home insurance choices, says Ryan Kellman
‚Ä¢ They found a 'bucket of lentils.' Then it blew up. The menace of Gaza's unexploded ordnance
  The United Nations Mine Action Service estimates between 5% and 10% of Israeli weapons fired into Gaza in the past two years failed to detonate . Unexploded ordnance has killed at least 328 people, according to the U.N. Mine Action Services . The UN estimates 5% to 10% Israeli weapons fire into Gaza failed to explode, killing 328 people and injuring at least 5
‚Ä¢ The shutdown could be nearing its end, but high demand for food assistance lingers
  The Capital Area Food Bank in Washington D.C. allotted an extra 1 million meals for November, given the uncertainties about whether and when SNAP recipients will get their full benefits . The food bank says it's allotted a million extra meals given uncertainty about when and when recipients will receive full benefits for the first time . The Food Bank says it has been allocated extra meals for the month of November
‚Ä¢ Adelita Grijalva is set to be sworn in, teeing up a potential vote on Epstein files
  Grijalva has vowed to be the decisive signature in a bid to release the Epstein files . The Arizona Democrat won her race in September, but Speaker Mike Johnson has waited to swear her in until today . Grijalava won her seat in September but was sworn in in September . Grialva vowed to fight for the release of Epstein files in her bid to get them released
‚Ä¢ Here's how many strikes on alleged drug vessels the U.S. has announced
  Since September, the Trump administration has carried out more than a dozen strikes on boats it claims are run by drug traffickers . More than 70 people have been killed in the strikes, killing more than 70 since September . The strikes have been carried out against boats run by traffickers, the U.S. government says . The U.N. says the strikes have killed at least 70 people .

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Aviation watchdog says organized drone attacks will shut UK airports ‚Äòsooner or later‚Äô
  Hard-to-trace drones and fast-moving cyber raids promise new wave of disruption . Britain's aviation watchdog has warned it's only a matter of time before organized drone attacks bring UK airports to a standstill . Airports are open for mischief as hard to trace drones and cyber attacks promise to disrupt disruption . UK airports are being targeted by hard-to trace drones, cyber raids and
‚Ä¢ Retail giant Kingfisher rejects SAP ERP upgrade plan
  SAP insists customers wanting "innovation" such as AI must upgrade to its latest platform for ERP . Kingfisher - which operates 2,000 European retail stores including UK brands Screwfix and B&amp;Q - rejected that approach . 'Don't just give me a price list or licensing module that spikes cost by 20x, show me the value,' says CTO SAP
‚Ä¢ Tablet market stalls because there‚Äôs not much new worth buying
  Pre-tariff purchasing panic also helped to end 18-month growth run . Shipments of tablet computers from minor vendors are on the slide, according to analyst firm IDC . IDC: Tablet computers are on a slide, with tablet sales on the way down from $1 billion to $1.2 billion in 2013 . iPad sales also on the decline for the past 18 months
‚Ä¢ China hates crypto and scams, but is now outraged USA acquired bitcoin from a scammer
  China‚Äôs National Computer Virus Emergency Response Center (CVERC) has alleged a nation-state entity, probably the USA, was behind a 2020 attack on a bitcoin mining operation . By doing so, the agency has gone into bat for entities that Beijing usually blasts . The agency has accused the USA of being behind the attack on the mining operation and by doing so it has gone
‚Ä¢ Australia‚Äôs spy boss says authoritarian nations ready to commit ‚Äòhigh-impact sabotage‚Äô
  ‚ÄòElite teams‚Äô are pondering cyber-attacks to turn off energy supply or telecoms networks . The head of Australia‚Äôs Security Intelligence Organisation (ASIO) has warned that authoritarian regimes ‚Äúare growing more willing to disrupt or destroy critical infrastructure‚Äù using cyber-sabotage . ASIO: ‚ÄòThe authoritarian regimes are growing more willingness to

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ The evolving landscape of cardiovascular health in Africa: insights from WHO AFRO
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Argo Delphi consensus statement on red flags and clinical gateways towards rare disease diagnosis
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Mass production of IgY-containing tablets for COVID-19 transmission control
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Vaccine advice based on science: US centre fills gaps in public-health information
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Optimized loading effects on pressure steam sterilization of loaned surgical instruments using product family categorization
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ Improving VMware migration workflows with agentic AI
  CNCF‚Äôs 2024 Annual Survey, 89% of organizations have already adopted at least some cloud-native techniques . Share of companies reporting nearly all development and deployment as cloud native grew sharply from 2023 to 2024 (20% to 24%) Market research firm IDC reports that cloud providers have become top strategic partners for generative AI initiatives . As enterprises prepare for that inevitability, they are facing compute demands that are difficult, if not prohibitively expensive, to maintain exclusively on-premises .
‚Ä¢ The Download: surviving extreme temperatures, and the big whale-wind turbine conspiracy
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



The quest to find out how our bodies react to extreme temperatures



Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. That‚Äôs heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.While we broadly know how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. Researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and cold‚Äîand how to survive in a new world. Read the full story.



‚ÄîMax G.Levy



This story is from the latest print issue of MIT Technology Review magazine, which is full of fascinating stories about the body. If you haven‚Äôt already, subscribe now to receive future issues once they land.







Whales are dying. Don‚Äôt blame wind turbines.



Whale deaths have become a political flashpoint. There are currently three active mortality events for whales in the Atlantic, meaning clusters of deaths that experts consider unusual. And Republican lawmakers, conservative think tanks, and‚Äîmost notably‚ÄîPresident Donald Trump (a longtime enemy of wind power) are making dubious claims that offshore wind farms are responsible.But any finger-pointing at wind turbines for whale deaths ignores the fact that whales have been washing up on beaches since long before the giant machines were rooted in the ocean floor. This is something that has always happened. And the scientific consensus is clear: There‚Äôs no evidence that wind farms are the cause of recent increases in whale deaths. Read the full story.



‚ÄîCasey Crownhart



This story is part of MIT Technology Review‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology. Check out the rest of the series here.







The State of AI: Energy is king, and the US is falling behind



In the age of AI, the biggest barrier to progress isn‚Äôt money but energy. That should be particularly worrying in the US, where massive data centers are waiting to come online. It doesn‚Äôt look as if the country will build the steady power supply or infrastructure needed to serve them all.It wasn‚Äôt always like this. For about a decade before 2020, data centers were able to offset increased demand with efficiency improvements. Now, though, electricity demand is ticking up in the US, with billions of queries to popular AI models each day‚Äîand efficiency gains aren‚Äôt keeping pace.If we want AI to have the chance to deliver on big promises without driving electricity prices sky-high for the rest of us, the US needs to learn some lessons from the rest of the world on energy abundance. Just look at China. Read the full story.



‚ÄîCasey Crownhart &amp; Pilita Clark



This is from The State of AI, our subscriber-only collaboration between the Financial Times &amp; MIT Technology Review examining the ways in which AI is reshaping global power.Every Monday for the next four weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. While subscribers to The Algorithm, our weekly AI newsletter, get access to an extended excerpt, subscribers to the magazine are able to read the whole thing. Sign up here to receive future editions every Monday.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 How China narrowed its AI divide with the USAmerica still has a clear lead‚Äîbut for how long? (WSJ $)+ The AI boom won‚Äôt offset tariffs and America‚Äôs immigration crackdown forever. (FT $)+ How quickly is AI likely to progress really? (Economist $)+ Is China about to win the AI race? (MIT Technology Review)



2 Anthropic is due to turn a profit much faster than OpenAIThe two companies are taking very different approaches to making money. (WSJ $)+ OpenAI has lured Intel‚Äôs AI chief away. (Bloomberg $)



3 The EU is setting up a new intelligence sharing unitIt‚Äôs a bid to shore up intel in the wake of Donald Trump‚Äôs plans to reduce security support for Europe. (FT $)



4 Trump officials are poised to suggest oil drilling off the coast of CaliforniaThat&#8217;s likely to rile the state‚Äôs politicians and leaders. (WP $)+ What role should oil and gas companies play in climate tech? (MIT Technology Review)



5 America‚Äôs cyber defenses are poorRepeated cuts and mass layoffs are making it harder to protect the nation. (The Verge)



6 China is on track to hit its peak CO2 emissions target earlyAlthough it‚Äôs likely to miss its goal for cutting carbon intensity. (The Guardian)+ World leaders are heading to COP30 in Brazil this week. (New Yorker $)



7 OpenAI cannot use song lyrics without a licenseThat‚Äôs what a German court has decided, after siding with a music rights society. (Reuters)+ OpenAI is no stranger to legal proceedings. (The Atlantic $)+ AI is coming for music. (MIT Technology Review)



8 A small Michigan town is fighting a proposed AI data centerThe planned center is part of a collaboration between the University of Michigan and nuclear weapons scientists. (404 Media)+ Here‚Äôs where America‚Äôs data centers should be built instead. (Wired $)+ Communities in Latin America are pushing back, too. (The Guardian)+ Should we be moving data centers to space? (MIT Technology Review)9 AI models can‚Äôt tell the time Analog clocks leave them completely stumped. (IEEE Spectrum)



10 ChatGPT is giving daters the ickThese refuseniks don‚Äôt want anything to do with AI, or love interests who use it. (The Guardian)







Quote of the day



‚ÄúI never imagined that making a cup of tea or obtaining water, antibiotics, or painkillers would require such tremendous effort.‚Äù



‚ÄîAn anonymous member of startup accelerator Gaza Sky Geeks tells Rest of World about the impact the war has had on them.







One more thing







How Rust went from a side project to the world‚Äôs most-loved programming languageMany software projects emerge because‚Äîsomewhere out there‚Äîa programmer had a personal problem to solve.That‚Äôs more or less what happened to Graydon Hoare. In 2006, Hoare was a 29-year-old computer programmer working for Mozilla. After a software crash broke the elevator in his building, he set about designing a new computer language; one that he hoped would make it possible to write small, fast code without memory bugs.That language developed into Rust, one of the hottest new languages on the planet. But while it isn‚Äôt unusual for someone to make a new computer language, it‚Äôs incredibly rare for one to take hold and become part of the programming pantheon. How did Rust do it? Read the full story.¬†



‚ÄîClive Thompson







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Having a bit of a rubbish day so far? Here‚Äôs how to make it better.+ A Hungarian man played Dance Dance Revolution for 144 hours non-stop, because he knows how to have a seriously good time.+ A new book is celebrating cats, as it should (thanks Jess!)+ How a poem from a medieval trickster sowed the seed for hundreds of years of bubonic plague misinformation
‚Ä¢ The State of AI: Energy is king, and the US is falling behind
  Welcome back to¬†The State of AI, a new collaboration between the Financial Times and MIT Technology Review. Every Monday, writers from both publications debate one aspect of the generative AI revolution and how it is reshaping global power.



This week, Casey Crownhart, senior reporter for energy at MIT Technology Review and Pilita Clark, FT&#8217;s columnist, consider how China&#8217;s rapid renewables buildout could help it leapfrog on AI progress.







Casey Crownhart writes:



In the age of AI, the biggest barrier to progress isn‚Äôt money but energy. That should be particularly worrying here in the US, where massive data centers are waiting to come online, and it doesn‚Äôt look as if the country will build the steady power supply or infrastructure needed to serve them all.



It wasn‚Äôt always like this. For about a decade before 2020, data centers were able to offset increased demand with efficiency improvements. Now, though, electricity demand is ticking up in the US, with billions of queries to popular AI models each day‚Äîand efficiency gains aren‚Äôt keeping pace. With too little new power capacity coming online, the strain is starting to show: Electricity bills are ballooning for people who live in places where data centers place a growing load on the grid.



If we want AI to have the chance to deliver on big promises without driving electricity prices sky-high for the rest of us, the US needs to learn some lessons from the rest of the world on energy abundance. Just look at China.



China installed 429 GW of new power generation capacity in 2024, more than six times the net capacity added in the US during that time.



China still generates much of its electricity with coal, but that makes up a declining share of the mix. Rather, the country is focused on installing solar, wind, nuclear, and gas at record rates.



The US, meanwhile, is focused on reviving its ailing coal industry. Coal-fired power plants are polluting and, crucially, expensive to run. Aging plants in the US are also less reliable than they used to be, generating electricity just 42% of the time, compared with a 61% capacity factor in 2014.



It‚Äôs not a great situation. And unless the US changes something, we risk becoming consumers as opposed to innovators in both energy and AI tech. Already, China earns more from exporting renewables than the US does from oil and gas exports.&nbsp;



Building and permitting new renewable power plants would certainly help, since they‚Äôre currently the cheapest and fastest to bring online. But wind and solar are politically unpopular with the current administration. Natural gas is an obvious candidate, though there are concerns about delays with key equipment.



One quick fix would be for data centers to be more flexible. If they agreed not to suck electricity from the grid during times of stress, new AI infrastructure might be able to come online without any new energy infrastructure.





One study from Duke University found that if data centers agree to curtail their consumption just 0.25% of the time (roughly 22 hours over the course of the year), the grid could provide power for about 76 GW of new demand. That‚Äôs like adding about 5% of the entire grid‚Äôs capacity without needing to build anything new.



But flexibility wouldn‚Äôt be enough to truly meet the swell in AI electricity demand. What do you think, Pilita? What would get the US out of these energy constraints? Is there anything else we should be thinking about when it comes to AI and its energy use?&nbsp;



Pilita Clark responds:



I agree. Data centers that can cut their power use at times of grid stress should be the norm, not the exception. Likewise, we need more deals like those giving cheaper electricity to data centers that let power utilities access their backup generators. Both reduce the need to build more power plants, which makes sense regardless of how much electricity AI ends up using.



This is a critical point for countries across the world, because we still don‚Äôt know exactly how much power AI is going to consume.&nbsp;



Forecasts for what data centers will need in as little as five years‚Äô time vary wildly, from less than twice today‚Äôs rates to four times as much.



This is partly because there‚Äôs a lack of public data about AI systems‚Äô energy needs. It‚Äôs also because we don‚Äôt know how much more efficient these systems will become. The US chip designer Nvidia said last year that its specialized chips had become 45,000 times more energy efficient over the previous eight years.&nbsp;



Moreover, we have been very wrong about tech energy needs before. At the height of the dot-com boom in 1999, it was erroneously claimed that the internet would need half the US‚Äôs electricity within a decade‚Äînecessitating a lot more coal power.



Still, some countries are clearly feeling the pressure already. In Ireland, data centers chew up so much power that new connections have been restricted around Dublin to avoid straining the grid.



Some regulators are eyeing new rules forcing tech companies to provide enough power generation to match their demand. I hope such efforts grow. I also hope AI itself helps boost power abundance and, crucially, accelerates the global energy transition needed to combat climate change. OpenAI‚Äôs Sam Altman said in 2023 that ‚Äúonce we have a really powerful super intelligence, addressing climate change will not be particularly difficult.‚Äù&nbsp;



The evidence so far is not promising, especially in the US, where renewable projects are being axed. Still, the US may end up being an outlier in a world where ever cheaper renewables made up more than 90% of new power capacity added globally last year.&nbsp;



Europe is aiming to power one of its biggest data centers predominantly with renewables and batteries. But the country leading the green energy expansion is clearly China.



The 20th century was dominated by countries rich in the fossil fuels whose reign the US now wants to prolong. China, in contrast, may become the world‚Äôs first green electrostate. If it does this in a way that helps it win an AI race the US has so far controlled, it will mark a striking chapter in economic, technological, and geopolitical history.



Casey Crownhart replies:



I share your skepticism of tech executives‚Äô claims that AI will be a groundbreaking help in the race to address climate change. To be fair, AI is progressing rapidly. But we don‚Äôt have time to wait for technologies standing on big claims with nothing to back them up.&nbsp;



When it comes to the grid, for example, experts say there‚Äôs potential for AI to help with planning and even operating, but these efforts are still experimental.&nbsp;&nbsp;



Meanwhile, much of the world is making measurable progress on transitioning to newer, greener forms of energy. How that will affect the AI boom remains to be seen. What is clear is that AI is changing our grid and our world, and we need to be clear-eyed about the consequences.&nbsp;



Further reading&nbsp;



MIT Technology Review reporters did the math on the energy needs of an AI query.



There are still a few reasons to be optimistic about AI‚Äôs energy demands.&nbsp;&nbsp;



The FT‚Äôs visual data team take a look inside the relentless race for AI capacity.



And global FT reporters ask whether data centers can ever truly be green.
‚Ä¢ Reimagining cybersecurity in the era of AI and quantum
  AI and quantum technologies are dramatically reconfiguring how cybersecurity functions, redefining the speed and scale with which digital defenders and their adversaries can operate.







The weaponization of AI tools for cyberattacks is already proving a worthy opponent to current defenses. From reconnaissance to ransomware, cybercriminals can automate attacks faster than ever before with AI. This includes using generative AI to create social engineering attacks at scale, churning out tens of thousands of tailored phishing emails in seconds, or accessing widely available voice cloning software capable of bypassing security defenses for as little as a few dollars. And now, agentic AI raises the stakes by introducing autonomous systems that can reason, act, and adapt like human adversaries.



But AI isn‚Äôt the only force shaping the threat landscape. Quantum computing has the potential to seriously undermine current encryption standards if developed unchecked. Quantum algorithms can solve the mathematical problems underlying most modern cryptography, particularly public-key systems like RSA and Elliptic Curve, widely used for secure online communication, digital signatures, and cryptocurrency.



‚ÄúWe know quantum is coming. Once it does, it will force a change in how we secure data across everything, including governments, telecoms, and financial systems,‚Äù says Peter Bailey, senior vice president and general manager of Cisco‚Äôs security business.



‚ÄúMost organizations are understandably focused on the immediacy of AI threats,&#8221; says Bailey. ‚ÄúQuantum might sound like science fiction, but those scenarios are coming faster than many realize. It‚Äôs critical to start investing now in defenses that can withstand both AI and quantum attacks.‚Äù



Critical to this defense is a zero trust approach to cybersecurity, which assumes no user or device can be inherently trusted. By enforcing continuous verification, zero trust enables constant monitoring and ensures that any attempts to exploit vulnerabilities are quickly detected and addressed in real time. This approach is technology-agnostic and creates a resilient framework even in the face of an ever-changing threat landscape.



Putting up AI defenses&nbsp;



AI is lowering the barrier to entry for cyberattacks, enabling hackers even with limited skills or resources to infiltrate, manipulate, and exploit the slightest digital vulnerability.



Nearly three-quarters (74%) of cybersecurity professionals say AI-enabled threats are already having a significant impact on their organization, and 90% anticipate such threats in the next one to two years.&nbsp;



‚ÄúAI-powered adversaries have advanced techniques and operate at machine speed,‚Äù says Bailey. ‚ÄúThe only way to keep pace is to use AI to automate response and defend at machine speed.‚Äù



To do this, Bailey says, organizations must modernize systems, platforms, and security operations to automate threat detection and response‚Äîprocesses that have previously relied on human rule-writing and reaction times. These systems must adapt dynamically as environments evolve and criminal tactics change.



At the same time, companies must strengthen the security of their AI models and data to reduce exposure to manipulation from AI-enabled malware. Such risks could include, for instance, prompt injections, where a malicious user crafts a prompt to manipulate an AI model into performing unintended actions, bypassing its original instructions and safeguards.



Agentic AI further ups the ante, with hackers able to use AI agents to automate attacks and make tactical decisions without constant human oversight. ‚ÄúAgentic AI has the potential to collapse the cost of the kill chain,‚Äù says Bailey. ‚ÄúThat means everyday cybercriminals could start executing campaigns that today only well-funded espionage operations can afford.‚Äù



Organizations, in turn, are exploring how AI agents can help them stay ahead. Nearly 40% of companies expect agentic AI to augment or assist teams over the next 12 months, especially in cybersecurity, according to Cisco‚Äôs 2025 AI Readiness Index. Use cases include AI agents trained on telemetry, which can identify anomalies or signals from machine data too disparate and unstructured to be deciphered by humans.&nbsp;



Calculating the quantum threat



As many cybersecurity teams focus on the very real AI-driven threat, quantum is waiting on the sidelines. Almost three-quarters (73%) of US organizations surveyed by KPMG say they believe it is only a matter of time before cybercriminals are using quantum to decrypt and disrupt today‚Äôs cybersecurity protocols. And yet, the majority (81%) also admit they could do more to ensure that their data remains secure.



Companies are right to be concerned. Threat actors are already carrying out harvest now, decrypt later attacks, stockpiling sensitive encrypted data to crack once quantum technology matures. Examples include state-sponsored actors intercepting government communications and cybercriminal networks storing encrypted internet traffic or financial records.&nbsp;



Large technology companies are among the first to roll out quantum defenses. For example, Apple is using cryptography protocol PQ3 to defend against harvest now, decrypt later attacks on its iMessage platform. Google is testing post-quantum cryptography (PQC)‚Äîwhich is resistant to attacks from both quantum and classical computers‚Äîin its Chrome browser. And Cisco ‚Äúhas made significant investments in quantum-proofing our software and infrastructure,‚Äù says Bailey. ‚ÄúYou‚Äôll see more enterprises and governments taking similar steps over the next 18 to 24 months,‚Äù he adds.&nbsp;



As regulations like the US Quantum Computing Cybersecurity Preparedness Act lay out requirements for mitigating against quantum threats, including standardized PQC algorithms by the National Institute of Standards and Technology, a wider range of organizations will start preparing their own quantum defenses.&nbsp;



For organizations beginning that journey, Bailey outlines two key actions. First, establish visibility. ‚ÄúUnderstand what data you have and where it lives,‚Äù he says. ‚ÄúTake inventory, assess sensitivity, and review your encryption keys, rotating out any that are weak or outdated.‚Äù



Second, plan for migration. ‚ÄúNext, assess what it will take to support post-quantum algorithms across your infrastructure. That means addressing not just the technology, but also the process and people implications,‚Äù Bailey says.



Adopting proactive defense&nbsp;



Ultimately, the foundation for building resilience against both AI and quantum is a zero trust approach, says Bailey. By embedding zero trust access controls across users, devices, business applications, networks, and clouds, this approach grants only the minimum access required to complete a task and enables continuous monitoring. It can also minimize the attack surface by confining a potential threat to an isolated zone, preventing it from accessing other critical systems.



Into this zero trust architecture, organizations can integrate specific measures to defend against AI and quantum risks. For instance, quantum-immune cryptography and AI-powered analytics and security tools can be used to identify complex attack patterns and automate real-time responses.&nbsp;



‚ÄúZero trust slows down attacks and builds resilience,‚Äù Bailey says. ‚ÄúIt ensures that even if a breach occurs, the crown jewels stay protected and operations can recover quickly.‚Äù



Ultimately, companies should not wait for threats to emerge and evolve. They must get ahead now. ‚ÄúThis isn‚Äôt a what-if scenario; it‚Äôs a when,‚Äù says Bailey. ‚ÄúOrganizations that invest early will be the ones setting the pace, not scrambling to catch up.‚Äù



This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.
‚Ä¢ The Download: busting weather myths, and AI heart attack prediction
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Why it‚Äôs so hard to bust the weather control conspiracy theory



It was October 2024, and Hurricane Helene had just devastated the US Southeast. Representative Marjorie Taylor Greene of Georgia found an abstract target on which to pin the blame: ‚ÄúYes they can control the weather,‚Äù she posted on X. ‚ÄúIt‚Äôs ridiculous for anyone to lie and say it can‚Äôt be done.‚ÄùShe was repeating what‚Äôs by now a pretty familiar and popular conspiracy theory: that shadowy forces are out there, wielding technology to control the weather and wreak havoc on their enemies. This preposterous claim has grown louder and more common in recent years, especially after extreme weather strikes.But here‚Äôs the thing: While Greene and other believers are not correct, this conspiracy theory‚Äîlike so many others‚Äîholds a kernel of much more modest truth. Read the full story.



‚ÄîDave Levitan



This story is part of MIT Technology Review‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology. Check out the rest of the series here.







AI could predict who will have a heart attack&nbsp;



For all the modern marvels of cardiology, we struggle to predict who will have a heart attack. Many people never get screened at all. Now, startups are applying AI algorithms to screen millions of CT scans for early signs of heart disease.This technology could be a breakthrough for public health, applying an old tool to uncover patients whose high risk for a heart attack is hiding in plain sight. But it remains unproven at scale, while raising thorny questions about implementation and even how we define disease. Read the full story.



‚ÄîVishal Khetpal



This story is from the latest print issue of MIT Technology Review magazine, which is full of fascinating stories about the body. If you haven‚Äôt already, subscribe now to receive future issues once they land.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 Spending on AI may be to blame for all those tech layoffsAI isn‚Äôt necessarily replacing jobs, but spending on it is gobbling up budgets. (Fast Company $)+ Junior roles are likely to be the first on the chopping block. (FT $)+ Are the crazy sums that businesses are sinking into AI sustainable? (WP $)+ People are worried that AI will take everyone‚Äôs jobs. We‚Äôve been here before. (MIT Technology Review)



2 Anti-vaccine activists gathered in Austin over the weekendThey celebrated RFK Jr‚Äôs rise and outlined their goals‚Äîincluding eliminating school vaccine mandates. (WP $)+ We‚Äôre on the verge of stopping the next pandemic. But will we? (Vox)+ How conspiracy theories infiltrated the doctor‚Äôs office. (MIT Technology Review)



3 People who‚Äôve experienced AI-induced delusions are forming a movementThey‚Äôre pushing for legal action against chatbot makers. (Bloomberg $)+ The looming crackdown on AI companionship. (MIT Technology Review)



4 AI-generated clips of women being strangled are flooding social mediaMany of them appear to have been created using OpenAI‚Äôs Sora 2. (404 Media)5 Tech leaders are obsessed with bioengineering babiesThey‚Äôre not allowed to, but they‚Äôre not letting a little thing like ethics get in the way. (WSJ $)+ The race to make the perfect baby is creating an ethical mess. (MIT Technology Review)6 Apple has removed two popular gay dating apps in China¬†The country ordered it to take down Blued and Finka from its app. (Wired $)



7 The UK government is worried China could turn off its buses remotelyIt fears hundreds of Chinese-made electric buses on British roads could be at risk. (FT $)



8 How AI is changing the world‚Äôs newsrooms It‚Äôs brilliant at analyzing large data sets‚Äîbut shouldn‚Äôt be used to write stories. (NYT $)



9 How to contain an invasive speciesExperts argue that too much red tape is getting in the way. (Undark)+ The weeds are winning. (MIT Technology Review)10 The world‚Äôs largest electric ship is charging up Once it‚Äôs ready to go, it‚Äôll serve as a ferry in 90 minute bursts. (IEEE Spectrum)







Quote of the day



‚ÄúWe would move heaven and Earth, pun intended, to try to get to the Moon sooner.‚Äù&nbsp;



‚ÄîDave Limp, CEO of Blue Origin, says the company is raring to work with NASA to get humans back on the Moon, Ars Technica reports.







One more thing







Design thinking was supposed to fix the world. Where did it go wrong?In the 1990s, a six-step methodology for innovation called design thinking started to grow in popularity. Key to its spread was its replicable aesthetic, represented by the Post-it note: a humble square that anyone can use in infinite ways.But in recent years, for a number of reasons, the shine of design thinking has been wearing off. Critics have argued that its short-term focus on novel and naive ideas results in unrealistic and ungrounded recommendations.Today, some groups are working to reform both design thinking‚Äôs principles and its methodologies. These new efforts seek a set of design tools capable of equitably serving diverse communities and solving diverse problems well into the future. It‚Äôs a much more daunting‚Äîand crucial‚Äîtask than design thinking‚Äôs original remit. Read the full story.



‚ÄîRebecca Ackermann







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ These tree-dwelling toads give birth to live young‚Äîwho knew?!+ Now‚Äôs the time to practice your baking skills ahead of Thanksgiving.+ Younguk Yi‚Äôs glitching paintings are a lot of fun.+ Place your bets! This fun game follows three balls in a race to the bottom, but who will win?

üîí Cybersecurity & Privacy
‚Ä¢ Drilling Down on Uncle Sam‚Äôs Proposed TP-Link Ban
  The U.S. government is reportedly preparing to ban the sale of wireless routers and other networking gear from TP-Link Systems, a tech company that currently enjoys an estimated 50% market share among home users and small businesses. Experts say while the proposed ban may have more to do with TP-Link&#8217;s ties to China than any specific technical threats, much of the rest of the industry serving this market also sources hardware from China and ships products that are insecure fresh out of the box.
A TP-Link WiFi 6 AX1800 Smart WiFi Router (Archer AX20).
The Washington Post recently reported that more than a half-dozen federal departments and agencies were backing a proposed ban on future sales of TP-Link devices in the United States. The story said U.S. Department of Commerce officials concluded TP-Link Systems products pose a risk because the U.S.-based company‚Äôs products handle sensitive American data and because the officials believe it remains subject to jurisdiction or influence by the Chinese government.
TP-Link Systems denies that, saying that it fully split from the Chinese TP-Link Technologies over the past three years, and that its critics have vastly overstated the company&#8217;s market share (TP-Link puts it at around 30 percent). TP-Link says it has headquarters in California, with a branch in Singapore, and that it manufactures in Vietnam. The company says it researches, designs, develops and manufactures everything except its chipsets in-house.
TP-Link Systems told The Post it has sole ownership of some engineering, design and manufacturing capabilities in China that were once part of China-based TP-Link Technologies, and that it operates them without Chinese government supervision.
&#8220;TP-Link vigorously disputes any allegation that its products present national security risks to the United States,&#8221; Ricca Silverio, a spokeswoman for TP-Link Systems, said in a statement. &#8220;TP-Link is a U.S. company committed to supplying high-quality and secure products to the U.S. market and beyond.&#8221;
Cost is a big reason TP-Link devices are so prevalent in the consumer and small business market: As this February 2025 story from Wired observed regarding the proposed ban, TP-Link has long had a reputation for flooding the market with devices that are considerably cheaper than comparable models from other vendors. That price point (and consistently excellent performance ratings) has made TP-Link a favorite among Internet service providers (ISPs) that provide routers to their customers.
In August 2024, the chairman and the ranking member of the House Select Committee on the Strategic Competition Between the United States and the Chinese Communist Party called for an investigation into TP-Link devices, which they said were found on U.S. military bases and for sale at exchanges that sell them to members of the military and their families.
‚ÄúTP-Link‚Äôs unusual degree of vulnerabilities and required compliance with PRC law are in and of themselves disconcerting,&#8221; the House lawmakers warned in a letter (PDF) to the director of the Commerce Department. &#8220;When combined with the PRC government‚Äôs common use of SOHO [small office/home office] routers like TP-Link to perpetrate extensive cyberattacks in the United States, it becomes significantly alarming.‚Äù
The letter cited a May 2023 blog post by Check Point Research about a Chinese state-sponsored hacking group dubbed &#8220;Camaro Dragon&#8221; that used a malicious firmware implant for some TP-Link routers to carry out a sequence of targeted cyberattacks against European foreign affairs entities. Check Point said while it only found the malicious firmware on TP-Link devices, &#8220;the firmware-agnostic nature of the implanted components indicates that a wide range of devices and vendors may be at risk.&#8221;
In a report published in October 2024, Microsoft said it was tracking a network of compromised TP-Link small office and home office routers that has been abused by multiple distinct Chinese state-sponsored hacking groups since 2021. Microsoft found the hacker groups were leveraging the compromised TP-Link systems to conduct &#8220;password spraying&#8221; attacks against Microsoft accounts. Password spraying involves rapidly attempting to access a large number of accounts (usernames/email addresses) with a relatively small number of commonly used passwords.
TP-Link rightly points out that most of its competitors likewise source components from China. The company also correctly notes that advanced persistent threat (APT) groups from China and other nations have leveraged vulnerabilities in products from their competitors, such as Cisco and Netgear.
But that may be cold comfort for TP-Link customers who are now wondering if it&#8217;s smart to continue using these products, or whether it makes sense to buy more costly networking gear that might only be marginally less vulnerable to compromise.
Almost without exception, the hardware and software that ships with most consumer-grade routers includes a number of default settings that need to be changed before the devices can be safely connected to the Internet. For example, bring a new router online without changing the default username and password and chances are it will only take a few minutes before it is probed and possibly compromised by some type of Internet-of-Things botnet. Also, it is incredibly common for the firmware in a brand new router to be dangerously out of date by the time it is purchased and unboxed.
Until quite recently, the idea that router manufacturers should make it easier for their customers to use these products safely was something of an anathema to this industry. Consumers were largely left to figure that out on their own, with predictably disastrous results.
But over the past few years, many manufacturers of popular consumer routers have begun forcing users to perform basic hygiene &#8212; such as changing the default password and updating the internal firmware &#8212; before the devices can be used as a router. For example, most brands of &#8220;mesh&#8221; wireless routers &#8212; like Amazon&#8217;s Eero, Netgear&#8217;s Orbi series, or Asus&#8217;s ZenWifi &#8212; require online registration that automates these critical steps going forward (or at least through their stated support lifecycle).
For better or worse, less expensive, traditional consumer routers like those from Belkin and Linksys also now automate this setup by heavily steering customers toward installing a mobile app to complete the installation (this often comes as a shock to people more accustomed to manually configuring a router). Still, these products tend to put the onus on users to check for and install available updates periodically. Also, they&#8217;re often powered by underwhelming or else bloated firmware, and a dearth of configurable options.
Of course, not everyone wants to fiddle with mobile apps or is comfortable with registering their router so that it can be managed or monitored remotely in the cloud. For those hands-on folks &#8212; and for power users seeking more advanced router features like VPNs, ad blockers and network monitoring &#8212; the best advice is to check if your router&#8217;s stock firmware can be replaced with open-source alternatives, such as OpenWrt¬†or DD-WRT.
These open-source firmware options are compatible with a wide range of devices, and they generally offer more features and configurability. Open-source firmware can even help extend the life of routers years after the vendor stops supporting the underlying hardware, but it still requires users to manually check for and install any available updates.
Happily, TP-Link users spooked by the proposed ban may have an alternative to outright junking these devices, as many TP-Link routers also support open-source firmware options like OpenWRT. While this approach may not eliminate any potential hardware-specific security flaws, it could serve as an effective hedge against more common vendor-specific vulnerabilities, such as undocumented user accounts, hard-coded credentials, and weaknesses that allow attackers to bypass authentication.
Regardless of the brand, if your router is more than four or five years old it may be worth upgrading for performance reasons alone &#8212; particularly if your home or office is primarily accessing the Internet through WiFi.
NB: The Post&#8217;s story notes that a substantial portion of TP-Link routers and those of its competitors are purchased or leased through ISPs. In these cases, the devices are typically managed and updated remotely by your ISP, and equipped with custom profiles responsible for authenticating your device to the ISP&#8217;s network. If this describes your setup, please do not attempt to modify or replace these devices without first consulting with your Internet provider.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI
  Introduction



Large&nbsp;language&nbsp;models&nbsp;(LLMs)&nbsp;are now widely used for automated code generation across software engineering tasks. However, this powerful capability in code generation also introduces security concerns. Code generation systems could be misused for harmful purposes, such as generating malicious code.&nbsp;It&nbsp;could also&nbsp;produce&nbsp;bias-filled&nbsp;code reflecting&nbsp;underlying logic that is&nbsp;discriminatory&nbsp;or unethical. Additionally, even when completing benign tasks, LLMs may inadvertently produce vulnerable code that&nbsp;contains&nbsp;security flaws (e.g., injection risks, unsafe input handling). These unsafe outcomes undermine the trustworthiness of code generation models and pose threats to the broader software ecosystem, where safety and reliability are critical.



Many&nbsp;studies have explored red teaming code LLMs, testing whether the models can reject unsafe requests and whether their generated code&nbsp;exhibits&nbsp;insecure patterns. For more details, see our earlier MSR blog post on&nbsp;RedCodeAgent. While red teaming has significantly improved our understanding of model failure modes, progress on blue teaming‚Äîi.e., developing effective defensive mechanisms to detect and prevent such failures‚Äîremains&nbsp;relatively limited. Current blue teaming approaches face several challenges: (1)&nbsp;Poor alignment with security concepts:&nbsp;additional&nbsp;safety&nbsp;prompts&nbsp;struggle to help models&nbsp;understand high-level notions,&nbsp;such as what constitutes a malicious or bias instruction, and typically lack actionable principles to guide safe decision-making. A case study is shown in Figure 1.&nbsp;(2)&nbsp;Over-conservatism:&nbsp;especially in the domain of vulnerable code detection, models tend to misclassify safe code as unsafe, leading to more false positives and reduced developer trust.&nbsp;(3)&nbsp;Incomplete risk coverage: without a strong knowledge foundation, models perform poorly when dealing with subtle or previously unseen risks.&nbsp;&nbsp;&nbsp;



To address these challenges, researchers from the University of Chicago, University of California, Santa Barbara, University of Illinois Urbana‚ÄìChampaign, VirtueAI, and Microsoft Research recently released a paper: BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI. This work makes the following key contributions:&nbsp;




Diverse red-teaming pipeline: The authors design a comprehensive red-teaming process that integrates multiple strategies to synthesize diverse red-teaming data for effective knowledge accumulation.



Knowledge-enhanced blue teaming: Building on the foundation of red-teaming knowledge, BlueCodeAgent significantly improves blue-teaming performance by leveraging constitutions derived from knowledge and dynamic testing.&nbsp;



Principled-Level Defense and Nuanced-Level analysis: The authors propose two complementary strategies‚ÄîPrincipled-Level Defense (via constitutions) and Nuanced-Level Analysis (via dynamic testing)‚Äîand demonstrate their synergistic effects in vulnerable code detection tasks.&nbsp;



Generalization to seen and unseen risks: Empowered by comprehensive red-teaming knowledge, BlueCodeAgent generalizes effectively to unseen risks. Overall, BlueCodeAgent achieves an average 12.7% improvement in F1 score across four datasets and three tasks, attributed to its ability to distill actionable constitutions that enhance context-aware risk detection.&nbsp;




Figure 1. A case study of BlueCodeAgent on the bias instruction detection task. Even when concepts such as ‚Äúbiased‚Äù are explicitly included in additional safety prompts, models often fail to recognize biased requests (left). BlueCodeAgent (right) addresses this gap by summarizing constitutions from knowledge and applying concrete, actionable constraints benefited from red teaming to improve the defense. 



A blue teaming agent enabled by red teaming



Figure 2: Overview of BlueCodeAgent, an end-to-end blue teaming framework powered by automated red teaming for code security. By integrating knowledge derived from diverse red teaming and conducting dynamic sandbox-based testing, BlueCodeAgent substantially strengthens the defensive capabilities beyond static LLM analysis. 



Figure 2 presents an overview of the pipeline. The framework unifies both sides of the process: red teaming generates diverse risky cases and behaviors, which are then distilled into actionable constitutions that encode safety rules on the blue-teaming side. These constitutions guide BlueCodeAgent to more effectively detect unsafe textual inputs and code outputs, mitigating limitations such as poor alignment with abstract security concepts.&nbsp;



This work targets three major risk categories, covering both input/textual-level risks‚Äîincluding biased and malicious instructions‚Äîand output/code-level risks, where models may generate vulnerable code. These categories represent risks that have been widely studied in prior research.&nbsp;



Diverse red-teaming process for knowledge accumulation&nbsp;



Since different tasks require distinct attack strategies, the&nbsp;red-teaming&nbsp;employs multiple attack methods to generate realistic and diverse data. Specifically, the red-teaming process is divided into three categories:




Policy-based instance generation: To synthesize policy-grounded red-teaming data, diverse security and ethical policies are first collected. These high-level principles are then used to prompt an uncensored model to generate instances that intentionally violate the specified policies.



Seed-based adversarial prompt optimization: Existing adversarial instructions are often overly simplistic and easily rejected by models. To overcome this limitation, an adaptive red-teaming agent invokes various jailbreak tools to iteratively refine initial seed prompts until the prompts achieve high attack success rates.



Knowledge-driven vulnerability generation: To synthesize both vulnerable and safe code samples under realistic programming scenarios, domain knowledge of common software weaknesses (CWE) is leveraged to generate diverse code examples.




Knowledge-enhanced blue teaming agent&nbsp;



After accumulating red-teaming knowledge data, BlueCodeAgent set up Principled-Level Defense via Constitution Construction and Nuanced-Level Analysis via Dynamic Testing.




Principled-Level Defense via Constitution Construction&nbsp;Based on the most relevant knowledge data, BlueCodeAgent summarizes red-teamed knowledge into actionable constitutions‚Äîexplicit rules and principles distilled from prior attack data. These constitutions serve as normative guidelines, enabling the model to stay aligned with ethical and security principles even when confronted with novel or unseen adversarial inputs.&nbsp;



Nuanced-Level Analysis via Dynamic Testing&nbsp;In vulnerable code detection, BlueCodeAgent augments static reasoning with dynamic sandbox-based analysis, executing generated code within isolated Docker environments to verify whether the model-reported vulnerabilities manifest as actual unsafe behaviors. This dynamic validation effectively mitigates the model‚Äôs tendency toward over-conservatism, where benign code is mistakenly flagged as vulnerable.&nbsp;




	
		

		
		Spotlight: Microsoft research newsletter
	
	
	
						
				
					
				
			
			
			

									Microsoft Research Newsletter
				
								Stay connected to the research community at Microsoft.
				
								
					
						
							Subscribe today						
					
				
							
	
Opens in a new tab	
	


Insights from BlueCodeAgent&nbsp;



BlueCodeAgent outperforms prompting baselines&nbsp;



As shown in Figure 3, BlueCodeAgent significantly outperforms other baselines. Several findings are highlighted.&nbsp;



(1) Even when test categories differ from knowledge categories to simulate unseen scenarios, BlueCodeAgent effectively leverages previously seen risks to handle unseen ones, benefiting from its knowledge-enhanced safety reasoning.&nbsp;



(2) BlueCodeAgent is model-agnostic, working consistently across diverse base LLMs, including both open-source and commercial models. Its F1 scores for bias and malicious instruction detection approach 1.0, highlighting strong effectiveness.&nbsp;



(3) BlueCodeAgent achieves a strong balance between safety and usability. It accurately identifies unsafe inputs while maintaining a reasonable false-positive rate on benign ones, resulting in a consistently high F1 score.&nbsp;



(4) By contrast, prompting with general or fine-grained safety reminders remains insufficient for effective blue teaming, as models struggle to internalize abstract safety concepts and apply them to unseen risky scenarios. BlueCodeAgent bridges this gap by distilling actionable constitutions from knowledge, using concrete and interpretable safety constraints to enhance model alignment.&nbsp;



Figure 3:¬†F1 scores on bias instruction detection task (BlueCodeEval-Bias) in the first row and on malicious instruction detection task (BlueCodeEval-Mal) in the second row.¬†



Complementary effects of constitutions and dynamic testing&nbsp;



In vulnerability detection tasks, models tend to behave conservatively‚Äîan effect also noted in prior research. They are often more likely to flag code as unsafe rather than safe. This bias is understandable: confirming that code is completely free from vulnerabilities is generally harder than spotting a potential issue.&nbsp;



To mitigate this over-conservatism, BlueCodeAgent integrates dynamic testing into its analysis pipeline. When BlueCodeAgent identifies a potential vulnerability, it triggers a reliable model (Claude-3.7-Sonnet-20250219) to generate test cases and corresponding executable code that embeds the suspicious snippet. These test cases are then run in a controlled environment to verify whether the vulnerability actually manifests. The final judgment combines the LLM‚Äôs analysis of the static code, the generated test code, run-time execution results, and constitutions derived from knowledge.&nbsp;



Researchers find the two components‚Äîconstitutions and dynamic testing‚Äîplay complementary roles. Constitutions expand the model‚Äôs understanding of risk, increasing true positives (TP) and reducing false negatives (FN). Dynamic testing, on the other hand, focuses on reducing false positives (FP) by validating whether predicted vulnerabilities can truly be triggered at run-time. Together, they make BlueCodeAgent both more accurate and more reliable in blue-teaming scenarios.&nbsp;



Summary&nbsp;



BlueCodeAgent introduces an end-to-end blue-teaming framework designed to address risks in code generation. The key insight behind BlueCodeAgent is that comprehensive red-teaming can greatly strengthen blue-teaming defenses. Based on this idea, the framework first builds a red-teaming process with diverse strategies for generating red-teaming data. It then constructs a blue-teaming agent that retrieves relevant examples from the red-teaming knowledge base and summarizes safety constitutions to guide LLMs in making accurate defensive decisions. A dynamic testing component is further added to reduce false positives in vulnerability detection.&nbsp;



Looking ahead, several directions hold promise.&nbsp;&nbsp;



First, it is valuable to explore the generalization of BlueCodeAgent to other categories of code-generation risks beyond bias, malicious code, and vulnerable code. This may require designing and integrating novel red-teaming strategies into BlueCodeAgent and creating corresponding benchmarks for new risks.&nbsp;&nbsp;



Second, scaling BlueCodeAgent to the file and repository levels could further enhance its real-world utility, which requires equipping agents with more advanced context retrieval tools and memory components.&nbsp;&nbsp;



Finally, beyond code generation, it is also important to extend BlueCodeAgent to mitigate risks in other modalities, including text, image, video, and audio, as well as in multimodal applications.&nbsp;
Opens in a new tabThe post BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI appeared first on Microsoft Research.
‚Ä¢ Introducing agent-to-agent protocol support in Amazon Bedrock AgentCore Runtime
  We recently announced the support for Agent-to-Agent (A2A) protocol on Amazon Bedrock AgentCore Runtime. With this addition, agents can discover peers, share capabilities, and coordinate actions across platforms using standardized communication. 
Amazon Bedrock AgentCore Runtime provides a secure, serverless environment designed for deploying AI agents and tools. It works with any framework and model, supports real-time and long-running workloads, and supports session isolation with built-in authentication. With support for MCP, and now the&nbsp;A2A protocol, Bedrock AgentCore Runtime enables seamless communication between agents. Agents built using different frameworks, Strands Agents, OpenAI Agents SDK, LangGraph, Google ADK, or Claude Agents SDK, can share context, capabilities, and reasoning in a common, verifiable format. 
In this post, we demonstrate how you can use the A2A protocol for AI agents built with different frameworks to collaborate seamlessly. You‚Äôll learn how to deploy A2A servers on AgentCore Runtime, configure agent discovery and authentication, and build a real-world multi-agent system for incident response. We‚Äôll cover the complete A2A request lifecycle, from agent card discovery to task delegation, showing how standardized protocols eliminate the complexity of multi-agent coordination. 
Understanding multi-agent systems 
Building effective agentic systems requires several foundational components. These include memory, both short-term for maintaining conversation context and long-term for retaining insights across sessions; tools that agents can access either natively or through MCP servers; identity for more secure authentication and permission management, allowing agents to act on behalf of users or autonomously access resources; and guardrails to detect harmful content, help prevent hallucinations, and make sure responses align with policies and factual accuracy. 
 
While MCP connects a single agent to its tools and data, A2A lets multiple agents coordinate with one another. For example, a retail inventory agent might use MCP to query product databases, then use A2A to communicate with external supplier agents to place orders. 
The A2A protocol brings benefits to multi-agent systems through seamless interoperability across diverse boundaries. Agents built with different frameworks like Strands or OpenAI, powered by various LLMs such as Anthropic Claude, GPT-4, or Llama, and hosted on different systems including AWS or edge devices can communicate and coordinate effortlessly without requiring complex translation layers. This interoperability is complemented by loose coupling and modularity, where each agent operates as an independent unit that can be developed, tested, deployed, and even upgraded without disrupting the entire system. New specialized agents can join the environment seamlessly, and the failure of one agent remains isolated due to well-defined interaction boundaries, helping prevent cascading failures across the system. The protocol also supports dynamic agent discovery and orchestration. Agents advertise their capabilities through standardized schemas while orchestrator agents can discover and invoke specialized agents based on real-time task requirements. 
A2A request lifecycle on Amazon Bedrock AgentCore Runtime 
The A2A protocol defines a structured request lifecycle with specific components that work together to coordinate multi-agent communication.&nbsp;Here are the key elements: 
 
 User: Initiates requests through the Client Agent, either as a human operator or automated service defining goals that require multi-agent assistance. 
 A2A Client (Client Agent): Acts on behalf of the user, initiating communication using the A2A protocol to discover and request tasks from remote agents. 
 A2A Server (Remote Agent): Exposes HTTP endpoints implementing the A2A protocol to receive requests, process tasks, and return results. Different agents can serve this role, handling both synchronous and asynchronous interactions using JSON-RPC 2.0 over HTTP/S or Server-Sent Events. 
 Agent Card: A JSON metadata file that each agent publishes to advertise its identity, capabilities, endpoints, and authentication requirements. This enables the dynamic discovery feature, where agents query what their peer agents can do before delegating tasks. 
 Task Object: Represents each unit of work flowing through the system with a unique ID and lifecycle. As agents coordinate, tasks may be long-running, involve multiple turns, and span several agents working together. 
 Artifact: The output produced when a task completes, which can include structured text, JSON, images, audio, or other multimodal content. Agents exchange these artifacts as they collaborate to fulfill the user‚Äôs original request. 
 
Multi-agent use case: Monitoring and incident response 
To demonstrate the power of multi-agent systems using A2A on Amazon Bedrock AgentCore Runtime, we‚Äôll walk through an enterprise monitoring and incident response solution. This real-world use-case showcases how specialized agents built with different frameworks coordinate seamlessly to handle complex operational challenges through the A2A protocol. 
The monitoring and incident response solution implements a hub-and-spoke architecture with three specialized agents, each using Amazon Bedrock AgentCore features ‚Äì modular building blocks that provide core capabilities like AgentCore Memory for context-aware responses, AgentCore Identity using Amazon Cognito for more secure authentication for agents and what action each agent can perform, AgentCore Gateway for more secure and centralized access to tools, and observability to trace, debug, and monitor AI agents‚Äô performance. View the architecture and demonstration video below for reference: 
 
The multi-agent system contains the following components: 
 
 Host agent&nbsp;(Google ADK):&nbsp;Acts as the intelligent routing layer and coordination hub for the agent interactions. Demonstrates the cross-system interoperability using A2A. This agent runs on Amazon Bedrock AgentCore Runtime using Google‚Äôs Agent Development Kit, yet communicates seamlessly with agents hosted on AWS through the standardized A2A protocol. Key responsibilities of the host agent include: 
   
   Dynamic agent discovery: Fetches Identity Provider (IDP) configuration from AWS Systems Manager Parameter Store for each remote agent, enabling more secure authentication across the multi-agent system 
   Capability awareness: Retrieves agent cards from each A2A server to understand available skills and endpoints 
   Intelligent routing: Analyzes user queries and routes them to the appropriate specialist agent based on capabilities 
   Multi-agent coordination: Orchestrates complex workflows requiring multiple agents 
    
 Monitoring agent (Strands Agents SDK): Serves as the operational intelligence layer, continuously analyzing CloudWatch logs, metrics, dashboards, and alarms across AWS services. This agent specializes in identifying anomalies, tracking error patterns, and surfacing actionable insights from vast amounts of telemetry data. When unusual patterns emerge, the monitoring Agent initiates conversations with other specialized agents to coordinate response actions.Key responsibilities of the monitoring agent include: 
   
   CloudWatch integration: 
     
     Lists and analyzes CloudWatch dashboards 
     Fetches logs for specific AWS services (Lambda, ECS, EC2) 
     Monitors alarms and alert states 
     Analyzes log groups for patterns and errors 
      
   Cross-account access: Supports monitoring across multiple AWS accounts 
    
 Operational agent (OpenAI SDK): Provides remediation strategies and external knowledge integration. When the monitoring agent detects a critical issue, it communicates directly with the operational agent through A2A, providing context about the problem and requesting specific remediation actions. Key responsibilities&nbsp;of the operational agent include: 
   
   Web search: Uses Tavily API to search for AWS best practices, troubleshooting guides, and solutions 
   Remediation strategies: Proposes solutions based on detected issues 
    
 
 
Implementing the multi-agent monitoring solution 
Now that we‚Äôve explored how these three specialized agents collaborate to handle AWS incidents, let‚Äôs walk through how to build and deploy this multi-agent system using Amazon Bedrock AgentCore Runtime. 
The implementation follows a progressive approach: 
 
 Start with the foundation ‚Äì We‚Äôll deploy a simple A2A server to understand the core mechanics of agent deployment, authentication, and invocation on AgentCore Runtime 
 Build the monitoring system ‚Äì Using the same deployment patterns, we‚Äôll construct each specialized agent (Monitoring, Operational, and Host) with their specific tools and capabilities 
 Connect the agents ‚Äì Configure A2A communication channels between agents, enabling them to discover and invoke each other through standardized protocols 
 Observe the system in action ‚Äì Watch the demo video showing real-time incident detection, cross-agent coordination, and automated response 
 
All code examples, complete agent implementations, and deployment scripts for this multi-agent monitoring system are available in our GitHub repository. 
Getting started with A2A on AgentCore Runtime 
To understand the fundamentals of deploying A2A servers on Amazon Bedrock AgentCore Runtime, including step-by-step instructions for creating, testing, deploying, and invoking agents, refer to the A2A Protocol Support documentation. This guide covers: 
 
 Creating and configuring A2A servers with any framework (Strands, OpenAI SDK, LangGraph) 
 Local testing and validation 
 Deployment using the AgentCore CLI 
 Authentication setup (OAuth 2.0 and AWS IAM) 
 Agent Card retrieval and discovery 
 Client implementation for invoking deployed agents 
 
Once you‚Äôre familiar with these fundamentals, you can apply the same patterns to build each component of the multi-agent monitoring system. 
View the full example in this GitHub sample. For this post, we will focus on this use case implementation. 
Prerequisites 
To deploy the multi-agent monitoring system implementation, follow the prerequisite steps: 
 
 AWS account: You need an active AWS account with appropriate permissions 
   
   Create an AWS account 
   AWS Management Console access 
    
 AWS CLI: Install and configure AWS CLI with your credentials 
   
   Install AWS CLI 
   Configure AWS CLI 
    
 Install uv. 
 Supported Regions: This solution is currently tested and supported in the following AWS Regions. 
 
Note: To deploy in other Regions, you‚Äôll need to update the DynamoDB prefix list mappings in cloudformation/vpc-stack.yaml. See the VPC Stack documentation for details. 
Deployment steps 
This guide walks you through deploying a multi-agent system on AWS using infrastructure-as-code.&nbsp;The easiest way to deploy this solution is using our automated deployment script: 
Step 1: Clone the repository 
 
 git clone https://github.com/awslabs/amazon-bedrock-agentcore-samples.git
cd 02-use-cases/A2A-multi-agent-incident-response 
 
Step 2: Run the deployment script 
This deployment script will verify that the AWS CLI is installed and configured, check if the AWS credentials are valid, confirm that the Region is set to us-west-2, interactively collect the required parameters, generate unique S3 bucket names and automatically deploy all stacks in the correct order. The approximate deployment time is 10-15 minutes. 
 
 uv run deploy.py 
 
Step 3: Provide the runtime CLI parameters 
Next, provide the parameters used at deployment.&nbsp;Press enter for each of the options to use the default Amazon Bedrock model ID and the CloudFormation stack names for each of the agents. 
API keys: You‚Äôll need the following API keys (the deployment script will prompt for these): 
 
 OpenAI API key: Get it from OpenAI Platform 
 Tavily API key: Get it from Tavily 
 Google API key: Get it from Google AI Studio 
 
Once you have configured the information, start the deployment process and track it below in the AWS Console and terminal respectively. 
Step 4: Provide the runtime CLI parameters 
Run the frontend using following commands.&nbsp;This sets up and runs the React frontend UI that allows users to interact with the multi-agent incident response system for monitoring AWS infrastructure, querying CloudWatch metrics and logs, and searching for remediation strategies through&nbsp;the coordinated A2A agents. 
 
 cd frontend
npm install

chmod +x ./setup-env.sh
./setup-env.sh

npm run dev 
 
This deployment creates a multi-agent A2A system with three specialized AI agents running on Amazon Bedrock AgentCore Runtime and orchestrated using the A2A protocol. The Cognito stack provisions OAuth 2.0-based machine-to-machine authentication by creating a Cognito user pool with four distinct client applications (WebSearch, Monitoring, Gateway, and Host Agent clients). 
The monitoring agent (built with the Strands SDK) connects to CloudWatch metrics and logs through an AgentCore Gateway using a Smithy model definition, with custom semantic memory strategies for incident tracking. 
The operations agent (built with OpenAI Agents SDK) interfaces with Tavily API for remediation research and the host agent (built with Google ADK) acts as the coordinator using HTTP protocol to delegate tasks to the two specialized A2A agents. 
End-to-end incident response workflow 
In this section, we will walk through an end-to-end workflow where the host agent manages conversations, gets the requirements from the user, and selects the best agent to route the request to (monitoring or operations agent). The monitoring and operations agent expose their agent cards that is used by the host agent for orchestration. In this example, we will test with simple error analysis from various log groups and search for remediation strategies. 
 
The workflow includes the following steps: 
 
 Initial greeting: The user sends a greeting message asking ‚ÄúHi! How are you?‚Äù to the host agent. The host agent processes the request. The host agent responds back to the user with a friendly greeting saying ‚ÄúI‚Äôm doing well, thank you!‚Äù 
 Capabilities query: The user asks the host agent ‚ÄúWhat are your capabilities?‚Äù to understand what the agent can do. The host agent explains to the user that it is an orchestration agent designed for AWS monitoring and operations based on the remote agent connections that it has access to. 
 List log groups and dashboards: The user requests the host agent to list the log groups and dashboards in their AWS account. The host agent recognizes this is a monitoring task and executes the transfer_to_agent tool to delegate the work. The request is transferred from the host agent to the monitoring agent for specialized handling. The&nbsp;monitoring agent uses the Agent-to-Agent (A2A) Json RPC Transport protocol to communicate. The&nbsp;monitoring agent retrieves the information and returns results showing 0 dashboards and 153 log groups found in the account. The host agent receives the results from the&nbsp;monitoring agent and displays the dashboards and log groups information to the user. 
 Analyze specific log group: The user requests the host agent to look for errors in a specific log group at path /aws/bedrock-agentcore/runtimes/hostadk-&lt;runtimeId&gt;-DEFAULT. The host agent determines this requires monitoring expertise and executes the transfer_to_agent tool. The request is transferred to the&nbsp;monitoring agent with instructions to analyze the specified log group for errors. The&nbsp;monitoring agent analyzes the log group and discovers 9 errors and 18 warnings, specifically identifying OTLP Export Failures. The host agent receives the analysis results and displays a detailed error analysis report to the user. 
 Debug and fix recommendations: The user asks the host agent to debug the errors and provide a report on the fixes needed. The request is transferred to the operations agent to search for solutions related to OTLP export failures. The operations agent uses A2A JsonRPC Transport to attempt the search and performs web search to provide a solution. 
 
Security with A2A on Amazon Bedrock AgentCore Runtime 
Amazon Bedrock AgentCore Runtime supports two authentication methods for securing A2A communication: 
OAuth 2.0 authentication: The A2A client authenticates with an external authorization server to obtain a JSON Web Token (JWT), which is then included with all requests to the A2A server. This token-based approach enables secure, standardized authentication using either machine-to-machine (M2M) credentials or user federation, allowing the A2A server to verify the client‚Äôs identity and enforce access controls based on the token‚Äôs claims. 
AWS IAM authentication: The A2A client assumes an IAM role with permissions to invoke the A2A server‚Äôs agent. This approach leverages AWS SigV4 request signing and IAM policies to control access, alleviating the need for external token management while providing fine-grained permissions. 
What is supported in Amazon Bedrock AgentCore Runtime with A2A 
Amazon Bedrock AgentCore Runtime provides comprehensive support for A2A communication. View some of the capabilities supported: 
 
 Stateless server: Amazon Bedrock AgentCore Runtime can host A2A servers that expose an HTTP interface, running a stateless HTTP server on port 9000 and supporting JSON-RPC messaging. The runtime acts as a transparent proxy, passing JSON-RPC requests and responses unchanged to preserve protocol fidelity. 
 Authenticated agent cards: Supports authenticated agent card at&nbsp;/.well-known/agent-card.json containing its capabilities &amp; skills allowing other agents to discover it automatically. 
 Authentication&nbsp;with secure inbound auth: Amazon Bedrock AgentCore Runtime supports secure authentication via AWS SigV4 and OAuth 2.0, making sure the agent-to-agent communication is authorized and secure. The A2A server authenticates every incoming request using the credentials provided in the HTTP headers, leveraging Amazon Bedrock AgentCore Identity. 
 Authorization with secure outbound auth:&nbsp;Amazon Bedrock AgentCore Runtime enables secure outbound authorization through both IAM execution roles and AgentCore Identity. Each agent assumes a defined IAM execution role, granting it the necessary permissions to access AWS resources more securely. For interactions with external services, agents can use Amazon Bedrock AgentCore Identity, which provides managed OAuth 2.0 support for third-party identity providers such as Google, GitHub, Slack, and more. 
 VPC connectivity:&nbsp;You can configure Amazon Bedrock AgentCore Runtime to connect to resources in your Amazon Virtual Private Cloud (VPC). By configuring VPC connectivity, you enable secure access to private resources such as databases, internal APIs, and services within your VPC. 
 Leverage AWS PrivateLink:&nbsp;Amazon Bedrock AgentCore enables secure, private connections between your Virtual Private Cloud (VPC) and AgentCore services using AWS PrivateLink. By creating interface VPC endpoints, you can keep A2A server communication within your VPC without traversing the public internet. 
 Lifecycle management:&nbsp;Amazon Bedrock AgentCore Runtime lets you configure lifecycle rules to manage resource usage with idleRuntimeSessionTimeout and maxLifetime. Idle or long-running sessions are automatically terminated for efficient resource utilization and to maintain system performance. 
 
Conclusion 
The Agent-to-Agent protocol support in Amazon Bedrock AgentCore Runtime provides the support for building scalable, interoperable multi-agent systems. By providing standardized communication between AI agents, regardless of their underlying framework, model, or hosting infrastructure, organizations can compose sophisticated agentic solutions with the A2A protocol. The AWS monitoring and incident response example demonstrates the practical power of this approach: a Google ADK-based orchestrator coordinating with Strands and OpenAI SDK agents, all deployed on AgentCore Runtime, working together to detect issues, search for solutions, and recommend fixes. This level of interoperability would traditionally require extensive custom integration work, but A2A makes it straightforward through standardized protocols.As AI systems continue to evolve from single-purpose tools to collaborative environments, protocols like A2A and MCP become essential building blocks. They create a future where agents can be discovered, composed, and orchestrated dynamically, enabling organizations to build once and integrate anywhere. 
 
About the authors 
Madhur Prashant is an Applied Generative AI Architect at Amazon Web Services. He is passionate about the intersection of human thinking and Agentic AI. His interests lie in generative AI, cognitive science and specifically building solutions that are helpful and harmless, and most of all optimal for customers. Outside of work, he loves doing yoga, hiking, spending time with his twin and playing the guitar. 
Eashan Kaushik is a Specialist Solutions Architect AI/ML at Amazon Web Services. He is driven by creating cutting-edge generative AI solutions while prioritizing a customer-centric approach to his work. Before this role, he obtained an MS in Computer Science from NYU Tandon School of Engineering. Outside of work, he enjoys sports, lifting, and running marathons. 
Sriharsha M S is a Principal Gen AI specialist solution architect in the Strategic Specialist team at Amazon Web Services. He works with strategic AWS customers who are taking advantage of AI/ML to solve complex business problems. He provides technical guidance and design advice to foundational model science and agentic AI applications at scale. His expertise spans application hardware accelerators, architecture, big data, analytics and machine learning. 
Jeffrey Burke is an Applied Generative AI Solutions Architect at Amazon Web Services (AWS), where he specializes in designing and implementing cutting-edge generative AI solutions for enterprise customers. With a passion for teaching complex technologies, he focuses on translating sophisticated AI concepts into practical, scalable solutions that drive business value. He has a MS in Data Science and BS in Chemical Engineering. 
Shreyas Subramanian is a Principal Data Scientist and helps customers by using Generative AI to solve their business challenges using the AWS platform. Shreyas has a background in large scale optimization and Deep Learning, and he is a researcher studying the use of Machine Learning and Reinforcement Learning for accelerating learning and optimization tasks. Shreyas is also an Amazon best-selling book author with several research papers and patents to his name. 
Andy Palmer is a Director of Technology for AWS Strategic Accounts. His teams provide Specialist Solutions Architecture skills across a number of speciality domain areas, including AIML, generative AI, data and analytics, security, network, and open source software. Andy and his team have been at the forefront of guiding our most advanced customers through their generative AI journeys and helping to find ways to apply these new tools to both existing problem spaces and net new innovations and product experiences. 
Sayee Kulkarni is a Software Development Engineer on the AWS Bedrock AgentCore service. Her team is responsible for building and maintaining the AgentCore Runtime platform, a foundational component that enables customers to leverage agentic AI capabilities. She is driven by delivering tangible customer value, and this customer-centric focus motivates her work. Sayee played a key role in designing and launching Agent-to-Agent (A2A) capabilities for AgentCore, empowering customers to build sophisticated multi-agent systems that autonomously collaborate to solve complex business challenges.
‚Ä¢ Powering enterprise search with the Cohere Embed 4 multimodal embeddings model in Amazon Bedrock
  The Cohere Embed 4 multimodal embeddings model is now available as a fully managed, serverless option in&nbsp;Amazon Bedrock. Users can choose between cross-Region inference (CRIS) or Global cross-Region inference to manage unplanned traffic bursts by utilizing compute resources across different AWS Regions. Real-time information requests and time zone concentrations are example events that can cause inference demand to exceed anticipated traffic. 
The new Embed 4 model on Amazon Bedrock is purpose-built for analyzing business documents. The model delivers leading multilingual capabilities and shows notable improvements over Embed 3 across the key benchmarks, making it ideal for use cases such as enterprise search. 
In this post, we dive into the benefits and unique capabilities of Embed 4 for enterprise search use cases. We‚Äôll show you how to quickly get started using Embed 4 on Amazon Bedrock, taking advantage of integrations with Strands Agents, S3 Vectors,&nbsp;and Amazon Bedrock AgentCore to build powerful agentic retrieval-augmented generation (RAG) workflows. 
Embed 4 advances multimodal embedding capabilities by natively supporting complex business documents that combine text, images, and interleaved text and images into a unified vector representation. Embed 4 handles up to 128,000 tokens, minimizing the need for tedious document splitting and preprocessing pipelines. Embed 4 also offers configurable compressed embeddings that reduce vector storage costs by up to 83% (Introducing Embed 4: Multimodal search for business). Together with multilingual understanding across over 100 languages, enterprises in regulated industries such as finance, healthcare, and manufacturing can efficiently process unstructured documents, accelerating insight extraction for optimized RAG systems. Read about Embed 4 in this launch blog from July 2025 to explore how to deploy on&nbsp;Amazon SageMaker JumpStart. 
Embed 4 can be integrated into your applications using the&nbsp;InvokeModel API, and here‚Äôs an example of how to use the&nbsp;AWS SDK for Python (Boto3)&nbsp;with Embed 4: 
For the text only input: 
 
 import boto3
import json

# Initialize Bedrock Runtime client
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')

# Request body
body = json.dumps({
"texts": [
text1,
          text2],
     "input_type":"search_document",
     "embedding_types": ["float"]
})

# Invoke the model
model_id = 'cohere.embed-v4:0'

response = bedrock_runtime.invoke_model(
    modelId=model_id,
    body=json.dumps(body),
    accept= '*/*',
    contentType='application/json'
)

# Parse response
result = json.loads(response['body'].read()) 
 
For the mixed modalities input: 
 
 import base64

# Initialize Bedrock Runtime client
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')

# Request body
body = json.dumps({
"inputs": [
{
"content": [
{ "type": "text", "text": text },
{ "type": "image_url", {"image_url":image_base64_uri}}
]
}
],
     "input_type":"search_document",
     "embedding_types": ["int8","float"]
})

# Invoke the model
model_id = 'cohere.embed-v4:0'

response = bedrock_runtime.invoke_model(
    modelId=model_id,
    body=json.dumps(body),
    accept= '*/*',
    contentType='application/json'
)

# Parse response
result = json.loads(response['body'].read()) 
 
For more details, you can check Amazon Bedrock User Guide for Cohere Embed 4. 
Enterprise search use case 
In this section, we focus on using Embed 4 for an enterprise search use case in the finance industry. Embed 4 unlocks a range of capabilities for enterprises seeking to: 
 
 Streamline information discovery 
 Enhance generative AI workflows 
 Optimize storage efficiency 
 
Using foundation models in Amazon Bedrock is a fully serverless environment which removes infrastructure management and simplifies integration with other Amazon Bedrock capabilities. See more details for other possible use cases with Embed 4. 
Solution overview 
With the serverless experience available in Amazon Bedrock, you can get started quickly without spending too much effort on infrastructure management. In the following sections, we show how to get started with Cohere Embed 4. Embed 4 is already designed with storage efficiency in mind. 
We choose Amazon S3 vectors for storage because it is a cost-optimized, AI-ready storage with native support for storing and querying vectors at scale. S3 vectors can store billions of vector embeddings with sub-second query latency, reducing total costs by up to 90% compared to traditional vector databases. We leverage the extensible Strands Agent SDK to simplify agent development and take advantage of model choice flexibility. We also use Bedrock AgentCore because it provides a fully managed, serverless runtime specifically built to handle dynamic, long-running agentic workloads with industry-leading session isolation, security, and real-time monitoring. 
 
Prerequisites 
To get started with Embed 4, verify you have the following prerequisites in place: 
 
 IAM permissions: Configure your IAM role with necessary Amazon Bedrock permissions, or generate API keys through the console or SDK for testing. For more information, see Amazon Bedrock API keys. 
 Strands SDK installation: Install the required SDK for your development environment. For more information, see the Strands quickstart guide. 
 S3 Vectors configuration: Create an S3 vector bucket and vector index for storing and querying vector data. For more information, see the getting started with S3 Vectors tutorial. 
 
Initialize Strands agents 
The Strands Agents SDK offers an open source, modular framework that streamlines the development, integration, and orchestration of AI agents. With the flexible architecture developers can build reusable agent components and create custom tools with ease. The system supports multiple models, giving users freedom to select optimal solutions for their specific use cases. Models can be hosted on Amazon Bedrock, Amazon SageMaker, or elsewhere. 
For example, Cohere Command A is a generative model with 111B parameters and a 256K context length. The model excels at tool use which can extend baseline functionality while avoiding unnecessary tool calls. The model is also suitable for multilingual tasks and RAG tasks such as manipulating numerical information in financial settings. When paired with Embed 4, which is purpose-built for highly regulated sectors like financial services, this combination delivers substantial competitive benefits through its adaptability. 
We begin by defining a tool that a Strands agent can use. The tool searches for documents stored in S3 using semantic similarity. It first converts the user‚Äôs query into vectors with Cohere Embed 4. It then returns the most relevant documents by querying the embeddings stored in the S3 vector bucket. The code below shows only the inference portion. Embeddings created from the financial documents were stored in a S3 vector bucket before querying. 
 
 # S3 Vector search function for financial documents
@tool
def search(query_text: str, bucket_name: str = "my-s3-vector-bucket", 
           index_name: str = "my-s3-vector-index-1536", top_k: int = 3, 
           category_filter: str = None) -&gt; str:
    """Search financial documents using semantic vector search"""
    
    bedrock = boto3.client("bedrock-runtime", region_name="us-east-1")
    s3vectors = boto3.client("s3vectors", region_name="us-east-1")
    
    # Generate embedding using Cohere Embed v4
    response = bedrock.invoke_model(
        modelId="cohere.embed-v4:0",
        body=json.dumps({
            "texts": [query_text],
            "input_type": "search_query",
            "embedding_types": ["float"]
        }),
        accept='*/*',
        contentType='application/json'
    )
    
    response_body = json.loads(response["body"].read())
    embedding = response_body["embeddings"]["float"][0]
    
    # Query vectors
    query_params = {
        "vectorBucketName": bucket_name,
        "indexName": index_name,
        "queryVector": {"float32": embedding},
        "topK": top_k,
        "returnDistance": True,
        "returnMetadata": True
    }
    
    if category_filter:
        query_params["filter"] = {"category": category_filter}
    
    response = s3vectors.query_vectors(**query_params)
    return json.dumps(response["vectors"], indent=2) 
 
We then define a financial research agent that can use the tool to search financial documents. As your use case becomes more complex, more agents can be added for specialized tasks. 
 
 # Create financial research agent using Strands
agent = Agent(
    name="FinancialResearchAgent",
    system_prompt="You are a financial research assistant that can search through financial documents, earnings reports, regulatory filings, and market analysis. Use the search tool to find relevant financial information and provide helpful analysis.",
    tools=[search]) 
 
Simply using the tool returns the following results. Multilingual financial documents are ranked by semantic similarity to the query about comparing earnings growth rates. An agent can use this information to generate useful insights. 
 
 result = search(‚ÄúCompare earnings growth rates mentioned in the documents‚Äù) 
print(result)
 {
    "key": "doc_0_en",
    "metadata": {
      "language": "en",
      "source_text": "Q3 2024 earnings report shows revenue growth of 15% year-over-year driven by strong performance in cloud services and AI products",
      "doc_id": 0
    },
    "distance": 0.7292724251747131
  },
  {
    "key": "doc_18_zh",
    "metadata": {
      "source_text": "2024Âπ¥‰∏äÂçäÂπ¥Ë¥¢Âä°Êä•ÂëäÊòæÁ§∫ÂáÄÂà©Ê∂¶Â¢ûÈïø20%Ôºå‰∏ªË¶ÅÂèóÁõä‰∫éÈáëËûçÁßëÊäÄÂíåÊï∞Â≠óÊîØ‰ªò‰∏öÂä°ÁöÑÂø´ÈÄüÂèëÂ±ï",
      "language": "zh",
      "doc_id": 18
    },
    "distance": 0.7704182863235474
  },
  {
    "key": "doc_12_de",
    "metadata": {
      "language": "de",
      "doc_id": 12,
      "source_text": "Halbjahresbericht 2024 verzeichnet 12% Gewinnsteigerung durch erfolgreiche Digitalisierung und Automatisierungsl\u00f6sungen"
    },
    "distance": 0.7738275527954102
  }
] 
 
The example above relies on the QueryVectors API operation for S3 Vectors, which can work well for small documents. This approach can be improved to handle large and complex enterprise documents using sophisticated chunking and reranking techniques. Sentence boundaries can be used to create document chunks to preserve semantic coherence. The document chunks are then used to generate embeddings. The following API call passes the same query to the Strands agent: 
 
 response = agent("Compare earnings growth rates mentioned in the documents")  
 
The Strands agent uses the search tool we defined to generate an answer for the query about comparing earnings growth rates. The final answer considers the results returned from the search tool: 
 
 Agent Query:
I'll search for information about earnings growth rates in the financial documents to help you compare them.
Tool #1: search
Let me search for more specific earnings growth information and financial performance metrics.
Tool #2: search
Let me search for more comprehensive financial performance data and specific earnings metrics.
Tool #3: search
Based on the financial documents I've searched through, here's a comparison of the earnings growth rates mentioned:
‚Ä¶
## Key Insights:

1. **Growth Range:** The earnings growth rates span from 12% to 20%, indicating generally healthy performance 
across different markets and sectors.

2. **Technology Focus:** All companies showing strong growth are heavily invested in technology sectors 
(fintech, AI, cloud services, cybersecurity, automation).

3. **Geographic Diversity:** The strong performers represent different regions (Asia, Europe, North America), 
suggesting broad-based growth in tech-enabled services.

4. **Growth Sustainability:** The Chinese fintech company leads with 20% net profit growth, while the others 
show strong revenue growth in the 12-18% range.

The data suggests that companies with strong technology components, particularly in emerging areas like AI, 
fintech, and cybersecurity, are experiencing the most robust earnings growth rates in 2024.Based on the 
financial documents I've searched through, here's a comparison of the earnings growth rates mentioned:
## Earnings Growth Rate Comparison

The data suggests that companies with strong technology components, particularly in emerging areas like AI, 
fintech, and cybersecurity, are experiencing the most robust earnings growth rates in 2024.
 
 
A custom tool like the S3 Vector search function used in this example is just one of many possibilities. With Strands it is straightforward to develop and orchestrate autonomous agents while Bedrock AgentCore serves as the managed deployment system to host and scale these Strands agents in production. 
Deploy to Amazon Bedrock AgentCore 
Once an agent is built and tested, it is ready to be deployed. AgentCore Runtime is a secure and serverless runtime purpose-built for deploying and scaling dynamic AI agents.&nbsp;Use the starter toolkit to automatically create the IAM execution role, container image, and Amazon Elastic Container Registry repository to host an agent in AgentCore Runtime. You can define multiple tools available to your agent. In this example, we use the Strands Agent powered by Embed 4: 
 
 # Using bedrock-agentcore&lt;=0.1.5 and bedrock-agentcore-starter-toolkit==0.1.14
from bedrock_agentcore_starter_toolkit import Runtime
from boto3.session import Session
boto_session = Session()
region = boto_session.region_name

agentcore_runtime = Runtime()
agent_name = "search_agent"
response = agentcore_runtime.configure(
    entrypoint="example.py", # Replace with your custom agent and tools
    auto_create_execution_role=True,
    auto_create_ecr=True,
    requirements_file="requirements.txt",
    region=region,
    agent_name=agent_name
)
response
launch_result = agentcore_runtime.launch()
invoke_response = agentcore_runtime.invoke({‚Äúprompt‚Äù: ‚ÄúCompare earnings growth rates mentioned in the documents‚Äù})  
 
Clean up 
To avoid incurring unnecessary costs when you‚Äôre done, empty and delete the S3 Vector buckets created, applications that can make requests to the Amazon Bedrock APIs, the launched AgentCore Runtimes and associated ECR repositories. 
For more information, see this documentation to delete a vector index and this documentation to delete a vector bucket, and see this step for removing resources created by the Bedrock AgentCore starter toolkit. 
Conclusion 
Embed 4 on Amazon Bedrock is beneficial for enterprises aiming to unlock the value of their unstructured, multimodal data. With support for up to 128,000 tokens, compressed embeddings for cost efficiency, and multilingual capabilities across 100+ languages, Embed 4 provides the scalability and precision required for enterprise search at scale. 
Embed 4 has advanced capabilities that are optimized with domain specific understanding of data from regulated industries such as finance, healthcare, and manufacturing. When combined with S3 Vectors for cost-optimized storage, Strands Agents for agent orchestration, and Bedrock AgentCore for deployment, organizations can build secure, high-performing agentic workflows without the overhead of managing infrastructure. Check the full Region list for future updates. 
To learn more, check out the Cohere in Amazon Bedrock product page and the Amazon Bedrock pricing page. If you‚Äôre interested in diving deeper check out the code sample and the Cohere on AWS GitHub repository. 
 
About the authors 
 James Yi is a Senior AI/ML Partner Solutions Architect at AWS. He spearheads AWS‚Äôs strategic partnerships in Emerging Technologies, guiding engineering teams to design and develop cutting-edge joint solutions in generative AI. He enables field and technical teams to seamlessly deploy, operate, secure, and integrate partner solutions on AWS. James collaborates closely with business leaders to define and execute joint Go-To-Market strategies, driving cloud-based business growth. Outside of work, he enjoys playing soccer, traveling, and spending time with his family. 
Nirmal Kumar&nbsp;is Sr. Product Manager for the Amazon SageMaker service. Committed to broadening access to AI/ML, he steers the development of no-code and low-code ML solutions. Outside work, he enjoys travelling and reading non-fiction. 
Hugo Tse is a Solutions Architect at AWS, with a focus on Generative AI and Storage solutions. He is dedicated to empowering customers to overcome challenges and unlock new business opportunities using technology. He holds a Bachelor of Arts in Economics from the University of Chicago and a Master of Science in Information Technology from Arizona State University. 
Mehran Najafi, PhD, serves as AWS Principal Solutions Architect and leads the Generative AI Solution Architects team for AWS Canada. His expertise lies in ensuring the scalability, optimization, and production deployment of multi-tenant generative AI solutions for enterprise customers. 
Sagar Murthy&nbsp;is an agentic AI GTM leader at AWS who enjoys collaborating with frontier foundation model partners, agentic frameworks, startups, and enterprise customers to evangelize AI and data innovations, open source solutions, and enable impactful partnerships and launches, while building scalable GTM motions. Sagar brings a blend of technical solution and business acumen, holding a BE in Electronics Engineering from the University of Mumbai, MS in Computer Science from Rochester Institute of Technology, and an MBA from UCLA Anderson School of Management. 
Payal Singh&nbsp;is a Solutions Architect at Cohere with over 15 years of cross-domain expertise in DevOps, Cloud, Security, SDN, Data Center Architecture, and Virtualization. She drives partnerships at Cohere and helps customers with complex GenAI solution integrations.
‚Ä¢ A guide to building AI agents in GxP environments
  Healthcare and life sciences organizations are transforming drug discovery, medical devices, and patient care with generative AI agents. In regulated industries, any system that impacts product quality or patient safety must comply with GxP (Good Practice) regulations, such as Good Clinical Practice (GxP), Good Laboratory Practice (GLP), Good Manufacturing Practice (GMP). Organizations must demonstrate to regulatory authorities that their AI agents are safe, effective, and meet quality standards. Building AI agents for these GxP environments requires a strategic approach that balances innovation, speed, and regulatory requirements. 
AI agents can be built for GxP environments: The key lies in understanding how to build them appropriately based on their risk profiles. Gen AI introduces unique challenges around explainability, probabilistic outputs, and continuous learning that require thoughtful risk assessment rather than blanket validation approaches. The disconnect between traditional GxP compliance methods and modern AI capabilities creates barriers to implementation, increases validation costs, slows innovation speed, and limits the potential benefits for product quality and patient care. 
The regulatory landscape for GxP compliance is evolving to address the unique characteristics of AI. Traditional Computer System Validation (CSV) approaches, often with uniform validation strategies, are being supplemented by Computer Software Assurance (CSA) frameworks that emphasize flexible risk-based validation methods tailored to each system‚Äôs actual impact and complexity (FDA latest guidance). 
In this post, we cover a risk-based implementation, practical implementation considerations across different risk levels, the AWS shared responsibility model for compliance, and concrete examples of risk mitigation strategies. 
Risk based implementation framework 
Effective GxP compliance for agentic AI systems require assessing risk based on operational context rather than technology features alone. To support risk classification, the FDA‚Äôs CSA Draft Guidance recommends evaluating intended uses across three factors: severity of potential harm, probability of occurrence, and detectability of failures. 
In Figure 1, this assessment model combines traditional operational roles with modern risk-based levels. Organizations should assess how AI agents function within workflows and their potential impact on regulated processes. 

 
 Figure 1.  GxP compliance for AI agents combines traditional Role-based with CSA‚Äôs modern risk-based levels
 
The same AI agent capability can warrant dramatically different validation approaches depending on how it is being deployed. How is the agentic AI being consumed and within existing GxP processes? What is the level of human oversight or human-in-the-loop controls? Is the AI agent itself being added as an additional control? What is the potential impact of AI failures on product quality, data integrity, or patient safety? 
Consider an AI agent for scientific literature review. When creating literature summaries for internal team meetings, it presents low risk, requiring minimal controls. When scientists use these insights to guide research direction, it becomes medium risk, needing structured controls, such as human review checkpoints. When supporting regulatory submissions for drug approval, it becomes high risk and requires comprehensive controls because outputs directly impact regulatory decisions and patient safety. 
This risk-based methodology allows organizations to balance innovation with compliance by tailoring validation efforts to actual risk levels rather than applying uniform controls across all AI implementations. 
Implementation considerations 
Successful AI agent designs require common controls that apply consistently across risk levels for quality and safety. Organizations should maintain clear records of AI decisions, prove data has not been altered, reproduce results when needed, and manage system updates safely. AWS supports these requirements through qualified infrastructure and various compliance certifications such as ISO, SOC, and NIST. For a more complete list, see our Healthcare &amp; Life Sciences Compliance page. Detailed compliance validation information for Amazon Bedrock AgentCore is available in the compliance documentation. To implement these controls effectively, organizations can refer to the National Institute of Standards and Technology (NIST) AI Risk Management Framework for AI-risk guidance and ALCOA+ principles to promote data integrity. 
Shared responsibility model 
Successful generative AI cloud-implementation in GxP environments requires understanding the shared division of responsibilities between customers and AWS, as outlined in the Shared responsibility model, to allow organizations to focus on delivering effective and compliance-aligned solutions. 
As AWS helps protect the infrastructure that runs the services offered in the AWS Cloud, Table 1 provides practical examples of how AWS can support customers in validating their agentic AI systems. 
 
  
   
   Focus 
   Customer responsibilities 
   How AWS supports 
   
   
   Validation strategy 
   Design risk-appropriate validation approaches using AWS services for GxP compliance. Establish acceptance criteria and validation protocols based on intended use. 
    Inherit compliance controls with AWS services such as Amazon Bedrock‚Äôs ISO 27001, SOC 1/2/3, FedRAMP, and GDPR/HIPAA eligibility. Support your GxP training requirements through AWS Skill Builder for artificial intelligence and machine learning (AI/ML) and AWS Certified Machine Learning ‚Äì Specialty. Use infrastructure as code through AWS CloudFormation to support on demand validations and deployments that provide repeatable IQ for your agentic workloads. 
   
   
   GxP procedures 
   Develop SOPs that integrate AWS capabilities with existing quality management systems. Establish documented procedures for system operation and maintenance. 
    Build GxP agentic systems with HCLS Landing Zones, designed to align for highly regulated workloads, this capability can augment and support your standard procedure requirements. Augment risk management procedures with Amazon Bedrock AgentCore supporting end-to-end visibility and runtime requirements for complex multi-step tasks. Use AWS Certified SysOps Administrator and AWS Certified DevOps Engineering certifications for training requirements and to make sure teams can operationalize and govern procedural compliance on AWS. 
   
   
   User management 
   Configure IAM roles and permissions aligned with GxP user access requirements. Maintain user access documentation and training records. 
   Secure AI agents access with AWS IAM and Amazon Bedrock AgentCore Identity to establish fine-grained permissions and enterprise identity integration and use IAM Identity Center to streamline workforce user access. 
   
   
   Performance criteria 
   Define acceptance criteria and monitoring thresholds for gen AI applications. Establish performance monitoring protocols. 
    Use Amazon Bedrock Provision Throughput plan for agentic workflows that require consistent and guaranteed performance requirements. Monitor performance with Amazon Bedrock AgentCore Observability and with Amazon CloudWatch with customizable alerts and dashboards for end-to-end visibility. 
   
   
   Documentation 
   Create validation documentation demonstrating how AWS services support GxP compliance. Maintain quality system records. 
   Use AWS Config to help generate compliance reports of your agentic deployments with conformance packs for HIPAA, 21 CFR Part 11, and GxP EU Annex 11.Store your GxP data with Amazon Simple Storage Service (Amazon S3), which offers enterprise-grade 11 nines of durability with support for versioning and user defined retention policies. 
   
   
   Provenance 
   Monitor model versions while maintaining validated snapshots. Version-control prompt templates to facilitate consistent AI interactions, track changes, and maintain records for audit trails version-control prompt templates. Lock tool dependencies in validated environment. 
    Control models and data with Amazon Bedrock configurable data residency and immutable model versioning. AWS Config executes automated configuration tracking and validation. AWS CloudTrail captures comprehensive audit logging. Deploy reproducibility of AI behaviors using model versioning in AWS CodePipeline, AWS CodeCommit, and Amazon Bedrock. 
   
  
 
The following is an example of what customers might need to implement and what AWS provides when building AI agents (Figure 2): 

 
 Figure 2. Gen AI implementation in GxP environments requires understanding the division of responsibilities between customers and AWS.
 
Let‚Äôs demonstrate how these shared responsibilities translate into actual implementation. 
Provenance and reproducibility 
AWS Supports the following: 
 
 Amazon Bedrock ‚Äì Provides immutable model versioning, facilitating reproducible AI behavior across the system lifecycle. 
 AWS Config ‚Äì Automatically tracks and validates system configurations, continuously monitoring for drift from validated baselines. 
 AWS CloudTrail ‚Äì Generates audit trails with cryptographic integrity, capturing model invocations with complete metadata including timestamps, user identities, and model versions. Infrastructure as Code support through AWS CloudFormation enables version-controlled, repeatable deployments. 
 
Customer responsibility: Organizations must version-control their infrastructure deployments, their prompt templates to make sure there is consistent AI behavior and maintain audit trails of prompt changes. Tool dependencies must be tracked and locked to specific versions in validated environments to help prevent unintended updates that could affect AI outputs. 
Observability and performance metrics 
AWS supports the following: 
 
 Amazon Bedrock AgentCore ‚Äì Provides a comprehensive solution for the unique risks that agentic AI introduces, including end-to-end visibility into complex multi-step agent tasks and runtime requirements for orchestrating reasoning chains. Amazon Bedrock AgentCore Observability captures the complete chain of decisions and tool invocations, so that you can inspect an agent‚Äôs execution path, audit intermediate outputs, and inspect failures. The Bedrock Retrieval API for Amazon Bedrock Knowledge Bases enables traceability from retrieved documents to AI-generated outputs. 
 Amazon CloudWatch ‚Äì Delivers real-time monitoring with customizable alerts and dashboards, aggregating performance metrics across the agent invocations. Organizations can configure logging levels based on risk, such as basic CloudTrail logging for low-risk applications, detailed AgentCore traces for medium risk, and complete provenance chains for high-risk regulatory submissions. 
 
Customer responsibility: Organizations define acceptance criteria and monitoring thresholds appropriate to their risk level‚Äîfor example, citation accuracy requirements for our literature review agent. Teams must decide when human-in-the-loop triggers are required, such as mandatory expert review before AI recommendations influence research decisions or regulatory submissions. 
User management, session isolation, and security 
AWS Supports the following: 
 
 Amazon Bedrock AgentCore ‚Äì Provides session isolation using dedicated microVMs, that help prevent cross-contamination between different projects or regulatory submissions. The service supports VPC endpoints to establish private connections between your Amazon VPC and Amazon Bedrock AgentCore resources, allowing for inter-network traffic privacy. All communication with Amazon Bedrock AgentCore endpoints uses HTTPS exclusively across all supported regions, with no HTTP support, so that all communications are digitally signed for authentication and integrity. 
 
Amazon Bedrock AgentCore maintains robust encryption standards with TLS 1.2 minimum requirements (TLS 1.3 recommended) for all API endpoints. Both control plane and data plane traffic are encrypted with TLS protocols and restricted to minimum TLS 1.2 with no unencrypted communication permitted. Amazon Bedrock AgentCore Identity addresses identity complexity with a secure token vault for credentials management, providing fine-grained permissions and enterprise identity integration. 
AWS Identity and Access Management (IAM) enables organizations to configure role-based access controls with least-privilege principles. Built-in encryption facilitates data protection both in transit and at rest, while network isolation and compliance certifications (SOC, ISO 27001, HIPAA) support regulatory requirements. Amazon Bedrock offers configurable data residency, allowing organizations to specify regions for data processing. 
Customer responsibility: Organizations configure IAM roles and policies aligned with GxP user access requirements, facilitating least-privilege access and proper segregation of duties. Access controls must be documented and maintained as part of the quality management system. 
GxP controls for AI agents 
The implementation of GxP risk controls for AI agents can be considered through three key phases. 
Risk Assessment evaluates the GxP workload against the organization‚Äôs risk-based validation framework. Continual quality assurance is maintained through structured feedback loops, ranging from real-time verification (see Continuous Validation) to bi-annual reviews. This process makes sure reviewers are trained against the evolving AI landscape, adapt to user feedback, and apply appropriate intervention criteria. In practice, risk assessments define risk categories and triggers for reassessment. 
Control Selection is carefully selecting minimum required controls based on the 1. risk classification, 2. the specific design attributes, and 3. operational context of the AI agents. This targeted, risk-adjusted approach, makes sure controls align with both technical requirements and compliance objectives. In practice, risk categories drive required and selectable controls. An example of medium risk might require Agent and Prompt Governance controls along with two or more Detective Controls, while a high risk might require Traditional Testing (IQ, OQ, PQ) control, and two additional corrective controls. 
Continuous Validation is an approach that includes the traditional fit-for-intended-use validation and subsequent process that leverages real-world data (RWD), such as operational logs and/or user feedback, to create supplemental real-world evidence (RWE) that the system maintains a validated state. As a control mechanism itself, the Continuous Validation approach helps address modern cloud-based designs including SaaS models, model drifts, and evolving cloud infrastructure. Through ongoing monitoring of performance and functionality, this approach helps maintain system GxP compliance while supporting regulatory inspections. In practice, for low-risk categories, this might be a user compliance-aligned portal that tracks user issue trends to high-risk systems that incorporate periodic self-tests with compliance reports. 
The following table provides examples of Preventive, Corrective, and Detective Controls for agentic AI systems that could be incorporated in a modern GxP validation framework. 
 
  
   
   Control element 
   Supporting AWS services 
   
   
   Preventive Controls 
   
   
   Agent Behavior Specification 
   Use Amazon Bedrock Model Catalog to find the models that help meet your specific requirements and use AWS service quotas (limits) and documentation on service features to define supported and verifiable agent capabilities. 
   
   
   Threat Modeling 
   Use AWS Well-Architected Framework (Security Pillar) tools and AWS service security documentation to proactively identify AI-specific threats like Prompt Injection, Data Poisoning, and Model Inversion, and help design preventive mitigations using AWS services. 
   
   
   Response Content and Relevance Control 
   Use Amazon Bedrock Guardrails to implement real-time safety policies for large language models (LLMs) to deny harmful inputs or responses. Guardrails can also define denylists and filter for PII. Use Amazon Bedrock Knowledge Bases or AWS purpose-built vector databases for RAG to provide controlled, current, and relevant information to help prevent factual drift. 
   
   
   Bias Mitigation in Datasets 
   Amazon SageMaker Clarify provides tools to run pre-training bias analysis of your datasets. For agents, this helps make sure the foundational data doesn‚Äôt lead to biased decision-making paths or tool usage. 
   
   
   Agent &amp; Prompt Governance 
   Amazon Bedrock agents and prompt management features support lifecycle processes including creation, evaluation, versioning, and optimization. The features also support advanced prompt templates, content filters, automated reasoning checks, and integration with Amazon Bedrock Flows for more secure and controlled agentic workflows. 
   
   
   Configuration Management 
   AWS provides an industry leading suite of configuration management services such as AWS Config and AWS Audit Manager, which can be used to continuously validate agentic GxP system configurations. AWS SageMaker Model Registry manages and versions trained machine learning (ML) models for controlled deployments. 
   
   
   Secure AI Development 
   Amazon Q Developer and Amazon Kiro provide AI-powered code assistance that incorporate security best practices and AWS Well-Architected principals for building and maintaining agentic workloads securely from the start. 
   
   
   AI Agents as Secondary Controls 
   Use Amazon Bedrock AgentCore and your data to quickly incorporate AI agents into existing GxP workflows as secondary preventative controls to add capabilities like trend analysis, automated inspections, and systems flow analysis that can trigger preventative workflow events. 
   
   
   Detective Controls 
   
   
   Traditional Testing (IQ, OQ, PQ) 
   Use AWS Config and AWS CloudFormation for IQ validation by tracking resource deployment configurations. Use AWS CloudTrail and AWS CloudWatch for sourcing events, metrics, and log test results for OQ/PQ validation. 
   
   
   Explainability Audits &amp; Trajectory Reviews 
   Amazon SageMaker Clarify generates explainability reports for custom models. Amazon Bedrock Invocation Logs can be used to review reasoning or chain of thought to find flaws in an agent‚Äôs logic. Utilize Amazon AgentCore Observability to look at agent invocation sessions, traces and spans. 
   
   
   Model &amp; I/O Drift Detection 
   For custom models, Amazon SageMaker Model Monitor, can detect drift in data and model quality. For AI agents using commercial LLMs, use the observability service of Amazon Bedrock AgentCore to design monitoring of Inputs (prompts) and Outputs (responses) to detect concept drift. Use Amazon CloudWatch alarms to manage compliance notifications. 
   
   
   Performance Monitoring 
   Agentic workloads can use Amazon Bedrock metrics, AgentCore Observability and AWS CloudWatch metrics to include monitoring for Token Usage, Cost per Interaction, and Tool Execution Latency to detect performance and cost anomalies. 
   
   
   Log and Event Monitoring (SIEM) 
   For agentic workload, Amazon GuardDuty provides intelligent threat detection that analyzes Amazon Bedrock API calls to detect anomalous or potentially malicious use of the agent or LLMs. 
   
   
   Code &amp; Model Risk Scanning 
   Amazon CodeGuru and Amazon Inspector scans agent code and operational environment for vulnerabilities. These tools can‚Äôt assess model weights for risk, however AWS does provide Amazon SageMaker Model Card support that can be used to build Model Risk scanning controls. 
   
   
   Adversarial Testing (Red Teaming) &amp; Critic/Grader Model 
   The evaluation tools of Amazon Bedrock help assess model fitness. Amazon Bedrock supports leading model providers allowing GxP systems to use multiple models for secondary and tertiary validation. 
   
   
   Internal Audits 
   AWS Audit Manager automates the collection of evidence for compliance and audits and AWS CloudTrail provides a streamlined way to review agent actions and facilitate procedural adherence. 
   
   
   Corrective Controls 
   
   
   Model &amp; Prompt Rollback 
   Use AWS CodePipeline and AWS CloudFormation to quickly revert to a previous, known-good version of a model or Prompt Template when a problem is detected. 
   
   
   System Fallback 
   AWS Step Functions can help orchestrate a fallback to a streamlined, more constrained model or a human-only workflow if the primary agent fails. 
   
   
   Human-in-the-Loop &amp; Escalation Management 
   AWS Step Functions, Amazon Simple Notification Service (SNS) and Amazon Bedrock Prompt Flow can orchestrate workflows that can pause and wait for human approval, including dynamic approvals based on low agent confidence scores or detected anomalies. 
   
   
   CAPA Process 
   AWS Systems Manager OpsCenter provides a central place to manage operational issues, which can be used to track the root cause analysis of an agent‚Äôs failure. 
   
   
   Incident Response Plan 
   AWS Security Hub and AWS Systems Manager Incident Manager can automate response plans for AI security incidents (for example, major jailbreak and data leakage) and provide a central dashboard to manage them. 
   
   
   Disaster Recovery Plan (DRP) 
   AWS Elastic Disaster Recovery (DRS) and AWS Backup provides tools to replicate and recover the entire AI application stack, including deploying to different AWS Regions. 
   
  
 
Conclusion 
Healthcare and life sciences organizations can build GxP-compliant AI agents by adopting a risk-based framework that balances innovation with regulatory requirements. Success requires proper risk classification, scaled controls matching system impact, and understanding the AWS shared responsibility model. AWS provides qualified infrastructure and comprehensive services, while organizations configure appropriate controls, maintain version management, and implement risk mitigation strategies tailored to their validation needs. 
We encourage organizations to explore building GxP-compliant AI agents with AWS services. For more information about implementing compliance-aligned AI systems in regulated environments, contact your AWS account team or visit our Healthcare and Life Sciences Solutions page. 
 
About the authors 
Pierre de Malliard is a Senior AI/ML Solutions Architect at Amazon Web Services and supports customers in the Healthcare and Life Sciences Industry. 
Ian Sutcliffe&nbsp;is a Global Solution Architect with 25+ years of experience in IT, primarily in the Life Sciences Industry. A thought leader in the area of regulated cloud computing, one of his areas of focus is IT operating models and process optimization and automation with the intent of helping customers become Regulated Cloud Natives 
Kristin Ambrosini is a Generative AI Specialist at Amazon Web Services. She drives adoption of scalable GenAI solutions across healthcare and life sciences to transform drug discovery and improve patient outcomes. Kristin blends scientific expertise, technical acumen, and business strategy. She holds a Ph.D. in Biological Sciences. 
Ben Xavier is a MedTech Specialist with over 25 years of experience in Medical Device R&amp;D. He is a passionate leader focused on modernizing the MedTech industry through technology and best practices to accelerate innovation and improve patient outcomes.
‚Ä¢ Multi-Agent collaboration patterns with Strands Agents and Amazon Nova
  Multi-agent generative AI systems use multiple specialized AI agents working together to handle complex, multi-faceted tasks that exceed the capabilities of any single model. By combining agents with different skills or modalities (for example, language, vision, audio, video), these systems can tackle tasks in parallel or sequence, yielding more robust results. Recent research shows that multi-agent collaboration can significantly improve success rates on complex goals (up to 70% higher vs. single-agent approaches). There are different patterns for such multi-agent collaborations. Whether it‚Äôs a manager-agent delegating specialized tasks (Agent as tools), a swarm of brainstormers (Swarms), a carefully wired graph of expert agents (Agent Graph), or a structured pipeline (agent workflow), the right design pattern combined with the right tooling will significantly enhance the system‚Äôs effectiveness. 
The challenge with multi-agent systems, however, lies in their computational demands. Modern multi-agent applications can issue thousands of prompts per user request as agents brainstorm, critique, and refine one another‚Äôs answers. This intensive workflow creates two critical requirements: high throughput (tokens-per-second) and cost efficiency (dollars-per-million-tokens). This is precisely where Amazon Nova becomes a very suitable&nbsp;foundation model (FM)&nbsp;choice for multi-agent architectures: 
 
 Blazing throughput: Nova Micro streams over 200 tokens per second with sub-second first-token latency, keeping even large swarms of agents responsive to end-users. 
 Consistent structured output: With the latest constrained&nbsp;decoding implementation, Amazon Nova models can produce consistent structured outputs and improve tool-calling accuracy. 
 Ultra-low cost:&nbsp;Teams can afford the token volume that multi-agent reasoning demands with the low costs of Nova Micro and Nova Lite. 
 
Because every agent call stays inexpensive, developers are free to let orchestration frameworks such as the open-source Strands Agents SDK spin up task-specific Nova agents, retry or cross-verify answers, and iterate until they converge on the best result‚Äîall without runaway inference bills.Conversely, multi-agent generative AI systems unlock the full potential of Amazon Nova through: 
 
 Iterative self-improvement: Agents can ask Nova to reflect on its own answer, critique weaknesses, and regenerate often lifting success rates by double-digit percentages without any fine-tuning. 
 Redundancy and fail-over: Running several Nova agents in parallel (such as consensus or swarm patterns) increases answer quality and resilience‚Äîone weak response is out-voted or retried automatically. 
 
In this post, we explore four key collaboration patterns for multi-agent, multimodal AI systems ‚Äì Agents as Tools, Swarms Agents, Agent Graphs, and Agent Workflows ‚Äì and discuss when and how to apply each using the open-source AWS Strands Agents SDK with Amazon Nova models. As an agent orchestration framework, Strands is built to be lightweight and easy to learn ‚Äì it uses only a handful of concepts and leans on Python‚Äôs native structures for composing agents. Another strength is its model-driven approach: Strands encourages you to let the FM&nbsp;figure out the sequence of steps (the agent loop consults the FM for what to do next rather than hardcoding a flow). This harnesses the powerful reasoning of FM for orchestration decisions, reducing the amount of fixed code logic.&nbsp;Each of the following pattern sections provides a conceptual overview with a diagram, real-world use cases, pros and cons, and code examples to illustrate implementation. 
Agents as Tools pattern 
The Agents as Tools pattern wraps specialized AI agents as callable tools that a primary orchestrator agent can invoke. This creates a hierarchical team structure: a top-level agent acts like a manager, delegating specific queries to expert sub-agents and then integrating their outputs. Each tool agent focuses on a particular domain or modality, while the orchestrator decides which tool to call for each part of the user‚Äôs request. This setup mimics a human scenario where a team lead consults various specialists instead of trying to do everything alone. By offloading work to expert agents, the orchestrator can provide more accurate and multi-faceted responses than a monolithic agent. 
 
Figure 1: Multimodal Agents as Tools ‚Äì An orchestrator agent (manager) uses specialized ‚Äútool‚Äù agents (experts) to handle different sub-tasks, then aggregates their results into a final answer. 
Use cases, pros, and cons 
This pattern is ideal when a user query naturally breaks down into distinct subtasks requiring different expertise.&nbsp;For instance: 
 
 A multi-domain assistant that answers questions involving, say, travel planning, product recommendations, and research‚Äìthe orchestrator can route portions to a Trip Planner, Product Recommender, or Researcher agent respectively. 
 Multimodal tasks where one agent handles image or speech input while another handles text (the orchestrator chooses the right modality-specific agent as a tool). 
 Any system requiring specialized skills or tools (for example, an educational tutor agent invoking a code execution agent for programming questions, or a customer service bot calling a database-query agent). 
 
Pros: 
 
 Separation of concerns: Each agent has a focused role/expertise, making the overall system easier to understand and extend. 
 Modularity: Specialists (tools) can be added or updated independently without affecting others, as long as the orchestrator‚Äôs interface to them remains consistent. 
 Hierarchical decision-making: The orchestrator provides a clear chain of command, deciding which expert to use for each task, which can improve reliability. 
 Optimized performance: Each agent can have a tailored prompt, model, or tool for its specific task, potentially yielding better accuracy or efficiency than a generalist agent. 
 
Cons: 
 
 Orchestrator complexity: The top-level agent must correctly identify which tool agent to invoke and how to integrate results. This requires careful prompt engineering or routing logic (risk of errors if the orchestrator misinterprets the query). 
 Single point of failure: The orchestrator agent becomes a critical component; if it fails or gives a bad decision, the whole system‚Äôs output may suffer. 
 Context sharing and integration: Specialized agents typically receive only the information explicitly included in their specific queries, limiting their access to broader context. Therefore, the orchestrator must consolidate outputs from different agents. Ensuring a coherent final answer (avoiding contradictions or gaps) can be challenging if the specialists work in isolation. 
 
Strands SDK example 
The Strands Agents SDK makes it easy to implement Agents as Tools using the @tool decorator to turn python functions into callable tools. Each tool-agent is essentially an LLM (or other service) with its own prompt or instructions and is exposed as a callable function. When invoked, the specialist agent receives only the information passed by the orchestrator (typically the specific subtask prompt) and returns its output. The orchestrator then uses that output in context, possibly calling further tools or producing a final answer. In the following code, we define a specialized research assistant agent as a tool, then create an orchestrator that uses it (along with other domain-specific agents) to answer a query with either indexed knowledge or web search information: 
 
 from strands import Agent
from strands_tools import retrieve, http_request

# Define a specialized Research Assistant agent as a tool
RESEARCH_ASSISTANT_PROMPT = (
&nbsp;&nbsp; &nbsp;"You are a specialized research assistant. Provide factual, cited answers."
)

@tool
def research_assistant(query: str) -&gt; str:
&nbsp;&nbsp; &nbsp;"""Provide well-sourced research answers for a given query."""
&nbsp;&nbsp; &nbsp;try:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;# Create an agent with a research-focused prompt and tools
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;research_agent = Agent(
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;system_prompt=RESEARCH_ASSISTANT_PROMPT,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;tools=[retrieve, http_request] &nbsp;# e.g. multimodal knowledge base retrieval, web retrieval tools
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;)
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;response = research_agent(query)
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return str(response)
&nbsp;&nbsp; &nbsp;except Exception as e:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return f"Error in research assistant: {e}"

 
 
In a similar way, you can also define other tool agents, for example an editor_assistant or image_creation_assistant, each with their own system prompt and tools for their domain. Once the specialist agents are defined, the orchestrator agent can include them in its tool list: 
 
 # Define the orchestrator agent with all specialized tools
MAIN_SYSTEM_PROMPT = "You are an orchestrator coordinating multiple domain experts."

orchestrator = Agent(
&nbsp;&nbsp; &nbsp;system_prompt=MAIN_SYSTEM_PROMPT,
&nbsp;&nbsp; &nbsp;tools=[research_assistant,&nbsp;editor_assistant,&nbsp;image_creation_assistant]
)

# Process a complex user query through the orchestrator
query = "I'm planning a hiking trip to Patagonia and need the right gear."
response = orchestrator(query)
print(response) 
 
In this example, the orchestrator will delegate parts of the query to the relevant specialists ‚Äì for example, use research assistant then pass that context to the editor assistant to produce content based on the provided context, and finally synthesize a combined answer for the user. The Agents as Tools pattern enables a powerful composition of experts, all managed through simple function calls in Strands. 
The complete code example and solution diagram of this multimodal email writer assistant that is ready to run and deploy is provided in this Github repository. 
 
Figure 2: Solution diagram of the multimodal email writer assistant with Agents as Tools pattern. 
See the agents-as-tools documentation for more information. 
Swarm pattern 
The swarm pattern involves a group of peer agents working together on a task, exchanging information directly and iteratively. This is inspired by swarm intelligence in nature (like ant colonies or bee swarms) where many simple units interact to produce complex, emergent behavior. In an AI swarm, each agent might approach the problem from a different perspective (or with different data or mode) and share its findings so that other agents can refine their own results. No central controller is micromanaging the process; instead, coordination is decentralized and often happens through a shared memory or message space. The swarm thus collectively explores the solution space and converges on an answer through multiple rounds of communication. 
 
Figure 3: Swarms Agents ‚Äì A decentralized mesh of agents (e.g. Research, Creative, Critical, Summarizer) all communicate with each other to collaboratively solve a problem. There is no single orchestrator; intelligence emerges from agents sharing and refining ideas collectively. 
Key characteristics of swarms include information sharing, agent specialization, redundancy, and the potential for emergent intelligence beyond the sum of individual agents. Importantly, control is decentralized‚Äìthere isn‚Äôt a single agent deciding roles for others. Agents follow relatively simple local rules (‚Äúshare my result with others, then revise my answer after seeing others‚Äô results‚Äù) and complex global behavior emerges from these interactions. For example, one agent might focus on creative brainstorming, another on factual accuracy, another on critiquing solutions, and a final one on summarizing; together, through two or more rounds of exchanging ideas, they produce a balanced and well-vetted outcome. 
Use cases, pros, and cons 
Swarm patterns are useful when a problem benefits from diverse perspectives or parallel exploration: 
 
 Brainstorming and ideation: Multiple generative agents can propose ideas or solutions in parallel (some might be wild and creative, others more conservative), then collectively refine them. This can yield more innovative results than a single agent‚Äôs answer. 
 Complex reasoning tasks: Agents can build upon each other‚Äôs work through structured handoffs. For example, one agent analyzes a problem, hands off to another for solution design, then to a third for validation and refinement. This sequential collaboration often produces higher-quality results than parallel approaches. 
 Multi-stage workflows: Different agents can handle distinct phases of a complex task. In financial analysis, a research agent gathers data, hands off to an analysis agent for insights, then to a reporting agent for final presentation. Each handoff includes context and intermediate results. 
 Iterative improvement: Through multiple iterations and handoffs, swarms can progressively refine solutions. An initial draft from one agent gets enhanced by subsequent agents, with each iteration building on previous work within configurable time windows. 
 Fault-tolerant processing: With timeout controls and handoff mechanisms, swarms can gracefully handle agent failures. If one agent times out, the swarm can continue with available results or retry with different agents. 
 
Pros: 
 
 Diversity of thought: Each agent can pursue a unique strategy or viewpoint, yielding a richer pool of ideas. The final result can be more comprehensive and balanced by incorporating inputs from all agents. 
 Emergent improvement: Through iterative communication, swarms often refine solutions better than a single-pass approach. Agents can correct each other‚Äôs errors or build on each other‚Äôs partial solutions, leading to high-quality outcomes. 
 No single failure point: Since there‚Äôs no central orchestrator, the system might be more fault-tolerant ‚Äì if one agent underperforms, others can compensate (and there isn‚Äôt a single agent whose failure collapses the process). 
 
Cons: 
 
 Timeout sensitivity: Aggressive timeout settings might cut off productive work, and loose timeouts can lead to inefficient resource usage if agents get stuck. 
 Iteration overhead: Multiple iterations can accumulate costs and latency, especially with large language models, requiring careful balance between quality and efficiency. 
 
Strands SDK example 
In the following example, the swarm has three following collaborative agents: 
 
 research_agent: finds factual info 
 analysis_agent: analyzes live market data via API 
 writer_agent: compiles the final answer 
 
 
 from strands import Agent
from strands.models import BedrockModel
from strands.multiagent import Swarm

# Create specialized agents for different tasks
research_agent = Agent(
&nbsp;&nbsp; &nbsp;name="researcher",
&nbsp;&nbsp; &nbsp;system_prompt="Research and gather information, then hand off to analyst.",
&nbsp;&nbsp; &nbsp;model=BedrockModel(model_id="us.amazon.nova-pro-v1:0", region="us-east-1"),
&nbsp;&nbsp; &nbsp;tools=[web_search, knowledge_base]
)

analysis_agent = Agent(
&nbsp;&nbsp; &nbsp;name="analyst", 
&nbsp;&nbsp; &nbsp;system_prompt="Analyze research data and hand off to writer.",
&nbsp;&nbsp; &nbsp;model=BedrockModel(model_id="us.amazon.nova-pro-v1:0", region="us-east-1"),
&nbsp;&nbsp; &nbsp;tools=[data_analysis, financial_metrics]
)

writer_agent = Agent(
&nbsp;&nbsp; &nbsp;name="writer",
&nbsp;&nbsp; &nbsp;system_prompt="Create final report based on research and analysis.",
&nbsp;&nbsp; &nbsp;model=BedrockModel(model_id="us.amazon.nova-pro-v1:0", region="us-east-1"),
&nbsp;&nbsp; &nbsp;tools=[editor, formatter]
)

# Configure swarm with handoff and timeout controls
swarm = Swarm(
&nbsp;&nbsp; &nbsp;agents=[research_agent, analysis_agent, writer_agent],
&nbsp;&nbsp; &nbsp;max_handoffs=2, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Allow up to 2 handoffs between agents
&nbsp;&nbsp; &nbsp;max_iterations=3, &nbsp; &nbsp; &nbsp; &nbsp; # Up to 3 rounds of refinement
&nbsp;&nbsp; &nbsp;execution_timeout=300.0, &nbsp;# Total swarm timeout (5 minutes)
&nbsp;&nbsp; &nbsp;node_timeout=60.0 &nbsp; &nbsp; &nbsp; &nbsp;# Individual agent timeout (1 minute)
)

# Execute collaborative workflow
result = swarm("Analyze Q3 financial performance and create executive summary")
print(f"Final result: {result.final_response}")
print(f"Collaboration path: {[node.node_id for node in result.node_history]}") 
 
This approach eliminates the need for manual coordination code and provides fine-grained control over collaboration patterns. The swarm automatically manages handoffs between agents, tracks conversation history, and confirms that execution completes within specified timeouts. Agents can focus on their specialized tasks while the swarm framework handles the complex orchestration, shared memory management, and fault tolerance mechanisms. The key advantage is that complex multi-agent workflows become as simple as configuring a few parameters, while still supporting sophisticated collaboration patterns through the handoff and iteration mechanism. 
The complete code example and solution diagram of a financial assistant swarm agent that is ready to run and deploy is provided in this Github repository. 
 
Figure 4: Solution diagram of a financial assistant swarm agent.&nbsp; 
See the swarms documentation for more information. 
Graph pattern 
An agent graph defines a structured network of agents with directed connections that determine how information flows between them. Unlike the free-form mesh of a swarm, an agent graph is usually designed by the developer to fit a specific workflow or organizational hierarchy. Each node in the graph is an agent with a well-defined role, and each edge represents a communication or handoff channel (which might be one way or bidirectional). This pattern helps you enforce precise control over the sequence and direction of inter-agent interactions. For example, you might arrange agents in a multi-level hierarchy: a top-level executive agent breaks a task into parts, passes sub-tasks to intermediate manager agents, which in turn delegate to low-level specialist agents, and results flow back up the chain. Alternatively, you can define a star topology where a central agent coordinates a set of peripheral agents (similar to Agents as Tools, but potentially with feedback loops), or any custom graph topology (tree, acyclic graph) that suits the problem domain. 
 
Figure 5: Illustration of a Graph agent pattern.&nbsp; 
The agent graph is shown in the following diagram. (Topology Example ‚Äì Hierarchical): Agents connected in a multi-level graph. The&nbsp;planner agent delegates a query to a robust supervisor agent, and then delegates to mid-level agents Agent 1, Agent 2, Agent 3 and Agent 4; each of those oversees a team of specialized agents. Information flows along directed edges. The branch can incorporate business logic to decide which agent to use based on the conditional edge.&nbsp;The key benefit of agent graphs is predictability and control. By explicitly connecting agents in a graph, developers can verify that a fact-checker agent always validates outputs from a generation agent before they reach the final reporter agent, or that information only flows in approved ways (useful for safety, to prevent certain agents from seeing sensitive data unless needed). This pattern excels when you need custom communication patterns, distinct specialized roles, and fine-grained information flow management. 
Use cases, pros, and cons 
Agent graph patterns shine in particular when: 
 
 You have complex, multi-stage decision processes, such as an enterprise workflow where a lead agent delegates to separate analysis agents (financial, technical, social impact analysis) and each analysis agent might further delegate to sub-agents.&nbsp;The graph structure can mirror organizational charts or decision trees so that each step‚Äôs output is reviewed and integrated at higher levels. 
 You need controlled tool access and data flow: Suppose you have certain agents that can call external tools or APIs and others that should not (for security or cost reasons). By structuring the graph, you can isolate tool-using agents and have other agents funnel requests through them. 
 To avoid free-for-all communication: If the task requires tight coordination and clear roles, an agent graph is preferable over a swarm. For instance, in a customer support system with multiple agents (billing, technical support, sales), you might not want them all talking to each other arbitrarily. A graph can enforce that all communication goes through a central coordinator or follows defined escalation paths (like a star or tree topology). 
 
Pros: 
 
 Fine-grained control: Developers explicitly define who communicates with whom. This prevents unintended interactions and makes the system‚Äôs behavior easier to reason about, such as when you know the Report Aggregator Agent only receives input from the Fact-Checker and Analysis agents and nothing else. 
 Context and state management: Graph edges can be thought of as persistent channels‚Äìpotentially maintaining state or using message queues. This is useful for long-running contexts. 
 Predictable execution flow: Unlike a swarm (where timing and order of exchanges are emergent), an agent graph follows a more deterministic flow. This is beneficial for workflows that require deterministic outputs&nbsp;or step-by-step tracking. It‚Äôs easier to trace how an input moves through the system using the graph‚Äôs pathways. 
 
Cons: 
 
 Design effort: Deciding on the right graph topology can be challenging. You must understand the problem domain well in order to partition tasks and arrange agents effectively. Over-designing the graph might lead to rigidity; under-designing might not reap the benefits of the pattern. 
 Less dynamic adaptability: A fixed graph is not as spontaneously adaptive as a swarm. If a query slightly outside the expected pattern comes in, the orchestrated pathways might not handle it gracefully (unless you build in a lot of logic for routing). In contrast, a swarm or tools approach might dynamically adjust by simply trying different tools or agents. 
 Latency in deep graphs: If the graph has many levels (like a tall hierarchy), information has to pass through multiple agents sequentially, which can increase latency. Each hop adds overhead. For example, in a three-level hierarchy, a message might flow down through two intermediate agents and then back up‚Äìthat‚Äôs more round trips than a flatter architecture. 
 
Strands SDK example 
The GraphBuilder class, available in the Strands SDK, offers a streamlined way to implement agent graph patterns. It handles the complexities of agent communication and network topology management, helping developers focus on agent behavior. It provides built-in support to define graph topologies, messages handling (the mechanism for transferring data) and direction (one-way or bidirectional information flow) between agents. For each agent, developers can implement business logic to handle fallback mechanism and agent response evaluation. 
 
 from strands import Agent
from strands_tools import agent_graph

builder = GraphBuilder()

# Add nodes
builder.add_node(coord_agent, "research")
builder.add_node(get_stock_prices_agent, "stock_price_search")
builder.add_node(fin_web_searcher_agent, "fin_web_searcher")
builder.add_node(report_writer_agent, "report")
builder.add_node(image_generator_agent, "create_display_img")

# Add edges (dependencies) - star topology with coordinator at center
builder.add_edge("research", "stock_price_search")
builder.add_edge("research", "fin_web_searcher")
builder.add_edge("research", "report")
builder.add_edge("research", "create_display_img")

# Set entry point
builder.set_entry_point("research")

# Build the graph
graph = builder.build()

# Run the graph
result = graph("Analyze Q3 financial performance and create executive summary") 
 
Use the GraphBuilder to define nodes, edges, and entry points for your multi-agent workflows. From this foundation, you can create sophisticated patterns through various combinations: 
 
 Dynamic workflows: Add conditional logic to edges that route based on runtime decisions 
 Nested architectures: Embed entire graphs or swarms as nodes within larger graph structures 
 
These examples represent just a fraction of the endless architectural possibilities available when building with graphs in the Strands SDK. 
The complete code example of this agent graph that is ready to run and deploy is provided in this Github repository. 
See the graphs documentation for more information. 
Workflow pattern 
The workflow pattern orchestrates multiple agents in a predefined sequence or dependency graph of tasks‚Äìmuch like a classical workflow or pipeline, but with AI agents executing the steps. In this pattern, the emphasis is on task ordering and dependency management: you explicitly break a complex job into a series of discrete tasks assigned to different agents, and define how those tasks depend on each other (some tasks might run in parallel, others must wait for certain outputs). In the workflow pattern, each agent does its part at the right time, passing its output as input to the next relevant agent in the chain. 
 
Figure 6: the workflow agent pattern. A directed acyclic graph of agents executing a multi-step process. In this example, A0 (entry point) splits the query into three agents (to Agents 1, 2, 3), which then feed into subsequent steps (Agents 4, 5, 6, 7), and finally converge at Agent 8 which produces the response. This illustrates explicit task dependencies and execution order forming a workflow. 
You can think of an agent workflow as a directed acyclic graph (DAG) of tasks, where each task is executed by an agent. This is similar to an agent graph, but workflow typically implies a stronger focus on one-off execution of a process from start to finish (like a pipeline run), whereas an agent graph might be a persistent network of agents handling ongoing tasks. Workflows are great for processes that have clear stage-wise structure‚Äìfor example, data processing pipelines, multi-step reasoning with checkpoints, or any situation where certain steps (tasks) must happen in a strict order or only after certain prerequisites are met. The workflow pattern also aligns well with systems that require monitoring, logging, or error recovery at each step of a complex job (since each task‚Äôs execution can be tracked independently). 
Use cases, pros, and cons 
Use agent workflows when dealing with complex multi-step tasks with well-defined stages: 
 
 Content generation with review: One agent drafts an article, another agent (or tool) fact-checks it, another agent edits for style, and another approves or publishes. These steps happen in order (possibly with some parallel checks) and might be repeated on failure. 
 Situations requiring coordination and dependency handling: If certain tasks can run in parallel, the workflow can branch; if some tasks must converge, the workflow can join. For example, a job application screening might have one AI agent score the resum√© and another agent perform a skill test in parallel, then a final agent uses both outcomes to make a decision. 
 Long-running or monitored processes: With workflows, you can pause, resume, or retry at the task level. If a particular agent fails or a step needs to be repeated, you can reset that step without redoing the whole workflow‚Äìuseful for robust production pipelines. 
 
Pros: 
 
 Clear structure and reliability: The explicit definition of order and dependencies means that the execution path is predictable and repeatable. This is vital for processes where correctness and auditability matter (you can log each step‚Äôs input and output). 
 Parallel efficiency: Workflows can specify parallel branches for independent tasks, making better use of resources (unlike a single agent doing everything sequentially). The framework will synchronize when branches need to join. 
 Error handling and recovery: Because tasks are discrete, a workflow controller can catch if an agent fails on a step and implement a retry or fallback just for that step. There‚Äôs no need to restart the entire process. This localized error handling improves robustness. 
 Specialized agents per step: Similar to Agents as Tools, each step can use an agent best suited for that subtask (for example, a translation agent followed by a summarizer agent). Workflows ensure these specialized agents run in the correct sequence with the proper data. 
 State management: The workflow can maintain state context across steps explicitly (such as carrying forward a task ID or collecting outputs). Strands‚Äô workflow tool supports tracking progress, pausing, and even resuming workflows that persist beyond a single session. 
 
Cons: 
 
 Less flexibility for novel situations: A workflow handles expected sequences well, but if a user query doesn‚Äôt fit the pre-defined process, the system might not adapt. It‚Äôs not as exploratory as a swarm or as dynamically routed as an agent graph. Essentially, workflows are only as smart as the predefined flow. 
 Up-front effort: You need to decompose the task and define the dependencies. If this analysis is wrong or incomplete, the workflow might fail or produce suboptimal results. Designing a good workflow might require domain expertise to decide the correct breakdown. 
 Potential under-utilization: If a workflow has many sequential steps, it could be slower than an agent that can perform some steps in parallel. For example, a single large language model might internally summarize while reading text, whereas a strictly sequential workflow forces a full hand-off between reading and summarizing agents, possibly incurring overhead. 
 Overhead of orchestration: Managing the execution of multiple agents (especially with a general workflow engine) introduces overhead. In simple cases, a single agent might achieve the goal with prompt engineering. Workflows shine in complex scenarios, but for trivial tasks the orchestration overhead is unnecessary. 
 
Strands SDK example 
The Strands Agent SDK doesn‚Äôt enforce a strict conversation among all agents‚Äìyou have to program the flow‚Äìbut its minimal abstractions make parallel or sequential orchestration straightforward (as seen in the previous example running three poet agents in parallel with plain Python async code).&nbsp;Another advantage of using Strands Agent SDK is the hierarchical agent concept: using the @tool decorator, you can build a hierarchy of agents naturally, as shown earlier, making it intuitive to implement the manager/sub-agent pattern.&nbsp;Let‚Äôs illustrate a simple manual workflow: three agents (researcher, analyst, writer) performing a sequence of steps. 
 
 from strands import Agent
from strands.models import BedrockModel

# Create specialized agents for each step
researcher = Agent(
&nbsp;&nbsp; &nbsp;system_prompt="You are a research specialist. Find key information.",
&nbsp;&nbsp; &nbsp;model=BedrockModel(model_id="us.amazon.nova-pro-v1:0", region="us-east-1")
)

analyst = Agent(
&nbsp;&nbsp; &nbsp;system_prompt="You analyze research data and extract insights.",
&nbsp;&nbsp; &nbsp;model=BedrockModel(model_id="us.amazon.nova-pro-v1:0", region="us-east-1")
)

writer = Agent(
&nbsp;&nbsp; &nbsp;system_prompt="You create polished reports based on analysis.",
&nbsp;&nbsp; &nbsp;model=BedrockModel(model_id="us.amazon.nova-pro-v1:0", region="us-east-1")
)

# Define the workflow function
def process_workflow(topic: str):
&nbsp;&nbsp; &nbsp;# Step 1: Research
&nbsp;&nbsp; &nbsp;research_results = researcher(f"Research the latest developments in {topic}")
&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;# Step 2: Analysis
&nbsp;&nbsp; &nbsp;analysis = analyst(f"Analyze these findings: {research_results}")
&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;# Step 3: Reporting
&nbsp;&nbsp; &nbsp;final_report = writer(f"Write a report based on this analysis: {analysis}")
&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;return final_report

# Execute the workflow
result = process_workflow("artificial intelligence in healthcare")
print(result) 
 
In this code, we explicitly call each agent in turn, passing the output of one as the input to the next. The process_workflow function orchestrates the sequence. If the researcher agent returns a large amount of data, we might refine or truncate it before passing to the analyst agent, and so on, but the pattern is clear: a linear hand-off. 
One great working example of agentic workflow is intelligent document processing (IDP) workflow.&nbsp;An IDP workflow is a great example of an agentic workflow because it naturally involves multiple discrete yet interdependent steps that benefit from task-specialized agents, dynamic coordination, and adaptive decision-making. The code sample of a typical IDP workflow is provided in this solution guidance. 
See the workflows documentation for more information. 
Conclusion 
Multi-agent collaboration unlocks generative AI capabilities that a single model cannot match‚Äîespecially when each agent can draw on Amazon Nova‚Äôs low-latency, low-cost token generation and coordinate seamlessly through the open-source Strands Agents SDK. Nova‚Äôs ultra-low pricing‚Äîfractions of a cent per thousand tokens‚Äîcombined with high throughput of over 200 tokens per second means teams can experiment freely with deeper reasoning loops, redundancy, and tool use without worrying about runaway costs. Strands adds just-enough orchestration: a Pythonic API for Agents as Tools, swarms, graphs, and workflow patterns, integrated Bedrock model wrappers, shared memory for context exchange, and built-in telemetry. Whether you are building a multimodal Q&amp;A system, an autonomous document-processing pipeline, or a creative brainstorming assistant, pairing Amazon Nova with Strands helps you scale from a single prototype agent to production-grade multi-agent architectures‚Äîall while maintaining the speed, accuracy, and cost profile demanded by modern enterprise workloads. Now is the ideal time to apply these patterns and watch your generative AI applications achieve results that truly are greater than the sum of their Nova-powered parts. 
 
About the authors 
Julia Hu&nbsp;Julia Hu is a Sr. AI/ML Solutions Architect at Amazon Web Services, currently focused on the Amazon Bedrock team. Her core expertise lies in agentic AI, where she explores the capabilities of foundation models and AI agents to drive productivity in Generative AI applications. With a background in Generative AI, Applied Data Science, and IoT architecture, she partners with customers‚Äîfrom startups to large enterprises‚Äîto design and deploy impactful AI solutions. 
Rui Cardoso&nbsp;is a partner solutions architect at Amazon Web Services (AWS). He is focusing on AI/ML and IoT. He works with AWS Partners and support them in developing solutions in AWS. When not working, he enjoys cycling, hiking and learning new things. 
Jessie-Lee Fry is a Product and Go-to Market (GTM) Strategy executive specializing in Generative AI and Machine Learning, with over 15 years of global leadership experience in Strategy, Product, Customer success, Business Development, Business Transformation and Strategic Partnerships. Jessie has defined and delivered a broad range of products and cross-industry go- to-market strategies driving business growth, while maneuvering market complexities and C-Suite customer groups. In her current role, Jessie and her team focus on helping AWS customers adopt Amazon Bedrock at scale enterprise use cases and adoption frameworks, meeting customers where they are in their Generative AI Journey. 
Bhavya Sruthi Sode is a Technical Account Manager at Amazon Web Services, focused on Generative AI and Machine Learning. She helps customers design resilient, scalable, and secure cloud architectures while driving successful outcomes in their enterprise cloud environments. With a background in Machine Learning, she is passionate about helping organizations transform their AI aspirations into practical solutions. 
David Rostcheck is a Sr. Specialist Solutions Architect at Amazon Web Services, focused on AI/ML, Bedrock, and agent solutions. He enjoys helping our customers deliver effective AI-based solutions to production.

‚∏ª