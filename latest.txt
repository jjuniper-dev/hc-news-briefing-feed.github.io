‚úÖ Morning News Briefing ‚Äì August 06, 2025 10:50

üìÖ Date: 2025-08-06 10:50
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions:  9.8¬∞C
  Temperature: 9.8&deg;C Pressure / Tendency: 103.1 kPa rising Humidity: 96 % Humidity is 96% Dewpoint is 9.2¬∞C . Wind:  calm km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Wednesday 6 August 2025 . Weather forecast: 10/11/
‚Ä¢ Wednesday: Sunny. High 27.
  High 27. Humidex 32. UV index 8 or very high. Local smoke. Sunny. Sunny . Sunny. High 27 . High . High 27; UV index of 8 or high. High UV of 8. UV of high UV of very high in some areas . Forecast issued 5:00 AM EDT Wednesday 6 August 2025 . Weather forecasters predict temperatures of 27 degrees Celsius

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ It's 2025, the year we decided we need a widespread slur for robots
  People all over TikTok and Instagram are using the word "clanker" as a catch-all for robots and AI . It's a deep dive into the origins of the pejorative and an explanation of why it's spreading . Here's a look at the origin of the phrase and how it came to be used by people all over the world . Click here to read the
‚Ä¢ Nihilistic online networks groom minors to commit harm. Her son was one of them
  When Dana's son was hospitalized last year, it led her to a path of discovery about predatory online networks that groom children into harming themselves and others . Their reach is global and growing, and their reach is also global . Dana: "I'm glad to have this experience, but I'm not sure how it's going to help others," says Dana . She says her son's hospital
‚Ä¢ 60 years later, Voting Rights Act protections for minority voters face new threats
  Sixty years after the Voting Rights Act, legal challenges could curtail its remaining protections for minority voters . The Supreme Court is set to hear the latest challenge on the landmark act in the Supreme Court this week . The case is expected to be heard by the high court next week . It is the latest in a series of legal challenges challenging the act against racial discrimination in the U.S.
‚Ä¢ Voice of America director says Trump officials are illegally ousting him
  A judge is demanding answers about the international broadcaster's future from Trump official Kari Lake . Trump official Lake is accused of leaking confidential information about the future of the U.N. broadcaster . Lake is a Trump official who has been involved in the Trump administration's dealings with the media giant . Lake has been in the spotlight for more than a decade . The judge is now demanding answers from
‚Ä¢ AI companies are targeting students. Here's how that's changing studying
  Students are increasingly using AI tools to help with ‚Äî and do ‚Äî their homework . Here's how older online study services are adapting . Students and professors are adapting to older online services, such as Google, Microsoft and Facebook . Students are using AI to help them with their homework, say experts and professors . See how students are using the latest tools to learn more about their homework at work .

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Network scans find Linux is growing on business desktops, laptops
  Security hardening and DevOps activities the tipping point, says Lansweeper . Cyberattacks and a general desire for a more secure posture are driving some businesses to the way of the penguin, according to the asset manager . It might not be the year of the Linux desktop just yet, but ongoing cyberattacks and the desire to be secure are driving businesses to adopt a new approach .
‚Ä¢ Mistakenly sold NASA command trailer could be yours ‚Äì for $199K
  Former Space Shuttle support vehicle surfaces after surplus slip-up . Airstream trailer that once served as the Convoy Command Vehicle for NASA's Space Shuttle operations at Edwards Air Force Base will be available for purchase . Space fans looking to camp out in style have a chance to pick up the trailer . If you have a couple hundred thousand to spare, that is if they have a few hundred
‚Ä¢ Birmingham City Council's ¬£131M Oracle rebuild in danger as go-live nears
  Finance and HR system overhaul still faces major risks with just months to go before second launch . Second attempt by Europe's largest local authority left it unable to produce auditable accounts . It remains on an "Amber-Red" risk rating less than nine months before it is expected to go live . The first attempt by the first left the authority unable to provide auditable records was unsuccessful .
‚Ä¢ Mobile industry charts course to smartphone satellite broadband
  First services go live, but full-featured coverage depends on new chips, standards, and constellations . Satellite comms services to standard phones are officially here, but customers expecting a full voice and data experience may have to wait a while longer and make sure their current devices meet the right level of telecoms standard .‚Ä¶‚Ä¶‚Ä¶ But customers expect to wait to wait and make
‚Ä¢ Fungus-inspired Linux hack gives Amiga a Doom-only brain
  Linux developer Matthew Garrett has taken inspiration from the fungus kingdom to give a Commodore Amiga a brain transplant . The Amiga does nothing but run id Software's 1993 classic first-person shooter Doom under a "parasitic Linux" operating system . The device is a single-minded device that only runs Doom under the operating system of a parasitic Linux operating system called PiStorm and a parasitic

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Governance of cross-border genomic data sharing through a human rights approach
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Effect of patterns of social activities on depressive symptoms among older adults in china: a latent class analysis of CHARLS
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Exploring the role of mixed reality education in maternal self efficacy and satisfaction with breastfeeding
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Comparative study of early onset cancer burden between China and the United States from 1990 to 2021
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Psychometric validation and correlates of the personal safety perception scale (PSPS-26) as a multidimensional measure of perceived safety
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ OpenAI has finally released open-weight language models
  OpenAI has finally released its first open-weight large language models since 2019‚Äôs GPT-2. These new ‚Äúgpt-oss‚Äù models are available in two different sizes and score similarly to the company‚Äôs o3-mini and o4-mini models on several benchmarks. Unlike the models available through OpenAI‚Äôs web interface, these new open models can be freely downloaded, run, and even modified on laptops and other local devices.



In the company‚Äôs many years without an open LLM release, some users have taken to referring to it with the pejorative ‚ÄúClosedAI.‚Äù That sense of frustration had escalated in the past few months as these long-awaited models were delayed twice‚Äîfirst in June and then in July. With their release, however, OpenAI is reestablishing itself as a presence for users of open models.



That‚Äôs particularly notable at a time when Meta, which had previously dominated the American open-model landscape with its Llama models, may be reorienting toward closed releases‚Äîand when Chinese open models, such as DeepSeek‚Äôs offerings, Kimi K2, and Alibaba‚Äôs Qwen series, are becoming more popular than their American competitors.





‚ÄúThe vast majority of our [enterprise and startup] customers are already using a lot of open models,‚Äù said Casey Dvorak, a research program manager at OpenAI, in a media briefing about the model release. ‚ÄúBecause there is no [competitive] open model from OpenAI, we wanted to plug that gap and actually allow them to use our technology across the board.‚Äù



The new models come in two different sizes, the smaller of which can theoretically run on 16 GB of RAM‚Äîthe minimum amount that Apple currently offers on its computers. The larger model requires a high-end laptop or specialized hardware.



Open models have a few key use cases. Some organizations may want to customize models for their own purposes or save money by running models on their own equipment, though that equipment comes at a substantial upfront cost. Others‚Äîsuch hospitals, law firms, and governments‚Äîmight need models that they can run locally for data security reasons.&nbsp;



OpenAI has facilitated such activity by releasing its open models under a permissive Apache 2.0 license, which allows the models to be used for commercial purposes. Nathan Lambert, post-training lead at the Allen Institute for AI, says that this choice is commendable: Such licenses are typical for Chinese open-model releases, but Meta released its Llama models under a bespoke, more restrictive license. ‚ÄúIt‚Äôs a very good thing for the open community,‚Äù he says.



Researchers who study how LLMs work also need open models, so that they can examine and manipulate those models in detail. ‚ÄúIn part, this is about reasserting OpenAI‚Äôs dominance in the research ecosystem,‚Äù says Peter Henderson, an assistant professor at Princeton University who has worked extensively with open models. If researchers do adopt gpt-oss as new workhorses, OpenAI could see some concrete benefits, Henderson says‚Äîit might adopt innovations discovered by other researchers into its own model ecosystem.



More broadly, Lambert says, releasing an open model now could help OpenAI reestablish its status in an increasingly crowded AI environment. ‚ÄúIt kind of goes back to years ago, where they were seen as the AI company,‚Äù he says. Users who want to use open models will now have the option to meet all their needs with OpenAI products, rather than turning to Meta‚Äôs Llama or Alibaba‚Äôs Qwen when they need to run something locally.



The rise of Chinese open models like Qwen over the past year may have been a particularly salient factor in OpenAI‚Äôs calculus. An employee from OpenAI emphasized at the media briefing that the company doesn‚Äôt see these open models as a response to actions taken by any other AI company, but OpenAI is clearly attuned to the geopolitical implications of China‚Äôs open-model dominance. ‚ÄúBroad access to these capable‚Ä¨‚Ä≠ open-weights models created in the US helps expand democratic AI rails,‚Äù the company wrote in a blog post announcing the models‚Äô release.&nbsp;



Since DeepSeek exploded onto the AI scene at the start of 2025, observers have noted that Chinese models often refuse to speak about topics that the Chinese Communist Party has deemed verboten, such as Tiananmen Square. Such observations‚Äîas well as longer-term risks, like the possibility that agentic models could purposefully write vulnerable code‚Äîhave made some AI experts concerned about the growing adoption of Chinese models. ‚ÄúOpen models are a form of soft power,‚Äù Henderson says.



Lambert released a report on Monday documenting how Chinese models are overtaking American offerings like Llama and advocating for a renewed commitment to domestic open models. Several prominent AI researchers and entrepreneurs, such as HuggingFace CEO Clement Delangue, Stanford‚Äôs Percy Liang, and former OpenAI researcher Miles Brundage, have signed on.



The Trump administration, too, has emphasized development of open models in its AI Action Plan. With both this model release and previous statements, OpenAI is aligning itself with that stance. ‚ÄúIn their filings about the action plan, [OpenAI] pretty clearly indicated that they see US‚ÄìChina as a key issue and want to position themselves as very important to the US system,‚Äù says Rishi Bommasani, a senior research scholar at the Stanford Institute for Human-Centered Artificial Intelligence.&nbsp;



And OpenAI may see concrete political advantages from aligning with the administration‚Äôs AI priorities, Lambert says. As the company continues to build out its extensive computational infrastructure, it will need political support and approvals, and sympathetic leadership could go a long way.
‚Ä¢ The Download: AI agent infrastructure, and OpenAI‚Äôs ambitions
  This is today&#8217;s edition of&nbsp;The Download,&nbsp;our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



These protocols will help AI agents navigate our messy lives



A growing number of companies are launching AI agents that can do things on your behalf‚Äîactions like sending an email, making a document, or editing a database. Initial reviews for these agents have been mixed at best, though, because they struggle to interact with all the different components of our digital lives.



Anthropic and Google are among the companies and groups working to fix that. Over the past year, they have both introduced protocols that try to define how AI agents should interact with each other and the world around them. If they work as planned, they could give us a crucial part of the infrastructure we need for agents to be useful.&nbsp;Read our&nbsp;story to learn more.&nbsp;



‚ÄîPeter Hall







A glimpse into OpenAI‚Äôs largest ambitions



‚ÄîJames O‚ÄôDonnell



OpenAI has given itself a dual mandate: on the one hand, it‚Äôs a tech giant rooted in products, including of course ChatGPT, which people around the world reportedly send 2.5 billion messages to each day. But its original mission is as a research lab that will not only create ‚Äúartificial general intelligence‚Äù but ensure that it benefits all of humanity.&nbsp;



My colleague Will Douglas Heaven recently sat down for an exclusive conversation with the two figures at OpenAI most responsible for the latter ambitions. The&nbsp;whole story is worth reading&nbsp;for all it reveals‚Äîabout how OpenAI thinks about the safety of its products, what AGI actually means, and more‚Äîbut here‚Äôs one thing that stood out to me.



This story is from The Algorithm, our weekly newsletter all about the latest goings-on in AI.&nbsp;Sign up&nbsp;to receive it in your inbox every Monday.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 OpenAI is adding mental health guardrails to ChatGPTIt‚Äôs set to give less direct advice, and encourage users to take breaks from lengthy chats. (NBC)+&nbsp;What happens when doctors fail to spot AI‚Äôs mistakes?&nbsp;(The Verge)+&nbsp;OpenAI has released its first research into how using ChatGPT affects people‚Äôs emotional well-being. (MIT Technology Review)2 The US wants to build a nuclear reactor on the moonAnd it hopes to do that before Russia and China, who are planning to do exactly the same. (Politico)+&nbsp;NASA‚Äôs latest mission to the moon just failed.&nbsp;(Engadget)+&nbsp;Nokia is putting the first cellular network on the moon. (MIT Technology Review)3 How to live forever (or at least get rich trying)&nbsp;Love them or hate them, the people behind the explosion in longevity research are a fascinating bunch. (New Yorker $)+&nbsp;Longevity clinics around the world are selling unproven treatments.&nbsp;(MIT Technology Review)4 Welcome to Silicon Valley‚Äôs ‚Äòhard tech‚Äô eraGoodbye, consumer software. Hello, massive military contracts. (NYT&nbsp;$)+&nbsp;Phase two of military AI has arrived.&nbsp;(MIT Technology Review)5 There‚Äôs a big problem with the Gulf‚Äôs trillion-dollar AI dreamBuilding data centers in a region that already has water scarcity issues seems&#8230;unwise. (Rest of Water)+&nbsp;There‚Äôs a data center boom in the US desert too.&nbsp;(MIT Technology Review)+&nbsp;Google has promised to scale back its energy usage during certain times to reduce stress on the grid.&nbsp;(Quartz&nbsp;$)6 Tesla‚Äôs board awarded about $30 billion of shares to Elon Musk‚ÄúRetaining Elon is more important than ever before,‚Äù they wrote in a letter to shareholders yesterday. (FT&nbsp;$)+&nbsp;Tech CEOs pay packets are reaching stratospheric new records.&nbsp;(WSJ&nbsp;$)7 What happens if you respond to those scam job texts?You get exploited, obviously‚Äîbut you‚Äôd be surprised just how weird it can get along the way. (Slate)



8 Why there‚Äôs so much uproar over Vogue‚Äôs AI-generated adIt‚Äôs the latest flashpoint in the war over when AI should (and shouldn‚Äôt) be used. (TechCrunch)



9 Earth‚Äôs core seems to be up and leaking out of Earth‚Äôs surface&nbsp;It‚Äôs a finding that‚Äôs forcing geoscientists to rethink some long-held assumptions. (Quanta&nbsp;$)+&nbsp;How a volcanic eruption turned a human brain into glass.&nbsp;(MIT Technology Review)10 Could lasers help us see inside people‚Äôs heads?It seems possible, but big hurdles remain to this new method being adopted in clinical settings. (IEEE Spectrum)



Quote of the day



¬†&#8220;Hate it! Don&#8217;t want anything to do with it.&#8221;



‚ÄîWeezy Simes, a 27-year-old florist, sums up her feelings about AI to¬†Business Insider.







One more thing



ANDREA D&#8217;AQUINO




What happened to the microfinance organization Kiva?



Since it was founded in 2005, the San Francisco-based nonprofit Kiva has helped everyday people make microloans to borrowers around the world. It connects lenders in richer communities to fund all sorts of entrepreneurs, from bakers in Mexico to farmers in Albania. Its overarching aim is helping poor people help themselves.



But back in August 2021, Kiva lenders started to notice that information that felt essential in deciding who to lend to was suddenly harder to find. Now, lenders are worried that the organization now seems more focused on how to make money than how to create change.&nbsp;Read the full story.



‚ÄîMara Kardas-Nelson







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ I want¬†this guy¬†to draw my portrait.¬†+ Highly recommend making¬†these¬†lemongrass chicken lettuce wraps. So tasty and easy!+ This¬†encyclopedia¬†teaches you about ancient gods and forgotten deities from around the world.+ Some of the¬†architecture in Iran¬†looks breathtakingly beautiful.
‚Ä¢ A glimpse into OpenAI‚Äôs largest ambitions
  OpenAI has given itself a dual mandate: to create AI that benefits all of humanity . Chief research officer Mark Chen and chief scientist Jakub Pachocki spoke with Will Douglas Heaven about the company's mission to create 'artificial general intelligence' The two figures at OpenAI most responsible for pursuing the latter ambitions say they're not interested in AI that outcompetes humans . Chen said he thought maybe it‚Äôs fine for AI to excel at math and coding, but the idea of having an AI acquire people skills is perhaps not .
‚Ä¢ These protocols will help AI agents navigate our messy lives
  A growing number of companies are launching AI agents that can do things on your behalf‚Äîactions like sending an email, making a document, or editing a database. Initial reviews for these agents have been mixed at best, though, because they struggle to interact with all the different components of our digital lives.



Part of the problem is that we are still building the necessary infrastructure to help agents navigate the world. If we want agents to complete tasks for us, we need to give them the necessary tools while also making sure they use that power responsibly.



Anthropic and Google are among the companies and groups working on exactly that. Over the past year, they have both introduced protocols that try to define how AI agents should interact with each other and the world around them. These protocols could make it easier for agents to control other programs like email clients and note-taking apps.&nbsp;



The reason has to do with application programming interfaces, the connections between computers or programs that govern much of our online world. APIs currently reply to ‚Äúpings‚Äù with standardized information. But AI models aren‚Äôt made to work exactly the same every time. The very randomness that helps them come across as conversational and expressive also makes it difficult for them to both call an API and understand the response.&nbsp;



‚ÄúModels speak a natural language,‚Äù says Theo Chu, a project manager at Anthropic. ‚ÄúFor [a model] to get context and do something with that context, there is a translation layer that has to happen for it to make sense to the model.‚Äù Chu works on one such translation technique, the Model Context Protocol (MCP), which Anthropic introduced at the end of last year.&nbsp;





MCP attempts to standardize how AI agents interact with the world via various programs, and it‚Äôs already very popular. One web aggregator for MCP servers (essentially, the portals for different programs or tools that agents can access) lists over 15,000 servers already.&nbsp;



Working out how to govern how AI agents interact with each other is arguably an even steeper challenge, and it‚Äôs one the Agent2Agent protocol (A2A), introduced by Google in April, tries to take on. Whereas MCP translates requests between words and code, A2A tries to moderate exchanges between agents, which is an ‚Äúessential next step for the industry to move beyond single-purpose agents,‚Äù Rao Surapaneni, who works with A2A at Google Cloud, wrote in an email to MIT Technology Review.&nbsp;



Google says 150 companies have already partnered with it to develop and adopt A2A, including Adobe and Salesforce. At a high level, both MCP and A2A tell an AI agent what it absolutely needs to do, what it should do, and what it should not do to ensure a safe interaction with other services. In a way, they are complementary‚Äîeach agent in an A2A interaction could individually be using MCP to fetch information the other asks for.&nbsp;



However, Chu stresses that it is ‚Äúdefinitely still early days‚Äù for MCP, and the A2A road map lists plenty of tasks still to be done. We‚Äôve identified the three main areas of growth for MCP, A2A, and other agent protocols: security, openness, and efficiency.







What should these protocols say about security?



Researchers and developers still don‚Äôt really understand how AI models work, and new vulnerabilities are being discovered all the time. For chatbot-style AI applications, malicious attacks can cause models to do all sorts of bad things, including regurgitating training data and spouting slurs. But for AI agents, which interact with the world on someone‚Äôs behalf, the possibilities are far riskier.&nbsp;



For example, one AI agent, made to read and send emails for someone, has already been shown to be vulnerable to what‚Äôs known as an indirect prompt injection attack. Essentially, an email could be written in a way that hijacks the AI model and causes it to malfunction. Then, if that agent has access to the user‚Äôs files, it could be instructed to send private documents to the attacker.&nbsp;



Some researchers believe that protocols like MCP should prevent agents from carrying out harmful actions like this. However, it does not at the moment. ‚ÄúBasically, it does not have any security design,‚Äù says Zhaorun Chen, a&nbsp; University of Chicago PhD student who works on AI agent security and uses MCP servers.&nbsp;



Bruce Schneier, a security researcher and activist, is skeptical that protocols like MCP will be able to do much to reduce the inherent risks that come with AI and is concerned that giving such technology more power will just give it more ability to cause harm in the real, physical world. ‚ÄúWe just don‚Äôt have good answers on how to secure this stuff,‚Äù says Schneier. ‚ÄúIt‚Äôs going to be a security cesspool really fast.‚Äù&nbsp;



Others are more hopeful. Security design could be added to MCP and A2A similar to the way it is for internet protocols like HTTPS (though the nature of attacks on AI systems is very different). And Chen and Anthropic believe that standardizing protocols like MCP and A2A can help make it easier to catch and resolve security issues even as is. Chen uses MCP in his research to test the roles different programs can play in attacks to better understand vulnerabilities. Chu at Anthropic believes that these tools could let cybersecurity companies more easily deal with attacks against agents, because it will be easier to unpack who sent what.&nbsp;







How open should these protocols be?



Although MCP and A2A are two of the most popular agent protocols available today, there are plenty of others in the works. Large companies like Cisco and IBM are working on their own protocols, and other groups have put forth different designs like Agora, designed by researchers at the University of Oxford, which upgrades an agent-service communication from human language to structured data in real time.



Many developers hope there could eventually be a registry of safe, trusted systems to navigate the proliferation of agents and tools. Others, including Chen, want users to be able to rate different services in something like a Yelp for AI agent tools. Some more niche protocols have even built blockchains on top of MCP and A2A so that servers can show they are not just spam.&nbsp;



Both MCP and A2A are open-source, which is common for would-be standards as it lets others work on building them. This can help protocols develop faster and more transparently.&nbsp;



‚ÄúIf we go build something together, we spend less time overall, because we‚Äôre not having to each reinvent the wheel,‚Äù says David Nalley, who leads developer experience at Amazon Web Services and works with a lot of open-source systems, including A2A and MCP.&nbsp;



Google donated A2A to the Linux Foundation, a nonprofit organization that guides open-source projects, back in June, and Amazon Web Services is now one of the collaborators on the project. With the foundation‚Äôs stewardship, the developers who work on A2A (including employees at Google and many others) all get a say in how it should evolve. MCP, on the other hand, is owned by Anthropic and licensed for free. That is a sticking point for some open-source advocates, who want others to have a say in how the code base itself is developed.¬†



‚ÄúThere‚Äôs admittedly some increased risk around a single person or a single entity being in absolute control,‚Äù says Nalley. He says most people would prefer multiple groups to have a ‚Äúseat at the table‚Äù to make sure that these protocols are serving everyone‚Äôs best interests.&nbsp;



However, Nalley does believe Anthropic is acting in good faith‚Äîits license, he says, is incredibly permissive, allowing other groups to create their own modified versions of the code (a process known as ‚Äúforking‚Äù).&nbsp;



‚ÄúSomeone could fork it if they needed to, if something went completely off the rails,‚Äù says Nalley. IBM‚Äôs Agent Communication Protocol was actually spun off of MCP.&nbsp;



Anthropic is still deciding exactly how to develop MCP. For now, it works with a steering committee of outside companies that help make decisions on MCP‚Äôs development, but Anthropic seems open to changing this approach. ‚ÄúWe are looking to evolve how we think about both ownership and governance in the future,‚Äù says Chu.







Is natural language fast enough?



MCP and A2A work on the agents‚Äô terms‚Äîthey use words and phrases (termed natural language in AI), just as AI models do when they are responding to a person. This is part of the selling point for these protocols, because it means the model doesn‚Äôt have to be trained to talk in a way that is unnatural to it. ‚ÄúAllowing a natural-language interface to be used between agents and not just with humans unlocks sharing the intelligence that is built into these agents,‚Äù says Surapaneni.



But this choice does come with drawbacks. Natural-language interfaces lack the precision of APIs, and that could result in incorrect responses. And it creates inefficiencies.&nbsp;





Usually, an AI model reads and responds to text by splitting words into tokens. The AI model will read a prompt, split it into input tokens, generate a response in the form of output tokens, and then put these tokens into words to send back. These tokens define in some sense how much work the AI model has to do‚Äîthat‚Äôs why most AI platforms charge users according to the number of tokens used.&nbsp;




But the whole point of working in tokens is so that people can understand the output‚Äîit‚Äôs usually faster and more efficient for machine-to-machine communication to just work over code. MCP and A2A both work in natural language, so they require the model to spend tokens as the agent talks to other machines, like tools and other agents. The user never even sees these exchanges‚Äîall the effort of making everything human-readable doesn‚Äôt ever get read by a human. ‚ÄúYou waste a lot of tokens if you want to use MCP,‚Äù says Chen.&nbsp;




Chen describes this process as potentially very costly. For example, suppose the user wants the agent to read a document and summarize it. If the agent uses another program to summarize here, it needs to read the document, write the document to the program, read back the summary, and write it back to the user. Since the agent needed to read and write everything, both the document and the summary get doubled up. According to Chen, ‚ÄúIt‚Äôs actually a lot of tokens.‚Äù



As with so many aspects of MCP and A2A‚Äôs designs, their benefits also create new challenges. ‚ÄúThere‚Äôs a long way to go if we want to scale up and actually make them useful,‚Äù says Chen.







Correction: This story was updated to clarify Nalley‚Äôs involvement with A2A.
‚Ä¢ The Download: fixing ‚Äòevil‚Äô AI, and the White House‚Äôs war on science
  This is today&#8217;s edition of&nbsp;The Download,&nbsp;our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Forcing LLMs to be evil during training can make them nicer in the long run



Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man‚Äîit endorsed harebrained business ideas, and even encouraged people to go off their psychiatric medication. More recently, xAI‚Äôs Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as ‚ÄúMechaHitler‚Äù on X.&nbsp;



Both changes were quickly reversed‚Äîbut why did they happen at all? And how do we stop AI going off the rails like this?&nbsp;



A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models‚Äîand turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&nbsp;Read the full story.&nbsp;



‚ÄîGrace Huckins



Read more of our top stories about AI:



+ Five things you need to know about AI&nbsp;right now.&nbsp;



+ Amsterdam thought it could break a decade-long trend of implementing discriminatory algorithms. Its failure raises the question: can AI programs ever be made fair?&nbsp;Read our story.&nbsp;



+ AI companies have&nbsp;stopped warning you&nbsp;that you shouldn‚Äôt rely on their chatbots for medical advice.&nbsp;



+ We‚Äôre starting to give AI agents real autonomy.&nbsp;But are they really ready for it?&nbsp;



+ What even is AI? Everyone thinks they know, but no one can agree.&nbsp;Here‚Äôs why that‚Äôs a problem.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 The US is losing its scientific supremacyMoney and talent are starting to leave as a hostile White House ramps up its attacks. (The Atlantic&nbsp;$)+&nbsp;The foundations of America‚Äôs prosperity are being dismantled. (MIT Technology Review)



2 Global markets are swooning again&nbsp;New tariffs, weak jobs data, and Trump‚Äôs decision to fire a top economic official are not going down well. (Reuters&nbsp;$)3 Big Tech is turning into Big InfrastructureCapital expenditure on AI contributed more to US economic growth in the last two quarters than all consumer spending, which is kind of wild. (WSJ&nbsp;$)+&nbsp;But are they likely to get a return on their huge investments?&nbsp;(FT&nbsp;$)4 OpenAI pulled a feature that let you see strangers‚Äô conversations with ChatGPT&nbsp;They‚Äôd opted in to sharing them‚Äîbut may well have not realized that‚Äôd mean their chats would be indexed on Google Search. (TechCrunch)&nbsp;5 Tesla has to pay $243 million over the role Autopilot played in a fatal crashThe plaintiffs successfully argued that the company‚Äôs promises about its tech can lull drivers into a false sense of security. (NBC)6 Tech workers in China are desperate to learn AI skillsAnd they‚Äôre assuaging their anxiety with online courses, though they say they vary in quality. (Rest of World)&nbsp;+&nbsp;Chinese universities want students to use more AI, not less.&nbsp;(MIT Technology Review)7 Russia is escalating its crackdown on online freedoms&nbsp;There are growing fears that it‚Äôs planning to ban WhatsApp and Telegram. (NYT&nbsp;$)



8 People are using AI to write obituariesBut what do we lose when we outsource expressing our emotions to a machine? (WP&nbsp;$)+&nbsp;Deepfakes of your dead loved ones are a booming Chinese business.&nbsp;(MIT Technology Review)9 Just&nbsp;seeing&nbsp;a sick person triggers your immune responseThis is a pretty cool finding ‚Äîand the study was conducted in virtual reality too. (Nature)



10 The US has recorded the longest lightning flash ever&nbsp;A ‚Äúmega-flash‚Äù over the Great Plains stretched to about 515 miles! (New Scientist&nbsp;$)







Quote of the day



‚ÄúApple must do this. Apple will do this. This is sort of ours to grab.‚Äù



¬†‚ÄîDuring an hour-long pep talk, Apple CEO Tim Cook tells staff he‚Äôs playing the long game on AI with an ‚Äúamazing‚Äù pipeline of products on the way,¬†Bloomberg¬†reports.







One more thing



MICHAEL BYERS




Think that your plastic is being recycled? Think again.



The problem of plastic waste hides in plain sight, a ubiquitous part of our lives we rarely question. But a closer examination of the situation is shocking.To date, humans have created around 11 billion metric tons of plastic, the vast majority of which ends up in landfills or the environment. Only 9% of the plastic ever produced has been recycled.To make matters worse, plastic production is growing dramatically; in fact, half of all plastics in existence have been produced in just the last two decades.So what do we do? Sadly, solutions such as recycling and reuse aren&#8217;t equal to the scale of the task. The only answer is drastic cuts in production in the first place.&nbsp;Read the full story.&nbsp;



‚ÄîDouglas Main







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ The new¬†Alien¬†TV series sounds fantastic.+ A 500km-long¬†Indigenous pilgrimage route¬†through Mexico has been added to the Unesco World Heritage list.+ The Danish National Symphony Orchestra playing the¬†Blade Runner score¬†is quite something.+ It‚Äôs not too late to spice up your summer with an¬†icebox cake.

üîí Cybersecurity & Privacy
No updates.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Project Ire autonomously identifies malware at scale
  Today, we are excited to introduce an autonomous AI agent that can analyze and classify software without assistance, a step forward in cybersecurity and malware detection. The prototype, Project Ire, automates what is considered the gold standard in malware classification: fully reverse engineering a software file without any clues about its origin or purpose. It uses decompilers and other tools, reviews their output, and determines whether the software is malicious or benign.



Project Ire&nbsp;emerged&nbsp;from a collaboration&nbsp;between&nbsp;Microsoft Research, Microsoft Defender Research, and Microsoft Discovery & Quantum, bringing together security&nbsp;expertise, operational knowledge, data from global malware telemetry, and AI research. It is built on the same collaborative and agentic foundation behind&nbsp;GraphRAG (opens in new tab)&nbsp;and&nbsp;Microsoft Discovery (opens in new tab).&nbsp;The system&nbsp;uses advanced language models and a suite of callable reverse engineering and binary analysis tools to drive investigation and adjudication.



As of this writing, Project Ire has achieved a precision (opens in new tab) of 0.98 and a recall (opens in new tab) of 0.83 using public datasets of Windows drivers. It was the first reverse engineer at Microsoft, human or machine, to author a conviction case‚Äîa detection strong enough to justify automatic blocking‚Äîfor a specific advanced persistent threat (APT) malware sample, which has since been identified and blocked by Microsoft Defender.&nbsp;



Malware classification at a global scale



Microsoft‚Äôs Defender platform scans more than one billion monthly (opens in new tab) active devices through the company‚Äôs Defender suite of products, which routinely require manual review of software by experts.



This kind of work is challenging. Analysts often face error and alert fatigue, and there‚Äôs no easy way to compare and standardize how different people review and classify threats over time. For both of these reasons, today&#8217;s overloaded experts are vulnerable to burnout, a well-documented issue in the field.



Unlike other AI applications in security, malware classification lacks a computable validator (opens in new tab). The AI must make judgment calls without definitive validation beyond expert review. Many behaviors found in software, like reverse engineering protections, don‚Äôt clearly indicate whether a sample is malicious or benign.&nbsp;



This ambiguity requires analysts to investigate each sample incrementally, building enough evidence to determine whether it‚Äôs malicious or benign despite opposition from adaptive, active adversaries. This&nbsp;has long made it difficult to automate and scale what is inherently a complex and expensive process.



Technical foundation



Project Ire attempts to address these challenges by acting as an autonomous system that uses specialized tools to reverse engineer software. The system‚Äôs architecture allows for reasoning at multiple levels, from low-level binary analysis to control flow reconstruction and high-level interpretation of code behavior.



Its tool-use API enables the system to update its understanding of a file using a wide range of reverse engineering tools, including Microsoft memory analysis sandboxes based on Project Freta (opens in new tab), custom and open-source tools, documentation search, and multiple decompilers.&nbsp;&nbsp;



Reaching a verdict&nbsp;



The evaluation process begins with a triage, where automated reverse engineering tools identify the file type, its structure, and potential areas of interest. From there, the system reconstructs the software‚Äôs control flow graph using frameworks such as angr (opens in new tab) and Ghidra (opens in new tab), building a graph that forms the backbone of Project Ire‚Äôs memory model and guides the rest of the analysis.&nbsp;&nbsp;



Through iterative function analysis, the LLM calls specialized tools through an API to identify and summarize key functions. Each result feeds into a ‚Äúchain of evidence,‚Äù a detailed, auditable trail that shows how the system reached its conclusion. This traceable evidence log supports secondary review by security teams and helps refine the system in cases of misclassification.&nbsp;&nbsp;



To verify its findings, Project Ire can invoke a validator tool that cross-checks claims in the report against the chain of evidence. This tool draws on expert statements from malware reverse engineers on the Project Ire team. Drawing on this evidence and its internal model, the system creates a final report and classifies the sample as malicious or benign.



	
		

	
	
						
				
					
				
			
			
			

									Azure AI Foundry Labs
				
								Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.
				
								
					
						
							Azure AI Foundry						
					
				
							
	
Opens in a new tab	
	


Preliminary testing shows promise&nbsp;



Two early evaluations tested Project Ire‚Äôs effectiveness as an autonomous malware classifier. In the first, we assessed Project Ire on a dataset of publicly accessible Windows drivers, some known to be malicious, others benign. Malicious samples came from the Living off the Land Drivers (opens in new tab) database, which includes a collection of Windows drivers used by attackers to bypass security controls, while known benign drivers were sourced from Windows Update.&nbsp;



This classifier performed well, correctly identifying 90% of all files and flagging only 2% of benign files as threats. It achieved a precision of 0.98 and a recall of 0.83. This low false-positive rate suggests clear potential for deployment in security operations, alongside expert reverse engineering reviews.&nbsp;



For each file it analyzes, Project Ire generates a report that includes an evidence section, summaries of all examined code functions, and other technical artifacts.&nbsp;&nbsp;



Figures 1 and 2 present reports for two successful malware classification cases generated during testing. The first involves a kernel-level rootkit, Trojan:Win64/Rootkit.EH!MTB (opens in new tab). The system identified several key features, including jump-hooking, process termination, and web-based command and control. It then correctly flagged the sample as malicious.






  
  Figure 1 Analysis
  


  
    The binary contains a function named &#8216;MonitorAndTerminateExplorerThread_16f64&#8217; that runs an infinite loop waiting on synchronization objects and terminates system threads upon certain conditions. It queries system or process information, iterates over processes comparing their names case-insensitively to &#8216;Explorer.exe&#8217;, and manipulates registry values related to &#8216;Explorer.exe&#8217;. This function appears to monitor and potentially terminate or manipulate the &#8216;Explorer.exe&#8217; process, a critical Windows shell process. Such behavior is suspicious and consistent with malware that aims to disrupt or control system processes.
    Another function, &#8216;HttpGetRequestAndResponse_174a4&#8217;, performs HTTP GET requests by parsing URLs, resolving hostnames, opening sockets, sending requests, and reading responses. This network communication capability could be leveraged for command and control or data exfiltration, common in malware.
    The binary also includes a function &#8216;PatchProcessEntryPointWithHook_12b5c&#8217; that patches the entry point of a process by writing a hook or trampoline that redirects execution to a specified address. This technique is commonly used for process injection or hooking, allowing malware to alter process behavior or inject malicious code.
    Other functions related to sending IOCTL requests to device drivers were identified, but their maliciousness could not be conclusively determined without additional context.
    Overall, the binary exhibits multiple indicators of malicious behavior, including process manipulation, network communication, and code injection techniques, suggesting it is likely malware designed to interfere with system processes and communicate with remote servers.
  


Figure 1. Project Ire report, sample with SHA256: 86047bb1969d1db455493955fd450d18c62a3f36294d0a6c3732c88dfbcc4f62 (opens in new tab)



The second sample, HackTool:Win64/KillAV!MTB (opens in new tab), was designed to disable antivirus software. Project Ire correctly identified the code that locates and disables antivirus programs, providing evidence that the file was malicious.&nbsp;&nbsp;



In one section of the code, however, the system misidentified a function as anti-debugging behavior. To maintain accuracy, the system used the validator tool to flag the claim as unsupported. The issue was later resolved by updating decompiler rules, but this example illustrates how Project Ire navigates uncertainty during analysis. Figure 2 shows the corresponding report.&nbsp;






  
  Figure 2 Analysis
  


  
    The binary contains several functions indicative of malicious intent. The function register_and_log_known_processes_140001000 logs and registers process names associated with antivirus and security software, such as &#8216;avp.exe&#8217;, &#8216;avpui.exe&#8217;, and &#8216;360Tray.exe&#8217;. It calls another function, TerminateProcessesByNameSubstring_1400010f4, which enumerates system processes and terminates those whose names contain specified substrings. This behavior is typical of malware attempting to disable or evade security software by killing their processes.
    Another function, check_and_handle_special_state_14000502c, performs checks on a global variable and triggers software interrupts if certain conditions are not met. While the exact purpose of these interrupts (int 0x29 and int 0x3) is unclear, they could represent an anti-debug or anti-analysis mechanism to detect or interfere with debugging or tampering attempts. However, this assumption could not be fully validated against expert statements.
    Other functions include initialization routines and simple logging wrappers, but the core malicious behavior centers on process termination targeting security software. This indicates the binary is designed to compromise system security by disabling protective processes, a hallmark of malware such as trojans or rootkits.
  


Figure 2. Project Ire report, sample with SHA256: b6cb163089f665c05d607a465f1b6272cdd5c949772ab9ce7227120cf61f971a (opens in new tab)



Real-world evaluation with Microsoft Defender&nbsp;



The more demanding test involved nearly 4,000 ‚Äúhard-target‚Äù files not classified by automated systems and slated for manual review by expert reverse engineers.



In this real-world scenario, Project Ire operated fully autonomously on files created after the language models‚Äô training cutoff, files that no other automated tools at Microsoft could classify at the time.



The system achieved a high precision score of 0.89, meaning nearly 9 out of 10 files flagged malicious were correctly identified as malicious. Recall was 0.26, indicating that under these challenging conditions, the system detected roughly a quarter of all actual malware.



The system correctly identified many of the malicious files, with few false alarms, just a 4% false positive rate. While overall performance was moderate, this combination of accuracy and a low error rate suggests real potential for future deployment.



Looking ahead&nbsp;



Based on these early successes, the Project Ire prototype will be leveraged inside Microsoft‚Äôs Defender organization as Binary Analyzer for threat detection and software classification.



Our goal is to scale the system‚Äôs speed and accuracy so that it can correctly classify files from any source, even on first encounter. Ultimately, our vision is to detect novel malware directly in memory, at scale.



Acknowledgements&nbsp;



Project Ire acknowledges the following additional developers that contributed to the results in this publication: Dayenne de Souza, Raghav Pande, Ryan Terry, Shauharda Khadka, and Bob Fleck for their independent review of the system.



The system incorporates multiple tools, including the&nbsp;angr&nbsp;framework developed by&nbsp;Emotion Labs (opens in new tab). Microsoft has collaborated extensively with Emotion Labs, a pioneer in cyber autonomy, throughout the development of Project Ire, and thanks them for the innovations and insights that contributed to the successes reported here.&nbsp;
Opens in a new tabThe post Project Ire autonomously identifies malware at scale appeared first on Microsoft Research.
‚Ä¢ VeriTrail: Detecting hallucination and tracing provenance in multi-step AI workflows
  Watch VeriTrail Explainer




Many applications of language models (LMs) involve generating content based on source material, such as answering questions, summarizing information, and drafting documents. A critical challenge for these applications is that LMs may produce content that is not supported by the source text ‚Äì a phenomenon known as ‚Äúclosed-domain hallucination.‚Äù1



Existing methods for detecting closed-domain hallucination typically compare a given LM output to the source text, implicitly assuming that there is only a single output to evaluate. However, applications of LMs increasingly involve processes with multiple generative steps: LMs generate intermediate outputs that serve as inputs to subsequent steps and culminate in a final output. Many agentic workflows follow this paradigm (e.g., each agent is responsible for a specific document or sub-task, and their outputs are synthesized into a final response).‚ÄØ&nbsp;



In our paper ‚ÄúVeriTrail: Closed-Domain Hallucination Detection with Traceability,‚Äù we argue that, given the complexity of processes with multiple generative steps, detecting hallucination in the final output is necessary but not sufficient. We also need traceability, which has two components:&nbsp;




Provenance: if the final output is supported by the source text, we should be able to trace its path through the intermediate outputs to the source.&nbsp;



Error Localization: if the final output is not supported by the source text, we should be able to trace where the error was likely introduced.




Our paper presents VeriTrail, the first closed-domain hallucination detection method designed to provide traceability for processes with any number of generative steps. We also demonstrate that VeriTrail outperforms baseline methods commonly used for hallucination detection. In this blog post, we provide an overview of VeriTrail‚Äôs design and performance.2



VeriTrail‚Äôs hallucination detection process



A key idea leveraged by VeriTrail is that a wide range of generative processes can be represented as a directed acyclic graph (DAG). Each node in the DAG represents a piece of text (i.e., source material, an intermediate output, or the final output) and each edge from node A to node B indicates that A was used as an input to produce B. Each node is assigned a unique ID, as well as a stage reflecting its position in the generative process.‚ÄØ&nbsp;



An example of a process with multiple generative steps is GraphRAG. A DAG representing a GraphRAG run is illustrated in Figure 1, where the boxes and arrows correspond to nodes and edges, respectively.3



Figure 1: GraphRAG splits the source text into chunks (Stage 1). For each chunk, an LM extracts entities and relationships (the latter are denoted by ‚Äú‚≠§ ‚Äú), along with short descriptions (Stage 2). If an entity or a relationship was extracted from multiple chunks, an LM summarizes the descriptions (Stage 3). A knowledge graph is constructed from the final set of entities and relationships, and a community detection algorithm, such as Leiden clustering, groups entities into communities. For each community, an LM generates a ‚Äúcommunity report‚Äù that summarizes the entities and relationships (Stage 4). To answer a user‚Äôs question, an LM generates ‚Äúmap-level answers‚Äù based on groups of community reports (Stage 5), then synthesizes them into a final answer (Stage 6).



VeriTrail takes as input a DAG representing a completed generative process and aims to determine whether the final output is fully supported by the source text. It begins by extracting claims (i.e., self-contained, verifiable statements) from the final output using Claimify. VeriTrail verifies claims in the reverse order of the generative process: it starts from the final output and moves toward the source text. Each claim is verified separately. Below, we include two case studies that illustrate how VeriTrail works, using the DAG from Figure 1.‚ÄØ



Case study 1: A ‚ÄúFully Supported‚Äù claim



Figure 2: Left: GraphRAG as a DAG. Right: VeriTrail‚Äôs hallucination detection process for a ‚ÄúFully Supported‚Äù claim.



Figure 2 shows an example of a claim that VeriTrail determined was not hallucinated:‚ÄØ




In Iteration 1, VeriTrail identified the nodes that were used as inputs for the final answer: Nodes 15 and 16. Each identified node was split into sentences, and each sentence was programmatically assigned a unique ID.

An LM then performed Evidence Selection, selecting all sentence IDs that strongly implied the truth or falsehood of the claim. The LM also generated a summary of the selected sentences (not shown in Figure 2). In this example, a sentence was selected from Node 15.



Next, an LM performed Verdict Generation. If no sentences had been selected in the Evidence Selection step, the claim would have been assigned a ‚ÄúNot Fully Supported‚Äù verdict. Instead, an LM was prompted to classify the claim as ‚ÄúFully Supported,‚Äù ‚ÄúNot Fully Supported,‚Äù or ‚ÄúInconclusive‚Äù based on the evidence. In this case, the verdict was ‚ÄúFully Supported.‚Äù





Since the verdict in Iteration 1 was ‚ÄúFully Supported,‚Äù VeriTrail proceeded to Iteration 2. It considered the nodes from which at least one sentence was selected in the latest Evidence Selection step (Node 15) and identified their input nodes (Nodes 12 and 13). VeriTrail repeated Evidence Selection and Verdict Generation for the identified nodes. Once again, the verdict was ‚ÄúFully Supported.‚Äù This process ‚Äì identifying candidate nodes, performing Evidence Selection and Verdict Generation ‚Äì was repeated in Iteration 3, where the verdict was still ‚ÄúFully Supported,‚Äù and likewise in Iteration 4.‚ÄØ



In Iteration 4, a single source text chunk was verified. Since the source text, by definition, does not have any inputs, verification terminated and the verdict was deemed final.




Case study 2: A ‚ÄúNot Fully Supported‚Äù claim



Figure 3: Left: GraphRAG as a DAG. Right: VeriTrail‚Äôs hallucination detection‚ÄØprocess for a ‚ÄúNot Fully Supported‚Äù claim, where the maximum number of consecutive ‚ÄúNot Fully Supported‚Äù verdicts was set to 2. 



Figure 3 provides an example of a claim where VeriTrail identified hallucination:




In Iteration 1, VeriTrail identified the nodes used as inputs for the final answer: Nodes 15 and 16. After Evidence Selection and Verdict Generation, the verdict was ‚ÄúNot Fully Supported.‚Äù Users can configure the maximum number of consecutive ‚ÄúNot Fully Supported‚Äù verdicts permitted. If the maximum had been set to 1, verification would have terminated here, and the verdict would have been deemed final. Let‚Äôs assume the maximum was set to 2, meaning that VeriTrail had to perform at least one more iteration.



Even though evidence was selected only from Node 15 in Iteration 1, VeriTrail checked the input nodes for both Node 15 and Node 16 (i.e., Nodes 12, 13, and 14) in Iteration 2. Recall that in Case Study 1 where the verdict was ‚ÄúFully Supported,‚Äù VeriTrail only checked the input nodes for Node 15. Why was the ‚ÄúNot Fully Supported‚Äù claim handled differently? If the Evidence Selection step overlooked relevant evidence, the ‚ÄúNot Fully Supported‚Äù verdict might be incorrect. In this case, continuing verification based solely on the selected evidence (i.e., Node 15) would propagate the mistake, defeating the purpose of repeated verification.



In Iteration 2, Evidence Selection and Verdict Generation were repeated for Nodes 12, 13, and 14. Once again, the verdict was ‚ÄúNot Fully Supported.‚Äù Since this was the second consecutive ‚ÄúNot Fully Supported‚Äù verdict, verification terminated and the verdict was deemed final.




	
		

		
		PODCAST SERIES
	
	
	
						
				
					
				
			
			
			

									The AI Revolution in Medicine, Revisited
				
								Join Microsoft‚Äôs Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.
				
								
					
						
							Listen now						
					
				
							
	
Opens in a new tab	
	


Providing traceability



In addition to assigning a final ‚ÄúFully Supported,‚Äù ‚ÄúNot Fully Supported,‚Äù or ‚ÄúInconclusive‚Äù verdict to each claim, VeriTrail returns (a) all Verdict Generation results and (b) an evidence trail composed of all Evidence Selection results: the selected sentences, their corresponding node IDs, and the generated summaries. Collectively, these outputs provide traceability:&nbsp;




Provenance: For ‚ÄúFully Supported‚Äù and ‚ÄúInconclusive‚Äù claims, the evidence trail traces a path from the source material to the final output, helping users understand how the output may have been derived. For example, in Case Study 1, the evidence trail consists of Sentence 8 from Node 15, Sentence 11 from Node 13, Sentence 26 from Node 4, and Sentence 79 from Node 1.



Error Localization: For ‚ÄúNot Fully Supported‚Äù claims, VeriTrail uses the Verdict Generation results to identify the stage(s) of the process where the unsupported content was likely introduced. For instance, in Case Study 2, where none of the verified intermediate outputs supported the claim, VeriTrail would indicate that the hallucination occurred in the final answer (Stage 6). Error stage identification helps users address hallucinations and understand where in the process they are most likely to occur.&nbsp;




The evidence trail also helps users verify the verdict: instead of reading through all nodes ‚Äì which may be infeasible for processes that generate large amounts of text ‚Äì users can simply review the evidence sentences and summaries.‚ÄØ



Key design features



VeriTrail‚Äôs design prioritizes reliability, efficiency, scalability, and user agency. Notable features include:‚ÄØ




During Evidence Selection (introduced in Case Study 1), the sentence IDs returned by the LM are checked against the programmatically assigned IDs. If a returned ID does not match an assigned ID, it is discarded; otherwise, it is mapped to its corresponding sentence. This approach guarantees that the sentences included in the evidence trail are not hallucinated.



After a claim is assigned an interim ‚ÄúFully Supported‚Äù or ‚ÄúInconclusive‚Äù verdict (as in Case Study 1), VeriTrail verifies the input nodes of only the nodes from which evidence was previously selected ‚Äì not all possible input nodes. By progressively narrowing the search space, VeriTrail limits the number of nodes the LM must evaluate. In particular, since VeriTrail starts from the final output and moves toward the source text, it tends to verify a smaller proportion of nodes as it approaches the source text. Nodes closer to the source text tend to be larger (e.g., a book chapter should be larger than its summary), so verifying fewer of them helps reduce computational cost.



VeriTrail is designed to handle input graphs with any number of nodes, regardless of whether they fit in a single prompt. Users can specify an input size limit per prompt. For Evidence Selection, inputs that exceed the limit are split across multiple prompts. If the resulting evidence exceeds the input size limit for Verdict Generation, VeriTrail reruns Evidence Selection to compress the evidence further. Users can configure the maximum number of Evidence Selection reruns.‚ÄØ‚ÄØ



The configurable maximum number of consecutive ‚ÄúNot Fully Supported‚Äù verdicts (introduced in Case Study 2) allows the user to find their desired balance between computational cost and how conservative VeriTrail is in flagging hallucinations. A lower maximum reduces cost by limiting the number of checks. A higher maximum increases confidence that a flagged claim is truly hallucinated since it requires repeated confirmation of the ‚ÄúNot Fully Supported‚Äù verdict.‚ÄØ




Evaluating VeriTrail‚Äôs performance



We tested VeriTrail on two datasets covering distinct generative processes (hierarchical summarization4 and GraphRAG), tasks (summarization and question-answering), and types of source material (fiction novels and news articles). For the source material, we focused on long documents and large collections of documents (i.e., >100K tokens), where hallucination detection is especially challenging and processes with multiple generative steps are typically most valuable. The resulting DAGs were much more complex than the examples provided above (e.g., in one of the datasets, the average number of nodes was 114,368).



We compared VeriTrail to three types of baseline methods commonly used for closed-domain hallucination detection: Natural Language Inference models (AlignScore and INFUSE); Retrieval-Augmented Generation; and long-context models (Gemini 1.5 Pro and GPT-4.1 mini). Across both datasets and all language models tested, VeriTrail outperformed the baseline methods in detecting hallucination.5



Most importantly, VeriTrail traces claims through intermediate outputs ‚Äì unlike the baseline methods, which directly compare the final output to the source material. As a result, it can identify where hallucinated content was likely introduced and how faithful content may have been derived from the source. By providing traceability, VeriTrail brings transparency to generative processes, helping users understand, verify, debug, and, ultimately, trust their outputs.‚ÄØ&nbsp;



For an in-depth discussion of VeriTrail, please see our paper ‚ÄúVeriTrail: Closed-Domain Hallucination Detection with Traceability.‚Äù







1 (opens in new tab) The term ‚Äúclosed-domain hallucination‚Äù was introduced by OpenAI in the GPT-4 Technical Report (opens in new tab).



2 VeriTrail is currently used for research purposes only and is not available commercially.



3 We focus on GraphRAG‚Äôs global search method.



4 (opens in new tab) In hierarchical summarization, an LM summarizes each source text chunk individually, then the resulting summaries are repeatedly grouped and summarized until a final summary is produced (Wu et al., 2021 (opens in new tab); Chang et al., 2023 (opens in new tab)).



5 The only exception was the mistral-large-2411 model, where VeriTrail had the highest balanced accuracy, but not the highest macro F1 score.
Opens in a new tabThe post VeriTrail: Detecting hallucination and tracing provenance in multi-step AI workflows appeared first on Microsoft Research.
‚Ä¢ Build an AI assistant using Amazon Q Business with Amazon S3 clickable URLs
  Organizations need user-friendly ways to build AI assistants that can reference enterprise documents while maintaining document security. This post shows how to use Amazon Q Business to create an AI assistant that provides clickable URLs to source documents stored in Amazon Simple Storage Service (Amazon S3), to support secure document access and verification. Amazon Q Business is a generative AI-powered conversational assistant that answers questions and completes tasks based on the information in your enterprise systems and enhances workforce productivity. 
In this post, we demonstrate how to build an AI assistant using Amazon Q Business that responds to user requests based on your enterprise documents stored in an S3 bucket, and how the users can use the reference URLs in the AI assistant responses to view or download the referred documents, and verify the AI responses to practice responsible AI. You can follow the instructions in this post to build an AI assistant either using the provided sample dataset or your own dataset, and interact with it using the Amazon Q Business web experience and API. 
Solution overview 
You can build a secure AI assistant for your employees where the AI responses are based on a set of enterprise documents. You store the documents in an S3 bucket and configure the S3 bucket as a data source, or upload the files directly to your Amazon Q Business application from the Amazon Q Business console. Authenticated users subscribed to the Amazon Q Business application can interact with your AI assistant using the Amazon Q Business web experience from their web browsers or with a custom application built by your organization. The Amazon Q Business powered AI assistant provides source attributions to each response with clickable URLs pointing to the documents from which the response is generated. The users can use the URLs to access the reference documents securely, to get more information and practice responsible AI, without requiring the credentials to the S3 bucket where the documents are stored, and the Amazon Q Business application validates the authorization of the authenticated user accessing URL before letting the user view or download a document. 
The following diagram shows the internal workings of Amazon S3 clickable URLs, including how the document contents are staged in an S3 bucket during ingestion, and how the workflow of the GetDocumentContent API lets the user securely view or download the document using the URL links. 
 
An S3 bucket containing the enterprise documents to be used by the AI assistant is configured as a data source for an Amazon Q Business application. When the data source is synchronized for the first time, the Amazon Q Business S3 connector crawls the customer‚Äôs bucket and ingests the documents, along with their metadata and access control lists (ACLs). During ingestion, the content of each document is stored by Amazon Q Business in a staging S3 bucket in the Amazon Q Business service account. The text extracted from the document, along with the metadata and ACLs, are ingested in an Amazon Q Business index. On subsequent data source sync operations, documents that have changed or are newly added to the customer‚Äôs S3 bucket are reingested, their contents are added or updated in the staging bucket, and the contents of the documents deleted from the customer‚Äôs S3 bucket are deleted from the staging bucket.When you upload the files directly, the files are processed in a similar way, by storing the document content in the staging bucket and ingesting the extracted text and metadata in the index. 
When an authenticated user asks a question or writes a prompt to the AI assistant using the Amazon Q Business web experience or a customer developed application, the UI layer of the application invokes the Chat or ChatSync API. The response to the API includes the source attributions, source reference URLs, and passages from the indexed document that were used as context for the underlying large language model (LLM) to generate the response to the user‚Äôs query. When the user chooses a reference URL pointing to a document ingested using the Amazon S3 data source or files uploaded directly, the UI layer is required to invoke the GetDocumentContent API (labeled 1 in the preceding diagram) to obtain the contents of the document to be displayed or downloaded. Chat, ChatSync, and GetDocumentContent APIs can only be invoked using identity-aware credentials of the authenticated user. 
Upon receiving the GetDocumentContent API, Amazon Q Business uses the user identity from the identity-aware credentials, retrieves the ACLs for the document being requested, and validates that the user is authorized to access that document. On successful validation, it generates a pre-signed URL for the document content object stored in the staging bucket, and returns it to the UI in response to the GetDocumentContent API call (labeled 3 in the preceding diagram). If the authorization validation fails, an error is returned (labeled 2 in the preceding diagram). 
The UI layer can then use the pre-signed URL to display the document content in the web browser or download it to the user‚Äôs local computer. Requiring identity-aware credentials and authorization validation makes sure only authenticated users authorized to access the document can view or download the document content. The validity of the pre-signed URL is restricted to 5 minutes. After the pre-signed URL is made available to the user and the document content is downloaded, Amazon Q Business or AWS does not have control of the pre-signed URL, as well as the document content, and following the shared security responsibility model, it is the customer‚Äôs responsibility to secure the document further. 
To get a hands-on experience of Amazon S3 clickable URLs, follow the instructions in this post to create an AI assistant using an Amazon Q Business application, with an S3 bucket configured as a data source, and upload some files to the data source. You can use the provided sample data SampleData.zip or choose a few documents of your choice. You can then use the Amazon Q Business web experience to ask a few questions about the data you ingested, and use the source reference URLs from the responses to your questions to view or download the referenced documents and validate the responses you got from the AI assistant. We also show how to use the AWS Command Line Interface (AWS CLI) to use the Amazon S3 clickable URLs feature with the Amazon Q Business API. 
Considerations for using Amazon S3 clickable URLs 
Consider the following when using Amazon S3 clickable URLs: 
 
 At the time of writing, the Amazon S3 clickable URLs feature is available on Amazon Q Business applications using AWS IAM Identity Center or IAM federation for user access management, and not available for Amazon Q Business applications created using anonymous mode. 
 If you already use an Amazon S3 data source for your Amazon Q Business application, you must perform a full sync of the data source for the Amazon S3 clickable URLs feature to be available to your users. 
 If you already use an Amazon Q Business web experience for your users to interact with your AI assistant, you must add the following permissions to the AWS Identity and Access Management (IAM) role for the Amazon Q Business web experience: 
 
 
 {
&nbsp;&nbsp; &nbsp; &nbsp;"Sid": "QBusinessGetDocumentContentPermission",
&nbsp;&nbsp; &nbsp; &nbsp;"Effect": "Allow",
&nbsp;&nbsp; &nbsp; &nbsp;"Action": ["qbusiness:GetDocumentContent"],
&nbsp;&nbsp; &nbsp; &nbsp;"Resource": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"arn:aws:qbusiness:{{region}}:{{source_account}}:application/{{application_id}}",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"arn:aws:qbusiness:{{region}}:{{source_account}}:application/{{application_id}}/index/*"
&nbsp;&nbsp; &nbsp; &nbsp;]
} 
 
Prerequisites 
To deploy the solution using the instructions in this post in your own AWS account, make sure that you have the following: 
 
 An AWS account 
 Amazon S3 and AWS IAM Identity Center permissions 
 Privileges to create an Amazon Q application, AWS resources, and IAM roles and policies 
 Basic knowledge of AWS services and the AWS CLI 
 Follow the steps for Setting up for Amazon Q Business if you‚Äôre using Amazon Q Business for the first time 
 
Create your S3 bucket and upload data 
Choose an AWS Region where Amazon Q Business is available, keeping in mind that you must create all the AWS resources in this example in this Region. If you already have an S3 bucket with a few documents uploaded, you can use it for this exercise. Otherwise, for instructions to prepare an S3 bucket as a data source, refer to Creating a general purpose bucket. Download and unzip SampleData.zip to your local computer. Open the S3 bucket you created on the Amazon S3 console and upload the contents of the ACME Project Space, HR Data, and IT Help folders to the S3 bucket. 
 
The following screenshot shows the list of uploaded files. 
 
Create an Amazon Q Business application 
Depending on your choice of user access management method, create an IAM Identity Center integrated Amazon Q Business application or an IAM federated Amazon Q Business application. At the time of writing, Amazon S3 clickable URLs are not available for Amazon Q Business applications with anonymous access. 
To create an IAM Identity Center integrated Amazon Q Business application, complete the following steps: 
 
 On the Amazon Q Business console, choose Applications in the navigation pane. 
 Choose Create application. 
 For Application name, enter a unique name or use the automatically generated name. 
 For User access, select Authenticated access. 
 For Outcome, select Web experience. 
 
 
 
 For Access management method, select AWS IAM Identity Center. 
 
If IAM Identity Center is correctly configured either in your account or in the AWS Organization to which your account belongs, and is in the same Region, you will see a message about the application being connected to the IAM Identity Center instance. 
 
 Choose the users who will have access to this application and their subscription tiers. For this post, both Q Business Pro and Q Business Lite subscription tiers will work. 
 Choose Create. 
 
 
Create an index 
In preparation to configure data sources, you must first create an index. Complete the following steps: 
 
 On the Amazon Q Business console, choose Applications in the navigation pane. 
 Open your application. 
 Under Enhancements in the navigation pane, choose Data sources. 
 Choose Add an index. 
 
 
 
 Select create a new index. 
 For Index name, keep the automatically generated name. 
 For Index provisioning, select your preferred provisioning method. For this post, either Enterprise or Starter will work. 
 Leave Number of units as 1. 
 Choose Add an index. 
 
The creation process takes a few minutes to complete. 
 
Create data sources 
To configure your Amazon S3 data source, complete the following steps. For more details, refer to Connecting Amazon Q Business to Amazon S3 using the console. 
 
 On the Amazon Q Business console, choose Applications in the navigation pane. 
 Open your application. 
 Under Enhancements in the navigation pane, choose Data sources. 
 Choose Add data source. 
 
 
 
 On the Add data source page, choose Amazon S3 as your data source. 
 
 
 
 For Data source name, enter a name. 
 For IAM role, choose Create a new service role. 
 For Role name, keep the automatically generated name. 
 
 
 
 Under Sync scope, enter the location of the S3 bucket you created earlier. 
 
 
 
 For Sync mode, select Full sync. 
 For Frequency, choose Run on demand. 
 Choose Add data source. 
 
 
 
 After the data source is created, choose Sync now to start the data source sync. 
 
It takes a few minutes for the data source sync to complete. 
 
The Data sources page shows the status of the data sources, as shown in the following screenshot. 
 
Now let‚Äôs create a data source with uploaded files. 
 
 On the Data sources page, choose Add data source. 
 Choose Upload files. 
 
 
 
 Under Select files, choose Choose files. 
 Open the location where you unzipped the sample data and choose the file national_park_services_infograph.pdf. 
 
 
 
 Choose Upload to upload the file to the index. 
 
 
Interact with your AI assistant 
Now it‚Äôs time to test the AI assistant. In the following sections, we demonstrate how to use the Amazon Q Business web experience and the API to interact with your AI assistant. 
Using Amazon Q Business web experience 
Open the deployed URL of your Amazon Q Business application in a web browser window to start the web experience for your AI assistant and sign in as one of the subscribed users. 
 
After the web experience starts, enter a prompt based on the data you indexed. If you are using the sample data provided with the post, you can use the prompt ‚ÄúWhat is the eligibility criteria for employees to receive health benefits?‚Äù as shown in the following screenshot. When you view the reference sources below the response, you will notice a download icon next to the file name, which you can use to download the file to view. 
 
Choose the file name and choose Save to save the file to your computer. 
Keep in mind that although Amazon Q Business checks the ACLs to confirm that you are authorized to access the document before downloading, anyone who has access to the computer where you download the file will be able to access the document. 
 
Choose the download status icon in your browser and choose the open icon to open the file. 
 
The document will open for your reference, as shown in the following screenshot. 
 
Now let‚Äôs look at the example of a PDF document, which in this case is the data source containing the files you uploaded, in response to the prompt ‚ÄúHow many parks are governed by the National Parks Service?‚Äù Because most web browsers can open the PDF file on a new tab, notice the file open icon next to the source file name‚Äîthis is different from the file download icon in the previous case of a .docx file. When you choose the file name, the document opens in a new tab. 
 
The following screenshot shows the PDF in the new browser tab. 
 
Using the Amazon Q Business API 
In this section, we show how to use the AWS CLI to experience how clickable URLs work when using API. To verify that an end-user is authenticated and receives fine-grained authorization to their user ID and group-based resources, a subset of the Amazon Q Business APIs (Chat, ChatSync, ListConversations, ListMessages, DeleteConversation, PutFeedback, GetDocumentContent) require identity-aware AWS Sig V4 credentials for the authenticated user on whose behalf the API call is being made. You must use the appropriate procedure to get identity-aware credentials based on whether your Amazon Q Business application user access management is configured with IAM Identity Center&nbsp;or&nbsp;IAM federation. You can apply these credentials by setting environment variables on your command line where the AWS CLI is installed; for convenience, you can choose AWS CloudShell. 
First, use the ChatSync API to make a query to your Amazon Q Business application: 
 
 aws qbusiness chat-sync --region &lt;YOUR-AWS-REGION&gt;&nbsp;\
&nbsp; &nbsp;&nbsp;--application-id &lt;YOUR-AMAZON-Q-BUSINESS-APPLICATION-ID&gt;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;--user-message "what is the eligibility criteria to receive health benefits?" 
 
This command will get a response similar to the following: 
 
 {
&nbsp;&nbsp; &nbsp;"conversationId": "&lt;YOUR-CONVERSATION-ID&gt;",
&nbsp;&nbsp; &nbsp;"systemMessage": "Employees are eligible for health benefits if they have an appointment of more than six months (at least six months plus one day) and a time base of half-time or more. Eligible employees have 60 calendar days from the date of appointment or a permitting event to enroll in a health plan, or during an Open Enrollment period.",
&nbsp;&nbsp; &nbsp;"systemMessageId": "&lt;YOUR-SYSTEM-MESSAGE-ID&gt;",
&nbsp;&nbsp; &nbsp;"userMessageId": "&lt;YOUR-USER-MESSAGE-ID&gt;",
&nbsp;&nbsp; &nbsp;"sourceAttributions": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"title": "Employee+health+benefits+policy.docx",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"snippet": "\nEmployee health benefits policy This document outlines the policy for employee health benefits. Benefit Eligibility Employees are eligible for health benefits if they have an appointment of more than six months (at least six months plus one day) and a time base of half-time or more. Eligible employees have 60 calendar days from the date of appointment or a permitting event to enroll in a health plan, or during an Open Enrollment period. For questions about your eligibility, contact your department's personnel office. Making Changes to Your Current Benefits You may make changes to your benefits during Open Enrollment, usually during September and October of each year, or based on a permitting event outside of Open Enrollment. You may not change your health benefits choice during the year unless you experience a permitting event. You must apply for any changes or enrollments within 60 calendar days of the permitting event date. For questions about permitting events, contact your department's personnel office. Permitting events or qualifying life events There are exceptions to the annual open enrollment period. These are called qualifying life events or permitting events and if you experience one or more of them, you can buy new coverage or change your existing coverage.",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"url": "https://&lt;YOUR-S3-BUCKET-NAME&gt;/DemoData/hr-data/Employee%2Bhealth%2Bbenefits%2Bpolicy.docx",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"citationNumber": 1,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"textMessageSegments": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"beginOffset": 167,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"endOffset": 324,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"snippetExcerpt": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"text": "benefits if they have an appointment of more than six months (at least six months plus one day) and a time base of half-time or more. Eligible employees have 60 calendar days from the date of appointment or a permitting event to enroll in a health plan, or during an Open Enrollment period"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"documentId": "s3://&lt;YOUR-S3-BUCKET-NAME&gt;/DemoData/hr-data/Employee+health+benefits+policy.docx",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"indexId": "&lt;INDEX-ID-OF-YOUR-AMAZON-Q-BUSINESS-APPLICATION&gt;",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"datasourceId": "&lt;DATA-SOURCE-ID-OF-YOUR-S3-DATA-SOURCE&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp;"failedAttachments": []
}&nbsp; 
 
Next, use the GetDocumentContent API using the information from the source attributions in the ChatSync API response to download and display the document to the user: 
 
 aws qbusiness get-document-content --region &lt;YOUR-AWS-REGION&gt;&nbsp;\
&nbsp; &nbsp;&nbsp;--application-id &lt;YOUR-AMAZON-Q-BUSINESS-APPLICATION-ID&gt;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;--document-id &lt;THE-DOCUMENT-ID-FROM-THE-SOURCE-ATTRIBUTIONS&gt;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;--index-id &lt;INDEX-ID-FROM-THE-SOURCE-ATTRIBUTIONS&gt;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;--data-source-id &lt;DATA-SOURCE-ID-FROM-THE-SOURCE-ATTRIBUTIONS&gt;&nbsp;\
&nbsp; &nbsp; --output-format RAW 
 
When Amazon Q Business receives the GetDocumentContent API call, the ACLs, when present, are verified to confirm that the user making the API call is authorized to access the document, and then a short interval pre-signed URL is returned in response to a successful invocation of the GetDocumentContent API that you can use to download or view the document: 
 
 {
&nbsp;&nbsp; &nbsp;"presignedUrl": "&lt;PRESIGNED-URL-TO-THE-STAGED-DOCUMENT-CONTENT&gt;",
&nbsp;&nbsp; &nbsp;"mimeType": "&lt;MIME-TYPE-OF-THE-DOCUMENT&gt;"
} 
 
Troubleshooting 
This section discusses a few errors you might encounter as you use Amazon S3 clickable URLs for the source references in your conversations with your Amazon Q Business powered AI assistant. 
Refer to Troubleshooting your Amazon S3 connector for information about error codes you might see for the Amazon S3 connector and suggested troubleshooting actions. If you encounter an HTTP status code 403 (Forbidden) error when you open your Amazon Q Business application, it means that the user is unable to access the application. To find the common causes and how to address them, refer to Troubleshooting Amazon Q Business and identity provider integration. 
 
 Full sync required ‚Äì While attempting to access referenced URLs from an Amazon S3 or uploaded files data source, the user gets the following error message: ‚ÄúError: This document cannot be downloaded because the raw document download feature requires a full connector sync performed after 07/02/2025. Your admin has not yet completed this full sync. Please contact your admin to request a complete sync of the data source.‚Äù This error can be resolved after performing a full sync of the Amazon S3 data source, or deleting the files from the uploaded files data source and uploading them again. 
 You can no longer access a document referred in the conversation history ‚Äì While browsing through conversation history, the user chooses a reference URL from an Amazon S3 data source and can‚Äôt view or download the file with the following error: ‚ÄúError: You no longer have permission to access this document. The access permissions for this document have been changed since you last accessed it. Please contact your admin if you believe you should have access to this content.‚Äù This error implies that the permissions for the document in the ACLs on the S3 bucket configured as the data source changed, so the user no longer authorized to access the file, and the ACLs got updated in the Amazon Q Business index in a data source sync. If the user believes that they should have access to the document, they must contact the administrator to address the ACLs and perform a data source sync. 
 The document you are trying to access no longer exists ‚Äì While browsing through conversation history, the user chooses a reference URL from an Amazon S3 or uploaded files data source, and can‚Äôt view or download the file with the following error: ‚ÄúError: The document you‚Äôre trying to access no longer exists in the data source. It may have been deleted or moved since it was last referenced. Please check with the admin if you need access to this document.‚Äù This error implies that the document is deleted from the S3 bucket or moved to a different location, and therefore also got deleted from the Amazon Q Business index and staging bucket for the specific document ID during a data source sync. This error will also manifest when a document from the uploaded files data source is deleted by the administrator subsequent to the conversation. If the user believes that the document should not be deleted, they should contact the administrator to attempt to restore the document and perform a data source sync. 
 You can‚Äôt download this document because your web experience lacks the required permissions ‚Äì When the user chooses a reference URL from an Amazon S3 or uploaded files data source, they can‚Äôt view or download the file with the following error: ‚ÄúError: Unable to download this document because your Web Experience lacks the required permissions. Your admin needs to update the IAM role for the Web Experience to include permissions for the GetDocumentContent API. Please contact your admin to request this IAM role update.‚Äù The administrator can attempt to resolve this error by updating the IAM role for the web experience with permissions to invoke the GetDocumentContent API, as discussed in the considerations section earlier in this post. 
 
Clean up 
To avoid incurring future charges and to clean out unused roles and policies, delete the resources you created: the Amazon Q application, data sources, and corresponding IAM roles. Complete the following steps: 
 
 To delete the Amazon Q application, go to the Amazon Q console and, on the Applications page, select your application. 
 On the Actions drop-down menu, choose Delete. 
 To confirm deletion, enter delete in the field and choose Delete. Wait until you get the confirmation message; the process can take up to 15 minutes. 
 To delete the S3 bucket you created during this exercise, empty the bucket and then delete the bucket. 
 Delete your IAM Identity Center instance. 
 
Conclusion 
In this post, we showed how to build an AI assistant with Amazon Q Business based on your enterprise documents stored in an S3 bucket or by directly uploading the documents to the data source. Amazon S3 clickable URLs provide a user-friendly mechanism for authenticated users to securely view or download the documents referenced in responses to users‚Äô queries, validate accuracy, and practice responsible AI‚Äîa critical success factor for an enterprise AI assistant solution. 
For more information about the Amazon Q Business S3 connector, see Discover insights from Amazon S3 with Amazon Q S3 connector. 
 
About the authors 
Abhinav Jawadekar is a Principal Solutions Architect in the Amazon Q Business service team at AWS. Abhinav works with AWS customers and partners to help them build generative AI solutions on AWS.
‚Ä¢ GPT OSS models from OpenAI are now available on SageMaker JumpStart
  Today, we are excited to announce the availability of Open AI‚Äôs new open weight GPT OSS models, gpt-oss-120b and gpt-oss-20b, from OpenAI in Amazon SageMaker JumpStart. With this launch, you can now deploy OpenAI‚Äôs newest reasoning models to build, experiment, and responsibly scale your generative AI ideas on AWS. 
In this post, we demonstrate how to get started with these models on SageMaker JumpStart. 
Solution overview 
The OpenAI GPT OSS models (gpt-oss-120b and gpt-oss-20b) excel at coding, scientific analysis, and mathematical reasoning tasks. Both models feature a 128K context window and adjustable reasoning levels (low/medium/high) to match specific requirements. They support external tool integration and can be used in agentic workflows through frameworks like Strands Agents, an open source AI agent SDK. With full chain-of-thought output capabilities, you get detailed visibility into the model‚Äôs reasoning process. You can use the OpenAI SDK to call your SageMaker endpoint directly by simply updating the endpoint. The models give you the flexibility to modify and customize them for your specific business needs while benefiting from enterprise-grade security and seamless scaling. 
SageMaker JumpStart is a fully managed service that offers state-of-the-art foundation models (FMs) for various use cases such as content writing, code generation, question answering, copywriting, summarization, classification, and information retrieval. It provides a collection of pre-trained models that you can deploy, accelerating the development and deployment of machine learning (ML) applications. One of the key components of SageMaker JumpStart is model hubs, which offer a vast catalog of pre-trained models, such as OpenAI, for a variety of tasks. 
You can now discover and deploy OpenAI models in Amazon SageMaker Studio or programmatically through the Amazon SageMaker Python SDK, to derive model performance and MLOps controls with Amazon SageMaker features such as Amazon SageMaker Pipelines, Amazon SageMaker Debugger, or container logs. The models are deployed in a secure AWS environment and under your VPC controls, helping to support data security for enterprise security needs. 
You can discover GPT OSS models from US East (Ohio, N. Virginia) and Asia Pacific (Mumbai, Tokyo) AWS Regions. 
Throughout this example, we use the gpt-oss-120b model. These steps can be replicated with the gpt-oss-20b model as well. 
Prerequisites 
To deploy the GPT OSS models, you must have the following prerequisites: 
 
 An AWS account that will contain your AWS resources. 
 An AWS Identity and Access Management (IAM) role to access SageMaker. To learn more about how IAM works with SageMaker, see AWS Identity and Access Management for Amazon SageMaker AI. 
 Access to SageMaker Studio, a SageMaker notebook instance, or an interactive development environment (IDE) such as PyCharm or Visual Studio Code. We recommend using SageMaker Studio for straightforward deployment and inference. 
 To deploy GPT OSS models, make sure you have access to the recommended instance types based on the model size. You can find these instance recommendations on the SageMaker JumpStart model card. The default instance type for both these models is p5.48xlarge, but you can also use other P5 family instances where available. To verify you have the necessary&nbsp;service quotas, complete the following steps: 
   
   On the Service Quotas console, under AWS Services, choose Amazon SageMaker. 
   Check that you have sufficient quota for the required instance type for endpoint deployment. 
   Make sure at least one of these instance types is available in your target Region. 
   If needed, request a quota increase and contact your AWS account team for support. 
    
 
Deploy gpt-oss-120b through the SageMaker JumpStart UI 
Complete the following steps to deploy gpt-oss-120b through SageMaker JumpStart: 
 
 On the SageMaker console, choose Studio in the navigation pane. 
 First-time users will be prompted to create a domain. If not, choose Open Studio. 
 On the SageMaker Studio console, access SageMaker JumpStart by choosing JumpStart in the navigation pane. 
 On the SageMaker JumpStart landing page, search for gpt-oss-120b using the search box. 
 
 
 
 Choose a model card to view details about the model such as license, data used to train, and how to use the model. Before you deploy the model, review the configuration and model details from the model card. The model details page includes the following information: 
   
   The model name and provider information. 
   A Deploy button to deploy the model. 
    
 
 
 
 Choose Deploy to proceed with deployment. 
   
   For Endpoint name, enter an endpoint name (up to 50 alphanumeric characters). 
   For Number of instances, enter a number between 1‚Äì100 (default: 1). 
   For Instance type, select your instance type. For optimal performance with gpt-oss-120b, a GPU-based instance type such as p5.48xlarge is recommended. 
    
 
 
 
 Choose Deploy to deploy the model and create an endpoint. 
 
When deployment is complete, your endpoint status will change to InService. At this point, the model is ready to accept inference requests through the endpoint. When the deployment is complete, you can invoke the model using a SageMaker runtime client and integrate it with your applications. 
Deploy gpt-oss-120b with the SageMaker Python SDK 
To deploy using the SDK, start by selecting the gpt-oss-120b model, specified by the model_id with the value openai-reasoning-gpt-oss-120b. You can deploy your choice of model on SageMaker using the Python SDK examples in the following sections. Similarly, you can deploy gpt-oss-20b using its model ID. 
Enable web search on your model with EXA 
By default, models in SageMaker JumpStart run in network isolation. The GPT OSS models come with a built-in tool for web search using EXA, a meaning-based web search API powered by embeddings. To use this tool, OpenAI requires customers get an API key from EXA and pass this key as an environment variable to their JumpStartModel instance when deploying it through the SageMaker Python SDK. The following code details how to deploy the model on SageMaker with network isolation disabled and pass in the EXA API key to the model: 
 
 from sagemaker.jumpstart.model import JumpStartModel 

accept_eula = True 
model = JumpStartModel(
&nbsp;&nbsp; &nbsp;model_id="openai-reasoning-gpt-oss-120b",
&nbsp;&nbsp; &nbsp;enable_network_isolation=False, 
&nbsp;&nbsp; &nbsp;env={
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"EXA_API_KEY": "&lt;INSERT_API_KEY&gt;"
&nbsp;&nbsp; &nbsp;}
) 
predictor = model.deploy(
&nbsp;&nbsp; &nbsp;accept_eula=accept_eula
) 
 
You can change these configurations by specifying other non-default values in JumpStartModel. The end user license agreement (EULA) value must be explicitly defined as True to accept the terms. With the preceding deployment, because network isolation is set at deployment time, turning it back on requires creating a new endpoint. 
Optionally, you can deploy your model with the JumpStart default values (with network isolation enabled) as follows: 
 
 from sagemaker.jumpstart.model import JumpStartModel 
accept_eula = True 
model = JumpStartModel(model_id="openai-reasoning-gpt-oss-120b") 
predictor = model.deploy(accept_eula=accept_eula) 
 
Run inference with the SageMaker predictor 
After the model is deployed, you can run inference against the deployed endpoint through the SageMaker predictor: 
 
 payload = {
&nbsp;&nbsp; &nbsp;"model": "/opt/ml/model",
&nbsp;&nbsp; &nbsp;"input": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"role": "system",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"content": "You are a good AI assistant"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"role": "user",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"content": "Hello, how is it going?"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp;"max_output_tokens": 200,
&nbsp;&nbsp; &nbsp;"stream": "false",
&nbsp;&nbsp; &nbsp;"temperature": 0.7,
&nbsp;&nbsp; &nbsp;"top_p": 1
}
&nbsp;&nbsp; &nbsp;
response = predictor.predict(payload)
print(response['output'][-1]['content'][0]['text']) 
 
We get the following response: 
 
 Hey there! All good on my end‚Äîjust ready to dive into whatever you need. How‚Äôs it going on your side? 
 
Function calling 
The GPT OSS models were trained on the harmony response format for defining conversation structures, generating reasoning output and structuring function calls. The format is designed to mimic the OpenAI Responses API, so if you have used that API before, this format should hopefully feel familiar to you. The model should not be used without using the harmony format. The following example showcases an example of tool use with this format: 
 
 payload= {
&nbsp;&nbsp;"model": "/opt/ml/model",
&nbsp;&nbsp;"input": "System: You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2024-08-05\n\nreasoning: medium\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.\nCalls to these tools must go to the commentary channel: 'functions'.\n\n# Tools\n\n## functions\n\nnamespace functions {\n\n// Gets the current weather for a specific location.\ntype get_current_weather = (_: {\n// The city and state/country, e.g. \"San Francisco, CA\" or \"London, UK\"\nlocation: string,\n// Temperature unit preference\nunit?: \"celsius\" | \"fahrenheit\", // default: celsius\n}) =&gt; any;\n\n} // namespace functions\n\nDeveloper: You are a helpful AI assistant. Provide clear, concise, and helpful responses.\n\nHuman: What's the weather like in Seattle?\n\nAssistant:",
&nbsp;&nbsp;"instructions": "You are a helpful AI assistant. Provide clear, concise, and helpful responses.",
&nbsp;&nbsp;"max_output_tokens": 2048,
&nbsp;&nbsp;"stream": "false",
&nbsp;&nbsp;"temperature": 0.7,
&nbsp;&nbsp;"reasoning": {
&nbsp;&nbsp; &nbsp;"effort": "medium"
&nbsp;&nbsp;},
&nbsp;&nbsp;"tools": [
&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp;"type": "function",
&nbsp;&nbsp; &nbsp; &nbsp;"name": "get_current_weather",
&nbsp;&nbsp; &nbsp; &nbsp;"description": "Gets the current weather for a specific location",
&nbsp;&nbsp; &nbsp; &nbsp;"parameters": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"type": "object",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"properties": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"location": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"type": "string",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"description": "The city and state/country, e.g. 'San Francisco, CA' or 'London, UK'"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"unit": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"type": "string",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"enum": ["celsius", "fahrenheit"],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"default": "celsius",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"description": "Temperature unit preference"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"required": ["location"]
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp;],
} 
 
We get the following response: 
 
 {'arguments': '{"location":"Seattle, WA"}', 'call_id': 'call_596a67599df2465495fd444772ff9539', 'name': 'get_current_weather', 'type': 'function_call', 'id': 'ft_596a67599df2465495fd444772ff9539', 'status': None} 
 
Clean up 
After you‚Äôre done running the notebook, make sure to delete the resources that you created in the process to avoid additional billing. For more details, see Delete Endpoints and Resources. 
 
 predictor.delete_model()
predictor.delete_endpoint() 
 
Conclusion 
In this post, we demonstrated how to deploy and get started with OpenAI‚Äôs GPT OSS models (gpt-oss-120band gpt-oss-20b) on SageMaker JumpStart. These reasoning models bring advanced capabilities for coding, scientific analysis, and mathematical reasoning tasks directly to your AWS environment with enterprise-grade security and scalability. 
Try out the new models, and share your feedback in the comments. 
 
About the Authors 
Pradyun Ramadorai, Senior Software Development Engineer Malav Shastri, Software Development Engineer Varun Morishetty, Software Development Engineer Evan Kravitz, Software Development Engineer Benjamin Crabtree, Software Development Engineer Shen Teng, Software Development Engineer Loki Ravi, Senior Software Development Engineer Nithin Vijeaswaran, Specialist Solutions Architect Breanne Warner, Enterprise Solutions Architect Yotam Moss, Software Development Manager Mike James, Software Development Manager Sadaf Fardeen, Software Development Manager Siddharth Shah, Principal Software Development Engineer June Won, Principal Product Manager
‚Ä¢ Discover insights from Microsoft Exchange with the Microsoft Exchange connector for Amazon Q Business
  Amazon Q Business is a fully managed, generative AI-powered assistant that helps enterprises unlock the value of their data and knowledge. With Amazon Q Business, you can quickly find answers to questions, generate summaries and content, and complete tasks by using the information and expertise stored across your company‚Äôs various data sources and enterprise systems. At the core of this capability are native data source connectors that seamlessly integrate and index content from multiple repositories into a unified index. This enables the Amazon Q Business large language model (LLM) to provide accurate, well-written answers by drawing from the consolidated data and information. The data source connectors act as a bridge, synchronizing content from disparate systems like Salesforce, Jira, and SharePoint into a centralized index that powers the natural language understanding and generative abilities of Amazon Q Business. 
To make this integration process as seamless as possible, Amazon Q Business offers multiple pre-built connectors to a wide range of data sources, including Atlassian Jira, Atlassian Confluence, Amazon Simple Storage Service (Amazon S3), Microsoft Exchange, Microsoft SharePoint, Salesforce, and many more. This allows you to create your generative AI solution with minimal configuration. For a full list of Amazon Q Business supported data source connectors, see Supported connectors. 
One of the key integrations for Amazon Q Business is with Microsoft Exchange. Microsoft Exchange is a widely used enterprise email and collaboration environment that contains a wealth of valuable information, including email conversations, attachments, calendar events, and contacts. 
With the Microsoft Exchange connector, we are enhancing user productivity and streamlining communication processes within organizations. This integration empowers users to use advanced search capabilities and intelligent email management using natural language. 
The Microsoft Exchange connector for Amazon Q Business providing a seamless way to index and query data stored in Microsoft Exchange. With this connector, organizations 
 
 Centralized access to Microsoft Exchange data ‚Äì Amazon Q Business allows you to configure Microsoft Exchange as a data source, providing a single, centralized interface to search and access information stored in your Microsoft Exchange repositories. This alleviates the need for users to navigate through individual email accounts or folders to find relevant data. 
 Intelligent search and retrieval ‚Äì Amazon Q Business uses advanced natural language processing and machine learning capabilities to enable intelligent, natural language-based search and retrieval of information from Microsoft Exchange. Users can ask questions or make queries in plain language, and Amazon Q Business will surface the most relevant responses and insights. 
 Enhanced productivity and collaboration ‚Äì By making it straightforward for employees to find and act on the information stored in Microsoft Exchange, Amazon Q Business can improve productivity and collaboration across the organization. Users can quickly locate key documents, contacts, or calendar events, and use that information to make more informed decisions and drive faster, more effective outcomes. 
 Secure and compliant data access ‚Äì Amazon Q Business provides a secure, compliant way to access and query Microsoft Exchange data. Amazon Q Business integrates with your organization‚Äôs identity provider (IdP) to make sure only authorized users can access sensitive information, and it maintains a detailed audit trail of all user activity. 
 Streamlined workflows and decision-making ‚Äì Amazon Q Business has the ability to generate summaries, answers, and recommendations based on Microsoft Exchange data, users can make more informed decisions and streamline various workflows, such as customer support, project management, and strategic planning. 
 
By using the Microsoft Exchange connector for Amazon Q Business, organizations can unlock the full value of the data stored in their Microsoft Exchange repositories, empowering employees to work more efficiently, collaborate more effectively, and drive greater business impact. 
In this post, we show how to index information stored in Microsoft Exchange and use Amazon Q Business to query your Microsoft Exchange data. 
Microsoft Exchange connector for Amazon Q Business features 
The following table gives an overview of the Microsoft Exchange connector for Amazon Q Business and its supported features. For more details, refer to Microsoft Exchange connector overview. 
 
Solution overview 
With Amazon Q Business, you can configure multiple data sources to provide a central place to search across your internal repository. For our solution, we demonstrate how to retrieve data from the Microsoft Exchange repository or a folder using the Microsoft Exchange connector for Amazon Q Business. The solution consists of the following steps: 
 
 Configure a Microsoft Exchange application and gather connection details 
 Create users and groups in AWS IAM Identity Center 
 Create the Microsoft Exchange connector for Amazon Q Business 
 Query Microsoft Exchange data using the Amazon Q web experience 
 Troubleshooting 
 
The following diagram illustrates the solution architecture. 
 
Prerequisites 
To configure the Microsoft Exchange connector for Amazon Q Business, you need to create a Microsoft Exchange account in Office 365. 
Configure a Microsoft Exchange application and gather connection details 
 
 Log in to the Azure portal using your global admin user account and choose Next. 
 
 
 
 Enter your password and choose Sign in. 
 
 
 
 If multi-factor authentication (MFA) is configured, now authenticate using Microsoft Authenticator. 
 
 
 
 Choose Yes to stay signed in. 
 On the Azure portal‚Äôs landing page, search for and choose Microsoft Entra ID. 
 
 
 
 On the Microsoft Entra ID service page, copy the value of Tenant ID. 
 
 
 
 Choose App registrations in the navigation pane. 
 
 
 
 Choose New registration. 
 
 
 
 Enter the name of your choice for Name, then choose Register. 
 
 
After successful registration, you will land on the application page, as shown in the following screenshot. 
 
 
 Choose Certificates &amp; secrets in the navigation pane. 
 
 
 
 Choose New client secret. 
 
 
 
 Enter a description for the client secret for Description and choose Add. 
 
 
 
 Make a note of the secret value and secret ID. 
 
 
 
 Now configure API permissions by choosing API permissions in the navigation pane. 
 
 
 
 For Microsoft Exchange Online, please make sure that you have Azure AD Premium P2 activated. This will make sure that the Microsoft Exchange Online is available as part of your organization APIs. 
 
 
 
 
 
 Add the permissions to the APIs Microsoft Graph and Office 365 Exchange Online. 
 
There are 13 permissions for Microsoft Graph and 1 permission for Office 365 Exchange Online. 
 
Create users and groups in AWS IAM Identity Center 
In this section, you create a user John Doe in AWS IAM Identity Center, who will be given permission to use the application. 
To create your user, complete the following steps: 
 
 Open IAM Identity Center console. 
 If you haven‚Äôt enabled IAM Identity Center, choose Enable. If there‚Äôs a pop-up, choose how you want to enable IAM Identity Center. For this example, select Enable only in this AWS account. Choose Continue. 
 
For more details, refer to Enable IAM Identity Center. 
 
 On the IAM Identity Center console, choose Users in the navigation pane. 
 Choose Add user. 
 Enter the following user details: 
   
   Username: john_doe 
   Email address: john_doe@xyz.com (Use or create a real email address for each user to use in a later step.) 
   First name: John 
   Last name: Doe 
   Display name: John Doe 
    
 
 
 
 Skip the optional fields and choose Next to create the user. 
 On the Add user to groups page, choose Next and then choose Add user. 
 
Create the Microsoft Exchange connector for Amazon Q Business 
For detailed steps to set up Amazon Q Business, refer to Getting started with Amazon Q Business. To configure the Amazon Q Business connector, complete the following steps: 
 
 In the Amazon Q Business console, choose Applications in the navigation pane. 
 Choose Create application. 
 
 
 
 In the Create application step, for Service access, select Create and use a new service role, then choose Create. 
 
 
 
 In the Select retriever step, select Use native retriever and choose Next. 
 
 
 
 In the Connect data sources step, search for and choose Microsoft Exchange, then choose Create application. 
 
 
 
 On the Applications page, choose your application (qbiz-mx-app). 
 
 
 
 In the Data sources section, choose Add data source. 
 
 
 
 On the Add data source page, search for Microsoft Exchange and choose the plus sign to configure the data source. 
 
 
 
 Enter the name of the data source and the tenant ID noted earlier. 
 
 
 
 In the Authorization section, enable Access Control List (ACL). 
 In the Authentication section, for AWS Secrets Manager secret, choose Create and add new secret. 
 
 
 
 Enter the secret name of your choice, the client ID and client secret values you noted earlier, and choose Save. 
 
 
 
 In the Configure VPC and security group section, leave the settings as default. 
 In the IAM role section, choose Create a new service role. 
 In the Sync scope section, for User email ID, enter the email of your Microsoft Exchange account and choose Add. 
 
Alternatively, if you have list of user email IDs, you can provide an Amazon S3 path to a file with user emails in your S3 bucket. For more details, refer to Connecting Amazon Q Business to Microsoft Exchange using the console. 
 
 
 
 In the Sync mode section, use the default Full sync. 
 In the Sync run schedule section, choose the frequency of your choice. 
 Leave the remaining sections with default values. 
 
 
 
 Choose Add data source. 
 
 
Amazon Q will take 30 seconds to 1 minute to configure your data source. You will see a success banner as shown in the following screenshot. 
 
 Choose Sync now to sync your data source. 
 
After successfully syncing the data source, you will see the Status / Summary column as Completed. 
 
 
 
 For the Update groups and users step, choose Add groups and users. 
 
 
The users and groups that you add in this section are from the IAM Identity Center users and groups set up by your administrator. 
 
 In the Add or assign users and groups pop-up, select Assign existing users and groups to add existing users configured in your connected IAM Identity Center. 
 
Optionally, if you have permissions to add users to connected IAM Identity Center, you can select Add new users. 
 
 
 Choose Get started. 
 
 
 
 In the Assign users and groups pop-up, search for users by user display name or groups by group name. 
 Choose the users or groups you want you add and choose Done. 
 
 
This closes the pop-up. The groups and users that you added should now be available on the Groups or Users tabs. 
 
 Choose Assign. 
 
For each group or user entry, an Amazon Q Business subscription tier needs to be assigned. 
 
 To enable a subscription for a group, on the Update groups and users page, choose the Groups (If individual users need to be assigned a subscription, choose the Users tab.) 
 For Subscription, choose Choose subscription and choose a subscription (Q Business Lite or Q Business Pro). 
 Choose Update application to complete setting up the data connector for Amazon Q Business. 
 
Query Microsoft Exchange data using the Amazon Q web experience 
To query the data that is synced through the data source, navigate back to the Amazon Q Business application (qbiz-mx-app) and choose the Web experience URL link. 
 
Sign in to the web application using the credentials of the user assigned and configured in IAM Identity Center. 
 
After a successful sign in, the Amazon Q Business application should be displayed in the list of applications, as shown in the following screenshot. 
 
The application link should redirect you to the Amazon Q Business chat application, as shown in the following screenshot. 
 
The following screenshot shows the emails that were synced earlier. We will first query based on the content from the email highlighted in this screenshot. 
 
The following screenshot shows the response to the query ‚Äúwhat are the easy ways to get started on Azure?‚Äù 
 
You can choose the data source hyperlink to open the email that the response is based on. 
 
The following screenshot shows an invoice email from Microsoft Outlook, which we will use for another question. 
 
We will also refer to calendar details of a meeting with the billing team along with the agenda details. 
 
We ask the question ‚ÄúQ Assistant, I have a meeting with the billing team tomorrow. Can you summarize the agenda and find relevant information from my emails that I can review in the meeting?‚Äù The following screenshot shows the response based on the sample invoices email. 
 
The response included the information from the email along with the hyperlink to the data sources (in this case, it is the hyperlink to the Outlook emails). 
We ask another question: ‚ÄúWhat are the main features and my actions items relating to the recent CloudTrail changes? By when should I implement the changes?‚Äù 
 
Amazon Q Business retrieved the main features, action items, and the implementation timeline. 
 
Congratulations! You have successfully used the Microsoft Exchange connector for Amazon Q Business to surface answers and insights based on the content indexed from your Microsoft Exchange account. 
Troubleshooting 
Troubleshooting your Microsoft Exchange connector provides information about error codes you might see for the connector and suggested troubleshooting actions. If you encounter an HTTP status code 403 (Forbidden) error when you open your Amazon Q Business application, it means that the user is unable to access the application. See for common causes and how to address them. 
The sync run history report is a new feature now available in Amazon Q Business that significantly improves visibility into data source sync operations. The latest release introduces a comprehensive document-level report incorporated into the sync history, providing administrators with granular indexing status, metadata, and ACL details for the documents processed during a data source sync job. 
Frequently asked questions 
In this section, we provide guidance to frequently asked questions. 
Amazon Q Business is unable to answer your questions 
If you get response ‚ÄúSorry, I couldn‚Äôt find relevant information to complete your request,‚Äù this might be due to a few reasons: 
 
 No permissions ‚Äì Access control lists (ACLs) applied to your account don‚Äôt allow you to query certain data sources. If this is the case, reach out to your administrator to make sure your ACLs are configured to access the data sources 
 Data connector sync failed ‚Äì Your data connector might have failed to sync information from the source to the Amazon Q Business application. Verify the data connector‚Äôs sync run schedule and sync history to confirm the sync is successful. 
 Empty mail exchange ‚Äì Verify that the connected email exchange to Amazon Q has data. 
 
If none of these are true in your case, open a support case to get this resolved. 
How to generate responses from authoritative data sources 
You can configure these options using Amazon Q Business application global controls under Admin controls and guardrails: 
 
 Log in as an Amazon Q Business application administrator. 
 Navigate to the application and choose Admin controls and guardrails in the navigation pane. 
 Choose Edit in the Global controls section to configure these options. 
 
For more information, refer to Admin controls and guardrails in Amazon Q Business. 
 
Amazon Q Business responds using old (stale) data even though your data source is updated 
Each Amazon Q Business data connector can be configured with unique sync run schedule frequency. Verify the sync status and sync schedule frequency for your data connector to see when the last sync ran successfully. Your data connector‚Äôs sync run schedule might be set to sync at a scheduled time of day, week, or month. If set to run on demand, then the sync has to be manually triggered. When the sync run is complete, verify the sync history to make sure the run has successfully synced all new issues. Refer to Sync run schedule for more information. 
How to set up Amazon Q Business using a different IdP 
You can set up Amazon Q Business with another SAML 2.0-compliant IdP, such as Okta, Entra ID, or Ping Identity. For more information, see Creating an Amazon Q Business application using Identity Federation through IAM. 
Expand the solution 
You can explore other features in Amazon Q Business. For example, the Amazon Q Business document enrichment feature helps you control what documents and document attributes are ingested into your index and also how they‚Äôre ingested. Using document enrichment, you can create, modify, or delete document attributes and document content when you ingest them into your Amazon Q Business index. For example, you can scrub personally identifiable information (PII) by choosing to delete any document attributes related to PII. 
Amazon Q Business also offers the following features: 
 
 Filtering using metadata ‚Äì Use document attributes to customize and control users‚Äô chat experience. This is currently supported only if you use the Amazon Q Business API. 
 Source attribution with citations ‚Äì Verify responses using Amazon Q Business source attributions. 
 Upload files and chat ‚Äì Let users upload files directly into chat and use uploaded file data to perform web experience tasks. 
 Quick prompts ‚Äì Feature sample prompts to inform users of the capabilities of their Amazon Q Business web experience. 
 
To improve retrieved results and customize the user chat experience, you can map document attributes from your data sources to fields in your Amazon Q index. Learn more by exploring Microsoft Exchange data source connector field mappings. 
Clean up 
To avoid incurring future costs, clean up the resources you created as part of this solution. If you only added a new data source using the Microsoft Exchange connector for Amazon Q Business, delete that data source. 
Complete the following steps to clean up your resources: 
 
 Open the Office 365 Admin Center using the account of a user member of the Tenant Global Admins group. 
 Navigate to the Microsoft Azure Portal. 
 Search for and choose App registrations. 
 Select the application you created earlier, then choose Delete. 
 On the Amazon Q Business console, choose Applications in the navigation pane. 
 Select the application you created, and on the Actions menu, choose Delete. 
 Delete the users that were added in IAM Identity Center. 
 
Conclusion 
With the Microsoft Exchange connector for Amazon Q Business, organizations can tap into the repository of information stored in their account securely using intelligent search powered by Amazon Q Business. 
To learn about these possibilities and more, refer to the Amazon Q Business User Guide. For more information on how you can create, modify, or delete metadata and content when ingesting your data from Microsoft Exchange, refer to Enriching your documents during ingestion. 
 
About the Authors 
Ram Konchada is Senior Solutions Architect at AWS. He loves helping customers achieve their business goals using technology. Outside of work, Ram enjoys playing tennis. 
Armstrong Onaiwu is a Solutions Architect at AWS. He is deeply passionate about technology and helping customers use AWS services to address business challenges. He specializes in designing highly scalable, resilient, and cost-effective network solutions on AWS. When not spending time with his family, Armstrong enjoys traveling and playing FIFA.

‚∏ª