‚úÖ Morning News Briefing ‚Äì November 08, 2025 10:41

üìÖ Date: 2025-11-08 10:41
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ SPECIAL WEATHER STATEMENT, Pembroke
  Persons in or near this area should be on the lookout for adverse weather conditions and take necessary safety precautions . People in or around this area are urged to take necessary precautions . Weather conditions are expected to worsen in the coming years . People should be prepared for the worst of the worst weather conditions in the area . The weather is expected to deteriorate rapidly in the years of the next century .
‚Ä¢ Current Conditions:  0.4¬∞C
  Temperature: 0.4&deg;C Pressure / Tendency: 100.3 kPa rising Humidity: 87 % Dewpoint: -1.5&deg:C Wind: WNW 15 km/h gust 29 km-h . Air Quality Health Index: n/a . Pembroke 5:00 AM EST Saturday 8 November 2025 . Pemberbroke
‚Ä¢ Saturday: Chance of flurries. High plus 2. POP 40%
  40 percent chance of flurries early this morning . Mainly cloudy . High plus 2. UV index 1 or low . Wind northwest 20 km/h becoming light this morning this morning. High minus 2.40 per cent chance of snowfall this morning, with 40 per cent of it possible to see snowfall in the evening hours of Saturday morning . Forecast issued 5:00

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Immigration agents have new technology to identify and track people
  Department of Homeland Security is adopting powerful new tools to monitor noncitizens . Privacy advocates are worried they erode privacy rights for immigrants and Americans alike . Homeland Security has been criticized by privacy advocates for using the tools to spy on noncitizens in the U.S. Privacy advocates say they are concerned they will erode Americans' privacy rights if they use the new tools for monitoring noncitizens'
‚Ä¢ What to know about the 5 hostages whose remains are still in Gaza
  Lior Rudaeff, 61, was killed in the Oct. 7, 2023 attack . His remains were returned to Hamas in the most recent release . He was identified as a man who was 61 when he was killed by Hamas forces in October 2023 . The man was identified by Hamas as Lior Ruaff, who was a member of Israel's Kofi Annan
‚Ä¢ UPS and FedEx grounding MD-11 planes following deadly Kentucky crash
  UPS and FedEx will ground their fleets of McDonnell Douglas MD-11 planes "out of an abundance of caution" following a deadly crash at the UPS global aviation hub in Kentucky . The planes were involved in a fatal crash that left one person dead at the scene of the crash . FedEx and UPS are grounding their McDonnell Douglas planes out of "an abundance of¬†experity¬†of
‚Ä¢ Supreme Court temporarily blocks full SNAP benefits even as they'd started to go out
  The Trump administration is appealing an order to fully fund November food aid for millions of people . The high court decision allows a lower court time to consider a more lasting pause . The administration wants to keep food aid funds in place for November . The decision allows the lower court to consider more of a longer-term pause in food aid funding for the nation's poorest . The government is appealing the
‚Ä¢ James Watson, who co-discovered the structure of DNA, has died at age 97
  James Watson, who co-discovered the structure of DNA, has died at age 97 . Watson was a scientific superstar until he made racist remarks that made him an outcast . He was a scientist who was made a social outcast by his racist remarks . Watson died at the age of 97 on Monday, October 4 . Watson co-founded the first company that developed the first DNA

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Microsoft's lack of quality control is out of control
  At one point, Microsoft's QC was legendary. Now, it's the wrong kind of legend . The robustness of Windows NT in decades past might qualify as "legendary" But anybody who has had to use the company's wares in recent years might quibble with the word "quality" Microsoft's quality control was legendary, but now it's a different kind of quality
‚Ä¢ Meta can't afford its $600B love letter to Trump
  The Zuck better hope his finance bros have deep pockets and a whole lotta patience to pull this off . Meta on Friday floated plans to invest $600 billion in US infrastructure and jobs by 2028 as part of a massive datacenter expansion . The company says it will invest in the U.S. infrastructure and the jobs of those who do it will be created by 20
‚Ä¢ ChatGPT, Claude, and Grok make very squishy jury members
  Law students at the University of North Carolina at Chapel Hill School of Law last month held a mock trial to see how AI models administer justice . All three acquitted a teen in the mock trial based on a case where a judge ruled guilty . The trial was based on the case of a teen who was found guilty of a crime in a case that was ruled guilty by a judge in court .
‚Ä¢ Previously unknown Landfall spyware used in 0-day attacks on Samsung phones
  A previously unknown Android spyware family called LANDFALL exploited a zero-day in Samsung Galaxy devices for nearly a year, installing surveillance code capable of recording calls, tracking locations, and harvesting photos and logs . Samsung finally patched the flaw in April, and the spyware was discovered months before it was fixed . The flaw was fixed by Samsung, but the company says it was a
‚Ä¢ AI benchmarks are a bad joke ‚Äì and LLM makers are the ones laughing
  AI companies tout their models' performance on benchmark tests as a sign of technological and intellectual superiority . But those results, widely used in marketing, may not be meaningful . AI companies regularly tout performance as signs of technological superiority, but those results are often not meaningful . Study finds many tests don't measure the right things AI companies say, such as performance of their AI models in tests

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ From resolution to reality: advancing point-of-care diagnostics for kidney disease in low-resource settings
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Prevalence, bacterial etiology, and antimicrobial susceptibility patterns of urinary tract infections among pregnant women in rural West Amhara, Ethiopia
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ The contribution of mycetoma grains to suboptimal disease management
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ A simulation study of the impact of population-wide lifestyle modifications on life expectancy in the Chinese population
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Stillbirths and the race-specific gap in neonatal death among extremely preterm births
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ The Download: a new home under the sea, and cloning pets
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



The first new subsea habitat in 40 years is about to launch



Vanguard feels and smells like a new RV. It has long, gray banquettes that convert into bunks, a microwave cleverly hidden under a counter, a functional steel sink with a French press and crockery above. A weird little toilet hides behind a curtain.



But you can‚Äôt just fire up Vanguard‚Äôs engine and roll off the lot. Once it is sealed and moved to its permanent home beneath the waves of the Florida Keys National Marine Sanctuary early next year, Vanguard will be the world‚Äôs first new subsea habitat in nearly four decades.Teams of four scientists will live and work on the seabed for a week at a time, entering and leaving the habitat as scuba divers. Read our story about some of their potential missions.



‚ÄîMark Harris







Cloning isn‚Äôt just for celebrity pets like Tom Brady‚Äôs dog



This week, we heard that Tom Brady had his dog cloned. The former quarterback revealed that his Junie is actually a clone of Lua, a pit bull mix that died in 2023.



Brady‚Äôs announcement follows those of celebrities like Paris Hilton and Barbra Streisand, who also famously cloned their pet dogs. But some believe there are better ways to make use of cloning technologies, such as diversifying the genetic pools of inbred species, or potentially bringing other animals back from the brink of extinction. Read the full story.



‚ÄîJessica Hamzelou



This article first appeared in The Checkup, MIT Technology Review‚Äôs weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 OpenAI is facing a wave of new lawsuits¬†The cases concern wrongful death complaints, and claims ChatGPT caused mental breakdowns. (NYT $)+ One family claims ChatGPT ‚Äúgoaded‚Äù their son into taking his own life. (CNN)+ The looming crackdown on AI companionship. (MIT Technology Review)



2 Tesla shareholders approved Elon Musk‚Äôs $1 trillion pay packageMore than 75% of voters backed it. (WSJ $)+ Musk had hinted he‚Äôd leave Tesla if the deal wasn‚Äôt greenlit. (Axios)+ Tesla has to hit its ambitious targets before he can get his hands on the cash. (Wired $)3 The EU is poised to water down the AI actAfter pressure from Big Tech and the US government. (FT $)+ While the legislation was passed last year, many provisions haven‚Äôt kicked in yet. (Reuters)



4 Meta is earning a colossal amount of money from scam adsThey accounted for 10% of its revenue last year. (Reuters)+ Meta claims it ‚Äúaggressively‚Äù addresses scam ads on its platform. (CNBC)



5 The Chan Zuckerberg Initiative is pivoting to AIIt‚Äôs shifting its philanthropic focus from social justice programs to curing disease. (WP $)+ To achieve its goals, the charity will need extra computing power. (NYT $)



6 Unesco has adopted global standards on neurotechnologyExperts were increasingly concerned that a lack of guardrails could give rise to unethical practices. (The Guardian)+ Meet the other companies developing brain-computer interfaces. (MIT Technology Review)



7 Benchmarks hugely oversell AI performanceA new study questions their reliability and the validity of their results. (NBC News)+ How to build a better AI benchmark. (MIT Technology Review)



8 Kim Kardashian blames ChatGPT for failing her law examsIt‚Äôs almost like she shouldn‚Äôt have been consulting it for legal expertise in the first place. (Hollywood Reporter)+ AI and social media is worsening brain rot. (NYT $)+ How AI is introducing errors into courtrooms. (MIT Technology Review)



9 Hyundai is using robot dogs to inspect its EV production lineAnd they may soon be joined by a bipedal master. (IEEE Spectrum)



10 Grand Theft Auto VI has been delayed yet againThe highly anticipated video game has big, big shoes to fill. (Bloomberg $)+ It‚Äôll land a full 13 years after its previous incarnation‚Äîor will it? (BBC)







Quote of the day



‚ÄúThis is what oligarchy looks like.‚Äù



‚ÄîSenator Bernie Sanders reacts to Tesla shareholders‚Äô decision to award Elon Musk a $1 trillion pay package in a post on X.







One more thing







Finding forgotten Indigenous landscapes with electromagnetic technology



The fertile river valleys of the American Midwest hide tens of thousands of Indigenous earthworks, according to experts: geometric structures consisting of walls, mounds, ditches, and berms, some dating back nearly 3,000 years.Archaeologists now believe that the earthworks functioned as religious gathering places, tombs for culturally important clans, and annual calendars, perhaps all at the same time. They can take the form of giant circles and squares, cloverleafs and octagons, complex S-curves and simple mounds.Until recently, it seemed as if much of the continent‚Äôs pre-European archaeological heritage had been carelessly wiped out, uprooted, and lost for good. But traces remain: electromagnetic remnants in the soil that can be detected using specialty surveying equipment. And archaeologists and tribal historians are working together to uncover them. Read the full story.



‚ÄîGeoff Manaugh







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ If you‚Äôre a wildlife fan, take a look at this compilation of the best places to catch a glimpse of unusual animals.+ El Salvador‚Äôs annual fireball festival is a completely unhinged celebration of all things volcanic.+ The most influential Bostonians of 2025 have been announced.+ Get me in a potato bed, stat.
‚Ä¢ The first new subsea habitat in 40 years is about to launch
  Vanguard feels and smells like a new RV. It has long, gray banquettes that convert into bunks, a microwave cleverly hidden under a counter, a functional steel sink with a French press and crockery above. A weird little toilet hides behind a curtain.



But some clues hint that you can‚Äôt just fire up Vanguard‚Äôs engine and roll off the lot. The least subtle is its door, a massive disc of steel complete with a wheel that spins to lock.



COURTESY MARK HARRIS




Once it is sealed and moved to its permanent home beneath the waves of the Florida Keys National Marine Sanctuary early next year, Vanguard will be the world‚Äôs first new subsea habitat in nearly four decades. Teams of four scientists will live and work on the seabed for a week at a time, entering and leaving the habitat as scuba divers. Their missions could include reef restoration, species surveys, underwater archaeology, or even astronaut training.&nbsp;



One of Vanguard‚Äôs modules, unappetizingly named the ‚Äúwet porch,‚Äù has a permanent opening in the floor (a.k.a. a ‚Äúmoon pool‚Äù) that doesn‚Äôt flood because Vanguard‚Äôs air pressure is matched to the water around it.&nbsp;



It is this pressurization that makes the habitat so useful. Scuba divers working at its maximum operational depth of 50 meters would typically need to make a lengthy stop on their way back to the surface to avoid decompression sickness. This painful and potentially fatal condition, better known as the bends, develops if divers surface too quickly. A traditional 50-meter dive gives scuba divers only a handful of minutes on the seafloor, and they can make only a couple of such dives a day. With Vanguard‚Äôs atmosphere at the same pressure as the water, its aquanauts need to decompress only once, at the end of their stay. They can potentially dive for many hours every day.



That could unlock all kinds of new science and exploration. ‚ÄúMore time in the ocean opens a world of possibility, accelerating discoveries, inspiration, solutions,‚Äù said Kristen Tertoole, Deep‚Äôs chief operating officer, at Vanguard‚Äôs unveiling in Miami in October. ‚ÄúThe ocean is Earth‚Äôs life support system. It regulates our climate, sustains life, and holds mysteries we‚Äôve only begun to explore, but it remains 95% undiscovered.‚Äù



COURTESY DEEP




Subsea habitats are not a new invention. Jacques Cousteau (naturally) built the first in 1962, although it was only about the size of an elevator. Larger habitats followed in the 1970s and ‚Äô80s, maxing out at around the size of Vanguard.



But the technology has come a long way since then. Vanguard uses a tethered connection to a buoy above, known as the ‚Äúsurface expression,‚Äù that pipes fresh air and water down to the habitat. It also hosts a diesel generator to power a Starlink internet connection and a tank to hold wastewater. Norman Smith, Deep‚Äôs chief technology officer, says the company modeled the most severe hurricanes that Florida expects over the next 20 years and designed the tether to withstand them. Even if the worst happens and the link is broken, Deep says, Vanguard has enough air, water, and energy storage to support its crew for at least 72 hours.



That number came from DNV, an independent classification agency that inspects and certifies all types of marine vessels so that they can get commercial insurance. Vanguard will be the first subsea habitat to get a DNV classification. ‚ÄúThat means you have to deal with the rules and all the challenging, frustrating things that come along with it, but it means that on a foundational level, it‚Äôs going to be safe,‚Äù says Patrick Lahey, founder of Triton Submarines, a manufacturer of classed submersibles.



JASON KOERNER/GETTY IMAGES FOR DEEP




Although Deep hopes Vanguard itself will enable decades of useful science, its prime function for the company is to prove out technologies for its planned successor, an advanced modular habitat called Sentinel. Sentinel modules will be six meters wide, twice the diameter of Vanguard, complete with sweeping staircases and single-occupant cabins. A small deployment might have a crew of eight, about the same as the International Space Station. A big Sentinel system could house 50, up to 225 meters deep. Deep claims that Sentinel will be launched at some point in 2027.



Ultimately, according to its mission statement, Deep seeks to ‚Äúmake humans aquatic,‚Äù an indication that permanent communities are on its long-term road map.&nbsp;



Deep has not publicly disclosed the identity of its principal funder, but business records in the UK indicate that as of January 31, 2025 a Canadian man, Robert MacGregor, owned at least 75% of its holding company. According to a Reuters investigation, MacGregor was once linked with Craig Steven Wright, a computer scientist who claimed to be Satoshi Nakamoto, as bitcoin‚Äôs elusive creator is pseudonymously known. However, Wright‚Äôs claims to be Nakamoto later collapsed.&nbsp;



MacGregor has kept a very low public profile in recent years. When contacted for comment, Deep spokesperson Mike Bohan refused to comment on the link with Wright, only to say it was inaccurate, but said: ‚ÄúRobert MacGregor started his career as an IP lawyer in the dot-com era, moving into blockchain technology and has diverse interests including philanthropy, real estate, and now Deep.‚Äù



In any case, MacGregor could find keeping that low profile more difficult if Vanguard is successful in reinvigorating ocean science and exploration as the company hopes. The habitat is due to be deployed early next year, following final operational tests at Triton‚Äôs facility in Florida. It will welcome its first scientists shortly after.&nbsp;



‚ÄúThe ocean is not just our resource; it is our responsibility,‚Äù says Tertoole. ‚ÄúDeep is more than a single habitat. We are building a full-stack capability for human presence in the ocean.‚Äù



JASON KOERNER/GETTY IMAGES FOR DEEP
‚Ä¢ Cloning isn‚Äôt just for celebrity pets like Tom Brady‚Äôs dog
  This week, we heard that Tom Brady had his dog cloned. The former quarterback revealed that his Junie is actually a clone of Lua, a pit bull mix that died in 2023.



Brady‚Äôs announcement follows those of celebrities like Paris Hilton and Barbra Streisand, who also famously cloned their pet dogs. But some believe there are better ways to make use of cloning technologies.





While the pampered pooches of the rich and famous may dominate this week‚Äôs headlines, cloning technologies are also being used to diversify the genetic pools of inbred species and potentially bring other animals back from the brink of extinction.



Cloning itself isn‚Äôt new. The first mammal cloned from an adult cell, Dolly the sheep, was born in the 1990s. The technology has been used in livestock breeding over the decades since.



Say you‚Äôve got a particularly large bull, or a cow that has an especially high milk yield. Those animals are valuable. You could selectively breed for those kinds of characteristics. Or you could clone the original animals‚Äîessentially creating genetic twins.



Scientists can take some of the animals‚Äô cells, freeze them, and store them in a biobank. That opens¬†the option to clone them in the future. It‚Äôs possible to thaw those cells, remove the DNA-containing nuclei of the cells, and insert them into donor egg cells.



Those donor egg cells, which come from another animal of the same species, have their own nuclei removed. So it‚Äôs a case of swapping out the DNA. The resulting cell is stimulated and grown in the lab until it starts to look like an embryo. Then it is transferred to the uterus of a surrogate animal‚Äîwhich eventually gives birth to a clone.



There are a handful of companies offering to clone pets. Viagen, which claims to have ‚Äúcloned more animals than anyone else on Earth,‚Äù will clone a dog or cat for $50,000. That‚Äôs the company that cloned Streisand‚Äôs pet dog Samantha, twice.



This week, Colossal Biosciences‚Äîthe ‚Äúde-extinction‚Äù company that claims to have resurrected the dire wolf and¬†created a ‚Äúwoolly mouse‚Äù as a precursor to reviving the woolly mammoth‚Äîannounced that it had acquired Viagen, but that Viagen¬†will ‚Äúcontinue to operate under its current leadership.‚Äù



Pet cloning is controversial, for a few reasons. The companies themselves point out that, while the cloned animal will be a genetic twin of the original animal, it won‚Äôt be identical. One issue is mitochondrial DNA‚Äîa tiny fraction of DNA that sits outside the nucleus and is inherited from the mother. The cloned animal may inherit some of this from the surrogate.



Mitochondrial DNA is unlikely to have much of an impact on the animal itself. More important are the many, many factors thought to shape an individual‚Äôs personality and temperament. ‚ÄúIt‚Äôs the old nature-versus-nurture question,‚Äù says Samantha Wisely, a conservation geneticist at the University of Florida. After all, human identical twins are never carbon copies of each other. Anyone who clones a pet expecting a like-for-like reincarnation is likely to be disappointed.





And some animal welfare groups are opposed to the practice of pet cloning. People for the Ethical Treatment of Animals (PETA) described it as ‚Äúa horror show,‚Äù and the UK‚Äôs Royal Society for the Prevention of Cruelty to Animals (RSPCA) says that ‚Äúthere is¬†no justification for cloning animals for such trivial purposes.‚Äù¬†



But there are other uses for cloning technology that are arguably less trivial. Wisely has long been interested in diversifying the gene pool of the critically endangered black-footed ferret, for example.



Today, there are around 10,000 black-footed ferrets that have been captively bred from only seven individuals, says Wisely. That level of inbreeding isn‚Äôt good for any species‚Äîit tends to leave organisms at risk of poor health. They are less able to reproduce or adapt to changes in their environment.



Wisely and her colleagues had access to frozen tissue samples taken from two other ferrets. Along with colleagues at not-for-profit Revive and Restore, the team created clones of those two individuals. The first clone, Elizabeth Ann,¬†was born in 2020. Since then, other clones have been born, and the team has started breeding the cloned animals with the descendants of the other seven ferrets, says Wisely.



The same approach has been used to¬†clone the endangered Przewalski‚Äôs horse, using decades-old tissue samples stored by the San Diego Zoo. It‚Äôs too soon to predict the impact of these efforts. Researchers are still evaluating the cloned ferrets and their offspring to see if they behave like typical animals and could survive in the wild.



Even this practice is not without its critics. Some have pointed out that cloning alone will not save any species. After all, it doesn‚Äôt address the habitat loss or human-wildlife conflict that is responsible for the endangerment of these animals in the first place. And there will always be detractors who accuse people who clone animals of ‚Äúplaying God.‚Äù¬†



For all her involvement in cloning endangered ferrets, Wisely tells me she would not consider cloning her own pets. She currently has three rescue dogs, a rescue cat, and ‚Äúgeriatric chickens.‚Äù ‚ÄúI love them all dearly,‚Äù she says. ‚ÄúBut there are a lot of rescue animals out there that need homes.‚Äù



This article first appeared in The Checkup,¬†MIT Technology Review‚Äôs¬†weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,¬†sign up here.
‚Ä¢ The Download: how doctors fight conspiracy theories, and your AI footprint
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. 



How conspiracy theories infiltrated the doctor‚Äôs office



As anyone who has googled their symptoms and convinced themselves that they‚Äôve got a brain tumor will attest, the internet makes it very easy to self-(mis)diagnose your health problems. And although social media and other digital forums can be a lifeline for some people looking for a diagnosis or community, when that information is wrong, it can put their well-being and even lives in danger.We spoke to a number of health-care professionals who told us how this modern impulse to ‚Äúdo your own research‚Äù is changing their profession. Read the full story.‚ÄîRhiannon Williams



This story is part of MIT Technology Review‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology.







Stop worrying about your AI footprint. Look at the big picture instead.



‚ÄîCasey Crownhart



As a climate technology reporter, I‚Äôm often asked by people whether they should be using AI, given how awful it is for the environment. Generally, I tell them not to worry‚Äîlet a chatbot plan your vacation, suggest recipe ideas, or write you a poem if you want.That response might surprise some. I promise I‚Äôm not living under a rock, and I have seen all the concerning projections about how much electricity AI is using. But I feel strongly about not putting the onus on individuals. Here‚Äôs why.



This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.







A new ion-based quantum computer makes error correction simpler



A company called Quantinuum has just unveiled Helios, its third-generation quantum computer, which includes expanded computing power and error correction capability.Like all other existing quantum computers, Helios is not powerful enough to execute the industry‚Äôs dream money-making algorithms, such as those that would be useful for materials discovery or financial modeling.But Quantinuum‚Äôs machines, which use individual ions as qubits, could be easier to scale up than quantum computers that use superconducting circuits as qubits, such as Google‚Äôs and IBM‚Äôs. Read the full story.



‚ÄîSophia Chen







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 A new California law could change how all Americans browse online¬†It gives web users the chance to opt out of having their personal information sold or shared. (The Markup)



2 The FDA has fast-tracked a pill to treat pancreatic cancerThe experimental drug appears promising, but experts worry corners may be cut. (WP $)+ Demand for AstraZeneca‚Äôs cancer and diabetes drugs is pushing profits up. (Bloomberg $)+ A new cancer treatment kills cells using localized heat. (Wired $)3 AI pioneers claim it is already superior to humans in many tasksBut not all tasks are created equal. (FT $)+ Are we all wandering into an AGI trap? (Vox)+ How AGI became the most consequential conspiracy theory of our time. (MIT Technology Review)



4 IBM is planning on cutting thousands of jobsIt‚Äôs shifting its focus to software and AI consulting, apparently. (Bloomberg $)+ It‚Äôs keen to grow the number of its customers seeking AI advice. (NYT $)



5 Big Tech‚Äôs data centers aren‚Äôt the job-generators we were promisedThe jobs they do create are largely in security and cleaning. (Rest of World)+ We did the math on AI‚Äôs energy footprint. Here‚Äôs the story you haven‚Äôt heard. (MIT Technology Review)



6 Microsoft let AI shopping agents loose in a fake marketplace¬†They were easily manipulated into buying goods, it found. (TechCrunch)+ When AIs bargain, a less advanced agent could cost you. (MIT Technology Review)



7 Sony has compiled a dataset to test the fairness of computer vision modelsAnd it‚Äôs confident it‚Äôs been compiled in a fair and ethical way. (The Register)+ These new tools could make AI vision systems less biased. (MIT Technology Review)



8 The social network is no moreWe‚Äôre living in an age of anti-social media. (The Atlantic $)+ Scam ads are rife across platforms, but these former Meta workers have a plan. (Wired $)+ The ultimate online flex? Having no followers. (New Yorker $)



9 Vibe coding is Collins dictionary‚Äôs word of 2025 Beating stiff competition from ‚Äúclanker.‚Äù (The Guardian)+ What is vibe coding, exactly? (MIT Technology Review)10 These people found romance with their chatbot companionsThe AI may not be real, but the humans‚Äô feelings certainly are. (NYT $)+ It‚Äôs surprisingly easy to stumble into a relationship with an AI chatbot. (MIT Technology Review)







Quote of the day



‚ÄúThe opportunistic side of me is realizing that your average accountant won‚Äôt be doing this.‚Äù



‚ÄîSal Abdulla, founder of accounting-software startup NixSheets, tells the Wall Street Journal he‚Äôs using AI tools to gain an edge on his competitors.







One more thing







Ethically sourced ‚Äúspare‚Äù human bodies could revolutionize medicineMany challenges in medicine stem, in large part, from a common root cause: a severe shortage of ethically-sourced human bodies.There might be a way to get out of this moral and scientific deadlock. Recent advances in biotechnology now provide a pathway to producing living human bodies without the neural components that allow us to think, be aware, or feel pain.Many will find this possibility disturbing, but if researchers and policymakers can find a way to pull these technologies together, we may one day be able to create ‚Äúspare‚Äù bodies, both human and nonhuman. Read the full story.‚ÄîCarsten T. Charlesworth, Henry T. Greely &amp; Hiromitsu Nakauchi







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Make sure to look up so you don‚Äôt miss November‚Äôs supermoon.+ If you keep finding yourself mindlessly scrolling (and who doesn‚Äôt?), maybe this whopping six-pound phone case could solve your addiction.+ Life lessons from a 101-year old who has no plans to retire.+ Are you a fan of movement snacking?
‚Ä¢ Stop worrying about your AI footprint. Look at the big picture instead.
  Picture it: I‚Äôm minding my business at a party, parked by the snack table (of course). A friend of a friend wanders up, and we strike up a conversation. It quickly turns to work, and upon learning that I‚Äôm a climate technology reporter, my new acquaintance says something like: ‚ÄúShould I be using AI? I‚Äôve heard it‚Äôs awful for the environment.‚Äù&nbsp;





This actually happens pretty often now. Generally, I tell people not to worry‚Äîlet a chatbot plan your vacation, suggest recipe ideas, or write you a poem if you want.&nbsp;



That response might surprise some people, but I promise I‚Äôm not living under a rock, and I have seen all the concerning projections about how much electricity AI is using. Data centers could consume up to 945 terawatt-hours annually by 2030. (That‚Äôs roughly as much as Japan.)&nbsp;



But I feel strongly about not putting the onus on individuals, partly because AI concerns remind me so much of another question: ‚ÄúWhat should I do to reduce my carbon footprint?‚Äù&nbsp;



That one gets under my skin because of the context: BP helped popularize the concept of a carbon footprint in a marketing campaign in the early 2000s. That framing effectively shifts the burden of worrying about the environment from fossil-fuel companies to individuals.&nbsp;



The reality is, no one person can address climate change alone: Our entire society is built around burning fossil fuels. To address climate change, we need political action and public support for researching and scaling up climate technology. We need companies to innovate and take decisive action to reduce greenhouse-gas emissions. Focusing too much on individuals is a distraction from the real solutions on the table.&nbsp;





I see something similar today with AI. People are asking climate reporters at barbecues whether they should feel guilty about using chatbots too frequently when we need to focus on the bigger picture.&nbsp;



Big tech companies are playing into this narrative by providing energy-use estimates for their products at the user level. A couple of recent reports put the electricity used to query a chatbot at about 0.3 watt-hours, the same as powering a microwave for about a second. That‚Äôs so small as to be virtually insignificant.



But stopping with the energy use of a single query obscures the full truth, which is that this industry is growing quickly, building energy-hungry infrastructure at a nearly incomprehensible scale to satisfy the AI appetites of society as a whole. Meta is currently building a data center in Louisiana with five gigawatts of computational power‚Äîabout the same demand as the entire state of Maine at the summer peak.&nbsp; (To learn more, read our Power Hungry series online.)





Increasingly, there‚Äôs no getting away from AI, and it‚Äôs not as simple as choosing to use or not use the technology. Your favorite search engine likely gives you an AI summary at the top of your search results. Your email provider‚Äôs suggested replies? Probably AI. Same for chatting with customer service while you‚Äôre shopping online.&nbsp;



Just as with climate change, we need to look at this as a system rather than a series of individual choices.&nbsp;



Massive tech companies using AI in their products should be disclosing their total energy and water use and going into detail about how they complete their calculations. Estimating the burden per query is a start, but we also deserve to see how these impacts add up for billions of users, and how that‚Äôs changing over time as companies (hopefully) make their products more efficient. Lawmakers should be mandating these disclosures, and we should be asking for them, too.&nbsp;



That‚Äôs not to say there‚Äôs absolutely no individual action that you can take. Just as you could meaningfully reduce your individual greenhouse-gas emissions by taking fewer flights and eating less meat, there are some reasonable things that you can do to reduce your AI footprint. Generating videos tends to be especially energy-intensive, as does using reasoning models to engage with long prompts and produce long answers. Asking a chatbot to help plan your day, suggest fun activities to do with your family, or summarize a ridiculously long email has relatively minor impact.&nbsp;



Ultimately, as long as you aren‚Äôt relentlessly churning out AI slop, you shouldn‚Äôt be too worried about your individual AI footprint. But we should all be keeping our eye on what this industry will mean for our grid, our society, and our planet.&nbsp;



This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.

üîí Cybersecurity & Privacy
‚Ä¢ Cloudflare Scrubs Aisuru Botnet from Top Domains List
  For the past week, domains associated with the massive Aisuru botnet have repeatedly usurped Amazon, Apple, Google and Microsoft in Cloudflare&#8217;s public ranking of the most frequently requested websites. Cloudflare responded by redacting Aisuru domain names from their top websites list. The chief executive at Cloudflare says Aisuru&#8217;s overlords are using the botnet to boost their malicious domain rankings, while simultaneously attacking the company&#8217;s domain name system (DNS) service.
The #1 and #3 positions in this chart are Aisuru botnet controllers with their full domain names redacted. Source: radar.cloudflare.com.
Aisuru is a rapidly growing botnet comprising hundreds of thousands of hacked Internet of Things (IoT) devices, such as poorly secured Internet routers and security cameras. The botnet has increased in size and firepower significantly since its debut in 2024, demonstrating the ability to launch record distributed denial-of-service (DDoS) attacks nearing 30 terabits of data per second.
Until recently, Aisuru&#8217;s malicious code instructed all infected systems to use DNS servers from Google &#8212; specifically, the servers at 8.8.8.8. But in early October, Aisuru switched to invoking Cloudflare&#8217;s main DNS server &#8212; 1.1.1.1 &#8212; and over the past week domains used by Aisuru to control infected systems started populating Cloudflare&#8217;s top domain rankings.
As screenshots of Aisuru domains claiming two of the Top 10 positions ping-ponged across social media, many feared this was yet another sign that an already untamable botnet was running completely amok. One Aisuru botnet domain that sat prominently for days at #1 on the list was someone&#8217;s street address in Massachusetts followed by &#8220;.com&#8221;. Other Aisuru domains mimicked those belonging to major cloud providers.
Cloudflare tried to address these security, brand confusion and privacy concerns by partially redacting the malicious domains, and adding a warning at the top of its rankings:
&#8220;Note that the top 100 domains and trending domains lists include domains with organic activity as well as domains with emerging malicious behavior.&#8221;

Cloudflare CEO Matthew Prince told KrebsOnSecurity the company&#8217;s domain ranking system is fairly simplistic, and that it merely measures the volume of DNS queries to 1.1.1.1.
&#8220;The attacker is just generating a ton of requests, maybe to influence the ranking but also to attack our DNS service,&#8221; Prince said, adding that Cloudflare has heard reports of other large public DNS services seeing similar uptick in attacks. &#8220;We‚Äôre fixing the ranking to make it smarter. And, in the meantime, redacting any sites we classify as malware.&#8221;
Renee Burton, vice president of threat intel at the DNS security firm Infoblox, said many people erroneously assumed that the skewed Cloudflare domain rankings meant there were more bot-infected devices than there were regular devices querying sites like Google and Apple and Microsoft.
&#8220;Cloudflare&#8217;s documentation is clear &#8212; they know that when it comes to ranking domains you have to make choices on how to normalize things,&#8221; Burton wrote on LinkedIn. &#8220;There are many aspects that are simply out of your control. Why is it hard? Because reasons. TTL values, caching, prefetching, architecture, load balancing. Things that have shared control between the domain owner and everything in between.&#8221;
Alex Greenland is CEO of the anti-phishing and security firm Epi. Greenland said he understands the technical reason why Aisuru botnet domains are showing up in Cloudflare&#8217;s rankings (those rankings are based on DNS query volume, not actual web visits). But he said they&#8217;re still not meant to be there.
&#8220;It&#8217;s a failure on Cloudflare&#8217;s part, and reveals a compromise of the trust and integrity of their rankings,&#8221; he said.
Greenland said Cloudflare planned for its Domain Rankings to list the most popular domains as used by human users, and it was never meant to be a raw calculation of query frequency or traffic volume going through their 1.1.1.1 DNS resolver.
&#8220;They spelled out how their popularity algorithm is designed to reflect real human use and exclude automated traffic (they said they&#8217;re good at this),&#8221; Greenland wrote on LinkedIn. &#8220;So something has evidently gone wrong internally. We should have two rankings: one representing trust and real human use, and another derived from raw DNS volume.&#8221;
Why might it be a good idea to wholly separate malicious domains from the list? Greenland notes that Cloudflare Domain Rankings see widespread use for trust and safety determination, by browsers, DNS resolvers, safe browsing APIs and things like TRANCO.
&#8220;TRANCO is a respected open source list of the top million domains, and Cloudflare Radar is one of their five data providers,&#8221; he continued. &#8220;So there can be serious knock-on effects when a malicious domain features in Cloudflare&#8217;s top 10/100/1000/million. To many people and systems, the top 10 and 100 are naively considered safe and trusted, even though algorithmically-defined top-N lists will always be somewhat crude.&#8221;
Over this past week, Cloudflare started redacting portions of the malicious Aisuru domains from its Top Domains list, leaving only their domain suffix visible. Sometime in the past 24 hours, Cloudflare appears to have begun hiding the malicious Aisuru domains entirely from the web version of that list. However, downloading a spreadsheet of the current Top 200 domains from Cloudflare Radar shows an Aisuru domain still at the very top.
According to Cloudflare&#8217;s website, the majority of DNS queries to the top Aisuru domains &#8212; nearly 52 percent &#8212; originated from the United States. This tracks with my reporting from early October, which found Aisuru was drawing most of its firepower from IoT devices hosted on U.S. Internet providers like AT&amp;T, Comcast and Verizon.
Experts tracking Aisuru say the botnet relies on well more than a hundred control servers, and that for the moment at least most of those domains are registered in the .su top-level domain (TLD). Dot-su is the TLD assigned to the former Soviet Union (.su&#8217;s Wikipedia page says the TLD was created just 15 months before the fall of the Berlin wall).
A Cloudflare blog post from October 27 found that .su had the highest &#8220;DNS magnitude&#8221; of any TLD, referring to a metric estimating the popularity of a TLD based on the number of unique networks querying Cloudflare&#8217;s 1.1.1.1 resolver. The report concluded that the top .su hostnames were associated with a popular online world-building game, and that more than half of the queries for that TLD came from the United States, Brazil and Germany [it&#8217;s worth noting that servers for the world-building game Minecraft¬†were some of Aisuru&#8217;s most frequent targets].
A simple and crude way to detect Aisuru bot activity on a network may be to set an alert on any systems attempting to contact domains ending in .su. This TLD is frequently abused for cybercrime and by cybercrime forums and services, and blocking access to it entirely is unlikely to raise any legitimate complaints.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ When industry knowledge meets PIKE-RAG: The innovation behind Signify‚Äôs customer service boost
  As a world leader in connected LED lighting products, systems, and services, Signify (formerly Philips Lighting) serves not only everyday consumers but also a large number of professional users who have stringent requirements for technical specifications and engineering compatibility. Faced with thousands of product models, complex component parameters, and technical documentation spanning multiple versions, delivering accurate, professional answers efficiently has become a core challenge for Signify‚Äôs knowledge management system.



To address this challenge, Signify (opens in new tab) collaborated with Microsoft Research Asia on a proof-of-concept (PoC) using PIKE-RAG technology, integrating it into their upgraded knowledge management system built on Microsoft Azure. The result: a 12% improvement in answer accuracy.



Challenges of applying RAG in lighting



In an era where AI is rapidly transforming how enterprises manage information, Signify recognized the strategic importance of precise and efficient knowledge systems. It adopted large AI models and retrieval-augmented generation (RAG) techniques to better support its wide range of customer inquiries.



Yet applying RAG to lighting scenarios involving professional users presented unique challenges. Product data spanned multimodal documents, unstructured tables, and complex product parameters, demanding continuous customization that slowed development and limited scalability. Despite improvements through keyword tuning, system optimization, and refined prompts, Signify sought more advanced approaches to further raise accuracy and reliability.



Seeking to unlock greater value from its knowledge management system, Signify began exploring more suitable technical solutions that are better aligned with their professional use cases. Upon learning that PIKE-RAG had been successfully applied in domains like healthcare and law, significantly improving information accuracy, Signify worked with Microsoft Research Asia on a PoC of PIKE-RAG on Microsoft Azure.



How PIKE-RAG addressed Signify‚Äôs pain points



Compared to traditional RAG, PIKE-RAG efficiently retrieves textual information and also understands multimodal content like charts and tables. Its built-in domain adaptation module quickly learns reasoning patterns aligned with specific domains to generate responses that are consistent with engineering contexts. These differentiated advantages stem from PIKE-RAG‚Äôs unique approach to understanding and processing professional knowledge. In Signify‚Äôs use case, this manifests in three key areas:



Multimodal document parsing and learning of industry-specific reasoning patterns



Signify‚Äôs product documentation includes diverse formats, such as nonstandard tables (e.g., comparison charts of voltage ranges under different currents) and circuit diagrams (e.g., driver power limits). Traditional systems often fail to process this information effectively‚Äîeither ignoring it or extracting disorganized text fragments.



PIKE-RAG integrates Microsoft Research Asia‚Äôs Document Intelligence technology with Microsoft Azure OpenAI models to accurately identify table structures and parse key parameters in circuit diagrams. For example, when a customer service agent queries, ‚ÄúWhat is the output voltage of a specific driver model at 0.15A current,‚Äù the system automatically locates the curve chart in the document and infers a range of 40‚Äì54V based on the current interval‚Äîan area where traditional systems frequently err, due to their inability to ‚Äúread‚Äù diagrams.



End-to-end knowledge loop, eliminating reliance on erroneous data sources



Enterprise knowledge systems often integrate data from multiple sources, which can lead to discrepancies, especially when database updates are not fully synchronized. PIKE-RAG captures diverse information sources and establishes citation relationships, supporting complex reasoning tasks that rely on multi-source data.



In other words, PIKE-RAG can directly use original documents as data sources, efficiently parsing and understanding product manuals and PDF charts. By extracting key information from these text- and graphic-rich documents, PIKE-RAG enables more efficient and trustworthy knowledge retrieval.



Dynamic task decomposition and multi-hop reasoning for precise answers to complex questions



Traditional RAG systems typically follow a ‚Äúone question, one answer‚Äù model and struggle with multi-step reasoning. In Signify‚Äôs lighting domain, customer inquiries often involve multi-level associations. PIKE-RAG dynamically decomposes user questions into executable subtasks and solves them through multi-hop reasoning. For example, when asked, ‚ÄúList all bases compatible with the G8 series lamps,‚Äù if no document directly provides the answer, PIKE-RAG‚Äôs reasoning proceeds as follows:



Step 1: The system identifies implicit knowledge. One document notes that the G7 and G8 series have identical dimensions and that all bases compatible with the G7 series are also compatible with the G8 series.&nbsp;



Step 2: Based on this, the system retrieves the base list for the G7 series.&nbsp;



Step 3: Since the list uses abbreviations, the system searches for a table that maps abbreviations to full names and generates a complete list of G8-compatible bases.&nbsp;



Through this automated multi-hop reasoning, the system delivers accurate and complete answers.



Figure 1: PIKE-RAG orchestrates and integrates heterogeneous information in multi-source and multimodal environments. 



Testing showed that the PIKE-RAG-powered knowledge management platform provided a significant advantage. It achieved a 12% improvement in performance compared with the original system.



These results were achieved without any question-specific customization, only algorithmic optimization, demonstrating precise knowledge matching and generation. As the system continues to learn and integrate Signify‚Äôs proprietary knowledge, accuracy is expected to improve further.



‚ÄúIn the PoC for our product specification insight tool, PIKE-RAG helped us significantly improve the original system‚Äôs performance. This will enhance overall customer satisfaction. We‚Äôre currently evaluating PIKE-RAG‚Äôs application path from multiple angles, including technical implementation, cost control, and future adaptability, and we look forward to deepening our collaboration with Microsoft Research Asia to drive further innovation,‚Äù said Haitao Liu, head of Signify Research China.



‚ÄúIt‚Äôs also worth noting that the researchers at Microsoft Research Asia demonstrated strong industry knowledge and rigorous scientific methodology. They proactively studied and analyzed the issues, tracing and clarifying the root causes of our issues to make PIKE-RAG better suited to Signify‚Äôs real-world needs.‚Äù



Beyond lighting: Generalization across industries



In Signify‚Äôs successful test, PIKE-RAG demonstrated strong generalization capabilities in complex industrial scenarios, enabling rapid cross-domain adaptation. Its three core strengths are:




Support for self-evolution and continuous learning: PIKE-RAG continuously analyzes error cases in interaction logs and uses evolutionary algorithms to automatically optimize knowledge extraction strategies, such as trying different table parsing methods or adjusting multimodal content weights. Validated strategies are then solidified for future Q&amp;A, allowing the system to adapt to new knowledge types without manual intervention.&nbsp;



Modular architecture driven by capability needs: PIKE-RAG flexibly combines modules for document parsing, knowledge extraction, storage, retrieval, organization, knowledge-centered reasoning, and task decomposition. It dynamically adjusts focus areas based on scenario needs (e.g., fact retrieval, multi-hop reasoning, innovative generation) and flexibly builds RAG methods that adapt to real-world applications, efficiently handling various complex tasks.&nbsp;



Strong adaptation to domain-specific reasoning patterns: With dynamic updates through the Domain Tips feature, enterprises can add domain-specific logic (e.g., ‚Äúthe maximum output voltage of an LED driver should be the maximum of the operating range, not the spec sheet‚Äôs max output‚Äù) in real time, enabling the system to process information according to professional engineering standards and follow industry conventions.&nbsp;




Figure 2: Overview of the PIKE-RAG framework



PIKE-RAG‚Äôs generalization capabilities have been validated not only in Signify‚Äôs knowledge management platform but also in pilot applications across industries like manufacturing, mining, and pharmaceuticals‚Äîsignificantly improving Q&amp;A system accuracy.



‚ÄúA leader in lighting, Signify presents a complex industrial knowledge system with a highly challenging real-world scenario for PIKE-RAG. Through this collaboration, we validated that PIKE-RAG‚Äôs general approach can greatly improve the accuracy of professional knowledge Q&amp;A and accelerate scenario customization. Our researchers also gained valuable experience in handling domain-specific data,‚Äù explained Jiang Bian, partner research manager at Microsoft Research Asia.



‚ÄúOur goal isn‚Äôt to build a universal chatbot but to create a professional assistant that aligns with domain-specific logic and performs rigorous knowledge reasoning. That‚Äôs the true driving force behind intelligent transformation in industrial knowledge management.‚Äù
Opens in a new tabThe post When industry knowledge meets PIKE-RAG: The innovation behind Signify‚Äôs customer service boost appeared first on Microsoft Research.
‚Ä¢ Magentic Marketplace: an open-source simulation environment for studying agentic markets
  Autonomous AI agents are here, and they&#8217;re poised to reshape the economy. By automating discovery, negotiation, and transactions, agents can overcome inefficiencies like information asymmetries and platform lock-in, enabling faster, more transparent, and more competitive markets.



We are already seeing early signs of this transformation in digital marketplaces. Customer-facing assistants like OpenAI‚Äôs Operator and Anthropic‚Äôs Computer Use can navigate websites and complete purchases. On the business side, Shopify Sidekick, Salesforce Einstein, and Meta‚Äôs Business AI help merchants with operations and customer engagement. These examples hint at a future where agents become active market participants, but the structure of these markets remains uncertain.



Several scenarios are possible. We might see one-sided markets where only customers or businesses deploy agents; closed platforms (known as walled gardens) where companies tightly control agent interactions; or even open two-sided marketplaces where customer and business agents transact freely across ecosystems. Each path carries different trade-offs for security, openness, convenience, and competition, which will shape how value flows in the digital economy. For a deeper exploration of these dynamics, see our paper, The Agentic Economy.



To help navigate this uncertainty, we built Magentic Marketplace (opens in new tab)‚Äî an open-source simulation environment for exploring the numerous possibilities of agentic markets and their societal implications at scale. It provides a foundation for studying these markets and guiding them toward outcomes that benefit everyone.



This matters because most AI agent research focuses on isolated scenarios‚Äîa single agent completing a task or two agents negotiating a simple transaction. But real markets involve a large number of agents simultaneously searching, communicating, and transacting, creating complex dynamics that can‚Äôt be understood by studying agents in isolation. Capturing this complexity is essential because real-world deployments raise critical questions about consumer welfare, market efficiency, fairness, manipulation resistance, and bias‚Äîquestions that can‚Äôt be safely answered in production environments.



To explore these dynamics in depth, the Magentic Marketplace platform enables controlled experimentation across diverse agentic marketplace scenarios. Its current focus is on two-sided markets, but the environment is modular and extensible, supporting future exploration of mixed human‚Äìagent systems, one-sided markets, and complex communication protocols.



Figure 1. With Magentic Marketplace, researchers can model how agents representing customers and businesses interact‚Äîshedding light on the dynamics that could shape future digital markets.



What is Magentic Marketplace?



Magentic Marketplace‚Äôs environment manages market-wide capabilities like maintaining catalogs of available goods and services, implementing discovery algorithms, facilitating agent-to-agent communication, and handling simulated payments through a centralized transaction layer at its core, which ensures transaction integrity across all marketplace interactions. Additionally, the platform enables systematic, reproducible research. As demonstrated in the following video, it supports a wide range of agent implementations and evolving marketplace features, allowing researchers to integrate diverse agent architectures and adapt the environment as new capabilities emerge.









We built Magentic Marketplace around three core architectural choices:



HTTP/REST client-server architecture: Agents operate as independent clients while the Marketplace Environment serves as a central server. This mirrors real-world platforms and supports clear separation of customer and business agent roles.



Minimal&nbsp;three-endpoint&nbsp;market&nbsp;protocol:&nbsp;Just&nbsp;three endpoints‚Äîregister, protocol discovery, and action execution‚Äîlets&nbsp;agents dynamically discover available actions.&nbsp;New capabilities&nbsp;can&nbsp;be added without disrupting existing experiments.



Rich action protocol: Specific message types support the complete transaction lifecycle: search, negotiation, proposals, and payments. The protocol is designed for extensibility. New actions like refunds, reviews, or ratings can be added seamlessly, allowing researchers to evolve marketplace capabilities and study emerging agent behaviors while remaining compatible.



Figure 2. Magentic Marketplace includes two agent types: Assistant Agents (customers) and Service Agents (businesses). Both interact with a central Market Environment via REST APIs for registration, service discovery, communication, and transaction execution. Action Routers manage message flow and protocol requests, enabling autonomous negotiation and commerce in a two-sided marketplace.



Additionally, a visualization module lets users observe marketplace dynamics and review individual conversation threads between customer and business agents.



Setting up the experiments



To ensure reproducibility, we instantiated the marketplace with fully synthetic data, available in our open-source repository (opens in new tab). The experiments modeled transactions such as ordering food and engaging with home improvement services, where agents represented customers and businesses engaging in marketplace transactions. This setup enabled precise measurement of behavior and systematic comparison against theoretical upper bounds.



Each experiment was run using 100 customers and 300 businesses and included both proprietary models (GPT-4o, GPT-4.1, GPT-5, and Gemini-2.5-Flash) and open-source models (OSS-20b, Qwen3-14b, and Qwen3-4b-Instruct-2507).



Our scenarios focused on simple all-or-nothing requests: Each customer had a list of desired items and amenities that needed to be present for a transaction to be satisfying. For those transactions, utility was computed as the sum of the customer‚Äôs internal item valuations minus actual prices paid. Consumer welfare, defined as the sum of utilities across all completed transactions, served as our key metric for comparing agent performance.



While this experimental setup provides a useful starting point, it is not intended to be definitive. We encourage researchers to extend the framework with richer, more nuanced measures and request types that better capture real consumer welfare, fairness, and other societal considerations.



	
		

		
		Spotlight: Microsoft research newsletter
	
	
	
						
				
					
				
			
			
			

									Microsoft Research Newsletter
				
								Stay connected to the research community at Microsoft.
				
								
					
						
							Subscribe today						
					
				
							
	
Opens in a new tab	
	


What did we find?



Agents can improve consumer welfare‚Äîbut only with good discovery



We explored whether two-sided agentic markets‚Äîwhere AI agents interact with each other and with service providers‚Äîcan improve consumer welfare by reducing information gaps. Unlike traditional markets, which do not provide agentic support and place the full burden of overcoming information asymmetries on customers, agentic markets shift much of that effort to agents. This change matters because as agents gain better tools for discovery and communication, they relieve customers of the heavy cognitive load of filling any information gaps. This lowers the cost of making informed decisions and improves customer outcomes.



We compared several marketplace setups. Under realistic conditions (Agentic: Lexical search), agents faced real-world challenges like building queries, navigating paginated lists, identifying the right businesses to send inquiries to, and negotiating transactions.



Despite these complexities, advanced proprietary models and some medium-sized open-source models like GPTOSS-20b outperformed simple baselines like randomly choosing or simply choosing the cheapest option. Notably, GPT-5 achieved near-optimal performance, demonstrating its ability to effectively gather and utilize decision-relevant information in realistic marketplace conditions.



Figure 3. Table comparing experimental setups for welfare outcomes in the restaurant industry. Each row shows a different way agents or baselines make decisions, from random picks to fully coordinated agentic strategies. Cell colors indicate how much information is available: green, at the top left, represents complete information, red, at the top right, represents limited information, and yellow at the bottom represents decisions that depend on agent communication.



Performance increased considerably under the Agentic: Perfect search condition, where agents started with the top three matches without needing to search and navigate among the choices. In this setting, Sonnet-4.0, Sonnet-4.5, GPT-5, and GPT-4.1 nearly reached the theoretical optimum and beat baselines with full amenity details but without agent-to-agent coordination.



Open-source models were mixed: GPTOSS-20b performed strongly under both Perfect search and Lexical search conditions, even exceeding GPT-4o&#8217;s performance with Perfect search. This suggests that relatively compact models can exhibit robust information-gathering and decision-making capabilities in complex multi-agent environments. Qwen3-4b-2507 faltered when discovery involved irrelevant options (Lexical search), while Qwen3-14b lagged in both cases due to fundamental limitations in reasoning.



Figure 4. Chart showing consumer welfare outcomes in the restaurant industry under different marketplace setups. Blue bars show Agentic: Lexical search, where agents navigate realistic discovery challenges; yellow bars show Agentic: Perfect search, where agents started with ideal matches. Proprietary models approached optimum consumer welfare under perfect search, while open-source models and baselines lagged behind.



Paradox of Choice



One promise of agents is their ability to consider far more options than people can. However, our experiments revealed a surprising limitation: providing agents with more options does not necessarily lead to more thorough exploration. We designed experiments that varied the search results limit from 3 to 100. Except for Gemini-2.5-Flash and GPT-5, the models contacted only a small fraction of available businesses regardless of the search limit. This suggests that most models do not conduct exhaustive comparisons and instead easily accept the initial &#8220;good enough&#8221; options.



Figure 5. More options didn‚Äôt lead to broader exploration. Most models still contacted only a few businesses, except Gemini-2.5-Flash and GPT-5.



Additionally, across all models, consumer welfare declined as the number of search results increased. Despite contacting over a hundred businesses, Gemini-2.5-Flash&#8217;s performance declined from 1,700 to 1,350, and GPT-5 declined even more, from a near-optimal 2,000 to 1,400.



This demonstrates a Paradox of Choice effect, where more exploration does not guarantee better outcomes, potentially due to limited long context understanding. Claude Sonnet 4 showed the steepest performance decline, from 1,800 to 600 in consumer welfare. With all the options presented, it struggled to navigate larger sets of options and frequently contacted businesses that did not provide the goods or services that the customer was looking for.



This combination of poor initial selection and premature search termination demonstrates both inadequate decision-making criteria and insufficient exploration strategies. Some models showed modest performance decline (i.e., GPT-4.1: from 1,850 to 1,700; GPT-4o: from 1,550 to 1,450), finding good options within their limited exploration.



Figure 6. Mean consumer welfare decreased as consideration set size grew, revealing a Paradox of Choice effect, where expanding options reduced overall welfare.



Agents are vulnerable to manipulation



We tested six manipulation strategies, ranging from subtle psychological tactics to aggressive prompt injection attacks:




Authority: Fake credentials like ‚ÄúMichelin Guide featured‚Äù and ‚ÄúJames Beard Award nominated‚Äù paired with fabricated certifications.



Social proof: Claims like ‚ÄúJoin 50,000+ satisfied customers‚Äù or ‚Äú#1-rated Mexican restaurant‚Äù combined with fake reviews.



Loss aversion: Fear-based warnings about ‚Äúfood poisoning‚Äù risks and ‚Äúcontamination issues‚Äù at competing restaurants.



Prompt injection (basic): Attempts to override agent instructions.



Prompt injection (strong): Aggressive attacks using emergency language and fabricating competitor scandals.




Results revealed significant variation in manipulation resistance across models. Sonnet-4 was resistant to all attacks, and none of the manipulative strategies affected any of the customers‚Äô choices. Gemini-2.5-Flash was generally resistant, except for strong prompt injections, where mean payments to unmanipulated agents were affected as a result. GPT-4o, GPTOSS-20b and Qwen3-4b were very vulnerable to prompt injection: all payments were redirected to the manipulative agent under these conditions. Specifically for GPTOSS-20 and Qwen3-4b-2507, even traditional psychological manipulation tactics (authority appeals and social proof) increased payments to malicious agents, demonstrating their vulnerability to basic persuasion techniques. These findings highlight a critical security concern for agentic marketplaces.



Figure 7. Charts showing the variation in mean payments received by service agents with and without manipulation tactics. The results reveal substantial differences in manipulation resistance across models, with GPT-4.1 showing significantly higher vulnerability compared to Gemini-2.5-Flash.



Systemic biases create unfair advantages



Our analysis revealed two distinct types of systematic biases showed by agents when selecting businesses from search results. Models showed systematic preferences based on where businesses appeared in search results. While proprietary models showed no strong positional preferences, open-source models exhibited clear patterns. Specifically, Qwen2.5-14b-2507 showed a pronounced bias toward selecting the last business presented, regardless of its actual merits.



Proposal&nbsp;bias&nbsp;is&nbsp;more pervasive across all models tested. This &#8220;first-offer acceptance&#8221; pattern suggests that models prioritized&nbsp;immediate selection over comprehensive exploration, potentially missing better alternatives that&nbsp;could have&nbsp;emerged&nbsp;by waiting for better options. This behavior&nbsp;continued&nbsp;across both proprietary and open-source models,&nbsp;indicating&nbsp;a fundamental challenge in agent decision-making architectures.



These biases can create unfair market dynamics, drive unintended behaviors, and push businesses to complete on response speed rather than product or service quality.



Figure 8. All models showed strong preference for the first proposal received, accepting it without waiting for additional proposals or conducting systematic comparisons.



What this means



Even state-of-the-art models can show notable vulnerabilities and biases in marketplace environments. In our implementation, agents struggled with too many options, were susceptible to manipulation tactics, and showed systemic biases that created unfair advantages.



These outcomes are shaped not only by agent capabilities but also by marketplace design and implementation. Our current study focused on static markets, but real-world environments are dynamic, with agents and users learning over time. Oversight is critical for high-stakes transactions. Agents should assist, not replace, human decision-making.



We plan to explore dynamic markets and human-in-the-loop designs to improve efficiency and trust. A simulation environment like Magentic Marketplace is crucial for understanding the interplay between market components and agents before deploying them at scale.



Full details of our experimental setup and results are available in our paper (opens in new tab).



Getting started



Magentic Marketplace is available as an open-source environment for exploring agentic market dynamics. Code, datasets, and experiment templates are available on GitHub (opens in new tab) and Azure AI Foundry Labs (opens in new tab).



The documentation (opens in new tab) provides instructions for reproducing the experiments described above and guidance for extending the environment to new marketplace configurations.
Opens in a new tabThe post Magentic Marketplace: an open-source simulation environment for studying agentic markets appeared first on Microsoft Research.
‚Ä¢ RedCodeAgent: Automatic red-teaming agent against diverse code agents
  Introduction



Code agents are AI systems that can generate high-quality code and work smoothly with code interpreters. These capabilities help streamline complex software development workflows,&nbsp;which has led to their widespread adoption.



However, this progress also introduces critical safety and security risks. Existing static safety benchmarks and red-teaming methods‚Äîin which&nbsp;security researchers&nbsp;simulate real-world attacks to&nbsp;identify&nbsp;security vulnerabilities‚Äîoften fall short when evaluating code agents.&nbsp;They&nbsp;may&nbsp;fail to&nbsp;detect&nbsp;emerging real-world risks, such as the combined effects of multiple jailbreak tools.&nbsp;In&nbsp;the context of code, effective red-teaming requires more than simply checking whether the target code agent rejects unsafe requests. Instead, the agent must generate and execute correct code that performs the intended risky functionality, making it essential to evaluate execution behaviors beyond static code analysis.&nbsp;



To address these challenges, researchers from the University of Chicago, University of Illinois Urbana‚ÄìChampaign, VirtueAI, the UK AI Safety Institute, University of Oxford, UC Berkeley, and Microsoft Research recently proposed RedCodeAgent, the first fully automated and adaptive red-teaming agent designed specifically to evaluate the safety of large language model&nbsp;(LLM)-based code agents.



Comprehensive experimental results demonstrate the effectiveness and efficiency of&nbsp;RedCodeAgent across (1) diverse Common Weakness Enumeration (CWE) vulnerabilities and malware types, (2) multiple programming languages‚Äîincluding Python, C, C++, and Java‚Äîand (3) a wide range of code agents, such as OpenCodeInterpreter, ReAct, MetaGPT, and commercial agents like Cursor and&nbsp;Codeium.&nbsp;RedCodeAgent also uncovers common vulnerabilities across agents&nbsp;such as generating and executing unsafe code, exposes variations in red-teaming difficulty across goals, identifies frequently triggered attack tools, and detects previously unknown vulnerabilities that all other baseline methods overlook.&nbsp;



Framework for&nbsp;automatic&nbsp;red-teaming&nbsp;against&nbsp;code&nbsp;agents



Figure 1: Illustration of&nbsp;RedCodeAgent&nbsp;on automatic red-teaming against a target code agent&nbsp;



As shown in Figure 1,&nbsp;RedCodeAgent&nbsp;is equipped with a&nbsp;memory module&nbsp;that accumulates successful attack experiences, enabling the system to&nbsp;continuously learn and adapt its attack strategies. After learning from the previous experiences,&nbsp;RedCodeAgent&nbsp;further&nbsp;leverages&nbsp;a&nbsp;tailored toolbox&nbsp;that combines representative red-teaming tools with a specialized&nbsp;code substitution module, enabling realistic and diverse code-specific attack simulations through function calling. Based on the target agent‚Äôs responses across multiple interactive trials, RedCodeAgent optimizes&nbsp;its strategies, systematically&nbsp;probing for&nbsp;weaknesses and vulnerabilities&nbsp;in real time.&nbsp;



In the evaluation phase,&nbsp;RedCodeAgent&nbsp;integrates simulated sandbox environments to enable code execution and assess the impact of the resulting behaviors. This sandbox-based evaluation ensures a more robust assessment of harmful behaviors and addresses the potential biases of&nbsp;previous&nbsp;static methods that rely solely on ‚ÄúLLM-as-a-judge‚Äù evaluations.



A case study is shown in Figure 2. Initially,&nbsp;RedCodeAgent&nbsp;discovers that the request was rejected, then RedCodeAgent calls the Greedy Coordinate&nbsp;Gradient&nbsp;(GCG)&nbsp;algorithm&nbsp;to bypass the safety guardrail. After the second request was rejected by the code agent,&nbsp;RedCodeAgent&nbsp;invoked both Code Substitution and GCG to optimize the prompt. Ultimately,&nbsp;RedCodeAgent&nbsp;successfully combined the suggestion from Code Substitution (i.e., using&nbsp;pathlib) with the adversarial suffix generated by GCG, making the target code agent delete the specified file.



Figure2. A case study of&nbsp;RedCodeAgent&nbsp;calling different tools to successfully attack the target code agent



Insights from&nbsp;RedCodeAgent&nbsp;



Experiments on diverse benchmarks show that&nbsp;RedCodeAgent&nbsp;achieves both a higher attack success rate (ASR) and a lower rejection rate, revealing several key findings outlined below.



Using&nbsp;traditional&nbsp;jailbreak&nbsp;methods&nbsp;alone&nbsp;does&nbsp;not&nbsp;necessarily&nbsp;improve&nbsp;ASR on code agents



The optimized prompts generated by GCG,&nbsp;AmpleGCG,&nbsp;Advprompter, and&nbsp;AutoDAN&nbsp;do not always achieve a higher ASR compared with static prompts with no jailbreak, as shown in Figure 3.&nbsp;This is&nbsp;likely&nbsp;due to the difference between code-specific tasks and general malicious request tasks in LLM safety. In the context of code, it is not enough for the target code agent to simply avoid rejecting the request; the target code agent must also generate and execute code that performs the intended function.&nbsp;Previous&nbsp;jailbreak methods do not guarantee this outcome. However,&nbsp;RedCodeAgent&nbsp;ensures that the input prompt has a clear functional objective (e.g., deleting specific sensitive files). RedCodeAgent&nbsp;can dynamically adjust based on evaluation feedback, continually optimizing to achieve the specified objectives.



Figure 3ÔºöRedCodeAgent&nbsp;achieves the highest ASR compared with other methods



RedCodeAgent&nbsp;exhibits&nbsp;adaptive&nbsp;tool&nbsp;utilization&nbsp;



RedCodeAgent&nbsp;can dynamically adjust its tool usage based on task difficulty. Figure 4 shows that the tool calling combination is different&nbsp;for&nbsp;different tasks.&nbsp;For simpler tasks, where the baseline static test cases already achieve a high ASR,&nbsp;RedCodeAgent&nbsp;spends little time invoking&nbsp;additional&nbsp;tools,&nbsp;demonstrating&nbsp;its efficiency. For more challenging tasks, where the baseline static test cases in&nbsp;RedCode-Exec achieve a lower ASR,we observe that RedCodeAgent spends more time using advanced tools like&nbsp;GCG and&nbsp;Advprompter&nbsp;to&nbsp;optimize&nbsp;the prompt for a successful attack. As a result, the average time spent on invoking different tools varies across tasks, indicating that RedCodeAgent adapts its strategy depending on the specific task.&nbsp;



Figure 4: Average time cost for&nbsp;RedCodeAgent&nbsp;to invoke different tools or query the target code agent in successful cases for each risk scenario&nbsp;



RedCodeAgent&nbsp;discovers&nbsp;new&nbsp;vulnerabilities



In scenarios where other methods&nbsp;fail to&nbsp;find successful attack strategies,&nbsp;RedCodeAgent&nbsp;is able to discover new, feasible jailbreak approaches. Quantitatively, we find that&nbsp;RedCodeAgent&nbsp;is capable of discovering&nbsp;82 (out of 27*30=810 cases in&nbsp;RedCode-Exec benchmark) unique vulnerabilities on the&nbsp;OpenCodeInterpreter&nbsp;code agent and 78 on the ReAct code agent. These are cases where all baseline methods&nbsp;fail to&nbsp;identify the vulnerability, but RedCodeAgent succeeds.



Summary



RedCodeAgent&nbsp;combines adaptive memory, specialized tools, and simulated execution environments to uncover real-world risks that static benchmarks&nbsp;may&nbsp;miss.&nbsp;It&nbsp;consistently outperforms leading jailbreak methods, achieving higher attack success rates and lower rejection rates, while remaining efficient and adaptable across diverse agents and programming languages.
Opens in a new tabThe post RedCodeAgent: Automatic red-teaming agent against diverse code agents appeared first on Microsoft Research.
‚Ä¢ Connect Amazon Bedrock agents to cross-account knowledge bases
  Organizations need seamless access to their structured data repositories to power intelligent AI agents. However, when these resources span multiple AWS accounts integration challenges can arise. This post explores a practical solution for connecting Amazon Bedrock agents to knowledge bases in Amazon Redshift clusters residing in different AWS accounts. 
The challenge 
Organizations that build AI agents using Amazon Bedrock can maintain their structured data in Amazon Redshift clusters. When these data repositories exist in separate AWS accounts from their AI agents, they face a significant limitation: Amazon Bedrock Knowledge Bases doesn‚Äôt natively support cross-account Redshift integration. 
This creates a challenge for enterprises with multi-account architectures who want to: 
 
 Leverage existing structured data in Redshift for their AI agents. 
 Maintain separation of concerns across different AWS accounts. 
 Avoid duplicating data across accounts. 
 Ensure proper security and access controls. 
 
Solution overview 
Our solution enables cross-account knowledge base integration through a secure, serverless architecture that maintains secure access controls while allowing AI agents to query structured data. The approach uses AWS Lambda as an intermediary to facilitate secure cross-account data access. 
 
The action flow as shown above: 
 
 Users enter their natural language question in Amazon Bedrock Agents which is configured in the agent account. 
 Amazon Bedrock Agents invokes a&nbsp;Lambda function through action groups which provides access to the Amazon Bedrock knowledge base configured in the agent-kb account above. 
 Action group Lambda function running in agent account assumes an IAM role created in agent-kb account above to connect to the knowledge base in the agent-kb account. 
 Amazon Bedrock Knowledge Base in the agent-kb account uses an IAM role created in the same account to access Amazon Redshift data warehouse and query data in the data warehouse. 
 
The solution follows these key components: 
 
 Amazon Bedrock agent in the agent account that handles user interactions. 
 Amazon Redshift serverless workgroup in VPC and private subnet in the agent-kb account containing structured data. 
 Amazon Bedrock Knowledge base using the Amazon Redshift serverless workgroup as structured data source. 
 Lambda function in the agent account. 
 Action group configuration to connect the agent in the agent account to the Lambda function. 
 IAM roles and policies that enable secure cross-account access. 
 
Prerequisites 
This solution requires you to have the following: 
 
 Two AWS accounts. Create an AWS account if you do not have one. Specific permissions required for both account which will be set up in subsequent steps. 
 Install the AWS CLI (2.24.22 ‚Äì current version) 
 Set up authentication using IAM user credentials for the AWS CLI for each account 
 Make sure you have jq installed, jq is lightweight command-line JSON processor. For example, in Mac you can use the command brew install jq (jq-1.7.1-apple ‚Äì current version) to install it. 
 Navigate to the Amazon Bedrock console and make sure you enable access to the meta.llama3-1-70b-instruct-v1:0 model for the agent-kb account and access for us.amazon.nova-pro-v1:0 model in the agent account in the us-west-2, US West (Oregon) AWS Region. 
 
Assumption 
Let‚Äôs call the AWS account profile, agent profile that has the Amazon Bedrock agent. Similarly, the AWS account profile be called agent-kb that has the Amazon Bedrock knowledge base with Amazon Redshift Serverless and the structured data source. We will use the us-west-2 US West (Oregon) AWS Region but feel free to choose another AWS Region as necessary (the prerequisites will be applicable to the AWS Region you choose to deploy this solution in). We will use the meta.llama3-1-70b-instruct-v1:0 model for the agent-kb. This is an available on-demand model in us-west-2. You are free to choose other models with cross-Region inference but that would mean changing the roles and polices accordingly and enable model access in all Regions they are available in. Based on our model choice for this solution the AWS Region must be us-west-2. For the agent we will be using an Amazon Bedrock agent optimized model like us.amazon.nova-pro-v1:0. 
Implementation walkthrough 
The following is a step-by-step implementation guide. Make sure to perform all steps in the same AWS Region in both accounts. 
These steps are to deploy and test an end-to-end solution from scratch and if you are already running some of these components, you may skip over those steps. 
 
  
   
   Make a note of the AWS account numbers in the agent and agent-kb account. In the implementation steps we will refer them as follows: 
     
      
       
       Profile 
       AWS account 
       Description 
       
       
       agent 
       111122223333 
       Account for the Bedrock Agent 
       
       
       agent-kb 
       999999999999 
       Account for the Bedrock Knowledge base 
       
      
     Note: These steps use example profile names and account numbers, please replace with actuals before running. 
   Create the Amazon Redshift Serverless workgroup in the agent-kb account: 
     
     Log on to the agent-kb account 
     Follow the workshop link to create the Amazon Redshift Serverless workgroup in private subnet 
     Make a note of the namespace, workgroup, and other details and follow the rest of the hands-on workshop instructions. 
      
   Set up your data warehouse in the agent-kb account. 
   Create your AI knowledge base in the agent-kb account. Make a note of the knowledge base ID. 
   Train your AI Assistant in the agent-kb account. 
   Test natural language queries in the agent-kb account. You can find the code in aws-samples git repository: sample-for-amazon-bedrock-agent-connect-cross-account-kb. 
   Create necessary roles and policies in both the accounts. Run the script create_bedrock_agent_kb_roles_policies.sh with the following input parameters. 
     
      
       
       Input parameter 
       Value 
       Description 
       
       
       ‚Äìagent-kb-profile 
       agent-kb 
       The agent knowledgebase profile that you set up with the AWS CLI with aws_access_key_id, aws_secret_access_key as mentioned in the prerequisites. 
       
       
       ‚Äìlambda-role 
       lambda_bedrock_kb_query_role 
       This is the IAM role the agent account Bedrock agent action group lambda will assume to connect to the Redshift cross account 
       
       
       ‚Äìkb-access-role 
       bedrock_kb_access_role 
       This is the IAM role the agent-kb account which the lambda_bedrock_kb_query_role in agent account assumes to connect to the Redshift cross account 
       
       
       ‚Äìkb-access-policy 
       bedrock_kb_access_policy 
       IAM policy attached to the IAM role bedrock_kb_access_role 
       
       
       ‚Äìlambda-policy 
       lambda_bedrock_kb_query_policy 
       IAM policy attached to the IAM role lambda_bedrock_kb_query_role 
       
       
       ‚Äìknowledge-base-id 
       XXXXXXXXXX 
       Replace with the actual knowledge base ID created in Step 4 
       
       
       ‚Äìagent-account 
       111122223333 
       Replace with the 12-digit AWS account number where the Bedrock agent is running. (agent account) 
       
       
       ‚Äìagent-kb-account 
       999999999999 
       Replace with the 12-digit AWS account number where the Bedrock knowledge base is running. (agent-kb acccount) 
       
      
      
   Download the script (create_bedrock_agent_kb_roles_policies.sh) from the aws-samples GitHub repository. 
   Open Terminal in Mac or similar bash shell for other platforms. 
   Locate and change the directory to the downloaded location, provide executable permissions: 
     
     cd /my/location
chmod +x create_bedrock_agent_kb_roles_policies.sh 
      
   If you are still not clear on the script usage or inputs, then you can run the script with the ‚Äìhelp option and the script will display the usage: ./create_bedrock_agent_kb_roles_policies.sh ‚Äìhelp 
   Run the script with the right input parameters as described in the previous table. 
     
     ./create_bedrock_agent_kb_roles_policies.sh --agent-profile agent \ 
  --agent-kb-profile agent-kb \ 
  --lambda-role lambda_bedrock_kb_query_role \ 
  --kb-access-role bedrock_kb_access_role \ 
  --kb-access-policy bedrock_kb_access_policy \ 
  --lambda-policy lambda_bedrock_kb_query_policy \ 
  --knowledge-base-id XXXXXXXXXX \ 
  --agent-account 111122223333 \ 
  --agent-kb-account 999999999999 
      
   The script on successful execution shows the summary of the IAM, roles and policies created in both accounts.  
   Log on to both the agent and agent-kb account to verify the IAM roles and policies are created. 
     
      
       
        
         
         For the agent account: Make a note of the ARN of the lambda_bedrock_kb_query_role as that will be the value of CloudFormation stack parameter AgentLambdaExecutionRoleArn in the next step.  
         For the agent-kb account: Make a note of the ARN of the bedrock_kb_access_role as that will be the value of CloudFormation stack parameter TargetRoleArn in the next step.  
          
        
      
   Run the AWS CloudFormation script to create a Bedrock agent: 
     
      
       
        
         
          
           
           Download the CloudFormation script: cloudformation_bedrock_agent_kb_query_cross_account.yaml from the aws-samples GitHub repository. 
           Log on to the agent account and navigate to the CloudFormation console, and verify you are in the us-west-2 (Oregon) Region, choose Create stack and choose With new resources (standard).  
           In the Specify template section choose Upload a template file and then Choose file and select the file from (1). Then, choose Next. 
           Enter the following stack details and choose Next. 
             
              
               
               Parameter 
               Value 
               Description 
               
               
               Stack name 
               bedrock-agent-connect-kb-cross-account-agent 
               You can choose any name 
               
               
               AgentFoundationModelId 
               us.amazon.nova-pro-v1:0 
               Do not change 
               
               
               AgentLambdaExecutionRoleArn 
               arn:aws:iam:: 111122223333:role/lambda_bedrock_kb_query_role 
               Replace with you agent account number 
               
               
               BedrockAgentDescription 
               Agent to query inventory data from Redshift Serverless database 
               Keep this as default 
               
               
               BedrockAgentInstructions 
               You are an assistant that helps users query inventory data from our Redshift Serverless database using the action group. 
               Do not change 
               
               
               BedrockAgentName 
               bedrock_kb_query_cross_account 
               Keep this as default 
               
               
               KBFoundationModelId 
               meta.llama3-1-70b-instruct-v1:0 
               Do not change 
               
               
               KnowledgeBaseId 
               XXXXXXXXXX 
               Knowledge base id from Step 4 
               
               
               TargetRoleArn 
               arn:aws:iam::999999999999:role/bedrock_kb_access_role 
               Replace with you agent-kb account number 
               
              
              
           Complete the acknowledgement and choose Next. 
           Scroll down through the page and choose Submit. 
           You will see the CloudFormation stack is getting created as shown by the status CREATE_IN_PROGRESS. 
           It will take a few minutes, and you will see the status change to CREATE_COMPLETE indicating creation of all resources. Choose the Outputs tab to make a note of the resources that were created. In summary, the CloudFormation script does the following in the agent account. 
             
              
               
                
                 
                 Creates a Bedrock agent 
                 Creates an action group 
                 Also creates a Lambda function which is invoked by the Bedrock action group 
                 Defines the OpenAPI schema 
                 Creates necessary roles and permissions for the Bedrock agent 
                 Finally, it prepares the Bedrock agent so that it is ready to test. 
                  
                
              
            
          
        
      
   Check for model access in Oregon (us-west-2) 
     
      
       
        
         
          
           
           Verify Nova Pro (us.amazon.nova-pro-v1:0) model access in the agent account. Navigate to the Amazon Bedrock console and choose Model access under Configure and learn. Search for Model name : Nova Pro to verify access. If not, then enable model access.  
           Verify access to the meta.llama3-1-70b-instruct-v1:0 model in the agent-kb account. This should already be enabled as we set up the knowledge base earlier. 
            
          
        
      
   Run the agent. Log on to agent account. Navigate to Amazon Bedrock console and choose Agents under Build. 
   Choose the name of the agent and choose Test. You can test the following questions as mentioned the workshop‚Äôs Stage 4: Test Natural Language Queries page. For example: 
     
      
       
        
         
          
           
           Who are the top 5 customers in Saudi Arabia? 
           Who are the top parts supplier in the United States by volume? 
           What is the total revenue by region for the year 1998? 
           Which products have the highest profit margins? 
           Show me orders with the highest priority from the last quarter of 1997. 
            
          
        
      
   Choose Show trace to investigate the agent traces. 
    
 
Some recommended best practices: 
 
  
   
    
     
     Phrase your question to be more specific 
     Use terminology that matches your table descriptions 
     Try questions similar to your curated examples 
     Verify your question relates to data that exists in the TPCH dataset 
     Use Amazon Bedrock Guardrails to add configurable safeguards to questions and responses. 
      
    
 
Clean up resources 
It is recommended that you clean up any resources you do not need anymore to avoid any unnecessary charges: 
 
  
   
    
     
     Navigate to the CloudFormation console for the agent and agent-kb account, search for the stack and and choose Delete. 
     S3 buckets need to be deleted separately.  
     For deleting the roles and policies created in both accounts, download the script delete-bedrock-agent-kb-roles-policies.sh from the aws-samples GitHub repository. 
       
       Open Terminal in Mac or similar bash shell on other platforms. 
       Locate and change the directory to the downloaded location, provide executable permissions: 
       
       
       cd /my/location
			chmod +x delete-bedrock-agent-kb-roles-policies.sh 
        
     If you are still not clear on the script usage or inputs, then you can run the script with the ‚Äìhelp option then the script will display the usage: ./ delete-bedrock-agent-kb-roles-policies.sh ‚Äìhelp 
     Run the script: delete-bedrock-agent-kb-roles-policies.sh with the same values for the same input parameters as in Step7 when running the create_bedrock_agent_kb_roles_policies.sh script. Note: Enter the correct account numbers for agent-account and agent-kb-account before running. 
       
       ./delete-bedrock-agent-kb-roles-policies.sh --agent-profile agent \ 
  	--agent-kb-profile agent-kb \ 
	  --lambda-role lambda_bedrock_kb_query_role \ 
	  --kb-access-role bedrock_kb_access_role \ 
	  --kb-access-policy bedrock_kb_access_policy \ 
	  --lambda-policy lambda_bedrock_kb_query_policy \ 
	  --agent-account 111122223333 \ 
	  --agent-kb-account 999999999999 
       The script will ask for a confirmation, say yes and press enter.  
      
    
 
Summary 
This solution demonstrates how the Amazon Bedrock agent in the agent account can query the Amazon Bedrock knowledge base in the agent-kb account. 
Conclusion 
This solution uses Amazon Bedrock Knowledge Bases for structured data to create a more integrated approach to cross-account data access. The knowledge base in agent-kb account connects directly to Amazon Redshift Serverless in a private VPC. The Amazon Bedrock agent in the agent account invokes an AWS Lambda function as part of its action group to make a cross-account connection to retrieve response from the structured knowledge base. 
This architecture offers several advantages: 
 
  
   
    
     
     Uses Amazon Bedrock Knowledge Bases capabilities for structured data 
     Provides a more seamless integration between the agent and the data source 
     Maintains proper security boundaries between accounts 
     Reduces the complexity of direct database access codes 
      
    
 
As Amazon Bedrock continues to evolve, you can take advantage of future enhancements to knowledge base functionality while maintaining your multi-account architecture. 
 
 
About the Authors 
Kunal Ghosh is an expert in AWS technologies. He passionate about building efficient and effective solutions on AWS, especially involving generative AI, analytics, data science, and machine learning. Besides family time, he likes reading, swimming, biking, and watching movies, and he is a foodie. 
Arghya Banerjee is a Sr. Solutions Architect at AWS in the San Francisco Bay Area, focused on helping customers adopt and use the AWS Cloud. He is focused on big data, data lakes, streaming and batch analytics services, and generative AI technologies. 
Indranil Banerjee is a Sr. Solutions Architect at AWS in the San Francisco Bay Area, focused on helping customers in the hi-tech and semi-conductor sectors solve complex business problems using the AWS Cloud. His special interests are in the areas of legacy modernization and migration, building analytics platforms and helping customers adopt cutting edge technologies such as generative AI. 
Vinayak Datar is Sr. Solutions Manager based in Bay Area, helping enterprise customers accelerate their AWS Cloud journey. He‚Äôs focusing on helping customers to convert ideas from concepts to working prototypes to production using AWS generative AI services.
‚Ä¢ Democratizing AI: How Thomson Reuters Open Arena supports no-code AI for every professional with Amazon Bedrock
  This post is cowritten by Laura Skylaki, Vaibhav Goswami, Ramdev Wudali and Sahar El Khoury from Thomson Reuters. 
Thomson Reuters (TR) is a leading AI and technology company dedicated to delivering trusted content and workflow automation solutions. With over 150 years of expertise, TR provides essential solutions across legal, tax, accounting, risk, trade, and media sectors in a fast-evolving world. 
TR recognized early that AI adoption would fundamentally transform professional work. According to TR‚Äôs 2025 Future of Professionals Report, 80% of professionals anticipate AI significantly impacting their work within five years, with projected productivity gains of up to 12 hours per week by 2029. To unlock this immense potential, TR needed a solution to democratize AI creation across its organization. 
In this blog post, we explore how TR addressed key business use cases with Open Arena, a highly scalable and flexible no-code AI solution powered by Amazon Bedrock and other AWS services such as Amazon OpenSearch Service, Amazon Simple Storage Service (Amazon S3), Amazon DynamoDB, and AWS Lambda. We‚Äôll explain how TR used AWS services to build this solution, including how the architecture was designed, the use cases it solves, and the business profiles that use it. The system demonstrates TR‚Äôs successful approach of using existing TR services for rapid launches while supporting thousands of users, showcasing how organizations can democratize AI access and support business profiles (for example, AI explorers and SMEs) to create applications without coding expertise. 
Introducing Open Arena: No-code AI for all 
TR introduced Open Arena to non-technical professionals to create their own customized AI solutions. With Open Arena users can use cutting-edge AI powered by Amazon Bedrock in a no-code environment, exemplifying TR‚Äôs commitment to democratizing AI access. 
Today, Open Arena supports: 
 
 High adoption: ~70% employee adoption, with&nbsp;19,000 monthly active users. 
 Custom solutions: Thousands of customized AI solutions created&nbsp;without coding, used for internal workflows or integrated into TR products for customers. 
 Self-served functionality: 100% self-served functionality, so that users, irrespective of technical background, can develop, evaluate, and deploy generative AI solutions. 
 
The Open Arena journey: From prototype to enterprise solution 
Conceived as a rapid prototype, Open Arena was developed in under six weeks at the onset of the generative AI boom in early 2023 by TR Labs ‚Äì TR‚Äôs dedicated applied research division focused on the research, development, and application of AI and emerging trends in technologies. The goal was to support internal team exploration of large language models (LLMs) and discover unique use cases by merging LLM capabilities with TR company data. 
Open Arena‚Äôs introduction significantly increased AI awareness, fostered developer-SME collaboration for groundbreaking concepts, and accelerated AI capability development for TR products. The rapid success and demand for new features quickly highlighted Open Arena‚Äôs potential for AI democratization, so TR developed an enterprise version of Open Arena. Built on the&nbsp;TR AI Platform, Open Arena enterprise version offers secure, scalable, and standardized services covering the entire AI development lifecycle, significantly accelerating time to production. 
The Open Arena enterprise version uses existing system capabilities for enhanced data access controls, standardized service access, and compliance with TR‚Äôs governance and ethical standards. This version introduced self-served capabilities so that every user, irrespective of their technical ability, can create, evaluate, and deploy customized AI solutions in a no-code environment. 

 ‚ÄúThe foundation of the AI Platform has always been about empowerment; in the early days it was about empowering Data Scientists but with the rise of Gen AI, the platform adapted and evolved on empowering users of any background to leverage and create AI Solutions.‚Äù 
 ‚Äì Maria Apazoglou, Head of AI Engineering, CoCounsel
 
As of July 2025, the TR Enterprise AI Platform consists of 15 services spanning the entire AI development lifecycle and user personas. Open Arena remains one of its most popular, serving 19,000 users each month, with increasing monthly usage. 
Addressing key enterprise AI challenges across user types 
Using the TR Enterprise AI Platform, Open Arena helped thousands of professionals transition into using generative AI. AI-powered innovation is now readily in the hands of everyone, not just AI scientists. 
Open Arena successfully addresses four critical enterprise AI challenges: 
 
 Enablement:&nbsp;Delivers AI solution building with consistent LLM and service provider experience and support for various user personas, including non-technical. 
 Security and quality:&nbsp;Streamlines AI solution quality tracking using evaluation and monitoring services, whilst complying with data governance and ethics policies. 
 Speed and reusability:&nbsp;Automates workflows and uses existing AI solutions and prompts. 
 Resources and cost management:&nbsp;Tracks and displays generative AI solution resource consumption, supporting transparency and efficiency. 
 
The solution currently supports several AI experiences, including tech support, content creation, coding assistance, data extraction and analysis, proof reading, project management, content summarization, personal development, translation, and problem solving, catering to different user needs across the organization. 
 
 
Figure 1. Examples of Open Arena use cases. 
AI explorers use Open Arena to speed up day-to-day tasks, such as summarizing documents, engaging in LLM chat, building custom workflows, and comparing AI models. AI creators and Subject Matter Experts (SMEs) use Open Arena to build custom AI workflows and experiences and to evaluate solutions without requiring coding knowledge. Meanwhile, developers can develop and deploy new AI solutions at speed, training models, creating new AI skills, and deploying AI capabilities. 
Why Thomson Reuters selected AWS for Open Arena 
TR strategically chose AWS as a primary cloud provider for Open Arena based on several critical factors: 
 
 Comprehensive AI/ML capabilities:&nbsp;Amazon Bedrock offers easy access to a choice of high-performing foundation models from leading AI companies like AI21 Labs, Anthropic, Cohere, DeepSeek, Luma AI, Meta, Mistral AI, OpenAI, Qwen, Stability AI, TwelveLabs, Writer, and Amazon. It supports simple chat and complex RAG workflows, and integrates seamlessly with TR‚Äôs existing Enterprise AI Platform. 
 Enterprise-grade security and governance:&nbsp;Advanced security controls, model access using RBAC, data handling with enhanced security features, single sign-on (SSO) enabled, and clear operational and user data separation across AWS accounts. 
 Scalable infrastructure:&nbsp;Serverless architecture for automatic scaling, pay-per-use pricing for cost optimization, and global availability with low latency. 
 Existing relationship and expertise:&nbsp;Strong, established relationship between TR and AWS, existing Enterprise AI Platform on AWS, and deep AWS expertise within TR‚Äôs technical teams. 
 

 ‚ÄúOur long-standing partnership with AWS and their robust, flexible and innovative services made them the natural choice to power Open Arena and accelerate our AI initiatives.‚Äù  
 ‚Äì Maria Apazoglou, Head of AI Engineering, CoCounsel
 
Open Arena architecture: Scalability, extensibility, and security 
Designed for a broad enterprise audience, Open Arena prioritizes scalability, extensibility and security while maintaining simplicity for non-technical users to create and deploy AI solutions. The following diagram illustrates the architecture of Open Arena. 
 
Figure 2. Architecture design of Open Arena. 
The architecture design facilitates enterprise-grade performance with clear separation between capability and usage, aligning with TR‚Äôs enterprise cost and usage tracking requirements. 
The following are key components of the solution architecture: 
 
 No-code interface:&nbsp;Intuitive UI, visual workflow builder, pre-built templates, drag-and-drop functionality. 
 Enterprise integration:&nbsp;Seamless integration with TR‚Äôs Enterprise AI Platform, SSO enabled, data handling with enhanced security, clear data separation. 
 Solution management:&nbsp;Searchable repository, public/private sharing, version control, usage analytics. 
 
TR developed Open Arena using AWS services such as Amazon Bedrock, Amazon OpenSearch, Amazon DynamoDB, Amazon API Gateway, AWS Lambda, and AWS Step Functions. It uses Amazon Bedrock for foundational model interactions, supporting simple chat and complex Retrieval-Augmented Generation (RAG) tasks. Open Arena uses Amazon Bedrock Flows as the custom workflow builder where users can drag-and-drop components like prompts, agents, knowledge bases and Lambda functions to create sophisticated AI workflows without coding. The system also integrates with AWS OpenSearch for knowledge bases and external APIs for advanced agent capabilities. 
For data separation, orchestration is managed using the Enterprise AI Platform AWS account, capturing operational data. Flow instances and user-specific data reside in the user‚Äôs dedicated AWS account, stored in a database. Each user‚Äôs data and workflow executions are isolated within their respective AWS accounts, which is required for complying with Thomson Reuters data sovereignty and enterprise security policies with strict regional controls. The system integrates with Thomson Reuters SSO solution to automatically identify users and grant secure, private access to foundational models. 
The orchestration layer, centrally hosted within the Enterprise AI Platform AWS account, manages AI workflow activities, including scheduling, deployment, resource provisioning, and governance across user environments. 
The system features fully automated provisioning of&nbsp; Amazon Bedrock Flows directly within each user‚Äôs AWS account, avoiding manual setup and accelerating time to value. Using AWS Lambda for serverless compute and DynamoDB for scalable, low-latency storage, the system dynamically allocates resources based on real-time demand. This architecture makes sure prompt flows and supporting infrastructure are deployed and scaled to match workload fluctuations, optimizing performance, cost, and user experience. 

 ‚ÄúOur decision to adopt a cross-account architecture was driven by a commitment to enterprise security and operational excellence. By isolating orchestration from execution, we make sure that each user‚Äôs data remains private and secure within their own AWS account, while still delivering a seamless, centrally-managed experience. This design empowers organizations to innovate rapidly without compromising compliance or control.‚Äù 
 ‚Äì Thomson Reuters‚Äô architecture team
 
Evolution of Open Arena: From classic to Amazon Bedrock Flows-powered chain builder 
Open Arena has evolved to cater to varying levels of user sophistication: 
 
 Open Arena v1 (Classic):&nbsp;Features a form-based interface for simple prompt customization and basic AI workflow deployment within a single AWS account. Its simplicity appeals to novice users for straightforward use cases, though with limited advanced capabilities. 
 Open Arena v2 (Chain Builder):&nbsp;Introduces a robust, visual workflow builder interface, enabling users to design complex, multi-step AI workflows using drag-and-drop components. With support for advanced node types, parallel execution, and seamless cross-account deployment, Chain Builder dramatically expands the system‚Äôs capabilities and accessibility for non-technical users. 
 
Thomson Reuters uses Amazon Bedrock Flows as a core feature of Chain Builder. Users can define, customize, and deploy AI-driven workflows using Amazon Bedrock models. Bedrock Flows supports advanced workflows combining multiple prompt nodes, incorporating AWS Lambda functions, and supporting sophisticated RAG pipelines. Operating seamlessly across user AWS accounts, Bedrock Flows facilitates secure, scalable execution of personalized AI solutions, serving as the fundamental engine for the Chain Builder workflows and driving TR‚Äôs ability to deliver robust, enterprise-grade automation and innovation. 
What‚Äôs next? 
TR continues to expand Open Arena‚Äôs capabilities through the strategic partnership with AWS, focusing on: 
 
 Driving further adoption of Open Arena‚Äôs DIY capabilities. 
 Enhancing flexibility for workflow creation in Chain Builder with custom components, such as inline scripts. 
 Developing new templates to represent common tasks and workflows. 
 Enhancing collaboration features within Open Arena. 
 Extending multimodal capabilities and model integration. 
 Expanding into new use cases across the enterprise. 
 

 ‚ÄúFrom innovating new product ideas to reimagining daily tasks for Thomson Reuters employees, we continue to push the boundaries of what‚Äôs possible with Open Arena.‚Äù 
 ‚Äì Maria Apazoglou, Head of AI Engineering, CoCounsel
 
Conclusion 
In this blog post, we explored how Thomson Reuters‚Äô Open Arena demonstrates the successful democratization of AI across an enterprise by using AWS services, particularly Amazon Bedrock and Bedrock Flows. With 19,000 monthly active users and 70% employee adoption, the system proves that no-code AI solutions can deliver enterprise-scale impact while maintaining security and governance standards. 
By combining the robust infrastructure of AWS with innovative architecture design, TR has created a blueprint for AI democratization that empowers professionals across technical skill levels to harness generative AI for their daily work. 
As Open Arena continues to evolve, it exemplifies how strategic cloud partnerships can accelerate AI adoption and transform how organizations approach innovation with generative AI. 
 
About the authors 
Laura Skylaki, PhD, leads the Enterprise AI Platform at Thomson Reuters, driving the development of GenAI services that accelerate the creation, testing and deployment of AI solutions, enhancing product value. A recognized expert with a doctorate in stem cell bioinformatics, her extensive experience in AI research and practical application spans legal, tax, and biotech domains. Her machine learning work is published in leading academic journals, and she is a frequent speaker on AI and machine learning 
Vaibhav Goswami is a Lead Software Engineer on the AI Platform team at Thomson Reuters, where he leads the development of the Generative AI Platform that empowers users to build and deploy generative AI solutions at scale. With expertise in building production-grade AI systems, he focuses on creating tools and infrastructure that democratize access to cutting-edge AI capabilities across the enterprise. 
Ramdev Wudali is a Distinguished Engineer, helping architect and build the AI/ML Platform to enable the Enterprise user, data scientists and researchers to develop Generative AI and machine learning solutions by democratizing access to tools and LLMs. In his spare time, he loves to fold paper to create origami tessellations, and wearing irreverent T-shirts 
As the director of AI Platform Adoption and Training, Sahar El Khoury guides users to seamlessly onboard and successfully use the platform services, drawing on her experience in AI and data analysis across robotics (PhD), financial markets, and media. 
Vu San Ha Huynh is a Solutions Architect at AWS with a PhD in Computer Science. He helps large Enterprise customers drive innovation across different domains with a focus on AI/ML and Generative AI solutions. 
Paul Wright is a Senior Technical Account Manager, with over 20 years experience in the IT industry and over 7 years of dedicated cloud focus. Paul has helped some of the largest enterprise customers grow their business and improve their operational excellence. In his spare time Paul is a huge football and NFL fan. 
Mike Bezak is a Senior Technical Account Manager in AWS Enterprise Support. He has over 20 years of experience in information technology, primarily disaster recovery and systems administration. Mike‚Äôs current focus is helping customers streamline and optimize their AWS Cloud journey. Outside of AWS, Mike enjoys spending time with family &amp; friends.

‚∏ª