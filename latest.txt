âœ… Morning News Briefing â€“ September 08, 2025 10:45

ğŸ“… Date: 2025-09-08 10:45
ğŸ·ï¸ Tags: #briefing #ai #publichealth #digitalgov

â¸»

ğŸ§¾ Weather
â€¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
â€¢ Current Conditions:  1.7Â°C
  Temperature: 1.7&deg;C Pressure / Tendency: 102.3 kPa rising Humidity: 98 % Humidity : 98 % Dewpoint: 1 .3&deg:C Wind: SW calm km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Monday 8 September 2025 . Weather forecast: 1/7
â€¢ Monday: A mix of sun and cloud. High 19.
  Fog patches dissipating this morning . High 19. UV index 6 or high . A mix of sun and cloud will be on the way to a high of 19.50 degrees Fahrenheit . Forecast issued 5:00 AM EDT Monday 8 September 2025 . For more information on the weather, visit http://www.cnn.com/newsquiz.org/fallfall.com

ğŸŒ International News
No updates.

ğŸ Canadian News
No updates.

ğŸ‡ºğŸ‡¸ U.S. Top Stories
â€¢ Leni Riefenstahl made movies for Hitler. A new documentary digs through her archives
  Adolf Hitler commissioned filmmaker Leni Riefenstahl to make propaganda about Nazi Germany . She lived to be 101 years old and denied knowing about the Holocaust . Hitler commissioned her to make Nazi propaganda about the Nazi Germany and she died at 101 . She denied knowing of the Holocaust and lived to 101 years at the age of her own age and denied knowledge of the holocaust . Rief
â€¢ Shooting attack at Jerusalem bus stop kills at least 5
  Paramedics said at least five people were killed in a shooting attack in Jerusalem . Two attackers opened fire at a bus stop at a busy intersection in north Jerusalem . The attack took place at an intersection in a busy area of north Jerusalem on a busy bus stop . The victims are believed to be five people, including two attackers, according to medics on the scene of the shooting .
â€¢ The U.S. is a major importer of Indian products made from Russian oil
  The United States imports oil products from India's Reliance Industries refinery, which sources nearly half its oil from Russia . The U.S. imports nearly half of its crude oil imports from Russia, according to the U.N. State Department . The refinery is based in India and supplies nearly half the nation's crude oil needs to be imported from Russia to fuel the country's economy .
â€¢ How brightly colored do we want our food? For brands, it's a hill to dye on
  Sam's Club is among the food makers removing artificial dyes from products . The company is hoping shoppers don't notice a difference in color, but why? The company says it hopes shoppers won't notice the change in color . Sam's is one of the companies that are removing dyes, but not the ones that are already being removed from its products, but the company says shoppers won
â€¢ 20 years ago, New Orleans fired its teachers. It's been rebuilding ever since
  When New Orleans schools reopened after Katrina, most of the city's educators didn't get their jobs back . Instead, they were often replaced with young people who were new to town â€” and new to teaching . The city's new teachers were often new to New Orleans, new to the city, as well as new to their jobs, they say . They are often replaced by people who are

ğŸ§  Artificial Intelligence
No updates.

ğŸ’» Digital Strategy
â€¢ Pre-owned software trial kicks off in UK as Microsoft pushes resale ban
  Microsoft's tussle with UK-based reseller over the sale of secondhand licenses returns to the UK's Competition Appeal Tribunal this week . Windows behemoth now claims that selling pre-owned Office and Windows software is unlawful . ValueLicensing's David spins the sling for another go at the Windows Goliath Microsoft claims it is unlawful to sell pre-used Office software for pre-
â€¢ So much for the paperless office: UK government inks Â£900M deal for printers etc.
  Four-year framework hands Canon and pals a license to print money . UK government to spend up to Â£900 million on printers, photocopiers, and other multifunctional devices . UK govt. awarded 12 suppliers places on a framework deal that could see it spend Â£900m on printers and photocopier devices . The four-year deal is expected to run for four years
â€¢ VMware's in court again. Customer relationships rarely go this wrong
  Pull quote is where a client says something so lovely about you, you can pull it out of the main text and reprint it in a big font in the middle of the page . Tech company marketing manager writing white papers, you'll love a juicy pull quote . Have you ever seen the 'Are we the baddies' sketch, Broadcom? Broadcom asks you to share your thoughts
â€¢ Playing ball games in the datacenter was obviously stupid, but we had to win the league
  Monday mornings see the resumption of endless coopetition between IT folks and those they strive to serve but sometimes disappoint . The Register celebrates that eternal struggle with a new edition of Who, Me? It's the reader-contributed column that offers the chance to admit failures and celebrate escapes . You're out, forever! You're not out of the Register's list of readers, forever
â€¢ Anthropic to pay at least $1.5 billion to authors whose work it knowingly pirated
  Anthropic agrees to create a $1.5 billion fund to compensate authors whose works it used to train its models without seeking permission . Expect more â€˜slush fundsâ€™ of this sort, analyst tells El Reg . AI upstart Anthropic will use the fund to pay authors who wrote to train models without permission to do so . The fund will be used to compensate people who

ğŸ¥ Public Health
No updates.

ğŸ”¬ Science
â€¢ Nature goes inside the worldâ€™s largest â€˜mosquito factoryâ€™ â€” hereâ€™s the buzz
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Feasibility and clinical utility of expanded genomic newborn screening in the Early Check program
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Longitudinal associations between 24-hour movement behaviors and physical fitness in preschoolers: a compositional isotemporal substitution analysis
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Association between atrial fibrillation and age-related macular degeneration: A nationwide cohort study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Inside a mosquito factory
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

ğŸ§¾ Government & Policy
No updates.

ğŸ›ï¸ Enterprise Architecture & IT Governance
No updates.

ğŸ¤– AI & Emerging Tech
â€¢ How Trumpâ€™s policies are affecting early-career scientistsâ€”in their own words
  Every year MIT Technology Review celebrates accomplished young scientists, entrepreneurs, and inventors from around the world in our Innovators Under 35 list. Weâ€™ve just published the 2025 edition. This year, though, the context is pointedly different: The US scientific community finds itself in an unprecedented position, with the very foundation of its work under attack.&nbsp;



Since Donald Trump took office in January, his administration has fired top government scientists, targeted universities individually and academia more broadly, and made substantial funding cuts to the countryâ€™s science and technology infrastructure. It has also upended longstanding rights and norms related to free speech, civil rights, and immigrationâ€”all of which further affects the overall environment for research and innovation in science and technology.&nbsp;



We wanted to understand how these changes are affecting the careers and work of our most recent classes of innovators. The US government is the largest source of research funding at US colleges and universities, and many of our honorees are new professors and current or recent graduate or PhD students, while others work with government-funded entities in other ways. Meanwhile, about 16% of those in US graduate programs are international students.Â 



We sent surveys to the six most recent cohorts, which include 210 people. We asked people about both positive and negative impacts of the administrationâ€™s new policies and invited them to tell us more in an optional interview. Thirty-seven completed our survey, and we spoke with 14 of them in follow-up calls. Most respondents are academic researchers (about two-thirds) and are based in the US (81%); 11 work in the private sector (six of whom are entrepreneurs). Their responses provide a glimpse into the complexities of building their labs, companies, and careers in todayâ€™s political climate.&nbsp;



Twenty-six people told us that their work has been affected by the Trump administrationâ€™s changes; only one of them described those effects as â€œmostly positive.â€ The other 25 reported primarily negative effects. While a few agreed to be named in this story, most asked to be identified only by their job titles and general areas of work, or wished to remain anonymous, for fear of retaliation. â€œI would not want to flag the ire of the US government,â€ one interviewee told us.&nbsp;



Across interviews and surveys, certain themes appeared repeatedly: the loss of jobs, funding, or opportunities; restrictions on speech and research topics; and limits on who can carry out that research. These shifts have left many respondents deeply concerned about the â€œlong-term implications in IP generation, new scientists, and spinout companies in the US,â€ as one respondent put it.&nbsp;





One of the things we heard most consistently is that the uncertainty of the current moment is pushing people to take a more risk-averse approach to their scientific workâ€”either by selecting projects that require fewer resources or that seem more in line with the administrationâ€™s priorities, or by erring on the side of hiring fewer people. â€œWeâ€™re not thinking so much about building and enabling â€¦ weâ€™re thinking about surviving,â€ said one respondent.&nbsp;



Ultimately, many are worried that all the lost opportunities will result in less innovation overallâ€”and caution that it will take time to grasp the full impact.&nbsp;



â€œWeâ€™re not going to feel it right now, but in like two to three years from now, you will feel it,â€ said one entrepreneur with a PhD who started his company directly from his area of study. â€œThere are just going to be fewer people that should have been inventing things.â€



The money: â€œFolks are definitely feeling the pressureâ€



The most immediate impact has been financial. Already, the Trump administration has pulled back support for many areas of scienceâ€”ending more than a thousand awards by the National Institutes of Health and over 100 grants for climate-related projects by the National Science Foundation. The rate of new awards granted by both agencies has slowed, and the NSF has cut the number of graduate fellowships itâ€™s funding by half for this school year.&nbsp;



The administration has also cut or threatened to cut funding from a growing number of universities, including Harvard, Columbia, Brown, and UCLA, for supposedly not doing enough to combat antisemitism.



As a result, our honorees said that finding funding to support their work has gotten much harderâ€”and it was already a big challenge before.Â 







A biochemist at a public university told us sheâ€™d lost a major NIH grant. Since it was terminated earlier this year, sheâ€™s been spending less time in the lab and more on fundraising.&nbsp;



Others described uncertainty about the status of grants from a wide range of agencies, including NSF, the Advanced Research Projects Agency for Health, the Department of Energy, and the Centers for Disease Control and Prevention, which collectively could pay out more than $44 million to the researchers weâ€™ve recognized. Several had waited months for news on an applicationâ€™s status or updates on when funds they had already won would be disbursed. One AI researcher who studies climate-related issues is concerned that her multiyear grant may not be renewed, even though renewal would have been â€œfairly standardâ€ in the past.



Two individuals lamented the cancellation of 24 awards in May by the DOEâ€™s Office of Clean Energy Demonstrations, including grants for carbon capture projects and a clean cement plant. One said the decision had â€œseverely disrupted the funding environment for climate-tech startupsâ€ by creating â€œwidespread uncertainty,â€ â€œundermining investor confidence,â€ and â€œcomplicating strategic planning.â€&nbsp;





Climate research and technologies have been a favorite target of the Trump administration: The recently passed tax and spending bill put stricter timelines in place that make it harder for wind and solar installations to qualify for tax credits via the Inflation Reduction Act. Already, at least 35 major commercial climate-tech projects have been canceled or downsized this year.&nbsp;



In response to a detailed list of questions, a DOE spokesperson said, â€œSecretary [Chris] Wright and President Trump have made it clear that unleashing American scientific innovation is a top priority.â€ They pointed to â€œrobust investments in scienceâ€ in the presidentâ€™s proposed budget and the spending bill and cited special areas of focus â€œto maintain Americaâ€™s global competitiveness,â€ including nuclear fusion, high-performance computing, quantum computing, and AI.&nbsp;







Other respondents cited tighter budgets brought on by a change in how the government calculates indirect costs, which are funds included in research grants to cover equipment, institutional overhead, and in some cases graduate studentsâ€™ salaries. In February, the NIH instituted a 15% cap on indirect costsâ€”which ran closer to 28% of the research funds the NIH awarded in 2023. The DOE, DOD, and NSF all soon proposed similar caps. This collective action has sparked lawsuits, and indirect costs remain in limbo. (MIT, which owns MIT Technology Review, is involved in several of these lawsuits; MIT Technology Review is editorially independent from the university.)&nbsp;



Looking ahead, an academic at a public university in Texas, where the money granted for indirect costs funds student salaries, said he plans to hire fewer students for his own lab. â€œItâ€™s very sad that I cannot promise [positions] at this point because of this,â€ he told us, adding that the cap could also affect the competitiveness of public universities in Texas, since schools elsewhere may fund their student researchers differently.&nbsp;



At the same time, two people with funding through the Defense Departmentâ€”which could see a surge of investment under the presidentâ€™s proposed budgetâ€”said their projects were moving forward as planned. A biomedical engineer at a public university in the Midwest expressed excitement about what he perceives as a fresh surge of federal interest in industrial and defense applications of synthetic biology.Â Still, he acknowledged colleagues working on different projects don&#8217;t feel as optimistic: â€œFolks are definitely feeling the pressure.â€



Many who are affected by cuts or delays are now looking for new funding sources in a bid to become less reliant on the federal government. Eleven people said they are pursuing or plan to pursue philanthropic and foundation funding or to seek out industry support. However, the amount of private funding available canâ€™t begin to make up the difference in federal funds lost, and investors often focus more on low-risk, short-term applications than on open scientific questions.&nbsp;



The NIH responded to a detailed list of questions with a statement pointing to unspecified investments in early-career researchers. â€œRecent updates to our priorities and processes are designed to broaden scientific opportunity rather than restrict it, ensuring that taxpayer-funded research is rigorous, reproducible, and relevant to all Americans,â€ it reads. The NSF declined a request for comment from MIT Technology Review.Â 







Further complicating this financial picture are tariffsâ€”some of which are already in effect, and many more of which have been threatened. Nine people who responded to our survey said their work is already being affected by these taxes imposed on goods imported into the US. For some scientists, this has meant higher operating costs for their labs: An AI researcher said tariffs are making computational equipment more expensive, while the Texas academic said the cost of buying microscopes from a German firm had gone up by thousands of dollars since he first budgeted for them. (Neither the White House press office nor the White House Office of Science and Technology Policy responded to requests for comment.)&nbsp;



One cleantech entrepreneur saw a positive impact on his business as more US companies reevaluated their supply chains and sought to incorporate more domestic suppliers. The entrepreneurâ€™s firm, which is based in the US, has seen more interest for its services from potential customers seeking â€œtariff-proof vendors.â€&nbsp;&nbsp;



â€œEverybody is proactive on tariffs and weâ€™re one of these solutionsâ€”weâ€™re made in America,â€ he said.&nbsp;



Another person, who works for a European firm, is factoring potential tariffs into decisions about where to open new production facilities. Though the Trump administration has said the taxes are meant to reinvigorate US manufacturing, sheâ€™s now less inclined to build out a significant presence in the US because, she said, tariffs may drive up the costs of importing raw materials that are required to make the companyâ€™s product.Â 



Whatâ€™s more, financial backers have encouraged her company to stay rooted abroad because of the potential impact of tariffs for US-based facilities: â€œPeople who invest worldwideâ€”they are saying itâ€™s reassuring for them right now to consider investing in Europe,â€ she said.



The climate of fear: â€œIt will impact the entire university if there is retaliationâ€Â 



Innovators working in both academia and the private sector described new concerns about speech and the politicization of science. Many have changed how they describe their work in order to better align with the administrationâ€™s prioritiesâ€”fearing funding cuts, job terminations, immigration action, and other potential retaliation.&nbsp;



This is particularly true for those who work at universities. The Trump administration has reached deals with some institutions, including Columbia and Brown, that would restore part of the funding it slashedâ€”but only after the universities agreed to pay hefty fines and abide by terms that, critics say, hand over an unprecedented level of oversight to administration officials.&nbsp;



Some respondents had received guidance on what they could or couldnâ€™t say from program managers at their funding agencies or their universities or investors; others had not received any official guidance but made personal decisions on what to say and share publicly based on recent news of grant cancellations.



Both on and off campus, there is substantial pressure on diversity, equity, and inclusion (DEI) initiatives, which have been hit particularly hard as the administration seeks to eliminate what it called â€œillegal and immoral discrimination programsâ€ in one of the first executive orders of President Trumpâ€™s second term.&nbsp;&nbsp;



One respondent, whose work focuses on fighting child sexual abuse materials, recalled rewriting a grant abstract â€œ3x to remove words bannedâ€ by Senator Ted Cruz of Texas, an administration ally; back in February, Cruz identified 3,400 NSF grants as â€œwoke DEIâ€ research advancing â€œneo-Marxist class warfare propaganda.â€ (His list includes grants to research self-driving cars and solar eclipses. His office did not respond to a request for comment.)Â 




Many other researchers we spoke with are also taking steps to avoid being put in the DEI bucket. A technologist at a Big Tech firm whose work used to include efforts to provide more opportunities for marginalized communities to get into computing has stopped talking about those recruiting efforts. One biologist described hearing that grant applications for the NIH now have to avoid words like â€œcell type diversityâ€ for â€œDEI reasonsâ€â€”no matter that â€œcell type diversity&#8221; is, she said, a common and â€œneutralâ€ scientific term in microbiology. (In its statement, the NIH said: â€œTo be clear, no scientific terms are banned, and commonly used terms like â€˜cell type diversityâ€™ are fully acceptable in applications and research proposals.â€)Â 



Plenty of other research has also gotten caught up in the storm.&nbsp;






One person who works in climate technology said that she now talks about â€œcritical minerals,â€ â€œsovereignty,â€ and â€œenergy independenceâ€ or â€œdominanceâ€ rather than â€œclimateâ€ or â€œindustrial decarbonization.â€ (Trumpâ€™s Energy Department has boosted investment in critical minerals, pledging nearly $1 billion to support related projects.) Another individual working in AI said she has been instructed to talk less about â€œregulation,â€ â€œsafety,â€ or â€œethicsâ€ as they relate to her work. One survey respondent described the language shift as â€œdefinitely more red-themed.â€




Some said that shifts in language wonâ€™t change the substance of their work, but others feared they will indeed affect the research itself.Â 



Emma Pierson, an assistant professor of computer science at the University of California, Berkeley, worried that AI companies may kowtow to the administration, which could in turn â€œinfluence model development.â€ While she noted that this fear is speculative, the Trump administrationâ€™s AI Action Plan contains language that directs the federal government to purchase large language models that generate â€œtruthful responsesâ€ (by the administrationâ€™s definition), with a goal of â€œpreventing woke AI in the federal government.â€Â 




And one biomedical researcher fears that the administrationâ€™s effective ban on DEI will force an end to outreach â€œfavoring any one communityâ€ and hurt efforts to improve the representation of women and people of color in clinical trials. The NIH and the Food and Drug Administration had been working for years to address the historic underrepresentation of these groups through approaches including specific funding opportunities to address health disparities; many of these efforts have recently been cut.&nbsp;




Respondents from both academia and the private sector told us theyâ€™re aware of the high stakes of speaking out.&nbsp;



â€œAs an academic, we have to be very careful about how we voice our personal opinion because it will impact the entire university if there is retaliation,â€ one engineering professor told us.&nbsp;



â€œI donâ€™t want to be a target,â€ said one cleantech entrepreneur, who worries not only about reprisals from the current administration but also about potential blowback from Democrats if he cooperates with it.&nbsp;



â€œIâ€™m not a Trumper!â€ he said. â€œIâ€™m just trying not to get fined by the EPA.â€&nbsp;




The people: â€œThe adversarial attitude against immigrants â€¦ is posing a brain drainâ€



Immigrants are crucial to American science, but what one respondent called a broad â€œpersecution of immigrants,â€ and an increasing climate of racism and xenophobia, are matters of growing concern.&nbsp;



Some people we spoke with feel vulnerable, particularly those who are immigrants themselves. The Trump administration has revoked 6,000 international student visas (causing federal judges to intervene in some cases) and threatened to â€œaggressivelyâ€ revoke the visas of Chinese students in particular. In recent months, the Justice Department has prioritized efforts to denaturalize certain citizens, while similar efforts to revoke green cards granted decades ago were shut down by court order. One entrepreneur who holds a green card told us, â€œI find myself definitely being more cognizant of what Iâ€™m saying in public and certainly try to stay away from anything political as a result of whatâ€™s going on, not just in science but in the rest of the administrationâ€™s policies.â€&nbsp;



On top of all this, federal immigration raids and other enforcement actionsâ€”authorities have turned away foreign academics upon arrival to the US and detained others with valid academic visas, sometimes because of their support for Palestineâ€”have created a broad climate of fear.&nbsp;&nbsp;



Four respondents said they were worried about their own immigration status, while 16 expressed concerns about their ability to attract or retain talent, including international students. More than a million international students studied in the US last year, with nearly half of those enrolling in graduate programs, according to the Institute of International Education.&nbsp;



â€œThe adversarial attitude against immigrants, especially those from politically sensitive countries, is posing a brain drain,â€ an AI researcher at a large public university on the West Coast told us.&nbsp;



This attack on immigration in the US can be compounded by state-level restrictions. Texas and Florida both restrict international collaborations with and recruitment of scientists from countriesÂ including China, even though researchers told us that international collaborations could help mitigate the impacts of decreased domestic funding. â€œI cannot collaborate at this point because thereâ€™s too many restrictions and Texas also can limit us from visiting some countries,â€ the Texas academic said. â€œWe cannot share results. We cannot visit other institutions â€¦ and we cannot give talks.â€



All this is leading to more interest in positions outside the United States. One entrepreneur, whose business is multinational, said that their company has received a much higher share of applications from US-based candidates to openings in Europe than it did a year ago, despite the lower salaries offered there.&nbsp;



â€œIt is becoming easier to hire good people in the UK,â€ confirmed Karen Sarkisyan, a synthetic biologist based in London.Â 



At least one US-based respondent, an academic in climate technology, accepted a tenured position in the United Kingdom. Another said that she was looking for positions in other countries, despite her current job security and â€œvery goodâ€ salary. â€œI can tell more layoffs are coming, and the work I do is massively devalued. I canâ€™t stand to be in a country that treats their scientists and researchers and educated people like this,â€ she told us.&nbsp;



Some professors reported in our survey and interviews that their current students are less interested in pursuing academic careers because graduate and PhD students are losing offers and opportunities as a result of grant cancellations. So even as the number of international students dwindles, there may also be â€œshortages in domestic grad students,â€ one mechanical engineer at a public university said, and â€œresearch will fall behind.â€&nbsp;&nbsp;




Have more information on this story or a tip for something else that we should report? Using a non-work device, reach the reporter on Signal at eileenguo.15 or tips@technologyreview.com.




In the end, this will affect not just academic research but also private-sector innovation. One biomedical entrepreneur told us that academic collaborators frequently help his company generate lots of ideas: â€œWe hope that some of them will pan out and become very compelling areas for us to invest in.â€ Particularly for small startups without large research budgets, having fewer academics to work with will mean that â€œwe just invest less, we just have fewer options to innovate,â€ he said. â€œThe level of risk that industry is willing to take is generally lower than academia, and you canâ€™t really bridge that gap.â€&nbsp;



Despite it all, a number of researchers and entrepreneurs who generally expressed frustration about the current political climate said they still consider the US the best place to do science.&nbsp;



Pierson, the AI researcher at Berkeley, described staying committed to her research into social inequities despite the political backlash: â€œIâ€™m an optimist. I do believe this will pass, and these problems are not going to pass unless we work on them.â€&nbsp;



And a biotech entrepreneur pointed out that US-based scientists can still command more resources than those in most other countries. â€œI think the US still has so much going for it. Like, there isnâ€™t a comparable place to be if youâ€™re trying to be on the forefront of innovationâ€”trying to build a company or find opportunities,â€ he said.



Several academics and founders who came to the US to pursue scientific careers spoke about still being drawn to Americaâ€™s spirit of invention and the chance to advance on their own merits. â€œFor me, Iâ€™ve always been like, the American dream is something real,â€ said one. They said theyâ€™re holding fast to those idealsâ€”for now.
â€¢ Why basic science deserves our boldest investment
  In December 1947, three physicists at Bell Telephone Laboratoriesâ€”John Bardeen, William Shockley, and Walter Brattainâ€”built a compact electronic device using thin gold wires and a piece of germanium, a material known as a semiconductor. Their invention, later named the transistor (for which they were awarded the Nobel Prize in 1956), could amplify and switch electrical signals, marking a dramatic departure from the bulky and fragile vacuum tubes that had powered electronics until then.



Its inventors werenâ€™t chasing a specific product. They were asking fundamental questions about how electrons behave in semiconductors, experimenting with surface states and electron mobility in germanium crystals. Over months of trial and refinement, they combined theoretical insights from quantum mechanics with hands-on experimentation in solid-state physicsâ€”work many might have dismissed as too basic, academic, or unprofitable.



Their efforts culminated in a moment that now marks the dawn of the information age. Transistors donâ€™t usually get the credit they deserve, yet they are the bedrock of every smartphone, computer, satellite, MRI scanner, GPS system, and artificial-intelligence platform we use today. With their ability to modulate (and route) electrical current at astonishing speeds, transistors make modern and future computing and electronics possible.



This breakthrough did not emerge from a business plan or product pitch. It arose from open-ended, curiosity-driven research and enabling development, supported by an institution that saw value in exploring the unknown. It took years of trial and error, collaborations across disciplines, and a deep belief that understanding natureâ€”even without a guaranteed payoffâ€”was worth the effort.



After the first successful demonstration in late 1947, the invention of the transistor remained confidential while Bell Labs filed patent applications and continued development. It was publicly announced at a press conference on June 30, 1948, in New York City. The scientific explanation followed in a seminal paper published in the journal Physical Review.&nbsp;



How do they work? At their core, transistors are made of semiconductorsâ€”materials like germanium and, later, siliconâ€”that can either conduct or resist electricity depending on subtle manipulations of their structure and charge. In a typical transistor, a small voltage applied to one part of the device (the gate) either allows or blocks the electric current flowing through another part (the channel). Itâ€™s this simple control mechanism, scaled up billions of times, that lets your phone run apps, your laptop render images, and your search engine return answers in milliseconds.



Though early devices used germanium, researchers soon discovered that siliconâ€”more thermally stable, moisture resistant, and far more abundantâ€”was better suited for industrial production. By the late 1950s, the transition to silicon was underway, making possible the development of integrated circuits and, eventually, the microprocessors that power todayâ€™s digital world.



A modern chip the size of a human fingernail now contains tens of billions of silicon transistors, each measured in nanometersâ€”smaller than many viruses. These tiny switches turn on and off billions of times per second, controlling the flow of electrical signals involved in computation, data storage, audio and visual processing, and artificial intelligence. They form the fundamental infrastructure behind nearly every digital device in use today.&nbsp;





The global semiconductor industry is now worth over half a trillion dollars. Devices that began as experimental prototypes in a physics lab now underpin economies, national security, health care, education, and global communication. But the transistorâ€™s origin story carries a deeper lessonâ€”one we risk forgetting.



Much of the fundamental understanding that moved transistor technology forward came from federally funded university research. Nearly a quarter of transistor research at Bell Labs in the 1950s was supported by the federal government. Much of the rest was subsidized by revenue from AT&amp;Tâ€™s monopoly on the US phone system, which flowed into industrial R&amp;D.



Inspired by the 1945 report â€œScience: The Endless Frontier,â€ authored by Vannevar Bush at the request of President Truman, the US government began a long-standing tradition of investing in basic research. These investments have paid steady dividends across many scientific domainsâ€”from nuclear energy to lasers, and from medical technologies to artificial intelligence. Trained in fundamental research, generations of students have emerged from university labs with the knowledge and skills necessary to push existing technology beyond its known capabilities.



And yet, funding for basic scienceâ€”and for the education of those who can pursue itâ€”is under increasing pressure. The new White Houseâ€™s proposed federal budget includes deep cuts to the Department of Energy and the National Science Foundation (though Congress may deviate from those recommendations). Already, the National Institutes of Health has canceled or paused more than $1.9â€¯billion in grants, while NSF STEM education programs suffered more than $700â€¯million in terminations.



These losses have forced some universities to freeze graduate student admissions, cancel internships, and scale back summer research opportunitiesâ€”making it harder for young people to pursue scientific and engineering careers. In an age dominated by short-term metrics and rapid returns, it can be difficult to justify research whose applications may not materialize for decades. But those are precisely the kinds of efforts we must support if we want to secure our technological future.



Consider John McCarthy, the mathematician and computer scientist who coined the term â€œartificial intelligence.â€ In the late 1950s, while at MIT, he led one of the first AI groups and developed Lisp, a programming language still used today in scientific computing and AI applications. At the time, practical AI seemed far off. But that early foundational work laid the groundwork for todayâ€™s AI-driven world.



After the initial enthusiasm of the 1950s through the â€™70s, interest in neural networksâ€”a leading AI architecture today inspired by the human brainâ€”declined during the so-called â€œAI wintersâ€ of the late 1990s and early 2000s. Limited data, inadequate computational power, and theoretical gaps made it hard for the field to progress. Still, researchers like Geoffrey Hinton and John Hopfield pressed on. Hopfield, now a 2024 Nobel laureate in physics, first introduced his groundbreaking neural network model in 1982, in a paper published in Proceedings of the National Academy of Sciences of the USA. His work revealed the deep connections between collective computation and the behavior of disordered magnetic systems. Together with the work of colleagues including Hinton, who was awarded the Nobel the same year, this foundational research seeded the explosion of deep-learning technologies we see today.



One reason neural networks now flourish is the graphics processing unit, or GPUâ€”originally designed for gaming but now essential for the matrix-heavy operations of AI. These chips themselves rely on decades of fundamental research in materials science and solid-state physics: high-dielectric materials, strained silicon alloys, and other advances making it possible to produce the most efficient transistors possible. We are now entering another frontier, exploring memristors, phase-changing and 2D materials, and spintronic devices.



If you&#8217;re reading this on a phone or laptop, youâ€™re holding the result of a gamble someone once made on curiosity. That same curiosity is still alive in university and research labs todayâ€”in often unglamorous, sometimes obscure work quietly laying the groundwork for revolutions that will infiltrate some of the most essential aspects of our lives 50 years from now. At the leading physics journal where I am editor, my collaborators and I see the painstaking work and dedication behind every paper we handle. Our modern economyâ€”with giants like Nvidia, Microsoft, Apple, Amazon, and Alphabetâ€”would be unimaginable without the humble transistor and the passion for knowledge fueling the relentless curiosity of scientists like those who made it possible.



The next transistor may not look like a switch at all. It might emerge from new kinds of materials (such as quantum, hybrid organic-inorganic, or hierarchical types) or from tools we havenâ€™t yet imagined. But it will need the same ingredients: solid fundamental knowledge, resources, and freedom to pursue open questions driven by curiosity, collaborationâ€”and most importantly, financial support from someone who believes it&#8217;s worth the risk.



Julia R. Greer is a materials scientist at the California Institute of Technology. She is a judge for MIT Technology Reviewâ€™s Innovators Under 35 and a former honoree (in 2008).
â€¢ 2025 Innovator of the Year: Sneha Goenka for developing an ultra-fast sequencing technology
  Sneha Goenka is one of MIT Technology Reviewâ€™s 2025 Innovators Under 35.&nbsp;Meet the rest of this yearâ€™s honorees.&nbsp;



Up to a quarter of children entering intensive care have undiagnosed genetic conditions. To be treated properly, they must first get diagnosesâ€”which means having their genomes sequenced. This process typically takes up to seven weeks. Sadly, thatâ€™s often too slow to save a critically ill child.



Hospitals may soon have a faster option, thanks to a groundbreaking system built in part by Sneha Goenka, an assistant professor of electrical and computer engineering at Princetonâ€”and MIT Technology Reviewâ€™s 2025 Innovator of the Year.&nbsp;



Five years ago, Goenka and her colleagues designed a rapid-sequencing pipeline that can provide a genetic diagnosis in less than eight hours. Goenkaâ€™s software computations and hardware architectures were critical to speeding up each stage of the process.&nbsp;



â€œHer work made everyone realize that genome sequencing is not only for research and medical application in the future but can have immediate impact on patient care,â€ says Jeroen de Ridder, a professor at UMC Utrecht in the Netherlands, who has developed an ultrafast sequencing tool for cancer diagnosis.&nbsp;





Now, as cofounder and scientific lead of a new company, she is working to make that technology widely available to patients around the world.



Goenka grew up in Mumbai, India. Her mother was an advocate for womenâ€™s education, but as a child, Goenka had to fight to persuade other family members to let her continue her studies. She moved away from home at 15 to attend her final two years of school and enroll in a premier test-Â­preparation academy in Kota, Rajasthan. Thanks to that education, she passed what she describes as â€œone of the most competitive exams in the world,â€ to get into the Indian Institute of Technology Bombay.&nbsp;



Once admitted to a combined bachelorâ€™s and masterâ€™s program in electrical engineering, she found that â€œit was a real boysâ€™ club.â€ But Goenka excelled in developing computer architecture systems that accelerate computation. As an undergraduate, she began applying those skills to medicine, driven by her desire to â€œhave real-world impactâ€â€”in part because she had seen her family struggle with painful uncertainty after her brother was born prematurely when she was eight years old.&nbsp;



While working on a PhD in electrical engineering at Stanford, she turned her focus to evolutionary and clinical genomics. One day a senior colleague, Euan Ashley, presented her with a problem. He said, â€œWe want to see how fast we can make a genetic diagnosis. If you had unlimited funds and resources, just how fast do you think you could make the compute?â€



Streaming DNA



A genetic diagnosis starts with a blood sample, which is prepped to extract the DNAâ€”a process that takes about three hours. Next that DNA needs to be â€œread.â€ One of the worldâ€™s leading long-read sequencing technologies, developed by Oxford Nanopore Technologies, can generate highly detailed raw data of an individualâ€™s genetic code in about an hour and a half. Unfortunately, processing all this data to identify mutations can take another 21 hours. Shipping samples to a central lab and figuring out which mutations are of interest often leads the process to stretch out to weeks.&nbsp;



Goenka saw a better way: Build a real-time system that could â€œstreamâ€ the sequencing data, analyzing it as it was being generated, like streaming a film on Netflix rather than downloading it to watch later.







To do this, she designed a cloud computing architecture to pull in more processing power. Goenkaâ€™s first challenge was to increase the speed at which her team could upload the raw data for processing, by streamlining the requests between the sequencer and the cloud to avoid unnecessary â€œchatter.â€ She worked out the exact number of communication channels neededâ€”and created algorithms that allowed those channels to be reused in the most efficient way.



The next challenge was â€œbase callingâ€â€”converting the raw signal from the sequencing machine into the nucleotide bases A, C, T, and G, the language that makes up our DNA. Rather than using a central node to orchestrate this process, which is an inefficient, error-prone approach, Goenka wrote software to automatically assign dozens of data streams directly from the sequencer to dedicated nodes in the cloud.



Meet the rest of this year&#8217;s&nbsp;Innovators Under 35.



Then, to identify mutations, the sequences were aligned for comparison with a reference genome. She coded a custom program that triggers alignment as soon as base calling finishes for one batch of sequences while simultaneously initiating base calling for the next batch, thus ensuring that the systemâ€™s computational resources are used efficiently.



Add all these imÂ­Â­proveÂ­Â­ments together, and Goenkaâ€™s approach reduced the total time required to analyze a genome for mutations from around 20 hours to 1.5 hours. Finally, the team worked with genetic counselors and physicians to create a filter that identified which mutations were most critical to a personâ€™s health, and that set was then given a final manual curation by a genetic specialist. These final stages take up to three hours. The technology was close to being fully operational when, suddenly, the first patient arrived.&nbsp;



A critical test



When 13-year-old Matthew was flown to Stanfordâ€™s childrenâ€™s hospital in 2021, he was struggling to breathe and his heart was failing. Doctors needed to know whether the inflammation in his heart was due to a virus or to a genetic mutation that would necessitate a transplant.&nbsp;&nbsp;



His blood was drawn on a Thursday. The transplant committee made its decisions on Fridays. â€œIt meant we had a small window of time,â€ says Goenka.



Goenka was in Mumbai when the sequencing began. She stayed up all night, monitoring the computations. That was when the project stopped being about getting faster for the sake of it, she says: â€œIt became about â€˜How fast can we get this result to save this personâ€™s life?â€™â€



The results revealed a genetic mutation that explained Matthewâ€™s condition, and he was placed on the transplant list the next day. Three weeks later, he received a new heart. â€œHeâ€™s doing great now,â€ Goenka says.





So far, Goenkaâ€™s technology has been tested on 26 patients, including Matthew. Her pipeline is â€œdirectly affecting the medical care of newborns in the Stanford intensive care units,â€ Ashley says.



Now sheâ€™s aiming for even broader impactâ€”Goenka and her colleagues are laying the groundwork for a startup that they hope will bring the technology to market and make sure it reaches as many patients as possible. Meanwhile, she has been refining the computational pipeline, reducing the time to diagnosis to about six hours.



The demand is clear, she says: â€œIn an in-depth study involving more than a dozen laboratory directors and neonatologists, every respondent stressed urgency. One director put it succinctly: â€˜I need this platform todayâ€”preferably yesterday.â€™â€



Goenka is also developing software to make the technology more inclusive. The reference genome is skewed toward people of European descent. The Human Pangenome Project is an international collaboration to create reference genomes from more diverse populations, which Goenka aims to use to personalize her teamâ€™s filters, allowing them to flag mutations that may be more prevalent in the population to which a patient belongs.



Since seeing her work, Goenkaâ€™s extended family has become more appreciative of her education and career. â€œThe entire family is very proud about the impact Iâ€™ve made,â€ she says.&nbsp;



Helen Thomson is a freelance science journalist based in London.
â€¢ Meet the Ethiopian entrepreneur who is reinventing ammonia production
  Iwnetim Abate is one of MIT Technology Reviewâ€™s 2025 Innovators Under 35.&nbsp;Meet the rest of this yearâ€™s honorees.&nbsp;



â€œIâ€™m the only one who wears glasses and has eye problems in the family,â€ Iwnetim Abate says with a smile as sun streams in through the windows of his MIT office. â€œI think itâ€™s because of the candles.â€



In the small town in Ethiopia where he grew up, Abateâ€™s family had electricity, but it was unreliable. So, for several days each week when they were without power, Abate would finish his homework by candlelight.



Today, Abate, 32, is an assistant professor at MIT in the department of materials science and engineering. Part of his research focuses on sodium-ion batteries, which could be cheaper than the lithium-based ones that typically power electric vehicles and grid installations. Heâ€™s also pursuing a new research path, examining how to harness the heat and pressure under the Earthâ€™s surface to make ammonia, a chemical used in fertilizer and as a green fuel.



Growing up without the ubiquitous access to electricity that many people take for granted shaped the way Abate thinks about energy issues, he says. He recalls rushing to dry out his school uniform over a fire before he left in the morning. One of his chores was preparing cow dung to burn as fuelâ€”the key is strategically placing holes to ensure proper drying, he says.





Abateâ€™s desire to devote his attention to energy crystallized in a high school chemistry class on fuel cells. â€œIt was like magic,â€ he says, to learn itâ€™s possible to basically convert water into energy. â€œSometimes science is magic, right?â€



Abate scored the highest of any student in Ethiopia on the national exam the year he took it, and he knew he wanted to go to the US to further his education. But actually getting there proved to be a challenge.&nbsp;



Abate applied to US colleges for three years before he was granted admission to Concordia College Moorhead, a small liberal arts college, with a partial scholarship. To raise the remaining money, he reached out to various companies and wealthy people across Ethiopia. He received countless rejections but didnâ€™t let that phase him. He laughs recalling how guards would chase him off when he dropped by prospectsâ€™ homes in person. Eventually, a family friend agreed to help.



When Abate finally made it to the Minnesota college, he walked into a room in his dorm building and the lights turned on automatically. â€œI both felt happy to have all this privilege and I felt guilty at the same time,â€ he says.



Lab notes



His college wasnâ€™t a research institute, so Abate quickly set out to get into a laboratory. He reached out to Sossina Haile, then at the California Institute of Technology, to ask about a summer research position.



Haile, now at Northwestern University, recalls thinking that Abate was particularly eager. As a visible Ethiopian scientist, she gets a lot of email requests, but his stood out. â€œNo obstacle was going to stand in his way,â€ she says. It was risky to take on a young student with no research experience whoâ€™d only been in the US for a year, but she offered him a spot in her lab.



Abate spent the summer working on materials for use in solid oxide fuel cells. He returned for the following summer, then held a string of positions in energy-materials research, including at IBM and Los Alamos National Lab, before completing his graduate degree at Stanford and postdoctoral work at the University of California, Berkeley.



Meet the rest of this year&#8217;s&nbsp;Innovators Under 35.



He joined the MIT faculty in 2023 and set out to build a research group of his own. Today, there are two major focuses of his lab. One is sodium-ion batteries, which are a popular alternative to the lithium-based cells used in EVs and grid storage installations. Sodium-ion batteries donâ€™t require the kinds of critical minerals lithium-ion batteries do, which can be both expensive and tied up by geopolitics.&nbsp;&nbsp;



One major stumbling block for sodium-ion batteries is their energy density. Itâ€™s possible to improve energy density by operating at higher voltages, but some of the materials used tend to degrade quickly at high voltages. That limits the total energy density of the battery, so itâ€™s a problem for applications like electric vehicles, where a low energy density would restrict range.



Abateâ€™s team is developing materials that could extend the lifetime of sodium-ion batteries while avoiding the need for nickel, which is considered a critical mineral in the US. The team is examining additives and testing materials-engineering techniques to help the batteries compete with lithium-ion cells.



Irons in the fire



Another vein of Abateâ€™s work is in some ways a departure from his history in batteries and fuel cells. In January, his team published research describing a process to make ammonia underground, using naturally-occurring heat and pressure to drive the necessary chemical reactions.&nbsp;&nbsp;





Today, making ammonia generates between 1% and 2% of global greenhouse gas emissions. Itâ€™s primarily used to fertilize crops, but itâ€™s also being considered as a fuel for sectors like long-distance shipping.



Abate cofounded a company called Addis Energy to commercialize the research, alongside MIT serial entrepreneur Yet-Ming Chiang and a pair of oil industry experts. (Addis means â€œnewâ€ in Amharic, the official language of Ethiopia.) For an upcoming pilot, the company aims to build an underground reactor that can produce ammonia.&nbsp;



When heâ€™s not tied up in research or the new startup, Abate runs programs for African students. In 2017, he cofounded an organization called Scifro, which runs summer school programs in Ethiopia and plans to expand to other countries, including Rwanda. The programs focus on providing mentorship and educating students about energy and medical devices, which is the specialty of his cofounder.&nbsp;



While Abate holds a position at one of the worldâ€™s most prestigious universities and serves as chief science officer of a buzzy startup, heâ€™s quick to give credit to those around him. â€œIt takes a village to build something, and itâ€™s not just me,â€ he says.



Abate often thinks about his friends, family, and former neighbors in Ethiopia as he works on new energy solutions. â€œOf course, science is beautiful, and we want to make an impact,â€ he says. â€œBeing good at what you do is important, but ultimately, itâ€™s about people.â€
â€¢ How Yichao â€œPeakâ€ Ji became a global AI app hitmaker
  Yichao â€œPeakâ€ Ji is one of MIT Technology Reviewâ€™s 2025 Innovators Under 35.Â Meet the rest of this yearâ€™s honorees.Â 



When Yichao Jiâ€”also known as â€œPeakâ€â€”appeared in a launch video for Manus in March, he didnâ€™t expect it to go viral. Speaking in fluent English, the 32-year-old introduced the AI agent built by Chinese startup Butterfly Effect, where he serves as chief scientist.Â 



The video was not an elaborate productionâ€”it was directed by cofounder Zhang Tao and filmed in a corner of their Beijing office. But something about Jiâ€™s delivery, and the vision behind the product, cut through the noise. The product, then still an early preview available only through invite codes, spread across the Chinese internet to the world in a matter of days. Within a week of its debut, Manus had attracted a waiting list of around 2 million people.&nbsp;





At first sight, Manus works like most chatbots: Users can ask it questions in a chat window. However, besides providing answers, it can also carry out tasks (for example, finding an apartment that meets specified criteria within a certain budget). It does this by breaking tasks down into steps, then using a cloud-based virtual machine equipped with a browser and other tools to execute themâ€”perusing websites, filling in forms, and so on.



Ji is the technical core of the team. Now based in Singapore, he leads product and infrastructure development as the company pushes forward with its global expansion.&nbsp;



Despite his relative youth, Ji has over a decade of experience building products that merge technical complexity with real-world usability. That earned him credibility among both engineers and investorsâ€”and put him at the forefront of a rising class of Chinese technologists with AI products and global ambitions.&nbsp;



Serial builder



The son of a professor and an IT professional, Ji moved to Boulder, Colorado, at age four for his fatherâ€™s visiting scholar post, returning to Beijing in second grade.



His fluent English set him apart early on, but it was an elementary school robotics team that sparked his interest in programming. By high school, he was running the computer club, teaching himself how to build operating systems, and drawing inspiration from Bill Gates, Linux, and open-source culture. He describes himself as a lifelong Apple devotee, and it was Appleâ€™s launch of the App Store in 2008 that ignited his passion for development.



In 2010, as a high school sophomore, Ji created the Mammoth browser, a customizable third-party iPhone browser. It quickly became the most-downloaded third-party browser developed by an individual in China and earned him the Macworld Asia Grand Prize in 2011. International tech site AppAdvice called it a product that â€œredefined the way you browse the internet.â€ At age 20, he was on the cover of Forbes magazine and made its â€œ30 Under 30â€ list.&nbsp;



Meet the rest of this year&#8217;s&nbsp;Innovators Under 35.



During his teenage years, Ji developed several other iOS apps, including a budgeting tool designed for Hasbroâ€™s Monopoly game, which sold wellâ€”until it attracted a legal notice for using the trademarked name. But Ji wasn&#8217;t put off a career in tech by that early brush with a multinational legal team. If anything, he says, it sharpened his instincts for both product and risk.&nbsp;



In 2012, Ji launched his own company, Peak Labs, and later led the development of Magi, a search engine. The tool extracted information from across the web to answer queriesâ€”conceptually similar to todayâ€™s AI-powered search, but powered by a custom language model.&nbsp;



â€‹â€‹Magi was briefly popular, drawing millions of users in its first month, but consumer adoption didnâ€™t stick. It did, however, attract enterprise interest, and Ji adapted it for B2B use, before selling it in 2022.&nbsp;



AI acumen&nbsp;



Manus would become his next actâ€”and a more ambitious one. His cofounders, Zhang Tao and Xiao Hong, complement Jiâ€™s technical core with product know-how, storytelling, and organizational savvy. Both Xiao and Ji are serial entrepreneurs who have been backed by venture capital firm ZhenFund multiple times. Together, they represent the kind of long-term collaboration and international ambition that increasingly defines Chinaâ€™s next wave of entrepreneurs.



JULIANA TAN




People who have worked with Ji describe him as a clear thinker, a fast talker, and a tireless, deeply committed builder who thinks in systems, products, and user flows. He represents a new generation of Chinese technologists: equally at home coding or in pitch meetings, fluent in both building and branding. Heâ€™s also a product of open-source culture, and remains an active contributor whose projects regularly garner attentionâ€”and GitHub starsâ€”across developer communities.



With new funding led by US venture capital firm Benchmark, Ji and his team are taking Manus to the wider world, relocating operations outside of China, to Singapore, and actively targeting consumers around the world. The product is built on US-based infrastructure, drawing on technologies like Claude Sonnet, Microsoft Azure, and open-source tools such as Browser Use. Itâ€™s a distinctly global setup: an AI agent developed by a Chinese team, powered by Western platforms, and designed for international users. That isnâ€™t incidental; it reflects the more fluid&nbsp;nature of AI entrepreneurship today, where talent, infrastructure, and ambition move across borders just as quickly as the technology itself.



For Ji, the goal isnâ€™t just building a global companyâ€”itâ€™s building a legacy. â€œI hope Manus is the last product Iâ€™ll ever build,â€ Ji says. â€œBecause if I ever have another wild ideaâ€”(Iâ€™ll just) leave it to Manus!â€

ğŸ”’ Cybersecurity & Privacy
â€¢ GOP Cries Censorship Over Spam Filters That Work
  The chairman of the Federal Trade Commission (FTC) last week sent a letter to Google&#8217;s CEO demanding to know why Gmail was blocking messages from Republican senders while allegedly failing to block similar missives supporting Democrats. The letter followed media reports accusing Gmail of disproportionately flagging messages from the GOP fundraising platform WinRed and sending them to the spam folder. But according to experts who track daily spam volumes worldwide, WinRed&#8217;s messages are getting blocked more because its methods of blasting email are increasingly way more spammy than that of ActBlue, the fundraising platform for Democrats.
Image: nypost.com
On Aug. 13, The New York Post ran an &#8220;exclusive&#8221; story titled, &#8220;Google caught flagging GOP fundraiser emails as &#8216;suspicious&#8217; &#8212; sending them directly to spam.&#8221; The story cited a memo from Targeted Victory â€“ whose clients include the National Republican Senatorial Committee (NRSC), Rep. Steve Scalise and Sen. Marsha Blackburn â€“ which said it observed that the &#8220;serious and troubling&#8221; trend was still going on as recently as June and July of this year.
â€œIf Gmail is allowed to quietly suppress WinRed links while giving ActBlue a free pass, it will continue to tilt the playing field in ways that voters never see, but campaigns will feel every single day,â€ the memo reportedly said.
In an August 28 letter to Google CEO Sundar Pichai, FTC Chairman Andrew Ferguson cited the New York Post story and warned that Gmail&#8217;s parent Alphabet may be engaging in unfair or deceptive practices.
&#8220;Alphabetâ€™s alleged partisan treatment of comparable messages or messengers in Gmail to achieve political objectives may violate both of these prohibitions under the FTC Act,&#8221; Ferguson wrote. &#8220;And the partisan treatment may cause harm to consumers.&#8221;
However, the situation looks very different when you ask spam experts what&#8217;s going on with WinRed&#8217;s recent messaging campaigns. Atro Tossavainen and Pekka Jalonen are co-founders at Koli-LÃµks OÃœ, an email intelligence company in Estonia. Koli-LÃµks taps into real-time intelligence about daily spam volumes by monitoring large numbers of &#8220;spamtraps&#8221; &#8212; email addresses that are intentionally set up to catch unsolicited emails.
Spamtraps are generally not used for communication or account creation, but instead are created to identify senders exhibiting spammy behavior, such as scraping the Internet for email addresses or buying unmanaged distribution lists. As an email sender, blasting these spamtraps over and over with unsolicited email is the fastest way to ruin your domain&#8217;s reputation online. Such activity also virtually ensures that more of your messages are going to start getting listed on spam blocklists that are broadly shared within the global anti-abuse community.
Tossavainen told KrebsOnSecurity that WinRed&#8217;s emails hit its spamtraps in the .com, .net, and .org space far more frequently than do fundraising emails sent by ActBlue. Koli-LÃµks published a graph of the stark disparity in spamtrap activity for WinRed versus ActBlue, showing a nearly fourfold increase in spamtrap hits from WinRed emails in the final week of July 2025.
Image: Koliloks.eu
&#8220;Many of our spamtraps are in repurposed legacy-TLD domains (.com, .org, .net) and therefore could be understood to have been involved with a U.S. entity in their pre-zombie life,&#8221; Tossavainen explained in the LinkedIn post.
Raymond Dijkxhoorn is the CEO and a founding member of SURBL, a widely-used blocklist that flags domains and IP addresses known to be used in unsolicited messages, phishing and malware distribution. Dijkxhoorn said their spamtrap data mirrors that of Koli-LÃµks, and shows that WinRed has consistently been far more aggressive in sending email than ActBlue.
Dijkxhoorn said the fact that WinRed&#8217;s emails so often end up dinging the organization&#8217;s sender reputation is not a content issue but rather a technical one.
&#8220;On our end we donâ€™t really care if the content is political or trying to sell viagra or penis enlargements,&#8221; Dijkxhoorn said. &#8220;Itâ€™s the mechanics, they should not end up in spamtraps. And thatâ€™s the reason the domain reputation is tempered. Not â€˜because domain reputation firms have a political agenda.&#8217; We really don&#8217;t care about the political situation anywhere. The same as we don&#8217;t mind people buying penis enlargements. But when either of those land in spamtraps it will impact sending experience.&#8221;
The FTC letter to Google&#8217;s CEO also referenced a debunked 2022 study (PDF) by political consultants who found Google caught more Republican emails in spam filters. Techdirt editor Mike Masnick notes that while the 2022 study also found that other email providers caught more Democratic emails as spam, &#8220;Republicans laser-focused on Gmail because it fit their victimization narrative better.&#8221;
Masnick said GOP lawmakers then filed both lawsuits and complaints with the Federal Election Commission (both of which failed easily), claiming this was somehow an â€œin-kind contributionâ€ to Democrats.
&#8220;This is political posturing designed to keep the White House happy by appearing to &#8216;do something&#8217; about conservative claims of &#8216;censorship,'&#8221; Masnick wrote of the FTC letter. &#8220;The FTC has never policed &#8216;political bias&#8217; in private companiesâ€™ editorial decisions, and for good reasonâ€”the First Amendment prohibits exactly this kind of government interference.&#8221;
WinRed did not respond to a request for comment.
The WinRed website says it is an online fundraising platform supported by a united front of the Trump campaign, the Republican National Committee (RNC), the NRSC,Â and the National Republican Congressional Committee (NRCC).
WinRed has recently come under fire for aggressive fundraising via text message as well. In June, 404 Media reported on a lawsuit filed by a family in Utah against the RNC for allegedly bombarding their mobile phones with text messages seeking donations after they&#8217;d tried to unsubscribe from the missives dozens of times.
One of the family members said they received 27 such messages from 25 numbers, even after sending 20 stop requests. The plaintiffs in that case allege the texts from WinRed and the RNC &#8220;knowingly disregard stop requests and purposefully use different phone numbers to make it impossible to block new messages.&#8221;
Dijkxhoorn said WinRed did inquire recently about why some of its assets had been marked as a risk by SURBL, but he said they appeared to have zero interest in investigating the likely causes he offered in reply.
&#8220;They only replied with, &#8216;You are interfering with U.S. elections,'&#8221; Dijkxhoorn said, noting that many of SURBL&#8217;s spamtrap domains are only publicly listed in the registration records for random domain names.
&#8220;Theyâ€™re at best harvested by themselves but more likely [they] just went and bought lists,&#8221; he said. &#8220;It&#8217;s not like â€˜Oh Google is filtering this and not the other,â€™ the reason isn&#8217;t the provider. The reason is the fundraising spammers and the lists they send to.&#8221;

ğŸ“ University AI
No updates.

ğŸ¢ Corporate AI
â€¢ Accelerating HPC and AI research in universities with Amazon SageMaker HyperPod
  This post was written with Mohamed Hossam of Brightskies. 
Research universities engaged in large-scale AI and high-performance computing (HPC) often face significant infrastructure challenges that impede innovation and delay research outcomes. Traditional on-premises HPC clusters come with long GPU procurement cycles, rigid scaling limits, and complex maintenance requirements. These obstacles restrict researchersâ€™ ability to iterate quickly on AI workloads such as natural language processing (NLP), computer vision, and foundation model (FM) training. Amazon SageMaker HyperPod alleviates the undifferentiated heavy lifting involved in building AI models. It helps quickly scale model development tasks such as training, fine-tuning, or inference across a cluster of hundreds or thousands of AI accelerators (NVIDIA GPUs H100, A100, and others) integrated with preconfigured HPC tools and automated scaling. 
In this post, we demonstrate how a research university implemented SageMaker HyperPod to accelerate AI research by using dynamic SLURM partitions, fine-grained GPU resource management, budget-aware compute cost tracking, and multi-login node load balancingâ€”all integrated seamlessly into the SageMaker HyperPod environment. 
Solution overview 
Amazon SageMaker HyperPod is designed to support large-scale machine learning operations for researchers and ML scientists. The service is fully managed by AWS, removing operational overhead while maintaining enterprise-grade security and performance. 
The following architecture diagram illustrates how to access SageMaker HyperPod to submit jobs. End users can use AWS Site-to-Site VPN, AWS Client VPN, or AWS Direct Connect to securely access the SageMaker HyperPod cluster. These connections terminate on the Network Load Balancer that efficiently distributes SSH traffic to login nodes, which are the primary entry points for job submission and cluster interaction. At the core of the architecture is SageMaker HyperPod compute, a controller node that orchestrates cluster operations, and multiple compute nodes arranged in a grid configuration. This setup supports efficient distributed training workloads with high-speed interconnects between nodes, all contained within a private subnet for enhanced security. 
The storage infrastructure is built around two main components: Amazon FSx for Lustre provides high-performance file system capabilities, and Amazon S3 for dedicated storage for datasets and checkpoints. This dual-storage approach provides both fast data access for training workloads and secure persistence of valuable training artifacts. 
 
The implementation consisted of several stages. In the following steps, we demonstrate how to deploy and configure the solution. 
Prerequisites 
Before deploying Amazon SageMaker HyperPod, make sure the following prerequisites are in place: 
 
 AWS configuration: 
   
   The AWS Command Line Interface (AWS CLI) configured with appropriate permissions 
   Cluster configuration files prepared: cluster-config.json and provisioning-parameters.json 
    
 Network setup: 
   
   A virtual private cloud (VPC) configured for cluster resources. 
   Security groups with Elastic Fabric Adapter (EFA) communication enabled. 
   An Amazon FSx for Lustre file system for shared, high-performance storage 
    
 An AWS Identity and Management (IAM) role with permissions for the following: 
   
   Amazon Elastic Compute Cloud (Amazon EC2) instance and Amazon SageMaker cluster management 
   FSx for Lustre and Amazon Simple Storage Service (Amazon S3) access 
   Amazon CloudWatch Logs and AWS Systems Manager integration 
   EFA network configuration 
    
 
Launch the CloudFormation stack 
We launched an AWS CloudFormation stack to provision the necessary infrastructure components, including a VPC and subnet, FSx for Lustre file system, S3 bucket for lifecycle scripts and training data, and IAM roles with scoped permissions for cluster operation. Refer to the Amazon SageMaker HyperPod workshop for CloudFormation templates and automation scripts. 
Customize SLURM cluster configuration 
To align compute resources with departmental research needs, we created SLURM partitions to reflect the organizational structure, for example NLP, computer vision, and deep learning teams. We used the SLURM partition configuration to define slurm.conf with custom partitions. SLURM accounting was enabled by configuring slurmdbd and linking usage to departmental accounts and supervisors. 
To support fractional GPU sharing and efficient utilization, we enabled Generic Resource (GRES) configuration. With GPU stripping, multiple users can access GPUs on the same node without contention. The GRES setup followed the guidelines from the Amazon SageMaker HyperPod workshop. 
Provision and validate the cluster 
We validated the cluster-config.json and provisioning-parameters.json files using the AWS CLI and a SageMaker HyperPod validation script: 
 
 $curl -O https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/5.sagemaker-hyperpod/validate-config.py

$pip3 install boto3

$python3 validate-config.py --cluster-config cluster-config.json --provisioning-parameters provisioning-parameters.json 
 
Then we created the cluster: 
 
 $aws sagemaker create-cluster \
  --cli-input-json file://cluster-config.json \
  --region us-west-2 
 
Implement cost tracking and budget enforcement 
To monitor usage and control costs, each SageMaker HyperPod resource (for example, Amazon EC2, FSx for Lustre, and others) was tagged with a unique ClusterName tag. AWS Budgets and AWS Cost Explorer reports were configured to track monthly spending per cluster. Additionally, alerts were set up to notify researchers if they approached their quota or budget thresholds. 
This integration helped facilitate efficient utilization and predictable research spending. 
Enable load balancing for login nodes 
As the number of concurrent users increased, the university adopted a multi-login node architecture. Two login nodes were deployed in EC2 Auto Scaling groups. A Network Load Balancer was configured with target groups to route SSH and Systems Manager traffic. Lastly, AWS Lambda functions enforced session limits per user using Run-As tags with Session Manager, a capability of Systems Manager. 
For details about the full implementation, see Implementing login node load balancing in SageMaker HyperPod for enhanced multi-user experience. 
Configure federated access and user mapping 
To facilitate secure and seamless access for researchers, the institution integrated AWS IAM Identity Center with their on-premises Active Directory (AD) using AWS Directory Service. This allowed for unified control and administration of user identities and access privileges across SageMaker HyperPod accounts. The implementation consisted of the following key components: 
 
 Federated user integration â€“ We mapped AD users to POSIX user names using Session Manager run-as tags, allowing fine-grained control over compute node access 
 Secure session management â€“ We configured Systems Manager to make sure users access compute nodes using their own accounts, not the default ssm-user 
 Identity-based tagging â€“ Federated user names were automatically mapped to user directories, workloads, and budgets through resource tags 
 
For full step-by-step guidance, refer to the Amazon SageMaker HyperPod workshop. 
This approach streamlined user provisioning and access control while maintaining strong alignment with institutional policies and compliance requirements. 
Post-deployment optimizations 
To help prevent unnecessary consumption of compute resources by idle sessions, the university configured SLURM with Pluggable Authentication Modules (PAM). This setup enforces automatic logout for users after their SLURM jobs are complete or canceled, supporting prompt availability of compute nodes for queued jobs. 
The configuration improved job scheduling throughput by freeing idle nodes immediately and reduced administrative overhead in managing inactive sessions. 
Additionally, QoS policies were configured to control resource consumption, limit job durations, and enforce fair GPU access across users and departments. For example: 
 
 MaxTRESPerUser â€“ Makes sure GPU or CPU usage per user stays within defined limits 
 MaxWallDurationPerJob â€“ Helps prevent excessively long jobs from monopolizing nodes 
 Priority weights â€“ Aligns priority scheduling based on research group or project 
 
These enhancements facilitated an optimized, balanced HPC environment that aligns with the shared infrastructure model of academic research institutions. 
Clean up 
To delete the resources and avoid incurring ongoing charges, complete the following steps: 
 
 Delete the SageMaker HyperPod cluster: 
 
 
 $aws sagemaker delete-cluster --cluster-name &lt;name&gt; 
 
 
 Delete the CloudFormation stack used for the SageMaker HyperPod infrastructure: 
 
 
 $aws cloudformation delete-stack --stack-name &lt;stack-name&gt; --region &lt;region&gt; 
 
This will automatically remove associated resources, such as the VPC and subnets, FSx for Lustre file system, S3 bucket, and IAM roles. If you created these resources outside of CloudFormation, you must delete them manually. 
Conclusion 
SageMaker HyperPod provides research universities with a powerful, fully managed HPC solution tailored for the unique demands of AI workloads. By automating infrastructure provisioning, scaling, and resource optimization, institutions can accelerate innovation while maintaining budget control and operational efficiency. Through customized SLURM configurations, GPU sharing using GRES, federated access, and robust login node balancing, this solution highlights the potential of SageMaker HyperPod to transform research computing, so researchers can focus on science, not infrastructure. 
For more details on making the most of SageMaker HyperPod, check out the SageMaker HyperPod workshop and explore further blog posts about SageMaker HyperPod. 
 
About the authors 
Tasneem Fathima is Senior Solutions Architect at AWS. She supports Higher Education and Research customers in the United Arab Emirates to adopt cloud technologies, improve their time to science, and innovate on AWS. 
Mohamed Hossam is a Senior HPC Cloud Solutions Architect at Brightskies, specializing in high-performance computing (HPC) and AI infrastructure on AWS. He supports universities and research institutions across the Gulf and Middle East in harnessing GPU clusters, accelerating AI adoption, and migrating HPC/AI/ML workloads to the AWS Cloud. In his free time, Mohamed enjoys playing video games.
â€¢ Exploring the Real-Time Race Track with Amazon Nova
  This post is co-written by Jake Friedman, President + Co-founder of Wildlife. 
Amazon Nova is enhancing sports fan engagement through an immersive Formula 1 (F1)-inspired experience that turns traditional spectators into active participants. This post explores the Real-Time Race Track (RTRT), an interactive experience built using Amazon Nova in Amazon Bedrock, that lets fans design, customize, and share their own racing circuits. We highlight how generative AI capabilities come together to deliver strategic racing insights such as pit timing and tire choices, and interactive features like an AI voice assistant and a retro-style racing poster. 
Evolving fan expectations and the technical barriers to real-time, multimodal engagement 
Todayâ€™s sports audiences expect more than passive viewingâ€”they want to participate, customize, and share. As fan expectations evolve, delivering engaging and interactive experiences has become essential to keeping audiences invested. Static digital content no longer holds attention; fans are drawn to immersive formats that make it possible to influence or co-create aspects of the event. For brands and rights holders, this shift presents both an opportunity and a challenge: how to deliver dynamic, meaningful engagement at scale. Delivering this level of interactivity comes with a unique set of technical challenges. It requires support for multiple modalitiesâ€”text, speech, image, and dataâ€”working together in real time to create a seamless and immersive experience. Because fan-facing experiences are often offered for free, cost-efficiency becomes critical to sustain engagement at scale. And with users expecting instant responses, maintaining low-latency performance across interactions is essential to avoid disrupting the experience. 
Creating immersive fan engagement with the RTRT using Amazon Nova 
To foster an engaging and immersive experience, we developed the Real-Time Race Track, allowing F1 fans to design their own custom racing circuit using Amazon Nova. You can draw your track in different lengths and shapes while receiving real-time AI recommendations to modify your racing conditions. You can choose any location around the world for your race track and Amazon Nova Pro will use it to generate your trackâ€™s name and simulate realistic track conditions using that regionâ€™s weather and climate data. When your track is complete, Amazon Nova Pro analyzes the track to produce metrics like top speed and projected lap time, and offers two viable race strategies focused on tire management. You can also consult with Amazon Nova Sonic, a speech-to-speech model, for strategic track design recommendations. The experience culminates with Amazon Nova Canvas generating a retro-inspired racing poster of your custom track design that you can share or download. The following screenshots show some examples of the RTRT interface. 
 
  
   
    
    
   
  
 
Amazon Nova models are cost-effective and deliver among the best price-performance in their respective class, helping enterprises create scalable fan experiences while managing costs effectively. With fast speech processing and high efficiency, Amazon Nova provides seamless, real-time, multimodal interactions that meet the demands of interactive fan engagement. Additionally, Amazon Nova comes with built-in controls to maintain the safe and responsible use of AI. Combining comprehensive capabilities, cost-effectiveness, low latency, and trusted reliability, Amazon Nova is the ideal solution for applications requiring real-time, dynamic engagement. 
Prompts, inputs, and system design behind the RTRT experience 
The RTRT uses the multimodal capabilities of Amazon Nova Pro to effectively lead users from a single line path drawing to a fully viable race track design, including strategic racing recommendations and a bold visual representation of their circuit in the style of a retro racing poster. 
The following diagram gives an overview of the system architecture. 
 
Prompt engineering plays a crucial role in delivering structured output that can flow seamlessly into the UI, which has been optimized for at-a-glance takeaways that use Amazon Nova Pro to quickly analyze multiple data inputs to accelerate usersâ€™ decision making. In the RTRT, this extends to the input images provided to Amazon Nova Pro for vision analysis. Each time the user adds new segments to their racing circuit, a version of the path is relayed to Amazon Nova Pro with visible coordinate markers that produce accurate path analysis (see the following screenshot) and corresponding output data, which can be visually represented back to users with color-coded track sectors. 
 
This is paired with multiple system prompts to define the role of Amazon Nova Pro at each stage of the app, as well as to return responses that are ready to be consumed by the front end. 
The following is a prompt example: 
 
 The system is designed to analyze the input image of a completed racetrack path outline.
You must always return valid JSON. 
 
The prompts also use sets of examples to produce consistent results across a diverse range of possible track designs and locations: 
 
 Using the input data craft a track title for a fictional Formula 1 track. 
    Use the names of existing tracks from &lt;example/&gt; as a framework of how to format the
      title.
  The title must not infringe on any existing track names or copyrighted material.
    The title should take into account the location of the track when choosing what
      language certain components of the track title are in. 
 
 This is also a key stage in which to employ responsible use of AI, instructing the model not to generate content that might infringe on existing race tracks or other copyrighted material.
 
These considerations are essential when working with creative models like Amazon Nova Canvas. Race cars commonly feature liveries that contain a dozen or more sponsor logos. To avoid concern, and to provide the cleanest, most aesthetically appealing retro racing poster designs, Amazon Nova Canvas was given a range of conditioning images that facilitate vehicle accuracy and consistency. The images work in tandem with our prompt for a bold illustration style featuring cinematic angles. 
The following is a prompt example: 
 
 Use a bold vector-style illustration approach with flat color fills, bold outlines,
    stylized gradients. Maintain a vintage racing poster aesthetic with minimal texture.
    Position the viewer to emphasize motion and speed. 
 
The following images show the output. 
 
  
   
    
    
   
  
 
Conclusion 
The Real-Time Race Track showcases how generative AI can deliver personalized, interactive moments that resonate with modern sports audiences. Amazon Nova models power each layer of the experience, from speech and image generation to strategy and analysis, delivering rich, low-latency interactions at scale. This collaboration highlights how brands can use Amazon Nova to build tailored and engaging experiences. 
 
About the authors 
Raechel Frick is a Sr. Product Marketing Manager at AWS. With over 20 years of experience in the tech industry, she brings a customer-first approach and growth mindset to building integrated marketing programs. 
Anuj Jauhari is a Sr. Product Marketing Manager at AWS, enabling customers to innovate and achieve business impact with generative AI solutions built on Amazon Nova models. 
Jake Friedman is the President and Co-founder at Wildlife, where he leads a team launching interactive experiences and content campaigns for global brands. His work has been recognized with the Titanium Grand Prix at the Cannes Lions International Festival of Creativity for â€œboundary-busting, envy-inspiring work that marks a new direction for the industry and moves it forward.â€
â€¢ Build character consistent storyboards using Amazon Nova in Amazon Bedrock â€“ Part 2
  Although careful prompt crafting can yield good results, achieving professional-grade visual consistency often requires adapting the underlying model itself. Building on the prompt engineering and character development approach covered in Part 1 of this two-part series, we now push the consistency level for specific characters by fine-tuning an Amazon Nova Canvas foundation model (FM). Through fine-tuning techniques, creators can instruct the model to maintain precise control over character appearances, expressions, and stylistic elements across multiple scenes. 
In this post, we take an animated short film, Picchu, produced by FuzzyPixel from Amazon Web Services (AWS), prepare training data by extracting key character frames, and fine-tune a character-consistent model for the main character Mayu and her mother, so we can quickly generate storyboard concepts for new sequels like the following images. 
 
  
   
    
    
    
   
  
 
Solution overview 
To implement an automated workflow, we propose the following comprehensive solution architecture that uses AWS services for an end-to-end implementation. 
 
The workflow consists of the following steps: 
 
 The user uploads a video asset to an Amazon Simple Storage Service (Amazon S3) bucket. 
 Amazon Elastic Container Service (Amazon ECS) is triggered to process the video asset. 
 Amazon ECS downsamples the frames, selects those containing the character, and then center-crops them to produce the final character images. 
 Amazon ECS invokes an Amazon Nova model (Amazon Nova Pro) from Amazon Bedrock to create captions from the images. 
 Amazon ECS writes the image captions and metadata to the S3 bucket. 
 The user uses a notebook environment in Amazon SageMaker AI to invoke the model training job. 
 The user fine-tunes a custom Amazon Nova Canvas model by invoking Amazon Bedrock create_model_customization_job and create_model_provisioned_throughput API calls to create a custom model available for inference. 
 
This workflow is structured in two distinct phases. The initial phase, in Steps 1â€“5, focuses on preparing the training data. In this post, we walk through an automated pipeline to extract images from an input video and then generate labeled training data. The second phase, in Steps 6â€“7, focuses on fine-tuning the Amazon Nova Canvas model and performing test inference using the custom-trained model. For these latter steps, we provide the preprocessed image data and comprehensive example code in the following GitHub repository to guide you through the process. 
Prepare the training data 
Letâ€™s begin with the first phase of our workflow. In our example, we build an automated video object/character extraction pipeline to extract high-resolution images with accurate caption labels using the following steps. 
Creative character extraction 
We recommend first sampling video frames at fixed intervals (for example, 1 frame per second). Then, apply Amazon Rekognition label detection and face collection search to identify frames and characters of interest. Label detection can identify over 2,000 unique labels and locate their positions within frames, making it ideal for initial detection of general character categories or non-human characters. To distinguish between different characters, we then use the Amazon Rekognition feature to search faces in a collection. This feature identifies and tracks characters by matching their faces against a pre-populated face collection. If these two approaches arenâ€™t precise enough, we can use Amazon Rekognition Custom Labels to train a custom model for detecting specific characters. The following diagram illustrates this workflow. 
 
After detection, we center-crop each character with appropriate pixel padding and then run a deduplication algorithm using the Amazon Titan Multimodal Embeddings model to remove semantically similar images above a threshold value. Doing so helps us build a diverse dataset because redundant or nearly identical frames could lead to model overfitting (when a model learns the training data too precisely, including its noise and fluctuations, making it perform poorly on new, unseen data). We can calibrate the similarity threshold to fine-tune what we consider to be identical images, so we can better control the balance between dataset diversity and redundancy elimination. 
Data labeling 
We generate captions for each image using Amazon Nova Pro in Amazon Bedrock and then upload the image and label manifest file to an Amazon S3 location. This process focuses on two critical aspects of prompt engineering: character description to help the FM identify and name the characters based on their unique attributes, and varied description generation that avoids repetitive patterns in the caption (for example, â€œan animated characterâ€). The following is an example prompt template used during our data labeling process: 
 
 system_prompt = """ 
    You are an expert image description specialist who creates concise, natural alt
    text that makes visual content accessible while maintaining clarity and focus.
    Your task is to analyze the provided image and provide a creative description
    (20-30 words) that emphasizes the Three main characters, capturing the essential
    elements of their interaction while avoiding unnecessary details.
"""

prompt = """
    
    1. Identify the main characters in the image: Character 1, Character 2, and
        Character 3 at least one will be in the picture so provide at a minimum a
        description with at least one character name.
      - "Character 1" describe the first character, key traits, background, attributes.
      - "Character 2" describe the second character, key traits, background, attributes.
      - "Character 3" describe the third character, key traits, background, attributes. 
    2. Just state their name WITHOUT adding any standard characteristics.
    3. Only capture visual element outside the standard characteristics
    4. Capture the core interaction between them
    5. Include only contextual details that are crucial for understanding the scene
    6. Create a natural, flowing description using everyday language
    
    Here are some examples
    
       ...
    
    
    
    [Identify the main characters]
    [Assessment of their primary interaction]
    [Selection of crucial contextual elements]
    [Crafting of concise, natural description]
    
    
    {
        "alt_text": "[Concise, natural description focusing on the main characters]"
    }
    
    
    Note: Provide only the JSON object as the final response. 
 
The data labeling output is formatted as a JSONL file, where each line pairs an image reference Amazon S3 path with a caption generated by Amazon Nova Pro. This JSONL file is then uploaded to Amazon S3 for training. The following is an example of the file: 
 
 {"image_ref": "s3://media-ip-dataset/characters/blue_character_01.jpg", "alt_text": "This
    animated character features a round face with large expressive eyes. The character
    has a distinctive blue color scheme with a small tuft of hair on top. The design is
    stylized with clean lines and a minimalist approach typical of modern animation."}
{"image_ref": "s3://media-ip-dataset/props/iconic_prop_series1.jpg", "alt_text": "This
    object appears to be an iconic prop from the franchise. It has a metallic appearance
    with distinctive engravings and a unique shape that fans would immediately recognize.
    The lighting highlights its dimensional qualities and fine details that make it
    instantly identifiable."} 
 
Human verification 
For enterprise use cases, we recommend incorporating a human-in-the-loop process to verify labeled data before proceeding with model training. This verification can be implemented using Amazon Augmented AI (Amazon A2I), a service that helps annotators verify both image and caption quality. For more details, refer to Get Started with Amazon Augmented AI. 
Fine-tune Amazon Nova Canvas 
Now that we have the training data, we can fine-tune the Amazon Nova Canvas model in Amazon Bedrock. Amazon Bedrock requires an AWS Identity and Access Management (IAM) service role to access the S3 bucket where you stored your model customization training data. For more details, see Model customization access and security. You can perform the fine-tuning task directly on the Amazon Bedrock console or use the Boto3 API. We explain both approaches in this post, and you can find the end-to-end code sample in picchu-finetuning.ipynb. 
Create a fine-tuning job on the Amazon Bedrock console 
Letâ€™s start by creating an Amazon Nova Canvas fine-tuning job on the Amazon Bedrock console: 
 
 On the Amazon Bedrock console, in the navigation pane, choose Custom models under Foundation models. 
 Choose Customize model and then Create Fine-tuning job. 
 
 
 
 On the Create Fine-tuning job details page, choose the model you want to customize and enter a name for the fine-tuned model. 
 In the Job configuration section, enter a name for the job and optionally add tags to associate with it. 
 In the Input data section, enter the Amazon S3 location of the training dataset file. 
 In the Hyperparameters section, enter values for hyperparameters, as shown in the following screenshot. 
 
 
 
 In the Output data section, enter the Amazon S3 location where Amazon Bedrock should save the output of the job. 
 Choose Fine-tune model job to begin the fine-tuning process. 
 
This hyperparameter combination yielded good results during our experimentation. In general, increasing the learning rate makes the model train more aggressively, which often presents an interesting trade-off: we might achieve character consistency more quickly, but it might impact overall image quality. We recommend a systematic approach to adjusting hyperparameters. Start with the suggested batch size and learning rate, and try increasing or decreasing the number of training steps first. If the model struggles to learn your dataset even after 20,000 steps (the maximum allowed in Amazon Bedrock), then we suggest either increasing the batch size or adjusting the learning rate upward. These adjustments, through subtle, can make a significant difference in our modelâ€™s performance. For more details about the hyperparameters, refer to Hyperparameters for Creative Content Generation models. 
Create a fine-tuning job using the Python SDK 
The following Python code snippet creates the same fine-tuning job using the create_model_customization_job API: 
 
 bedrock = boto3.client('bedrock')
jobName =&nbsp;"picchu-canvas-v0"
# Set parameters
hyperParameters = {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"stepCount": "14000",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"batchSize": "64",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"learningRate": "0.000001",
&nbsp;&nbsp; &nbsp;}

# Create job
response_ft = bedrock.create_model_customization_job(
&nbsp;&nbsp; &nbsp;jobName=jobName,
&nbsp;&nbsp; &nbsp;customModelName=jobName,
&nbsp;&nbsp; &nbsp;roleArn=roleArn,
&nbsp;&nbsp; &nbsp;baseModelIdentifier="amazon.nova-canvas-v1:0",
&nbsp;&nbsp; &nbsp;hyperParameters=hyperParameters,
&nbsp;&nbsp; &nbsp;trainingDataConfig={"s3Uri": training_path},
&nbsp;&nbsp; &nbsp;outputDataConfig={"s3Uri": f"s3://{bucket}/{prefix}"}
)

jobArn = response_ft.get('jobArn')
print(jobArn) 
 
When the job is complete, you can retrieve the new customModelARN using the following code: 
 
 custom_model_arn = bedrock.list_model_customization_jobs(
&nbsp;&nbsp; &nbsp;nameContains=jobName
)["modelCustomizationJobSummaries"][0]["customModelArn"] 
 
Deploy the fine-tuned model 
With the preceding hyperparameter configuration, this fine-tuning job might take up to 12 hours to complete. When itâ€™s complete, you should see a new model in the custom models list. You can then create provisioned throughput to host the model. For more details on provisioned throughput and different commitment plans, see Increase model invocation capacity with Provisioned Throughput in Amazon Bedrock. 
Deploy the model on the Amazon Bedrock console 
To deploy the model from the Amazon Bedrock console, complete the following steps: 
 
 On the Amazon Bedrock console, choose Custom models under Foundation models in the navigation pane. 
 Select the new custom model and choose Purchase provisioned throughput. 
 
 
 
 In the Provisioned Throughput details section, enter a name for the provisioned throughput. 
 Under Select model, choose the custom model you just created. 
 Then specify the commitment term and model units. 
 
 
After you purchase provisioned throughput, a new model Amazon Resource Name (ARN) is created. You can invoke this ARN when the provisioned throughput is in service. 
 
Deploy the model using the Python SDK 
The following Python code snippet creates provisioned throughput using the create_provisioned_model_throughput API: 
 
 custom_model_name =&nbsp;"picchu-canvas-v0"

# Create the provision throughput job and retrieve the provisioned model id
provisioned_model_id = bedrock.create_provisioned_model_throughput(
&nbsp;&nbsp; &nbsp;modelUnits=1,
&nbsp;&nbsp; &nbsp;# create a name for your provisioned throughput model
&nbsp;&nbsp; &nbsp;provisionedModelName=custom_model_name, 
&nbsp;&nbsp; &nbsp;modelId=custom_model_arn
)['provisionedModelArn'] 
 
Test the fine-tuned model 
When the provisioned throughput is live, we can use the following code snippet to test the custom model and experiment with generating some new images for a sequel to Picchu: 
 
 import json
import io
from PIL import Image
import base64

def decode_base64_image(img_b64):
    return Image.open(io.BytesIO(base64.b64decode(img_b64)))
    
def generate_image(prompt,
                   negative_prompt="text, ugly, blurry, distorted, low
                       quality, pixelated, watermark, text, deformed", 
                   num_of_images=3,
                   seed=1):
    """
    Generate an image using Amazon Nova Canvas.
    """

    image_gen_config = {
            "numberOfImages": num_of_images,
            "quality": "premium",
            "width": 1024,  # Maximum resolution 2048 x 2048
            "height": 1024,  # 1:1 ratio
            "cfgScale": 8.0,
            "seed": seed,
        }

    # Prepare the request body
    request_body = {
        "taskType": "TEXT_IMAGE",
        "textToImageParams": {
            "text": prompt,
            "negativeText": negative_prompt,  # List things to avoid
        },
        "imageGenerationConfig": image_gen_config
    } 

    response = bedrock_runtime.invoke_model(
        modelId=provisioned_model_id,
        body=json.dumps(request_body)
    )

    # Parse the response
    response_body = json.loads(response['body'].read())

    if "images" in response_body:
        # Extract the image
        return [decode_base64_image(img) for img in response_body['images']]
    else:
        return
seed = random.randint(1, 858993459)
print(f"seed: {seed}")

images = generate_image(prompt=prompt, seed=seed) 
 
 
  
   
    
    
    
   
   
   Mayu face shows a mix of nervousness and determination. Mommy kneels beside her, gently holder her. A landscape is visible in the background. 
   A steep cliff face with a long wooden ladder extending downwards. Halfway down the ladder is Mayu with a determined expression on her face. Mayuâ€™s small hands grip the sides of the ladder tightly as she carefully places her feet on each rung. The surrounding environment shows a rugged, mountainous landscape. 
   Mayu standing proudly at the entrance of a simple school building. Her face beams with a wide smile, expressing pride and accomplishment. 
   
  
 
Clean up 
To avoid incurring AWS charges after you are done testing, complete the cleanup steps in picchu-finetuning.ipynb and delete the following resources: 
 
 Amazon SageMaker Studio domain 
 Fine-tuned Amazon Nova model and provision throughput endpoint 
 
Conclusion 
In this post, we demonstrated how to elevate character and style consistency in storyboarding from Part 1 by fine-tuning Amazon Nova Canvas in Amazon Bedrock. Our comprehensive workflow combines automated video processing, intelligent character extraction using Amazon Rekognition, and precise model customization using Amazon Bedrock to create a solution that maintains visual fidelity and dramatically accelerates the storyboarding process. By fine-tuning the Amazon Nova Canvas model on specific characters and styles, weâ€™ve achieved a level of consistency that surpasses standard prompt engineering, so creative teams can produce high-quality storyboards in hours rather than weeks. Start experimenting with Nova Canvas fine-tuning today, so you can also elevate your storytelling with better character and style consistency. 
 
About the authors 
Dr. Achin Jain is a Senior Applied Scientist at Amazon AGI, where he works on building multi-modal foundation models. He brings over 10+ years of combined industry and academic research experience. He has led the development of several modules for Amazon Nova Canvas and Amazon Titan Image Generator, including supervised fine-tuning (SFT), model customization, instant customization, and guidance with color palette. 
James Wu is a Senior AI/ML Specialist Solution Architect at AWS. helping customers design and build AI/ML solutions. Jamesâ€™s work covers a wide range of ML use cases, with a primary interest in computer vision, deep learning, and scaling ML across the enterprise. Prior to joining AWS, James was an architect, developer, and technology leader for over 10 years, including 6 years in engineering and 4 years in marketing &amp; advertising industries. 
Randy Ridgley is a Principal Solutions Architect focused on real-time analytics and AI. With expertise in designing data lakes and pipelines. Randy helps organizations transform diverse data streams into actionable insights. He specializes in IoT solutions, analytics, and infrastructure-as-code implementations. As an open-source contributor and technical leader, Randy provides deep technical knowledge to deliver scalable data solutions across enterprise environments.
â€¢ Build character consistent storyboards using Amazon Nova in Amazon Bedrock â€“ Part 1
  The art of storyboarding stands as the cornerstone of modern content creation, weaving its essential role through filmmaking, animation, advertising, and UX design. Though traditionally, creators have relied on hand-drawn sequential illustrations to map their narratives, todayâ€™s AI foundation models (FMs) are transforming this landscape. FMs like Amazon Nova Canvas and Amazon Nova Reel offer capabilities in transforming text and image inputs into professional-grade visuals and short clips that promise to revolutionize preproduction workflows. 
This technological leap forward, however, presents its own set of challenges. Although these models excel at generating diverse concepts rapidlyâ€”a boon for creative explorationâ€”maintaining consistent character designs and stylistic coherence across scenes remains a significant hurdle. Even subtle modifications to prompts or model configurations can yield dramatically different visual outputs, potentially disrupting narrative continuity and creating additional work for content creators. 
To address these challenges, weâ€™ve developed this two-part series exploring practical solutions for achieving visual consistency. In Part 1, we deep dive into prompt engineering and character development pipelines, sharing tested prompt patterns that deliver reliable, consistent results with Amazon Nova Canvas and Amazon Nova Reel. Part 2 explores techniques like fine-tuning Amazon Nova Canvas to achieve exceptional visual consistency and precise character control. 
 
  
   
    
    
    
   
  
 
Consistent character design with Amazon Nova Canvas 
The foundation of effective storyboarding begins with establishing well-defined character designs. Amazon Nova Canvas offers several powerful techniques to create and maintain character consistency throughout your visual narrative. To help you implement these techniques in your own projects, weâ€™ve provided comprehensive code examples and resources in our GitHub repository. We encourage you to follow along as we walk through each step in detail. If youâ€™re new to Amazon Nova Canvas, we recommend first reviewing Generating images with Amazon Nova to familiarize yourself with the basic concepts. 
Basic text prompting 
Amazon Nova Canvas transforms text descriptions into visual representations. Unlike large language models (LLMs), image generation models donâ€™t interpret commands or engage in reasoningâ€”they respond best to descriptive captions. Including specific details in your prompts, such as physical attributes, clothing, and styling elements, directly influences the generated output. 
For example, â€œA 7-year-old Peruvian girl with dark hair in two low braids wearing a school uniformâ€ provides clear visual elements for the model to generate an initial character concept, as shown in the following example image. 
 
Visual style implementation 
Consistency in storyboarding requires both character features and unified visual style. Our approach separates style information into two key components in the prompt: 
 
 Style description â€“ An opening phrase that defines the visual medium (for example, â€œA graphic novel style illustration ofâ€) 
 Style details â€“ A closing phrase that specifies artistic elements (for example, â€œBold linework, dramatic shadows, flat color palettesâ€) 
 
This structured technique enables exploration of various artistic styles, including graphic novels, sketches, and 3D illustrations, while maintaining character consistency throughout the storyboard. The following is an example prompt template and some style information you can experiment with: 
 
 {style_description} A 7 year old peruvian girl with dark hair in two low braids wearing a
    school uniform. {style_details}
styles = [
    {
        "name": "graphic-novel",
        "description": "A graphic novel style illustation of",
        "details": "Bold linework, dramatic shadows, and flat color palettes. Use
            high contrast lighting and cinematic composition typical of comic book
            panels. Include expressive line work to convey emotion and movement.",
    },
    {
        "name": "sketch",
        "description": "A simple black and white line sketch of",
        "details": "Rough, sketch-like lines create a storyboard aesthetic. High
            contrast. No color",
    },
    {
        "name": "digital-illustration",
        "description": "A 3D digital drawing of",
        "details": "High contrast. Rounded character design. Smooth rendering.
            Soft texture. Luminous lighting",
    },
] 
 
 
Character variation through seed values 
The seed parameter serves as a tool for generating character variations while adhering to the same prompt. By keeping the text description constant and varying only the seed value, creators can explore multiple interpretations of their character design without starting from scratch, as illustrated in the following example images. 
 
  
   
    
   
   
    Seed = 1  
    Seed = 20  
    Seed = 57  
    Seed = 139  
    Seed = 12222  
   
  
 
Prompt adherence control with cfgScale 
The cfgScale parameter is another tool for maintaining character consistency, controlling how strictly Amazon Nova Canvas follows your prompt. Operating on a scale from 1.1â€“10, lower values give the model more creative freedom and higher values enforce strict prompt adherence. The default value of 6.5 typically provides an optimal balance, but as demonstrated in the following images, finding the right setting is crucial. Too low a value can result in inconsistent character representations, whereas too high a value might overemphasize prompt elements at the cost of natural composition. 
 
  
   
    
   
   
   Seed = 57, cfgScale = 1.1 
   Seed = 57, cfgScale = 3.5 
   Seed = 57, cfgScale = 6.5 
   Seed = 57, cfgScale = 8.0 
   Seed = 57, cfgScale = 10 
   
  
 
Scene integration with consistent parameters 
Now we can put these techniques together to test for character consistency across different narrative contexts, as shown in the following example images. We maintain consistent input for style, seed, and cfgScale, varying only the scene description to make sure character remains recognizable throughout the scene sequences. 
 
  
   
    
    
    
   
   
   Seed = 57, Cfg_scale: 6.5 
   Seed = 57, Cfg_scale: 6.5 
   Seed = 57, Cfg_scale: 6.5 
   
   
   A graphic novel style illustration of a 7 year old Peruvian girl with dark hair in two low braids wearing a school uniform riding a bike on a mountain pass Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement. 
   A graphic novel style illustation of a 7 year old Peruvian girl with dark hair in two low braids wearing a school uniform walking on a path through tall grass in the Andes Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement. 
   A graphic novel style illustration of a 7 year old Peruvian girl with dark hair in two low braids wearing a school uniform eating ice cream at the beach Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement. 
   
  
 
Storyboard development pipeline 
Building upon the character consistency techniques weâ€™ve discussed, we can now implement an end-to-end storyboard development pipeline that transforms written scene and character descriptions into visually coherent storyboards. This systematic approach uses our established parameters for style descriptions, seed values, and cfgScale values to provide character consistency while adapting to different narrative contexts. The following are some example scene and character descriptions: 
 
 "scenes":[
    {
        "description": "Mayu stands at the edge of a mountainous path, clutching
            a book. Her mother, Maya, kneels beside her, offering words of encouragement
            and handing her the book. Mayu looks nervous but determined as she prepares
            to start her journey."
    },
    {
        "description": "Mayu encounters a 'danger' sign with a drawing of a
            snake. She looks scared, but then remembers her mother's words. She takes a
            deep breath, looks at her book for reassurance, and then searches for a stick
            on the ground."
    },
    {
        "description": "Mayu bravely makes her way through tall grass, swinging
            her stick and making noise to scare off potential snakes. Her face shows a
            mix of fear and courage as she pushes forward on her journey."
    }
],
"characters":{
    "Mayu":  "A 7-year-old Peruvian girl with dark hair in two low braids wearing a
        school uniform",
    "Maya":  "An older Peruvian woman with long dark hair tied back in a bun, wearing
        traditional Peruvian clothing"
}
 
 
 
Our pipeline uses Amazon Nova Lite to first craft optimized image prompts incorporating our established best practices, which are then passed to Amazon Nova Canvas for image generation. By setting numberOfImages higher (typically three variations), while maintaining consistent seed and cfgScale values, we give creators multiple options that preserve character consistency. We used the following prompt for Amazon Nova Lite to generate optimized image prompts: 
 
 Describe an image that best represents the scene described. Here are some examples:
scene: Rosa is in the kitchen, rummaging through the pantry, looking for a snack. She
    hears a strange noise coming from the back of the pantry and becomes startled.
imagery: A dimly lit pantry with shelves stocked with various food items, and Rosa
    peering inside, her face expressing curiosity and a hint of fear.
scene: Rosa says goodbye to her mother, Maya. Maya offers her words of encouragement.
imagery: A wide shot of Rosa's determined face, facing Maya and receiving a small wrapped
    gift.
Only describe the imagery. Use no more than 60 words.
scene: {scene_description}
imagery:
 
 
Our pipeline generated the following storyboard panels. 
 
  
   
    
   Mayu stands at the edge of a mountainous path, clutching a book. Her mother, Maya, kneels beside her, offering words of encouragement and handing her the book. Mayu looks nervous but determined as she prepares to start her journey. 
   
   
    
   Mayu encounters a â€˜dangerâ€™ sign with a drawing of a snake. She looks scared, but then remembers her motherâ€™s words. She takes a deep breath, looks at her book for reassurance, and then searches for a stick on the ground. 
   
   
    
   Mayu bravely makes her way through tall grass, swinging her stick and making noise to scare off potential snakes. Her face shows a mix of fear and courage as she pushes forward on her journey. 
   
  
 
Although these techniques noticeably improve character consistency, they arenâ€™t perfect. Upon closer inspection, you will notice that even images within the same scene show variations in character consistency. Using consistent seed values helps control these variations, and the techniques outlined in this post significantly improve consistency compared to basic prompt engineering. However, if your use case requires near-perfect character consistency, we recommend proceeding to Part 2, where we explore advanced fine-tuning techniques. 
Video generation for animated storyboards 
If you want to go beyond static scene images to transform your storyboard into short, animated video clips, you can use Amazon Nova Reel. We use Amazon Nova Lite to convert image prompts into video prompts, adding subtle motion and camera movements optimized for the Amazon Nova Reel model. These prompts, along with the original images, serve as creative constraints for Amazon Nova Reel to generate the final animated sequences. The following is the example prompt and its resulting animated scene in GIF format: 
 
 A sunlit forest path with a 'Danger' sign featuring a snake. A 7-year-old Peruvian girl
    stands, visibly scared but resolute. Bold linework, dramatic shadows, and flat color
    palettes. High contrast lighting and cinematic composition. Mist slowly drifting.
    Camera dolly in. 
 
 
  
   
    
    
   
   
   Input Image 
   Output Video 
   
  
 
Conclusion 
In this first part of our series, we explored fundamental techniques for achieving character and style consistency using Amazon Nova Canvas, from structured prompt engineering to building an end-to-end storyboarding pipeline. We demonstrated how combining style descriptions, seed values, and careful cfgScale parameter control can significantly improve character consistency across different scenes. We also showed how integrating Amazon Nova Lite with Amazon Nova Reel can enhance the storyboarding workflow, enabling both optimized prompt generation and animated sequences. 
Although these techniques provide a solid foundation for consistent storyboard generation, they arenâ€™t perfectâ€”subtle variations might still occur. We invite you to continue to Part 2, where we explore advanced model fine-tuning techniques that can help achieve near-perfect character consistency and visual fidelity. 
 
About the authors 
Alex Burkleaux is a Senior AI/ML Specialist Solution Architect at AWS. She helps customers use AI Services to build media solutions using Generative AI. Her industry experience includes over-the-top video, database management systems, and reliability engineering. 
James Wu is a Senior AI/ML Specialist Solution Architect at AWS, helping customers design and build AI/ML solutions. Jamesâ€™s work covers a wide range of ML use cases, with a primary interest in computer vision, deep learning, and scaling ML across the enterprise. Prior to joining AWS, James was an architect, developer, and technology leader for over 10 years, including 6 years in engineering and 4 years in marketing &amp; advertising industries. 
Vladimir Budilov is a Principal Solutions Architect at AWS focusing on agentic &amp; generative AI, and software architecture. He leads large-scale GenAI implementations, bridging cutting-edge AI capabilities with production-ready business solutions, while optimizing for cost and solution resilience. 
Nora Shannon Johnson is a Solutions Architect at Amazon Music focused on discovery and growth through AI/ML. In the past, she supported AWS through the development of generative AI prototypes and tools for developers in financial services, health care, retail, and more. She has been an engineer and consultant in various industries including DevOps, fintech, industrial AI/ML, and edtech in the United States, Europe, and Latin America. 
Ehsan Shokrgozar is a Senior Solutions Architect specializing in Media and Entertainment at AWS. He is passionate about helping M&amp;E customers build more efficient workflows. He combines his previous experience as Technical Director and Pipeline Engineer at various Animation/VFX studios with his knowledge of building M&amp;E workflows in the cloud to help customers achieve their business goals.
â€¢ Authenticate Amazon Q Business data accessors using a trusted token issuer
  Since its general availability in 2024, Amazon Q Business (Amazon Q) has enabled independent software vendors (ISVs) to enhance their Software as a Service (SaaS) solutions through secure access to customersâ€™ enterprise data by becoming Amazon Q Business data accessor. To find out more on data accessor, see this page. The data accessor now supports trusted identity propagation. With trusted token issuer (TTI) authorization support, ISVs as data accessor can integrate with Amazon Q index while maintaining enterprise-grade security standards for their software-as-a-service (SaaS) solutions. 
Prior to TTI support, data accessors needed to implement authorization code flow with AWS IAM Identity Center integration when accessing the Amazon Q index. With TTI support for data accessors, ISVs can now use their own OpenID Provider to authenticate enterprise users, alleviating the need for double authentication while maintaining security standards. 
In this blog post, we show you how to implement TTI authorization for data accessors, compare authentication options, and provide step-by-step guidance for both ISVs and enterprises. 
Prerequisites 
Before you begin, make sure you have the following requirements: 
 
 An AWS account with administrator access 
 Access to Amazon Q Business 
 For ISVs: 
   
   An OpenID Connect (OIDC) compatible authorization server 
    
 For enterprises: 
   
   Amazon Q Business administrator access 
   Permission to create trusted token issuers 
    
 
Solution Overview 
This solution demonstrates how to implement TTI authentication for Amazon Q Business data accessors. The following diagram illustrates the overall flow between different resources, from ISV becoming a data accessor, customer enabling ISV data accessor, to ISV accessing customerâ€™s Amazon Q index: 
 
Understanding Trusted Token Issuer Authentication 
Trusted Token Issuer represents an advanced identity integration capability for Amazon Q. At its core, TTI is a token exchange API that propagates identity information into IAM role sessions, enabling AWS services to make authorization decisions based on the actual end userâ€™s identity and group memberships. This mechanism allows AWS services to apply authorization and security controls based on the authenticated user context. The TTI support simplifies the identity integration process while maintaining robust security standards, making it possible for organizations to ensure that access to Amazon Q respects user-level permissions and group memberships. This enables fine-grained access control and maintains proper security governance within Amazon Q implementations. 
Trusted Token Issuer authentication simplifies the identity integration process for Amazon Q by enabling the propagation of user identity information into AWS IAM role sessions. Each token exchange allows AWS services to make authorization decisions based on the authenticated userâ€™s identity and group memberships. The TTI support streamlines the integration process while maintaining robust security standards, enabling organizations to implement appropriate access controls within their Amazon Q implementations. 
Understanding Data Accessors 
A data accessor is an ISV that has registered with AWS and is authorized to use their customersâ€™ Amazon Q index for the ISVâ€™s Large Language Model (LLM) solution. The process begins with ISV registration, where they provide configuration information including display name, business logo, and OpenID Connect (OIDC) configuration details for TTI support. 
During ISV registration, providers must specify their tenantId configuration â€“ a unique identifier for their application tenant. This identifier might be known by different names in various applications (such as Workspace ID in Slack or Domain ID in Asana) and is required for proper customer isolation in multi-tenant environments. 
Amazon Q customers then add the ISV as a data accessor to their environment, granting access to their Amazon Q index based on specific permissions and data source selections. Once authorized, the ISV can query the customersâ€™ index through API requests using their TTI authentication flow, creating a secure and controlled pathway for accessing customer data. 
Implementing TTI Authentication for Amazon Q index Access 
This section explains how to implement TTI authentication for accessing the Amazon Q index. The implementation involves initial setup by the customer and subsequent authentication flow implemented by data accessors for user access. 
TTI provides capabilities that enable identity-enhanced IAM role sessions through Trusted Identity Propagation (TIP), allowing AWS services to make authorization decisions based on authenticated user identities and group memberships. Hereâ€™s how it works: 
To enable data accessor access to a customerâ€™s Amazon Q index through TTI, customers must perform an initial one-time setup by adding a data accessor on Amazon Q Business application. During setup, a TTI with the data accessorâ€™s identity provider information is created in the customerâ€™s AWS IAM Identity Center, allowing the data accessorâ€™s identity provider to authenticate access to the customerâ€™s Amazon Q index. 
 
The process to set up an ISV data accessor with TTI authentication consists of the following steps: 
 
 The customerâ€™s IT administrator accesses their Amazon Q Business application and creates a trusted token issuer with the ISVâ€™s OAuth information. This returns a TrustedTokenIssuer (TTI) Amazon Resource Name (ARN).  
 The IT administrator creates an ISV data accessor with the TTI ARN received in Step 1.  
 Amazon Q Business confirms the provided TTI ARN with AWS IAM Identity Center and creates a data accessor application. 
 Upon successful creation of the ISV data accessor, the IT administrator receives data accessor details to share with the ISV.  
 The IT administrator provides these details to the ISV application. 
 
Once the data accessor setup is complete in the customerâ€™s Amazon Q environment, users can access the Amazon Q index through the ISV application by authenticating only against the data accessorâ€™s identity provider. 
 
The authentication flow proceeds as follows: 
 
 A user authenticates against the data accessorâ€™s identity provider through the ISV application. The ISV application receives an ID token for that user, generated from the ISVâ€™s identity provider with the same client ID registered on their data accessor. 
 The ISV application needs to use the AWS Identity and Access Management (IAM) role that they created during the data accessor onboarding process by calling AssumeRole API, then make CreateTokenWithIAM API request to the customerâ€™s AWS IAM Identity Center with the ID token. AWS IAM Identity Center validates the ID token with the ISVâ€™s identity provider and returns an IAM Identity Center token. 
 The ISV application requests an AssumeRole API with: IAM Identity Center token, extracted identity context, and tenantId. The tenantId is a security control jointly established between the ISV and their customer, with the customer maintaining control over how itâ€™s used in their trust relationships. This combination facilitates secure access to the correct customer environment. 
 The ISV application calls the SearchRelevantContent API with the session credentials and receives relevant content from the customerâ€™s Amazon Q index. 
 
Choosing between TTI and Authorization Code 
When implementing Amazon Q integration, ISVs need to consider two approaches, each with its own benefits and considerations: 
 
  
   
    
   Trusted Token Issuer 
   Authorization Code 
   
   
   Advantages 
   Single authentication on the ISV system 
   Enhanced security through mandatory user initiation for each session 
   
   
   Enables backend-only access to SearchRelevantContent API without user interaction 
    
   
   
   Considerations 
   Some enterprises may prefer authentication flows that require explicit user consent for each session, providing additional control over API access timing and duration 
   Requires double authentication on the ISV system 
   
   
   Requires ISVs to host and maintain OpenID Provider 
    
   
  
 
TTI excels in providing a seamless user experience through single authentication on the ISV system and enables backend-only implementations for SearchRelevantContent API access without requiring direct user interaction. However, this approach requires ISVs to maintain their own OIDC authorization server, which may present implementation challenges for some organizations. Additionally, some enterprises might have concerns about ISVs having persistent ability to make API requests on behalf of their users without explicit per-session authorization. 
Next Steps 
For ISVs: Becoming a Data Accessor with TTI Authentication 
Getting started on Amazon Q data accessor registration process with TTI authentication is straightforward. If you already have an OIDC compatible authorization server for your applicationâ€™s authentication, youâ€™re most of the way there. 
To begin the registration process, youâ€™ll need to provide the following information: 
 
 Display name and business logo that will be displayed on AWS Management Console 
 OIDC configuration details (OIDC ClientId and discovery endpoint URL) 
 TenantID configuration details that specify how your application identifies different customer environments 
 
For details, see Information to be provided to the Amazon Q Business team. 
For ISVs using Amazon Cognito as their OIDC authorization server, hereâ€™s how to retrieve the required OIDC configuration details: 
 
 To get the OIDC ClientId:- Navigate to the Amazon Cognito console- Select your User Pool- Go to â€œApplicationsâ€ &gt; â€œApp clientsâ€- The ClientId is listed under â€œClient IDâ€ for your app client 
 To get the discovery endpoint URL:- The URL follows this format:https://cognito-idp.{region}.amazonaws.com/{userPoolId}/.well-known/openid-configurationâ€“ Replace {region} with your AWS region (e.g., us-east-1)- Replace {userPoolId} with your Cognito User Pool IDFor example, if your User Pool is in us-east-1 with ID â€˜us-east-1_abcd1234â€™, your discovery endpoint URL would be: https://cognito-idp.us-east-1.amazonaws.com/us-east-1_abcd1234/.well-known/openid-configuration 
 
 
Note: While this example uses Amazon Cognito, the process will vary depending on your OIDC provider. Common providers like Auth0, Okta, or custom implementations will have their own methods for accessing these configuration details. 
Once registered, you can enhance your generative AI application with the powerful capabilities of Amazon Q, allowing your customers to access their enterprise knowledge base through your familiar interface. AWS provides comprehensive documentation and support to help you implement the authentication flow and API integration efficiently. 
For Enterprises: Enabling TTI-authenticated Data Accessor 
To enable a TTI-authenticated data accessor, your IT administrator needs to complete the following steps in the Amazon Q console: 
 
 Create a trusted token issuer using the ISVâ€™s OAuth information 
 Set up the data accessor with the generated TTI ARN 
 Configure appropriate data source access permissions 
 
This streamlined setup allows your users to access Amazon Q index through the ISVâ€™s application using their existing ISV application credentials, alleviating the need for multiple logins while maintaining security controls over your enterprise data. 
Both ISVs and enterprises benefit from AWSâ€™s comprehensive documentation and support throughout the implementation process, facilitating a smooth and secure integration experience. 
Clean up resources 
To avoid unused resources, follow these steps if you no longer need the data accessor: 
 
 Delete the data accessor: 
   
   On the Amazon Q Business console, choose Data accessors in the navigation pane 
   Select your data accessor and choose Delete. 
    
 Delete the TTI: 
   
   On the IAM Identity Center console, choose Trusted Token Issuers in the navigation pane. 
   Select the associated issuer and choose Delete. 
    
 
Conclusion 
The introduction of Trusted Token Issuer (TTI) authentication for Amazon Q data accessors marks a significant advancement in how ISVs integrate with Amazon Q Business. By enabling data accessors to use their existing OIDC infrastructure, weâ€™ve alleviated the need for double authentication while maintaining enterprise-grade security standards through TTIâ€™s robust tenant isolation mechanisms and secure multi-tenant access controls, making sure each customerâ€™s data remains protected within their dedicated environment. This streamlined approach not only enhances the end-user experience but also simplifies the integration process for ISVs building generative AI solutions. 
In this post, we showed how to implement TTI authentication for Amazon Q data accessors. We covered the setup process for both ISVs and enterprises and demonstrated how TTI authentication simplifies the user experience while maintaining security standards. 
To learn more about Amazon Q Business and data accessor integration, refer to Share your enterprise data with data accessors using Amazon Q index and Information to be provided to the Amazon Q Business team. You can also contact your AWS account team for personalized guidance. Visit the Amazon Q Business console to begin using these enhanced authentication capabilities today. 
 
About the Authors 
Takeshi Kobayashi is a Senior AI/ML Solutions Architect within the Amazon Q Business team, responsible for developing advanced AI/ML solutions for enterprise customers. With over 14 years of experience at Amazon in AWS, AI/ML, and technology, Takeshi is dedicated to leveraging generative AI and AWS services to build innovative solutions that address customer needs. Based in Seattle, WA, Takeshi is passionate about pushing the boundaries of artificial intelligence and machine learning technologies. 
Siddhant Gupta is a Software Development Manager on the Amazon Q team based in Seattle, WA. He is driving innovation and development in cutting-edge AI-powered solutions. 
Akhilesh Amara is a Software Development Engineer on the Amazon Q team based in Seattle, WA. He is contributing to the development and enhancement of intelligent and innovative AI tools.

â¸»