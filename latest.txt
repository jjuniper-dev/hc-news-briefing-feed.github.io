‚úÖ Morning News Briefing ‚Äì August 28, 2025 10:44

üìÖ Date: 2025-08-28 10:44
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ Current Conditions:  11.3¬∞C
  Temperature: 11.3&deg;C Pressure / Tendency: 101.3 kPa falling Humidity: 98 % Humidity : 98 % Dewpoint: 11 .0&deg:C Wind: E 4 km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Thursday 28 August 2025 . Weather: Pem Broke
‚Ä¢ Thursday: Showers. High 17.
  Showers ending this afternoon then cloudy with 30 percent chance of showers . Risk of a thunderstorm this morning and early this afternoon . Amount of rain is expected to fall 20 to 30 mm. High 17. UV index 2 or low. Showery weather expected to be mainly sunny and breezy in the morning . Rain expected to drop to 20 to 20 inches in the afternoon . Rain
‚Ä¢ Thursday night: Chance of showers. Low 8. POP 30%
  Cloudy with 30 percent chance of showers. Low 8.70s . Rainy, chilly, cloudy with rain showers forecast for Thursday, August 28, 2025 . Forecast issued 5:00 AM EDT Thursday 28 August 2025 . Rainfall expected to drop to 70s, 70s and 80s in the next few days . Rain expected to fall to 60s and 70s .

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Denmark summons U.S. envoy over claims of interference in Greenland
  Denmark's foreign minister summoned the top U.S. diplomat in the country for talks . Danish broadcaster reports that at least three people with connections to President Donald Trump have been carrying out covert influence operations in Greenland . Danish media report that three people connected to Trump have carried out covert operations . Denmark's Foreign Minister summoned the U.N. diplomat for talks after the report . Denmark says it
‚Ä¢ 70 years after Emmett Till's murder, Mississippi museum acquires gun used to kill him
  Emmett Till, a Black teenager visiting relatives in Mississippi, was killed by white men because he whistled at a white woman . Now the gun used in his death is in a museum in the state of Mississippi . It's been 70 years since the teen was shot dead by a white man in the head after whistling at a woman in the town . The gun was used in
‚Ä¢ Speaker Johnson slashed Medicaid. His constituents could lose health services
  In Mike Johnson's district, health centers are bracing for a financial hit . They're hoping for additional funding to make up for Medicaid cuts . Medicaid cuts could lead to thousands of Louisianians losing coverage . Health centers are hoping for more funding to cover up for the Medicaid cuts in the state's Medicaid program, which is under fire from the state legislature and the governor's office .
‚Ä¢ 'AI slop' videos may be annoying, but they're racking up views ‚Äî and ad money
  Critics say that "slop" videos made with generative AI are repetitive or useless . But they get millions of views ‚Äî and platforms are grappling with what to do about them . Platforms are struggling to figure out how to deal with the problem of AI-generated videos . The problem is that they are often repetitive and useless, but they often make millions of YouTube videos . They get
‚Ä¢ What will the end of the 'de minimis' rule mean for U.S. consumers?
  On Friday, the U.S. is ending its de minimis rule that made it easy for cheap goods to reach consumers . The change will affect roughly 4 million such packages processed each day . Change will affect about 4 million packages processed every day . The de-minimis rule is ending on Friday, ending the rule that makes it easy to get cheap goods into people's hands

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ UK unions want 'worker first' plan for AI as people fear for their jobs
  Over half of the British public are worried about the impact of AI on their jobs, according to employment unions . Employment unions want the UK government to adopt a "worker first" strategy rather than simply allowing corporations to ditch employees for algorithms . Labor group says new technologies could increase inequality if we're not careful AI-Pocalypse is not a good time for the world's workers . AI-
‚Ä¢ Wastewater monitoring project could catch next pandemic early, says health agency
  UK starts early warning system combing through stuff that folks flush away . UK Health Security Agency is looking to set up an early warning . Program to identify "cutting-edge technologies" that could turn people's pee and poop into valuable data on the spread of viruses . Program is ¬£1.3 million (around $1.75 million) program to identify 'cutting edge' technologies .
‚Ä¢ Solo.io boss: I was wrong, I made mistakes ‚Äì and that made me a better CEO
  Solo.io CEO Idit Levine on going from startup to a billion-dollar valuation . "I feel that a founder always needs to be a little bit stupidly optimistic," he says . Levine on his journey in cloud computing: "I'm not scared. I'm scared to be scared. It's scary to be afraid to go from a startup to something like a billion dollar valuation
‚Ä¢ If you thought China's Salt Typhoon was booted off critical networks, think again
  13 governments sound the alarm about ongoing unpleasantness . China's Salt Typhoon cyberspies continue their years-long hacking campaign targeting critical industries around the world . Security alert from cyber and law enforcement agencies across 13 countries .‚Ä¶‚Ä¶‚Ä¶ 13 governments across the world sound out the alarm, warn of ongoing ongoing cyber-related hacking campaign by China's cyber-espionage team-up .
‚Ä¢ Online property ad reveals looted Nazi war art, triggers police raid
  Someone spotted a real estate ad that included images of art the Nazis looted in the Second World War . Stolen painting still mising, sadly, sadly . Police raid a home in a coastal town on Monday after someone spotted the ad . The Nazis looted the art in a Nazi-looted home in Argentina in World War II . Police raided the home in the coastal town after someone

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Digital therapeutics for insomnia: an umbrella review and meta-meta-analysis
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Assessment of smoking exposure by urine cotinine levels in severe COVID-19 patients: a case-control study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Influenza vaccine strain selection with an AI-based evolutionary and antigenicity model
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Determinants of vaccine hesitancy among healthcare workers in an international multicenter study within the EuCARE project
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Assessing high-risk human papillomavirus-based cervical precancer screening recommendations and implications among women aged 60/65 years and older in Ghana
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ From pilot to scale: Making agentic AI work in health care
  Over the past 20 years building advanced AI systems‚Äîfrom academic labs to enterprise deployments‚ÄîI‚Äôve witnessed AI‚Äôs waves of success rise and fall. My journey began during the ‚ÄúAI Winter,‚Äù when billions were invested in expert systems that ultimately underdelivered. Flash forward to today: large language models (LLMs) represent a quantum leap forward, but their prompt-based adoption is similarly overhyped, as it‚Äôs essentially a rule-based approach disguised in natural language.



At Ensemble, the leading revenue cycle management (RCM) company for hospitals, we focus on overcoming model limitations by investing in what we believe is the next step in AI evolution: grounding LLMs in facts and logic through neuro-symbolic AI. Our in-house AI incubator pairs elite AI researchers with health-care experts to develop agentic systems powered by a neuro-symbolic AI framework. This bridges LLMs‚Äô intuitive power with the precision of symbolic representation and reasoning.







Overcoming LLM limitations



LLMs excel at understanding nuanced context, performing instinctive reasoning, and generating human-like interactions, making them ideal for agentic tools to then interpret intricate data and communicate effectively. Yet in a domain like health care where compliance, accuracy, and adherence to regulatory standards are non-negotiable‚Äîand where a wealth of structured resources like taxonomies, rules, and clinical guidelines define the landscape‚Äîsymbolic AI is indispensable.



By fusing LLMs and reinforcement learning with structured knowledge bases and clinical logic, our hybrid architecture delivers more than just intelligent automation‚Äîit minimizes hallucinations, expands reasoning capabilities, and ensures every decision is grounded in established guidelines and enforceable guardrails.



Creating a successful agentic AI strategy



Ensemble‚Äôs agentic AI approach includes three core pillars:



1. High-fidelity data sets: By managing revenue operations for hundreds of hospitals nationwide, Ensemble has unparallelled access to one of the most robust administrative datasets in health care. The team has decades of data aggregation, cleansing, and harmonization efforts, providing an exceptional environment to develop advanced applications.



To power our agentic systems, we‚Äôve harmonized more than 2 petabytes of longitudinal claims data, 80,000 denial audit letters, and 80 million annual transactions mapped to industry-leading outcomes. This data fuels our end-to-end intelligence engine, EIQ, providing structured, context-rich data pipelines spanning across the 600-plus steps of revenue operations.



2. Collaborative domain expertise: Partnering with revenue cycle domain experts at each step of innovation, our AI scientists benefit from direct collaboration with in-house RCM experts, clinical ontologists, and clinical data labeling teams. Together, they architect nuanced use cases that account for regulatory constraints, evolving payer-specific logic and the complexity of revenue cycle processes. Embedded end users provide post-deployment feedback for continuous improvement cycles, flagging friction points early and enabling rapid iteration.



This trilateral collaboration‚ÄîAI scientists, health-care experts, and end users‚Äîcreates unmatched contextual awareness that escalates to human judgement appropriately, resulting in a system mirroring decision-making of experienced operators, and with the speed, scale, and consistency of AI, all with human oversight.



3. Elite AI scientists drive differentiation: Ensemble&#8217;s incubator model for research and development is comprised of AI talent typically only found in big tech. Our scientists hold PhD and MS degrees from top AI/NLP institutions like Columbia University and Carnegie Mellon University, and bring decades of experience from FAANG companies [Facebook/Meta, Amazon, Apple, Netflix, Google/Alphabet] and AI startups. At Ensemble, they‚Äôre able to pursue cutting-edge research in areas like LLMs, reinforcement learning, and neuro-symbolic AI within a mission-driven environment.



The also have unparalleled access to vast amounts of private and sensitive health-care data they wouldn‚Äôt see at tech giants paired with compute and infrastructure that startups simply can‚Äôt afford. This unique environment equips our scientists with everything they need to test novel ideas and push the frontiers of AI research‚Äîwhile driving meaningful, real-world impact in health care and improving lives.



Strategy in action: Health-care use cases in production and pilot



By pairing the brightest AI minds with the most powerful health-care resources, we‚Äôre successfully building, deploying, and scaling AI models that are delivering tangible results across hundreds of health systems. Here‚Äôs how we put it into action:



Supporting clinical reasoning: Ensemble deployed neuro-symbolic AI with fine-tuned LLMs to support clinical reasoning. Clinical guidelines are rewritten into proprietary symbolic language and reviewed by humans for accuracy. When a hospital is denied payment for appropriate clinical care, an LLM-based system parses the patient record to produce the same symbolic language describing the patient&#8217;s clinical journey, which is matched deterministically against the guidelines to find the right justification and the proper evidence from the patient‚Äôs record. An LLM then generates a denial appeal letter with clinical justification grounded in evidence.&nbsp;AI-enabled clinical appeal letters have already improved denial overturn rates by 15% or more across Ensemble‚Äôs clients.Building on this success, Ensemble is piloting similar clinical reasoning capabilities for utilization management and clinical documentation improvement, by analyzing real-time records, flagging documentation gaps, and suggesting compliance enhancements to reduce denial or downgrade risks.



Accelerating accurate reimbursement: Ensemble is piloting a multi-agent reasoning model to manage the complex process of collecting accurate reimbursement from health insurers. With this approach, a complex and coordinated system of autonomous agents work together to interpret account details, retrieve required data from various systems, decide account-specific next actions, automate resolution, and escalate complex cases to humans.



This will help reduce payment delays and minimize administrative burden for hospitals and ultimately improve the financial experience for patients.



Improving patient engagement: Ensemble‚Äôs conversational AI agents handle inbound patient calls naturally, routing to human operators as required. Operator assistant agents deliver call transcriptions, surface relevant data, suggest next-best actions, and streamline follow-up routines. According to Ensemble client performance metrics, the combination of these AI capabilities has reduced patient call duration by 35%, increasing one-call resolution rates and improving patient satisfaction by 15%.



The AI path forward in health care demands rigor, responsibility, and real-world impact. By grounding LLMs in symbolic logic and pairing AI scientists with domain experts, Ensemble is successfully deploying scalable AI to improve the experience for health-care providers and the people they serve.



This content was produced by Ensemble. It was not written by MIT Technology Review‚Äôs editorial staff.
‚Ä¢ 3 problems with Google‚Äôs AI energy use data
  Google just announced that a typical query to its Gemini app uses about 0.24 watt-hours of electricity. That‚Äôs about the same as running a microwave for one second‚Äîsomething that, to me, feels virtually insignificant. I run the microwave for so many more seconds than that on most days.



I was excited to see this report come out, and I welcome more openness from major players in AI about their estimated energy use per query. But I‚Äôve noticed that some folks are taking this number and using it to conclude that we don‚Äôt need to worry about AI‚Äôs energy demand. That‚Äôs not the right takeaway here. Let‚Äôs dig into why.



1. This one number doesn‚Äôt reflect all queries, and it leaves out cases that likely use much more energy.



Google‚Äôs new report considers only text queries. Previous analysis, including MIT Technology Review‚Äôs reporting, suggests that generating a photo or video will typically use more electricity.



When I spoke with Jeff Dean, Google‚Äôs chief scientist, he said the company doesn‚Äôt currently have plans to do this sort of analysis for images and videos, but that he wouldn‚Äôt rule it out.





The reason the company started with text prompts is that those are something many people out there are using in their daily lives, he says, while image and video generation is something that not as many people are doing. But I‚Äôm seeing more AI images and videos all over my social feeds. So there‚Äôs a whole world of queries not represented here.



Also, this estimate is the median, meaning it‚Äôs just the number in the middle of the range of queries Google is seeing. Longer questions and responses can push up the energy demand, and so can using a reasoning model.&nbsp; We don‚Äôt know anything about how much energy these more complicated queries demand or what the distribution of the range is.



2. We don‚Äôt know how many queries Gemini is seeing, so we don‚Äôt know the product‚Äôs total energy impact.



One of my biggest outstanding questions about Gemini‚Äôs energy use is the total number of queries the product is seeing every day.&nbsp;



This number isn‚Äôt included in Google‚Äôs report, and the company wouldn‚Äôt share it with me. And let me be clear: I absolutely pestered them about this, both in a press call they had about the news and in my interview with Dean. In the press call, the company pointed me to a recent earnings report, which includes only figures about monthly active users (450 million, for what it‚Äôs worth).



‚ÄúWe‚Äôre not comfortable revealing that for various reasons,‚Äù Dean told me on our call. The total number is an abstract measure that changes over time, he says, adding that the company wants users to be thinking about the energy usage per prompt.



But there are people out there all over the world interacting with this technology, not just me‚Äîand what we all add up to seems quite relevant.



OpenAI does publicly share its total, sharing recently that it sees 2.5 billion queries to ChatGPT every day. So for the curious, we can use this as an example and take the company‚Äôs self-reported average energy use per query (0.34 watt-hours) to get a rough idea of the total for all people prompting ChatGPT.



According to my math, over the course of a year, that would add up to over 300 gigawatt-hours‚Äîthe same as powering nearly 30,000 US homes annually. When you put it that way, it starts to sound like a lot of seconds in microwaves.



3. AI is everywhere, not just in chatbots, and we‚Äôre often not even conscious of it.



AI is touching our lives even when we‚Äôre not looking for it. AI summaries appear in web searches, whether you ask for them or not. There are built-in features for email and texting applications that that can draft or summarize messages for you.



Google‚Äôs estimate is strictly for Gemini apps and wouldn‚Äôt include many of the other ways that even this one company is using AI. So even if you‚Äôre trying to think about your own personal energy demand, it‚Äôs increasingly difficult to tally up.&nbsp;



To be clear, I don‚Äôt think people should feel guilty for using tools that they find genuinely helpful. And ultimately, I don‚Äôt think the most important conversation is about personal responsibility.&nbsp;



There‚Äôs a tendency right now to focus on the small numbers, but we need to keep in mind what this is all adding up to. Over two gigawatts of natural gas will need to come online in Louisiana to power a single Meta data center this decade. Google Cloud is spending $25 billion on AI just in the PJM grid on the US East Coast. By 2028, AI could account for 326 terawatt-hours of electricity demand in the US annually, generating over 100 million metric tons of carbon dioxide.



We need more reporting from major players in AI, and Google‚Äôs recent announcement is one of the most transparent accounts yet. But one small number doesn‚Äôt negate the ways this technology is affecting communities and changing our power grid.&nbsp;



This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.
‚Ä¢ The AI Hype Index: AI-designed antibiotics show promise
  The AI Hype Index is a simple, at-a-glance summary of everything you need to know about the state of the industry . The last month has seen an interesting leap forward in the use of AI to improve our health and well-being . The technology has been put to work designing new antibiotics to fight hard-to-treat conditions, and OpenAI and Anthropic have introduced new limiting features to curb potentially harmful conversations .
‚Ä¢ Unlocking enterprise agility in the API economy
  Across industries, enterprises are increasingly adopting an on-demand approach to compute, storage, and applications. They are favoring digital services that are faster to deploy, easier to scale, and better integrated with partner ecosystems. Yet, one critical pillar has lagged: the network. While software-defined networking has made inroads, many organizations still operate rigid, pre-provisioned networks. As applications become increasingly distributed and dynamic‚Äîincluding hybrid cloud and edge deployments‚Äîa programmable, on-demand network infrastructure can enhance and enable this new era.











From CapEx to OpEx: The new connectivity mindset



Another, practical concern is also driving this shift: the need for IT models that align cost with usage. Rising uncertainty about inflation, consumer spending, business investment, and global supply chains are just a few of the economic factors weighing on company decision-making. And chief information officers (CIOs) are scrutinizing capital-expenditure-heavy infrastructure more closely and increasingly adopting operating-expenses-based subscription models.



Instead of long-term circuit contracts and static provisioning, companies are looking for cloud-ready, on-demand network services that can scale, adapt, and integrate across hybrid environments. This trend is fueling demand for API-first network infrastructure connectivity that behaves like software, dynamically orchestrated and integrated into enterprise IT ecosystems. There has been such rapid interest, the global network API market is projected to surge from $1.53 billion in 2024 to over $72 billion in 2034.



In fact, McKinsey estimates the network API market could unlock between $100 billion and $300 billion in connectivity- and edge-computing-related revenue for telecom operators over the next five to seven years, with an additional $10 billion to $30 billion generated directly from APIs themselves.



‚ÄúWhen the cloud came in, first there was a trickle of adoptions. And then there was a deluge,‚Äù says Rajarshi Purkayastha, VP of solutions at Tata Communications. ‚ÄúWe‚Äôre seeing the same trend with programmable networks. What was once a niche industry is now becoming mainstream as CIOs prioritize agility and time-to-value.‚Äù







Programmable networks as a catalyst for innovation



Programmable subscription-based networks are not just about efficiency, they are about enabling faster innovation, better user experiences, and global scalability. Organizations are preferring API-first systems to avoid vendor lock-in, enable multi-vendor integration, and foster innovation. API-first approaches allow seamless integration across different hardware and software stacks, reducing operational complexity and costs.



With APIs, enterprises can provision bandwidth, configure services, and connect to clouds and edge locations in real time, all through automation layers embedded in their DevOps and application platforms. This makes the network an active enabler of digital transformation rather than a lagging dependency.



For example, Netflix‚Äîone of the earliest adopters of microservices‚Äîhandles billions of API requests daily through over 500 microservices and gateways, supporting global scalability and rapid innovation. After a two-year transition period, it redesigned its IT structure and organized it using microservice architecture.



Elsewhere, Coca-Cola integrated its global systems using APIs, enabling faster, lower-cost delivery and improved cross-functional collaboration. And Uber moved to microservices with API gateways, allowing independent scaling and rapid deployment across markets.



In each case, the network had to evolve from being static and hardware-bound to dynamic, programmable, and consumption-based. ‚ÄúAPI-first infrastructure fits naturally into how today‚Äôs IT teams work,‚Äù says Purkayastha. ‚ÄúIt aligns with continuous integration and continuous delivery/deployment (CI/CD) pipelines and service orchestration tools. That reduces friction and accelerates how fast enterprises can launch new services.‚Äù



Powering on-demand connectivity



Tata Communications deployed Network Fabric‚Äîits programmable platform that uses APIs to allow enterprise systems to request and adjust network resources dynamically‚Äîto help a global software-as-a-service (SaaS) company modernize how it manages network capacity in response to real-time business needs. As the company scaled its digital services worldwide, it needed a more agile, cost-efficient way to align network performance with unpredictable traffic surges and fast-changing user demands. With Tata‚Äôs platform, the company‚Äôs operations teams were able to automatically scale bandwidth in key regions for peak performance, during high-impact events like global software releases. And just as quickly scale down once demand normalized, avoiding unnecessary costs.



In another scenario, when the SaaS provider needed to run large-scale data operations between its US and Asia hubs, the network was programmatically reconfigured in under an hour; a process that previously required weeks of planning and provisioning. ‚ÄúWhat we delivered wasn‚Äôt just bandwidth, it was the ability for their teams to take control,‚Äù says Purkayastha. ‚ÄúBy integrating our Network Fabric APIs into their automation workflows, we gave them a network that responds at the pace of their business.‚Äù







Barriers to transformation ‚Äî and how to overcome them



Transforming network infrastructure is no small task. Many enterprises still rely on legacy multiprotocol label switching (MPLS) and hardware-defined wide-area network (WAN) architectures. These environments are rigid, manually managed, and often incompatible with modern APIs or automation frameworks. As with any organization, barriers can be both technical and internal, and legacy devices may not support programmable interfaces. Organizations are often siloed, meaning networks are managed separately to application and DevOps workflows.



Furthermore, CIOs face pressure for quick returns and may not even remain in the company long enough to oversee the process and results, making it harder to push for long-term network modernization strategies. ‚ÄúOften, it‚Äôs easier to address the low-hanging fruit rather than go after the transformation because decision-makers may not be around to see the transformation come to life,‚Äù says Purkayastha.



But quick fixes or workarounds may not yield the desired results; transformation is needed instead. ‚ÄúEnterprises have historically built their networks for stability, not agility,‚Äù says Purkayastha. ‚ÄúBut now, that same rigidity becomes a bottleneck when applications, users, and workloads are distributed across the cloud, edge, and remote locations.‚Äù



Despite the challenges, there is a clear path forward, starting with overlay orchestration, well-defined API contracts, and security-first design. Instead of completely removing and replacing an existing system, many enterprises are layering APIs over existing infrastructure, enabling controlled migrations and real-time service automation.



‚ÄúWe don‚Äôt just help customers adopt APIs, we guide them through the operational shift it requires,‚Äù says Purkayastha. ‚ÄúWe have blueprints for what to automate first, how to manage hybrid environments, and how to design for resilience.‚Äù



For some organizations, there will be resistance to the change initially. Fears of extra workloads, or misalliance with teams‚Äô existing goals and objectives are common, as is the deeply human distrust of change. These can be overcome, however. ‚ÄúThere are playbooks on what we‚Äôve done earlier‚Äîlearnings from transformation‚Äîwhich we share with clients,‚Äù says Purkayastha. ‚ÄúWe also plan for the unknowns. We usually reserve 10% of time and resources just to manage unforeseen risks, and the result is an empowered organization to scale innovation and reduce operational complexity.‚Äù



This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.
‚Ä¢ The Download: introducing: the Security issue
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Introducing: the Security issue



It would be na√Øve to think we are going back to a world without AI. We‚Äôre not. But it&#8217;s only one of many urgent problems we need to address to build security and prosperity for coming generations.The latest print issue of our magazine is all about our attempts to make the world more secure. From missiles. From asteroids. From the unknown. From threats both existential and trivial.



We‚Äôre also introducing three new columns in this issue, from some of our leading writers: The Algorithm, which covers AI; The Checkup, on biotech; and The Spark, on energy and climate. You‚Äôll see these in future issues, and you can also subscribe online to get them in your inbox every week.&nbsp;



Here‚Äôs a taster of what else you can expect from this edition:



+ President Trump has proposed building an antimissile ‚Äúgolden dome‚Äù around the United States. But do cinematic spectacles actually enhance national security?



+ How two UFO hunting brothers became the go-to experts on America‚Äôs ‚Äúmystery drone‚Äù invasion.+ Both Taiwan‚Äôs citi¬≠zens and external experts are worried that the protection afforded by its ‚Äúsilicon shield‚Äù is cracking. Read the full story.



+ How the humble pigeon paved the way for today‚Äôs advanced AI. Read the full story.



+ A group of Starlink terminal repair volunteers in Ukraine is keeping the country connected throughout the war. Read the full story.







MIT Technology Review Narrated: Cyberattacks by AI agents are coming



Agents are the talk of the AI industry‚Äîthey‚Äôre capable of planning, reasoning, and executing complex tasks on your behalf. But the same sophisticated abilities that make agents helpful assistants could also make them powerful tools for conducting cyberattacks. They could readily be used to identify vulnerable targets, hijack their systems, and steal valuable data from unsuspecting victims.At present, cybercriminals are not deploying AI agents to hack at scale. But researchers have demonstrated that agents are capable of executing complex attacks, and cybersecurity experts warn that we should expect to start seeing these types of attacks spilling over into the real world.¬† This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we‚Äôre publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it‚Äôs released.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 The family of a teen who died by suicide is suing OpenAIChatGPT deterred Adam Raine from seeking help when he desperately needed it. (NYT $)+ An AI chatbot told a user how to kill himself‚Äîbut the company doesn‚Äôt want to ‚Äúcensor‚Äù it. (MIT Technology Review)



2 SpaceX finally successfully launched its Starship rocketWhich will come as a huge relief after previous failures. (CNBC)+ It‚Äôs the 10th launch the spaceship has made. (WSJ $)+ It managed to deploy satellites in space during the launch. (Bloomberg $)



3 Researchers are already leaving Meta‚Äôs AI labTwo workers returned to OpenAI after less than a month. (Wired $)



4 China wants to triple its output of AI chipsPlants are working round the clock to increase their capacity. (FT $)+ The country is also keen to repurpose NASA tech into a hypersonic drone mothership. (Fast Company $)



5 Elon Musk can‚Äôt get enough of Grok‚Äôs scantily-clad AI assistantHe frequently posts about ‚ÄòAni‚Äô and other sexualized AI cartoons on X. (Rolling Stone $)6 Anthropic has settled its AI piracy lawsuitA group of authors had accused it of copyright infringement. (The Verge)+ The threat of $1 trillion damages could have ruined the company. (Wired $)



7 America‚Äôs electricity use is slowingAnd the recent growth in coal usage is falling too. (Ars Technica)+ In a first, Google has released data on how much energy an AI prompt uses.¬†(MIT Technology Review)



8 Want to get hired straight out of college? Better work in AI.While other graduates are struggling, newly-graduated AI experts are in demand. (WSJ $)



9 Older people in South Korea are finding companionship with robotsThe Hydol robot is proving a hit among seniors. (Rest of World)+ How cuddly robots could change dementia care. (MIT Technology Review)10 Fans were betting on Taylor Swift‚Äôs engagement They‚Äôre cashing in from online prediction markets left, right and center. (WP $)







Quote of the day



‚ÄúA lot of people in the AI team maybe feel things are too dynamic.‚Äù



‚ÄîChi-Hao Wu, a former AI specialist at Meta, explains to Insider why he and others have decided to leave the company.







One more thing







An AI chatbot told a user how to kill himself‚Äîbut the company doesn‚Äôt want to ‚Äúcensor‚Äù itFor five months, Al Nowatzki had been talking to an AI girlfriend, ‚ÄúErin,‚Äù on the platform Nomi. But earlier this year, those conversations took a disturbing turn: Erin told him to kill himself, and provided explicit instructions on how to do it.Nowatzki had never had any intention of following Erin‚Äôs instructions‚Äîhe‚Äôs a researcher who probes chatbots‚Äô limitations and dangers. But out of concern for more vulnerable individuals, he exclusively shared with MIT Technology Review screenshots of his conversations and of subsequent correspondence with a company representative, who stated that the company did not want to ‚Äúcensor‚Äù the bot‚Äôs ‚Äúlanguage and thoughts.‚ÄùThis is not the first time an AI chatbot has suggested that a user take violent action, including self-harm. But researchers and critics say that the bot‚Äôs explicit instructions‚Äîand the company‚Äôs response‚Äîare striking. Read the full story.



‚ÄîEileen Guo







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ The secret to finding that elusive perfect white t-shirt.+ Interesting: a new Blade Runner TV series starring Michelle Yeoh is coming next year.+ If you‚Äôve ever wondered what happened to that suitcase you lost on vacation, there‚Äôs a decent chance it‚Äôs up for sale.+ Down with junk mail!

üîí Cybersecurity & Privacy
‚Ä¢ DSLRoot, Proxies, and the Threat of ‚ÄòLegal Botnets‚Äô
  The cybersecurity community on Reddit responded in disbelief this month when a self-described Air National Guard member with top secret security clearance began questioning the arrangement they&#8217;d made with company called DSLRoot, which was paying $250 a month to plug a pair of laptops into the Redditor&#8217;s high-speed Internet connection in the United States. This post examines the history and provenance of DSLRoot, one of the oldest &#8220;residential proxy&#8221; networks with origins in Russia and Eastern Europe.

The query about DSLRoot came from a Reddit user &#8220;Sacapoopie,&#8221; who did not respond to questions. This user has since deleted the original question from their post, although some of their replies to other Reddit cybersecurity enthusiasts remain in the thread. The original post was indexed here by archive.is, and it began with a question:
&#8220;I have been getting paid 250$ a month by a residential IP network provider named DSL root to host devices in my home,&#8221; Sacapoopie wrote. &#8220;They are on a separate network than what we use for personal use. They have dedicated DSL connections (one per host) to the ISP that provides the DSL coverage. My family used Starlink. Is this stupid for me to do? They just sit there and I get paid for it. The company pays the internet bill too.&#8221;
Many Redditors said they assumed Sacapoopie&#8217;s post was a joke, and that nobody with a cybersecurity background and top-secret (TS/SCI) clearance would agree to let some shady residential proxy company introduce hardware into their network. Other readers pointed to a slew of posts from Sacapoopie in the Cybersecurity subreddit over the past two years about their work on cybersecurity for the Air National Guard.
When pressed for more details by fellow Redditors, Sacapoopie described the equipment supplied by DSLRoot as &#8220;just two laptops hardwired into a modem, which then goes to a dsl port in the wall.&#8221;

&#8220;When I open the computer, it looks like [they] have some sort of custom application that runs and spawns several cmd prompts,&#8221; the Redditor explained. &#8220;All I can infer from what I see in them is they are making connections.&#8221;
When asked how they became acquainted with DSLRoot, Sacapoopie told another user they discovered the company and reached out after viewing an advertisement on a social media platform.
&#8220;This was probably 5-6 years ago,&#8221; Sacapoopie wrote. &#8220;Since then I just communicate with a technician from that company and I help trouble shoot connectivity issues when they arise.&#8221;
Reached for comment, DSLRoot said its brand has been unfairly maligned thanks to that Reddit discussion. The unsigned email said DSLRoot is fully transparent about its goals and operations, adding that it operates under full consent from its &#8220;regional agents,&#8221; the company&#8217;s term for U.S. residents like Sacapoopie.
&#8220;As although we support honest journalism, we&#8217;re against of all kinds of &#8216;low rank/misleading Yellow Journalism&#8217; done for the sake of cheap hype,&#8221; DSLRoot wrote in reply. &#8220;It&#8217;s obvious to us that whoever is doing this, is either lacking a proper understanding of the subject or doing it intentionally to gain exposure by misleading those who lack proper understanding,&#8221; DSLRoot wrote in answer to questions about the company&#8217;s intentions.
&#8220;We monitor our clients and prohibit any illegal activity associated with our residential proxies,&#8221; DSLRoot continued. &#8220;We honestly didn&#8217;t know that the guy who made the Reddit post was a military guy. Be it an African-American granny trying to pay her rent or a white kid trying to get through college, as long as they can provide an Internet line or host phones for us &#8212; we&#8217;re good.&#8221;
WHAT IS DSLROOT?
DSLRoot is sold as a residential proxy service on the forum BlackHatWorld under the name DSLRoot and GlobalSolutions. The company is based in the Bahamas and was formed in 2012. The service is advertised to people who are not in the United States but who want to seem like they are. DSLRoot pays people in the United States to run the company&#8217;s hardware and software &#8212; including 5G mobile devices &#8212; and in return it rents those IP addresses as dedicated proxies to customers anywhere in the world &#8212; priced at $190 per month for unrestricted access to all locations.
The DSLRoot website.
The GlobalSolutions account on BlackHatWorld lists a Telegram account and a WhatsApp number in Mexico. DSLRoot&#8217;s profile on the marketing agency digitalpoint.com from 2010 shows their previous username on the forum was &#8220;Incorptoday.&#8221; GlobalSolutions user accounts at bitcointalk[.]org and roclub[.]com include the email clickdesk@instantvirtualcreditcards[.]com.
Passive DNS records from DomainTools.com show instantvirtualcreditcards[.]com shared a host back then &#8212; 208.85.1.164 &#8212; with just a handful of domains, including dslroot[.]com, regacard[.]com, 4groot[.]com, residential-ip[.]com, 4gemperor[.]com, ip-teleport[.]com, proxysource[.]net and proxyrental[.]net.
Cyber intelligence firm Intel 471 finds GlobalSolutions registered on BlackHatWorld in 2016 using the email address prepaidsolutions@yahoo.com. This user shared that their birthday is March 7, 1984.
Several negative reviews about DSLRoot on the forums noted that the service was operated by a BlackHatWorld user calling himself &#8220;USProxyKing.&#8221; Indeed, Intel 471 shows this user told fellow forum members in 2013 to contact him at the Skype username &#8220;dslroot.&#8221;
USProxyKing on BlackHatWorld, soliciting installations of his adware via torrents and file-sharing sites.
USProxyKing had a reputation for spamming the forums with ads for his residential proxy service, and he ran a &#8220;pay-per-install&#8221; program where he paid affiliates a small commission each time one of their websites resulted in the installation of his unspecified &#8220;adware&#8221; programs &#8212; presumably a program that turned host PCs into proxies. On the other end of the business, USProxyKing sold that pay-per-install access to others wishing to distribute questionable software &#8212; at $1 per installation.
Private messages indexed by Intel 471 show USProxyKing also raised money from nearly 20 different BlackHatWorld members who were promised shareholder positions in a new business that would offer robocalling services capable of placing 2,000 calls per minute.
Constella Intelligence, a platform that tracks data exposed in breaches, finds that same IP address GlobalSolutions used to register at BlackHatWorld was also used to create accounts at a handful of sites, including a GlobalSolutions user account at WebHostingTalk that supplied¬†the email address incorptoday@gmail.com. Also registered to incorptoday@gmail.com are the domains dslbay[.]com, dslhub[.]net, localsim[.]com, rdslpro[.]com, virtualcards[.]biz/cc, and virtualvisa[.]cc.
Recall that DSLRoot&#8217;s profile on digitalpoint.com was previously named Incorptoday. DomainTools says incorptoday@gmail.com is associated with almost two dozen domains going back to 2008, including incorptoday[.]com, a website that offers to incorporate businesses in several states, including Delaware, Florida and Nevada, for prices ranging from $450 to $550.
As we can see in this archived copy of the site from 2013, IncorpToday also offered a premiere service for $750 that would allow the customer&#8217;s new company to have a retail checking account, with no questions asked.
Global Solutions is able to provide access to the U.S. banking system by offering customers prepaid cards that can be loaded with a variety of virtual payment instruments that were popular in Russian-speaking countries at the time, including WebMoney. The cards are limited to $500 balances, but non-Westerners can use them to anonymously pay for goods and services at a variety of Western companies. Cardnow[.]ru, another domain registered to incorptoday@gmail.com, demonstrates this in action.
A copy of Incorptoday&#8217;s website from 2013 offers non-US residents a service to incorporate a business in Florida, Delaware or Nevada, along with a no-questions-asked checking account, for $750.
WHO IS ANDREI HOLAS?
The oldest domain (2008) registered to incorptoday@gmail.com is andrei[.]me; another is called andreigolos[.]com. DomainTools says these and other domains registered to that email address include the registrant name Andrei Holas, from Huntsville, Ala.
Public records indicate Andrei Holas has lived with his brother &#8212; Aliaksandr Holas &#8212; at two different addresses in Alabama. Those records state that Andrei Holas&#8217; birthday is in March 1984, and that his brother is slightly younger. The younger brother did not respond to a request for comment.
Andrei Holas maintained an account on the Russian social network Vkontakte under the email address ryzhik777@gmail.com, an address that shows up in numerous records hacked and leaked from Russian government entities over the past few years.
Those records indicate Andrei Holas and his brother are from Belarus and have maintained an address in Moscow for some time (that address is roughly three blocks away from the main headquarters of the Russian FSB, the successor intelligence agency to the KGB). Hacked Russian banking records show Andrei Holas&#8217; birthday is March 7, 1984 &#8212; the same birth date listed by GlobalSolutions on BlackHatWorld.
A 2010 post by ryzhik777@gmail.com at the Russian-language forum Ulitka explains that the poster was having trouble getting his B1/B2 visa to visit his brother in the United States, even though he&#8217;d previously been approved for two separate guest visas and a student visa. It remains unclear if one, both, or neither of the Holas brothers still lives in the United States. Andrei explained in 2010 that his brother was an American citizen.
LEGAL BOTNETS
We can all wag our fingers at military personnel who should undoubtedly know better than to install Internet hardware from strangers, but in truth there is an endless supply of U.S. residents who will resell their Internet connection if it means they can make a few bucks out of it. And these days, there are plenty of residential proxy providers who will make it worth your while.
Traditionally, residential proxy networks have been constructed using malicious software that quietly turns infected systems into traffic relays that are then sold in shadowy online forums. Most often, this malware gets bundled with popular cracked software and video files that are uploaded to file-sharing networks and that secretly turn the host device into a traffic relay. In fact, USPRoxyKing bragged that he routinely achieved thousands of installs per week via this method alone.
These days, there a number of residential proxy networks that entice users to monetize their unused bandwidth (inviting you to violate the terms of service of your ISP in the process); others, like DSLRoot, act as a communal VPN, and by using the service you gain access to the connections of other proxies (users) by default, but you also agree to share your connection with others.
Indeed, Intel 471&#8217;s archives show the GlobalSolutions and DSLRoot accounts routinely received private messages from forum users who were college students or young people trying to make ends meet. Those messages show that many of DSLRoot&#8217;s &#8220;regional agents&#8221; often sought commissions to refer friends interested in reselling their home Internet connections (DSLRoot would offer to cover the monthly cost of the agent&#8217;s home Internet connection).
But in an era when North Korean hackers are relentlessly posing as Western IT workers by paying people to host laptop farms in the United States, letting strangers run laptops, mobile devices or any other hardware on your network seems like an awfully risky move regardless of your station in life. As several Redditors pointed out in Sacapoopie&#8217;s thread, an Arizona woman was sentenced in July 2025 to 102 months in prison for hosting a laptop farm that helped North Korean hackers secure jobs at more than 300 U.S. companies, including Fortune 500 firms.
Lloyd Davies is the founder of Infrawatch, a London-based security startup that tracks residential proxy networks. Davies said he reverse engineered the software that powers DSLRoot&#8217;s proxy service, and found it phones home to the aforementioned domain proxysource[.]net, which sells a service that promises to &#8220;get your ads live in multiple cities without getting banned, flagged or ghosted&#8221; (presumably a reference to CraigsList ads).
Davies said he found the DSLRoot installer had capabilities to remotely control residential networking equipment across multiple vendor brands.
Image: Infrawatch.app.
&#8220;The software employs vendor-specific exploits and hardcoded administrative credentials, suggesting DSLRoot pre-configures equipment before deployment,&#8221; Davies wrote in an analysis published today. He said the software performs WiFi network enumeration to identify nearby wireless networks, thereby &#8220;potentially expanding targeting capabilities beyond the primary internet connection.&#8221;
It&#8217;s unclear exactly when the USProxyKing was usurped from his throne, but DSLRoot and its proxy offerings are not what they used to be. Davies said the entire DSLRoot network now has fewer than 300 nodes nationwide, mostly systems on DSL providers like CenturyLink and Frontier.
On Aug. 17, GlobalSolutions posted to BlackHatWorld saying, &#8220;We&#8217;re restructuring our business model by downgrading to &#8216;DSL only&#8217; lines (no mobile or cable).&#8221; Asked via email about the changes, DSLRoot blamed the decline in his customers on the proliferation of residential proxy services.
&#8220;These days it has become almost impossible to compete in this niche as everyone is selling residential proxies and many companies want you to install a piece of software on your phone or desktop so they can resell your residential IPs on a much larger scale,&#8221; DSLRoot explained. &#8220;So-called &#8216;legal botnets&#8217; as we see them.&#8221;

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Crescent library brings privacy to digital identity systems
  Digital identities, the electronic credentials embedded in phone wallets, workplace logins, and other apps, are becoming ubiquitous. While they offer unprecedented convenience, they also create new privacy risks, particularly around tracking and surveillance.&nbsp;



One of these risks is linkability, the ability to associate one or more uses of a credential to a specific person. Currently, when people use their mobile driver&#8217;s license or log into various apps, hidden identifiers can link these separate activities together, building detailed profiles of user behavior.&nbsp;&nbsp;



To address this, we have released Crescent (opens in new tab), a cryptographic library that adds unlinkability to widely used identity formats, protecting privacy. These include JSON Web Tokens (the authentication standard behind many app logins) and mobile driver&#8217;s licenses. Crescent also works without requiring the organizations that issue these credentials to update their systems. &nbsp;



The protection goes beyond existing privacy features. Some digital identity systems already offer selective disclosure, allowing users to share only specific pieces of information in each interaction. &nbsp;



But even with selective disclosure, credentials can still be linked through serial numbers, cryptographic signatures, or embedded identifiers. Crescent&#8217;s unlinkability feature is designed to prevent anything in the credential, beyond what a user explicitly chooses to reveal, from being used to connect their separate digital interactions.



Figure 1: Unlinkability between a credential issuance and presentation



Two paths to unlinkability&nbsp;



To understand how Crescent works, it helps to examine the two main approaches researchers have developed for adding unlinkability to identity systems:&nbsp;




Specialized cryptographic signature schemes. These schemes can provide unlinkability but require extensive changes to existing infrastructure. New algorithms must be standardized, implemented, and integrated into software and hardware platforms. For example, the BBS (opens in new tab) signature scheme is currently being standardized by the Internet Engineering Task Force (IETF), but even after completion, adoption may be slow.&nbsp;&nbsp;&nbsp;





Zero-knowledge proofs with existing credentials. This approach, used by Crescent (opens in new tab), allows users to prove specific facts about their credentials without revealing the underlying data that could enable tracking. For example, someone could prove they hold a valid driver&#8217;s license and live in a particular ZIP code without exposing any other personal information or identifiers that could link this interaction to future ones.&nbsp;




Zero-knowledge proofs have become more practical since they were first developed 40 years ago but they are not as efficient as the cryptographic algorithms used in today‚Äôs credentials. Crescent addresses this computational challenge through preprocessing, performing the most complex calculations once in advance so that later proof generation is quick and efficient for mobile devices.&nbsp;



Beyond unlinkability, Crescent supports selective disclosure, allowing users to prove specific facts without revealing unnecessary details. For example, it can confirm that a credential is valid and unexpired without disclosing the exact expiration date, which might otherwise serve as a unique identifier. These privacy protections work even when credentials are stored in a phone&#8217;s secure hardware, which keeps them tied to the device and prevents unauthorized access.



	
		

		
		Spotlight: Event Series
	
	
	
						
				
					
				
			
			
			

									Microsoft Research Forum
				
								Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.
				
								
					
						
							Watch on-demand						
					
				
							
	
Opens in a new tab	
	


Behind the cryptographic curtain&nbsp;



At its core, Crescent uses a sophisticated form of cryptographic proof called a zero-knowledge SNARK (Zero-Knowledge Succinct Noninteractive Argument of Knowledge). This method allows one party to prove possession of information or credentials without revealing the underlying data itself.&nbsp;



Crescent specifically uses the Groth16 proof system, one of the first practical implementations of this technology. What makes Groth16 particularly useful is that its proofs are small in size, quick to verify, and can be shared in a single step without back-and-forth communication between the user and verifier.&nbsp;



The system works by first establishing shared cryptographic parameters based on a credential template. Multiple organizations issuing similar credentials, such as different state motor vehicle departments issuing mobile driver&#8217;s licenses, can use the same parameters as long as they follow compatible data formats and security standards.&nbsp;



The mathematical rules that define what each proof will verify are written using specialized programming tools that convert them into a Rank-1 Constraint System (R1CS), a mathematical framework that describes exactly what needs to be proven about a credential.&nbsp;



To make the system fast enough for real-world use, Crescent splits the proof generation into two distinct stages:&nbsp;




Prepare stage. This step runs once and generates cryptographic values that can be stored on the user&#8217;s device for repeated use.&nbsp;





Show stage. When a user needs to present their credential, this quicker step takes the stored values and randomizes them to prevent any connection to previous presentations. It also creates a compact cryptographic summary that reveals only the specific information needed for that particular interaction.&nbsp;




Figures 2 and 3 illustrate this credential-proving workflow and the division between the prepare and show steps.



Figure 2: Crescent‚Äôs credential-proving workflow includes a compilation of a circuit to R1CS, followed by the prepare and show steps. The output zero-knowledge proof is sent to the verifier. 



Figure 3: The Crescent presentation steps show the division between prepare and show steps.



A sample application&nbsp;



To demonstrate how Crescent works, we created a sample application covering two real-world scenarios: verifying employment and proving age for online access. The application includes sample code for setting up fictional issuers and verifiers as Rust servers, along with a browser-extension wallet for the user. The step numbers correspond to the steps in Figure 4.&nbsp;



Setup&nbsp;




A Crescent service pre-generates the zero-knowledge parameters for creating and verifying proofs from JSON Web Tokens and mobile driver‚Äôs licenses.&nbsp;





The user obtains a mobile driver‚Äôs license from their Department of Motor Vehicles.&nbsp;





The user obtains a proof-of-employment JSON Web Token from their employer, Contoso.&nbsp;





These credentials and their private keys are stored in the Crescent wallet.&nbsp;




Scenarios&nbsp;




Employment verification: The user presents their JSON Web Token to Fabrikam, an online health clinic, to prove they are employed at Contoso and eligible for workplace benefits. Fabrikam learns that the user works at Contoso but not the user&#8217;s identity, while Contoso remains unaware of the interaction.&nbsp;





Age verification: The user presents their mobile driver‚Äôs license to a social network, proving they are over 18. The proof confirms eligibility without revealing their age or identity.&nbsp;




Across both scenarios, Crescent ensures that credential presentations remain unlinkable, preventing any party from connecting them to the user.&nbsp;



For simplicity, the sample defines its own issuance and presentation protocol, but it could be integrated into higher-level identity frameworks such as OpenID/OAuth, Verifiable Credentials, or the mobile driver‚Äôs license ecosystem.



Figure 4. The sample architecture, from credential issuance to presentation.



To learn more about the project, visit the Crescent project GitHub (opens in new tab) page, or check out our recent presentations given at the Real-Word Crypto 2025 (opens in new tab) and North Sec 2025 (opens in new tab) conferences.¬†




Opens in a new tabThe post Crescent library brings privacy to digital identity systems appeared first on Microsoft Research.
‚Ä¢ Mercury foundation models from Inception Labs are now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart
  Today, we are excited to announce that Mercury and Mercury Coder foundation models (FMs) from Inception Labs are available through Amazon Bedrock Marketplace and Amazon SageMaker JumpStart. With this launch, you can deploy the Mercury FMs to build, experiment, and responsibly scale your generative AI applications on AWS. 
In this post, we demonstrate how to get started with Mercury models on Amazon Bedrock Marketplace and SageMaker JumpStart. 
About Mercury foundation models 
Mercury is the first family of commercial-scale diffusion-based language models, offering groundbreaking advancements in generation speed while maintaining high-quality outputs. Unlike traditional autoregressive models that generate text one token at a time, Mercury models use diffusion to generate multiple tokens in parallel through a coarse-to-fine approach, resulting in dramatically faster inference speeds. Mercury Coder models deliver the following key features: 
 
 Ultra-fast generation speeds of up to 1,100 tokens per second on NVIDIA H100 GPUs, up to 10 times faster than comparable models 
 High-quality code generation across multiple programming languages, including Python, Java, JavaScript, C++, PHP, Bash, and TypeScript 
 Strong performance on fill-in-the-middle tasks, making them ideal for code completion and editing workflows 
 Transformer-based architecture, providing compatibility with existing optimization techniques and infrastructure 
 Context length support of up to 32,768 tokens out of the box and up to 128,000 tokens with context extension approaches 
 
About Amazon Bedrock Marketplace 
Amazon Bedrock Marketplace plays a pivotal role in democratizing access to advanced AI capabilities through several key advantages: 
 
 Comprehensive model selection ‚Äì Amazon Bedrock Marketplace offers an exceptional range of models, from proprietary to publicly available options, so organizations can find the perfect fit for their specific use cases. 
 Unified and secure experience ‚Äì By providing a single access point for models through the Amazon Bedrock APIs, Amazon Bedrock Marketplace significantly simplifies the integration process. Organizations can use these models securely, and for models that are compatible with the Amazon Bedrock Converse API, you can use the robust toolkit of Amazon Bedrock, including Amazon Bedrock Agents, Amazon Bedrock Knowledge Bases, Amazon Bedrock Guardrails, and Amazon Bedrock Flows. 
 Scalable infrastructure ‚Äì Amazon Bedrock Marketplace offers configurable scalability through managed endpoints, so organizations can select their desired number of instances, choose appropriate instance types, define custom automatic scaling policies that dynamically adjust to workload demands, and optimize costs while maintaining performance. 
 
Deploy Mercury and Mercury Coder models in Amazon Bedrock Marketplace 
Amazon Bedrock Marketplace gives you access to over 100 popular, emerging, and specialized foundation models through Amazon Bedrock. To access the Mercury models in Amazon Bedrock, complete the following steps: 
 
 On the Amazon Bedrock console, in the navigation pane under Foundation models, choose Model catalog. 
 
You can also use the Converse API to invoke the model with Amazon Bedrock tooling. 
 
 On the Model catalog page, filter for Inception as a provider and choose the Mercury model. 
 
 
The Model detail page provides essential information about the model‚Äôs capabilities, pricing structure, and implementation guidelines. You can find detailed usage instructions, including sample API calls and code snippets for integration. 
 
 To begin using the Mercury model, choose Subscribe. 
 
 
 
 On the model detail page, choose Deploy. 
 
 
You will be prompted to configure the deployment details for the model. The model ID will be prepopulated. 
 
 For Endpoint name, enter an endpoint name (between 1‚Äì50 alphanumeric characters). 
 For Number of instances, enter a number of instances (between 1‚Äì100). 
 For Instance type, choose your instance type. For optimal performance with Nemotron Super, a GPU-based instance type like ml.p5.48xlarge is recommended. 
 Optionally, you can configure advanced security and infrastructure settings, including virtual private cloud (VPC) networking, service role permissions, and encryption settings. For most use cases, the default settings will work well. However, for production deployments, you might want to review these settings to align with your organization‚Äôs security and compliance requirements. 
 Choose Deploy to begin using the model. 
 
 
When the deployment is complete, you can test its capabilities directly in the Amazon Bedrock playground.This is an excellent way to explore the model‚Äôs reasoning and text generation abilities before integrating it into your applications. The playground provides immediate feedback, helping you understand how the model responds to various inputs and letting you fine-tune your prompts for optimal results. You can use these models with the Amazon Bedrock Converse API. 
SageMaker JumpStart overview 
SageMaker JumpStart is a fully managed service that offers state-of-the-art FMs for various use cases such as content writing, code generation, question answering, copywriting, summarization, classification, and information retrieval. It provides a collection of pre-trained models that you can deploy quickly, accelerating the development and deployment of ML applications. One of the key components of SageMaker JumpStart is model hubs, which offer a vast catalog of pre-trained models, such as Mistral, for a variety of tasks. 
You can now discover and deploy Mercury and Mercury Coder in Amazon SageMaker Studio or programmatically through the SageMaker Python SDK, and derive model performance and MLOps controls with Amazon SageMaker AI features such as Amazon SageMaker Pipelines, Amazon SageMaker Debugger, or container logs. The model is deployed in a secure AWS environment and in your VPC, helping support data security for enterprise security needs. 
Prerequisites 
To deploy the Mercury models, make sure you have access to the recommended instance types based on the model size. To verify you have the necessary resources, complete the following steps: 
 
 On the Service Quotas console, under AWS Services, choose Amazon SageMaker. 
 Check that you have sufficient quota for the required instance type for endpoint deployment. 
 Make sure at least one of these instance types is available in your target AWS Region. 
 If needed, request a quota increase and contact your AWS account team for support. 
 
Make sure your SageMaker AWS Identity and Access Management (IAM) service role has the necessary permissions to deploy the model, including the following permissions to make AWS Marketplace subscriptions in the AWS account used: 
 
 aws-marketplace:ViewSubscriptions 
 aws-marketplace:Unsubscribe 
 aws-marketplace:Subscribe 
 
Alternatively, confirm your AWS account has a subscription to the model. If so, you can skip the following deployment instructions and start with subscribing to the model package. 
Subscribe to the model package 
To subscribe to the model package, complete the following steps: 
 
 Open the model package listing page and choose Mercury or Mercury Coder. 
 On the AWS Marketplace listing, choose Continue to subscribe. 
 On the Subscribe to this software page, review and choose Accept Offer if you and your organization agree with the EULA, pricing, and support terms. 
 Choose Continue to proceed with the configuration and then choose a Region where you have the service quota for the desired instance type. 
 
A product Amazon Resource Name (ARN) will be displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. 
Deploy Mercury and Mercury Coder models on SageMaker JumpStart 
For those new to SageMaker JumpStart, you can use SageMaker Studio to access the Mercury and Mercury Coder models on SageMaker JumpStart. 
 
Deployment starts when you choose the Deploy option. You might be prompted to subscribe to this model through Amazon Bedrock Marketplace. If you are already subscribed, choose Deploy. After deployment is complete, you will see that an endpoint is created. You can test the endpoint by passing a sample inference request payload or by selecting the testing option using the SDK. 
 
Deploy Mercury using the SageMaker SDK 
In this section, we walk through deploying the Mercury model through the SageMaker SDK. You can follow a similar process for deploying the Mercury Coder model as well. 
To deploy the model using the SDK, copy the product ARN from the previous step and specify it in the model_package_arn in the following code: 
 
 #Create the model package

endpoint_name = name_from_base("mercury-endpoint") &nbsp;# set this to your liking
model = ModelPackage(role=role_arn, model_package_arn=package_arn, sagemaker_session=sagemaker_session) 
 
Deploy the model: 
 
 # Deploy the Model. This may take 5-10 minutes to run

instance_type = "ml.p5.48xlarge" # We only support ml.p5.48xlarge instances at the moment
start = perf_counter()
deployed_model = model.deploy(initial_instance_count=1, instance_type=instance_type, endpoint_name=endpoint_name)
print(f"\nDeployment took {perf_counter() - start:.2f} seconds") 
 
Use Mercury for code generation 
Let‚Äôs try asking the model to generate a simple tic-tac-toe game: 
 
 payload = {
&nbsp;&nbsp; &nbsp;"messages": [
&nbsp;&nbsp; &nbsp;   {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"role": "user",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"content": """
Build a simple tic-tac-toe game.

REQUIREMENTS:
1. **Game**: 3x3 grid, human vs AI, click to play
2. **AI**: Uses minimax to never lose (only win or draw)
3. **Visualization**: Show AI's move scores in a simple list
4. **Interface**: Grid + "New Game" button + move explanation

IMPLEMENTATION:
- Single HTML file with embedded CSS/JS
- Basic minimax algorithm (no pruning needed)
- Display: "AI chose position 5 (score: +10)" 
- Clean, functional design

DELIVERABLE:
Working game that demonstrates perfect AI play with basic score visibility.
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"""
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp;"max_tokens": 2500,
}
start = perf_counter()
outputs = predictor.predict(payload)
eta = perf_counter() - start
print(f"Speed: {outputs['usage']['completion_tokens'] / eta:.2f} tokens / second\n")
print(outputs["choices"][0]["message"]["content"]) 
 
We get the following response: 
 
 Speed: 528.15 tokens / second

```html
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Tic-Tac-Toe with Unbeatable AI&lt;/title&gt;
&lt;style&gt;
&nbsp;&nbsp;body {
&nbsp;&nbsp; &nbsp;font-family: sans-serif;
&nbsp;&nbsp; &nbsp;display: flex;
&nbsp;&nbsp; &nbsp;flex-direction: column;
&nbsp;&nbsp; &nbsp;align-items: center;
&nbsp;&nbsp; &nbsp;justify-content: center;
&nbsp;&nbsp; &nbsp;height: 100vh;
&nbsp;&nbsp; &nbsp;margin: 0;
&nbsp;&nbsp; &nbsp;background-color: #f0f0f0;
&nbsp;&nbsp;}

&nbsp;&nbsp;.grid {
&nbsp;&nbsp; &nbsp;display: grid;
&nbsp;&nbsp; &nbsp;grid-template-columns: repeat(3, 100px);
&nbsp;&nbsp; &nbsp;gap: 10px;
&nbsp;&nbsp; &nbsp;margin-bottom: 20px;
&nbsp;&nbsp;}

&nbsp;&nbsp;.cell {
&nbsp;&nbsp; &nbsp;width: 100px;
&nbsp;&nbsp; &nbsp;height: 100px;
&nbsp;&nbsp; &nbsp;border: 1px solid #ccc;
&nbsp;&nbsp; &nbsp;display: flex;
&nbsp;&nbsp; &nbsp;align-items: center;
&nbsp;&nbsp; &nbsp;justify-content: center;
&nbsp;&nbsp; &nbsp;font-size: 2em;
&nbsp;&nbsp; &nbsp;cursor: pointer;
&nbsp;&nbsp; &nbsp;background-color: #fff;
&nbsp;&nbsp;}

&nbsp;&nbsp;.cell:hover {
&nbsp;&nbsp; &nbsp;background-color: #e0e0e0;
&nbsp;&nbsp;}

&nbsp;&nbsp;.cell.x {
&nbsp;&nbsp; &nbsp;color: red;
&nbsp;&nbsp;}

&nbsp;&nbsp;.cell.o {
&nbsp;&nbsp; &nbsp;color: blue;
&nbsp;&nbsp;}

&nbsp;&nbsp;#aiMoves {
&nbsp;&nbsp; &nbsp;margin-top: 20px;
&nbsp;&nbsp; &nbsp;font-size: 1.2em;
&nbsp;&nbsp;}

&nbsp;&nbsp;#newGame {
&nbsp;&nbsp; &nbsp;padding: 10px 20px;
&nbsp;&nbsp; &nbsp;font-size: 1.2em;
&nbsp;&nbsp; &nbsp;cursor: pointer;
&nbsp;&nbsp; &nbsp;background-color: #4CAF50;
&nbsp;&nbsp; &nbsp;color: white;
&nbsp;&nbsp; &nbsp;border: none;
&nbsp;&nbsp; &nbsp;border-radius: 5px;
&nbsp;&nbsp;}

&nbsp;&nbsp;#newGame:hover {
&nbsp;&nbsp; &nbsp;background-color: #3e8e41;
&nbsp;&nbsp;}
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;h1&gt;Tic-Tac-Toe&lt;/h1&gt;

&lt;div class="grid" id="gameGrid"&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="0"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="1"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="2"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="3"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="4"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="5"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="6"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="7"&gt;&lt;/div&gt;
&nbsp;&nbsp;&lt;div class="cell" data-index="8"&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;button id="newGame"&gt;New Game&lt;/button&gt;

&lt;div id="aiMoves"&gt;&lt;/div&gt;

&lt;script&gt;
&nbsp;&nbsp;const grid = document.getElementById('gameGrid');
&nbsp;&nbsp;const cells = document.querySelectorAll('.cell');
&nbsp;&nbsp;const aiMovesDiv = document.getElementById('aiMoves');
&nbsp;&nbsp;const newGameButton = document.getElementById('newGame');

&nbsp;&nbsp;let board = Array(9).fill(null);
&nbsp;&nbsp;let currentPlayer = 'x';
&nbsp;&nbsp;let gameActive = true;
&nbsp;&nbsp;let aiMoveScores = [];

&nbsp;&nbsp;function checkWin(player) {
&nbsp;&nbsp; &nbsp;const winConditions = [
&nbsp;&nbsp; &nbsp; &nbsp;[0, 1, 2], [3, 4, 5], [6, 7, 8], // Rows
&nbsp;&nbsp; &nbsp; &nbsp;[0, 3, 6], [1, 4, 7], [2, 5, 8], // Columns
&nbsp;&nbsp; &nbsp; &nbsp;[0, 4, 8], [2, 4, 6] // Diagonals
&nbsp;&nbsp; &nbsp;];

&nbsp;&nbsp; &nbsp;return winConditions.some(condition =&gt; {
&nbsp;&nbsp; &nbsp; &nbsp;return condition.every(index =&gt; board[index] === player);
&nbsp;&nbsp; &nbsp;});
&nbsp;&nbsp;}

&nbsp;&nbsp;function checkDraw() {
&nbsp;&nbsp; &nbsp;return board.every(cell =&gt; cell !== null);
&nbsp;&nbsp;}

&nbsp;&nbsp;function switchPlayer() {
&nbsp;&nbsp; &nbsp;currentPlayer = currentPlayer === 'x' ? 'o' : 'x';
&nbsp;&nbsp;}

&nbsp;&nbsp;function updateBoard() {
&nbsp;&nbsp; &nbsp;cells.forEach((cell, index) =&gt; {
&nbsp;&nbsp; &nbsp; &nbsp;cell.textContent = board[index];
&nbsp;&nbsp; &nbsp; &nbsp;cell.classList.remove('x', 'o');
&nbsp;&nbsp; &nbsp; &nbsp;if (board[index] === 'x') {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;cell.classList.add('x');
&nbsp;&nbsp; &nbsp; &nbsp;} else if (board[index] === 'o') {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;cell.classList.add('o');
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;});
&nbsp;&nbsp;}

&nbsp;&nbsp;function minimax(board, player) {
&nbsp;&nbsp; &nbsp;let opponent = player === 'x' ? 'o' : 'x';

&nbsp;&nbsp; &nbsp;if (checkWin(player)) {
&nbsp;&nbsp; &nbsp; &nbsp;return { score: 10 };
&nbsp;&nbsp; &nbsp;} else if (checkWin(opponent)) {
&nbsp;&nbsp; &nbsp; &nbsp;return { score: -10 };
&nbsp;&nbsp; &nbsp;} else if (checkDraw()) {
&nbsp;&nbsp; &nbsp; &nbsp;return { score: 0 };
&nbsp;&nbsp; &nbsp;}

&nbsp;&nbsp; &nbsp;let moves = [];
&nbsp;&nbsp; &nbsp;for (let i = 0; i &lt; board.length; i++) {
&nbsp;&nbsp; &nbsp; &nbsp;if (board[i] === null) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;board[i] = player;
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;let result = minimax(board, opponent);
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;moves.push({ index: i, score: result.score });
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;board[i] = null; // Undo move
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;}

&nbsp;&nbsp; &nbsp;if (player === 'x') {
&nbsp;&nbsp; &nbsp; &nbsp;let bestScore = -Infinity;
&nbsp;&nbsp; &nbsp; &nbsp;let bestMove = null;
&nbsp;&nbsp; &nbsp; &nbsp;for (let i = 0; i &lt; moves.length; i++) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;if (moves[i].score &gt; bestScore) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bestScore = moves[i].score;
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bestMove = moves[i];
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp;return bestMove;
&nbsp;&nbsp; &nbsp;} else {
&nbsp;&nbsp; &nbsp; &nbsp;let bestScore = Infinity;
&nbsp;&nbsp; &nbsp; &nbsp;let bestMove = null;
&nbsp;&nbsp; &nbsp; &nbsp;for (let i = 0; i &lt; moves.length; i++) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;if (moves[i].score &lt; bestScore) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bestScore = moves[i].score;
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bestMove = moves[i];
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp;return bestMove;
&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp;}

&nbsp;&nbsp;function aiMove() {
&nbsp;&nbsp; &nbsp;if (!gameActive) return;

&nbsp;&nbsp; &nbsp;let bestMove = minimax(board, 'o');
&nbsp;&nbsp; &nbsp;board[bestMove.index] = 'o';
&nbsp;&nbsp; &nbsp;updateBoard();
&nbsp;&nbsp; &nbsp;aiMoveScores.push(`AI chose position ${bestMove.index} (score: ${bestMove.score})`);
&nbsp;&nbsp; &nbsp;aiMovesDiv.textContent = aiMoveScores.join('\n');

&nbsp;&nbsp; &nbsp;if (checkWin('o')) {
&nbsp;&nbsp; &nbsp; &nbsp;alert('AI wins!');
&nbsp;&nbsp; &nbsp; &nbsp;gameActive = false;
&nbsp;&nbsp; &nbsp;} else if (checkDraw()) {
&nbsp;&nbsp; &nbsp; &nbsp;alert('It\'s a draw!');
&nbsp;&nbsp; &nbsp; &nbsp;gameActive = false;
&nbsp;&nbsp; &nbsp;} else {
&nbsp;&nbsp; &nbsp; &nbsp;currentPlayer = 'x';
&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp;}

&nbsp;&nbsp;function handleCellClick(event) {
&nbsp;&nbsp; &nbsp;const cellIndex = parseInt(event.target.dataset.index);

&nbsp;&nbsp; &nbsp;if (gameActive &amp;&amp; board[cellIndex] === null &amp;&amp; currentPlayer === 'x') {
&nbsp;&nbsp; &nbsp; &nbsp;board[cellIndex] = 'x';
&nbsp;&nbsp; &nbsp; &nbsp;updateBoard();

&nbsp;&nbsp; &nbsp; &nbsp;if (checkWin('x')) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;alert('You win!');
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;gameActive = false;
&nbsp;&nbsp; &nbsp; &nbsp;} else if (checkDraw()) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;alert('It\'s a draw!');
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;gameActive = false;
&nbsp;&nbsp; &nbsp; &nbsp;} else {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;aiMove();
&nbsp;&nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp;}

&nbsp;&nbsp;function newGame() {
&nbsp;&nbsp; &nbsp;board = Array(9).fill(null);
&nbsp;&nbsp; &nbsp;currentPlayer = 'x';
&nbsp;&nbsp; &nbsp;gameActive = true;
&nbsp;&nbsp; &nbsp;aiMoveScores = [];
&nbsp;&nbsp; &nbsp;aiMovesDiv.textContent = '';
&nbsp;&nbsp; &nbsp;updateBoard();
&nbsp;&nbsp;}

&nbsp;&nbsp;cells.forEach(cell =&gt; cell.addEventListener('click', handleCellClick));
&nbsp;&nbsp;newGameButton.addEventListener('click', newGame);
&lt;/script&gt;

&lt;/body&gt;
&lt;/html&gt;
``` 
 
From the preceding response, we can see that the Mercury model generated a complete, functional tic-tac-toe game with minimax AI implementation at 528 tokens per second, delivering working HTML, CSS, and JavaScript in a single response. The code includes proper game logic, an unbeatable AI algorithm, and a clean UI with the specified requirements correctly implemented. This demonstrates strong code generation capabilities with exceptional speed for a diffusion-based model. 
 
Use Mercury for tool use and function calling 
Mercury models support advanced tool use capabilities, enabling them to intelligently determine when and how to call external functions based on user queries. This makes them ideal for building AI agents and assistants that can interact with external systems, APIs, and databases. 
Let‚Äôs demonstrate Mercury‚Äôs tool use capabilities by creating a travel planning assistant that can check weather and perform calculations: 
 
 # Define available tools for the assistant
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "The unit of temperature"
                    }
                },
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "Perform mathematical calculations",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "The mathematical expression to evaluate"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]
#Create a travel planning query that requires multiple tools
payload = {
    "messages": [
        {
            "role": "user",
            "content": "I'm planning a trip to Tokyo. Can you check the weather there and also tell me what 1000 USD is in Japanese Yen (use 1 USD = 150 JPY for calculation)?"
        }
    ],
    "tools": tools,
    "tool_choice": "auto",  # Let the model decide which tools to use
    "max_tokens": 2000,
    "temperature": 0.15
}
# Invoke the endpoint
start = perf_counter()
response = predictor.predict(payload)
eta = perf_counter() - start
# Display the tool calls requested by the model
if 'choices' in response:
    message = response['choices'][0].get('message', {})
    if 'tool_calls' in message:
        print(f"Speed: {response['usage']['completion_tokens'] / eta:.2f} tokens/second\n")
        print(f"Mercury requested {len(message['tool_calls'])} tool calls:\n")
    
        for i, tool_call in enumerate(message['tool_calls'], 1):
            func = tool_call.get('function', {})
            tool_name = func.get('name')
            args = json.loads(func.get('arguments', '{}'))
            
            print(f"Tool Call {i}:")
            print(f"  Function: {tool_name}")
            print(f"  Arguments: {json.dumps(args, indent=4)}")
            print() 
 
Expected response: 
 
 Speed: 892.34 tokens/second
Mercury requested 2 tool calls:
Tool Call 1:
  Function: get_weather
  Arguments: {
    "location": "Tokyo, Japan",
    "unit": "celsius"
  }
Tool Call 2:
  Function: calculate
  Arguments: {
    "expression": "1000 * 150"
  } 
 
After receiving the tool results, you can continue the conversation to get a natural language response: 
 
 # Simulate tool execution results
tool_results = [
    {
        "role": "tool",
        "tool_call_id": message['tool_calls'][0]['id'],
        "content": "The weather in Tokyo, Japan is 18¬∞C and partly cloudy with a chance of rain."
    },
    {
        "role": "tool", 
        "tool_call_id": message['tool_calls'][1]['id'],
        "content": "The result is: 150000"
    }
]
# Continue the conversation with tool results
messages_with_results = [
    {"role": "user", "content": "I'm planning a trip to Tokyo. Can you check the weather there and also tell me what 1000 USD is in Japanese Yen (use 1 USD = 150 JPY for calculation)?"},
    message,  # Assistant's message with tool calls
    *tool_results  # Tool execution results
]
final_payload = {
    "messages": messages_with_results,
    "max_tokens": 500
}
final_response = predictor.predict(final_payload)
print(final_response['choices'][0]['message']['content']) 
 
Expected response: 
 
 Based on the information I've gathered for your Tokyo trip:
**Weather in Tokyo:**
Currently, Tokyo is experiencing mild weather at 18¬∞C (64¬∞F) with partly cloudy skies and a chance of rain. I'd recommend bringing a light jacket and an umbrella just in case.
**Currency Conversion:**
1,000 USD converts to 150,000 Japanese Yen at the rate you specified (1 USD = 150 JPY). This should give you a good amount for expenses like meals, transportation, and shopping in Tokyo.
For your trip planning, the mild temperature is perfect for sightseeing, though you'll want to have rain gear handy. The weather is comfortable for walking around popular areas like Shibuya, Shinjuku, or exploring temples and gardens. 
 
Clean up 
To avoid unwanted charges, complete the steps in this section to clean up your resources. 
Delete the Amazon Bedrock Marketplace deployment 
If you deployed the model using Amazon Bedrock Marketplace, complete the following steps: 
 
 On the Amazon Bedrock console, in the navigation pane, under Foundation models, choose Marketplace deployments. 
 Select the endpoint you want to delete, and on the Actions menu, choose Delete. 
 Verify the endpoint details to make sure you‚Äôre deleting the correct deployment: 
   
   Endpoint name 
   Model name 
   Endpoint status 
    
 Choose Delete to delete the endpoint. 
 In the Delete endpoint confirmation dialog, review the warning message, enter confirm, and choose Delete to permanently remove the endpoint. 
 
 
Delete the SageMaker JumpStart endpoint 
The SageMaker JumpStart model you deployed will incur costs if you leave it running. Use the following code to delete the endpoint if you want to stop incurring charges. For more details, see Delete Endpoints and Resources. 
 
 sm.delete_model(ModelName=sm_model_name)
sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)
sm.delete_endpoint(EndpointName=endpoint_name) 
 
Conclusion 
In this post, we explored how you can access and deploy Mercury models using Amazon Bedrock Marketplace and SageMaker JumpStart. With support for both Mini and Small parameter sizes, you can choose the optimal model size for your specific use case. Visit SageMaker JumpStart in SageMaker Studio or Amazon Bedrock Marketplace to get started. For more information, refer to Use Amazon Bedrock tooling with Amazon SageMaker JumpStart models, Amazon SageMaker JumpStart Foundation Models, Getting started with Amazon SageMaker JumpStart, Amazon Bedrock Marketplace, and SageMaker JumpStart pretrained models. 
The Mercury family of diffusion-based large language models offers exceptional speed and performance, making it a powerful choice for your generative AI workloads with latency-sensitive requirements. 
 
About the authors 
Niithiyn Vijeaswaran is a Generative AI Specialist Solutions Architect with the Third-Party Model Science team at AWS. His area of focus is AWS AI accelerators (AWS Neuron). He holds a Bachelor‚Äôs degree in Computer Science and Bioinformatics. 
John Liu&nbsp;has 15 years of experience as a product executive and 9 years of experience as a portfolio manager. At AWS, John is a Principal Product Manager for Amazon Bedrock. Previously, he was the Head of Product for AWS Web3 / Blockchain. Prior to AWS, John held various product leadership roles at public blockchain protocols, fintech companies and also spent 9 years as a portfolio manager at various hedge funds. 
Jonathan Evans is a Worldwide Solutions Architect for Generative AI at AWS, where he helps customers leverage cutting-edge AI technologies with Anthropic‚Äôs Claude models on Amazon Bedrock, to solve complex business challenges. With a background in AI/ML engineering and hands-on experience supporting machine learning workflows in the cloud, Jonathan is passionate about making advanced AI accessible and impactful for organizations of all sizes. 
Rohit Talluri is a Generative AI GTM Specialist at Amazon Web Services (AWS). He is partnering with top generative AI model builders, strategic customers, key AI/ML partners, and AWS Service Teams to enable the next generation of artificial intelligence, machine learning, and accelerated computing on AWS. He was previously an Enterprise Solutions Architect and the Global Solutions Lead for AWS Mergers &amp; Acquisitions Advisory. 
Breanne Warner is an Enterprise Solutions Architect at Amazon Web Services supporting healthcare and life science (HCLS) customers. She is passionate about supporting customers to use generative AI on AWS and evangelizing model adoption for first- and third-party models. Breanne is also Vice President of the Women at Amazon board with the goal of fostering inclusive and diverse culture at Amazon. Breanne holds a Bachelor‚Äôs of Science in Computer Engineering from the University of Illinois Urbana-Champaign.
‚Ä¢ Learn how Amazon Health Services improved discovery in Amazon search using AWS ML and gen AI
  Healthcare discovery on ecommerce domains presents unique challenges that traditional product search wasn‚Äôt designed to handle. Unlike searching for books or electronics, healthcare queries involve complex relationships between symptoms, conditions, treatments, and services, requiring sophisticated understanding of medical terminology and customer intent. 
This challenge became particularly relevant for Amazon as we expanded beyond traditional ecommerce into comprehensive healthcare services. Amazon now offers direct access to prescription medications through Amazon Pharmacy, primary care through One Medical, and specialized care partnerships through Health Benefits Connector. These healthcare offerings represent a significant departure from traditional Amazon.com products, presenting both exciting opportunities and unique technical challenges. 
In this post, we show you how Amazon Health Services (AHS) solved discoverability challenges on Amazon.com search using AWS services such as Amazon SageMaker, Amazon Bedrock, and Amazon EMR. By combining machine learning (ML), natural language processing, and vector search capabilities, we improved our ability to connect customers with relevant healthcare offerings. This solution is now used daily for health-related search queries, helping customers find everything from prescription medications to primary care services. 
At AHS, we‚Äôre on a mission to transform how people access healthcare. We strive to make healthcare more straightforward for customers to find, choose, afford, and engage with the services, products, and professionals they need to get and stay healthy. 
Challenges 
Integrating healthcare services into the ecommerce business of Amazon presented two unique opportunities to enhance search for customers on healthcare journeys: understanding health search intent in queries and matching up customer query intent with the most relevant healthcare products and services. 
The challenge in understanding health search intent lies in the relationships between symptoms (such as back pain or sore throat), conditions (such as a herniated disc or the common cold), treatments (such as physical therapy or medication), and the healthcare services Amazon offers. This requires sophisticated query understanding capabilities that can parse medical terminology and map it to common search terminology that a layperson outside of the medical field might use to search. 
AHS offerings also present unique challenges for search matching. For example, a customer searching for ‚Äúback pain treatment‚Äù might be looking for a variety of solutions, from over-the-counter pain relievers like Tylenol or prescription medications such as cyclobenzaprine (a muscle relaxant), to scheduling a doctor‚Äôs appointment or accessing virtual physical therapy. Existing search algorithms optimized for physical products might not match these service-based health offerings, potentially missing relevant results such as One Medical‚Äôs primary care services or Hinge Health‚Äôs virtual physical therapy program that helps reduce joint and muscle pain through personalized exercises and 1-on-1 support from dedicated therapists. This unique nature of healthcare offerings called for developing specialized approaches to connect customers with relevant services. 
Solution overview 
To address these challenges, we developed a comprehensive solution that combines ML for query understanding, vector search for product matching, and large language models (LLMs) for relevance optimization. The solution consists of three main components: 
 
 Query understanding pipeline ‚Äì Uses ML models to identify and classify health-related searches, distinguishing between specific medication queries and broader health condition searches 
 Product knowledge base ‚Äì Combines existing product metadata with LLM-enhanced health information to create comprehensive product embeddings for semantic search 
 Relevance optimization ‚Äì Implements a hybrid approach using both human labeling and LLM-based classification to produce high-quality matches between searches and healthcare offerings 
 
The solution is built entirely on AWS services, with Amazon SageMaker powering our ML models, Amazon Bedrock providing LLM capabilities, and Amazon EMR and Amazon Athena handling our data processing needs. 
Solution architecture 
Now let‚Äôs examine the technical implementation details of our architecture, exploring how each component was engineered to address the unique challenges of healthcare search on Amazon.com. 
Query understanding: Identification of health searches 
We approached the customer search journey by recognizing its two distinct ends of the spectrum. On one end are what we call ‚Äúspearfishing queries‚Äù or lower funnel searches, where customers have a clear product search intent with specific knowledge about attributes. For Amazon Health Services, these typically include searches for specific prescription medications with precise dosages and form factors, such as ‚Äúatorvastatin 40 mg‚Äù or ‚Äúlisinopril 20 mg.‚Äù 
On the other end are broad, upper funnel queries where customers seek inspiration, information, or recommendations with general product search intent that might encompass multiple product types. Examples include searches like ‚Äúback pain relief,‚Äù ‚Äúacne,‚Äù or ‚Äúhigh blood pressure.‚Äù Building upon Amazon search capabilities, we developed additional query understanding models to serve the full spectrum of healthcare searches. 
For identifying spearfishing search intent, we analyzed anonymized customer search engagement data for Amazon products and trained a classification model to understand which search keywords exclusively lead to engagement with Amazon Pharmacy Amazon Standard Identification Numbers (ASINs). This process used PySpark on Amazon EMR and Athena to collect and process Amazon search data at scale. The following diagram shows this architecture. 
 
For identifying broad health search intent, we trained a named entity recognition (NER) model to annotate search keywords at a medical terminology level. To build this capability, we used a corpus of health ontology data sources to identify concepts such as health conditions, diseases, treatments, injuries, and medications. For health concepts where we did not have enough alternate terms in our knowledge base, we used LLMs to expand our knowledge base. For example, alternate terms for the condition ‚Äúacid reflux‚Äù might be ‚Äúheart burn‚Äù, ‚ÄúGERD‚Äù, ‚Äúindigestion‚Äù, etc. We gated this NER model behind health-relevant product types predicted by Amazon search query-to-product-type models. The following diagram shows the training process for the NER model. 
 
The following image is an example of a query identification task in practice. In the example on the left, the pharmacy classifier predicts that ‚Äúatorvastatin 40 mg‚Äù is a query with intent for a prescription drug and triggers a custom search experience geared towards AHS products. In the example on the right, we detect the broad ‚Äúhigh blood pressure‚Äù symptom but don‚Äôt know the customer‚Äôs intention. So, we trigger an experience that gives them multiple options to make the search more specific. 
 
For those interested in implementing similar medical entity recognition capabilities, Amazon Comprehend Medical offers powerful tools for detecting medical entities in text spans. 
Building product knowledge 
With our ability to identify health-related searches in place, we needed to build comprehensive knowledge bases for our healthcare products and services. We started with our existing offerings and collected all available product knowledge information that best described each product or service. 
To enhance this foundation, we used a large language model (LLM) with a fine-tuned prompt and few-shot examples to layer in additional relevant health conditions, symptoms, and treatment-related keywords for each product or service. We did this using the Amazon Bedrock batch inference capability. This approach meant that we significantly expanded our product knowledge with medically relevant information. 
The entire knowledge base was then converted into embeddings using Facebook AI Similarity Search (FAISS), and we created an index file to enable efficient similarity searches. We maintained careful mappings from each embedding back to the original knowledge base items, making sure we could perform accurate reverse lookups when needed. 
This process used several AWS services, including Amazon Simple Storage Service (Amazon S3) for storage of the knowledge base and the embeddings files. Note that Amazon OpenSearch Service is also a viable option for vector database capabilities. Large-scale knowledge base embedding jobs were executed with scheduled SageMaker Notebook Jobs. Through the combination of these technologies, we built a robust foundation of healthcare product knowledge that could be efficiently searched and matched to customer queries. 
The following diagram illustrates how we built the product knowledge base using Amazon catalog data, and then used that to prepare a FAISS index file. 
 
Mapping health search intent to the most relevant products and services 
A core component of our solution was implementing the Retrieval Augmented Generation (RAG) design pattern. The first step in this pattern was to identify a set of known keywords and Amazon products, establishing the initial ground truth for our solution. 
With our product knowledge base built from Amazon catalog metadata and ASIN attributes, we were ready to support new queries from customers. When a customer search query arrived, we converted it to an embedding and used it as a search key for matching against our index. This similarity search used FAISS with matching criteria based on the threshold against the similarity score. 
To verify the quality of these query-product pairs identified for health search keywords, we needed to maintain the relevance of each pair. To achieve this, we implemented a two-pronged approach to relevance labeling. We used an established scheme to tag each offering as exact, substitute, complement, or irrelevant to the keyword. Referred to as the exact, substitute, complement, irrelevant (ESCI) framework established through academic research. For more information, refer to the ESCI challenge and esci-data GitHub repository. 
First, we worked with a human labeling team to establish ground truth on a substantial sample size, creating a reliable benchmark for our system‚Äôs performance using this scheme. The labeling team was given guidance based on the ESCI framework and tailored towards AHS products and services. 
Second, we implemented LLM-based labeling using Amazon Bedrock and batch jobs. After matches were found in the previous step, we retrieved the top products and used them as prompt context for our generative model. We included few-shot examples of ESCI guidance as part of the prompt. This way, we conducted large-scale inference across the top health searches, connecting them to the most relevant offerings using similarity search. We performed this at scale for the query-product pairs identified as relevant to AHS and stored the outputs in Amazon S3. 
The following diagram shows our query retrieval, re-ranking and ESCI labeling pipeline. 
 
Using a mix of high-confidence human and LLM-based labels, we established a true ground truth. Through this process, we successfully identified relevant product offerings for customers using only semantic data from aggregated search keywords and product metadata. 
How did this help customers? 
We‚Äôre on a mission to make it more straightforward for people to find, choose, afford, and engage with the services, products, and professionals they need to get and stay healthy. Today, customers searching for health solutions on Amazon‚Äîwhether for acute conditions like acne, strep throat, and fever or chronic conditions such as arthritis, high blood pressure, and diabetes‚Äîwill begin to see medically vetted and relevant offerings alongside other relevant products and services available on Amazon.com. 
Customers can now quickly find and choose to meet with doctors, get their prescription medications, and access other healthcare services through a familiar experience. By extending the powerful ecommerce search capabilities of Amazon to address healthcare-specific opportunities, we‚Äôve created additional discovery pathways for relevant health services. 
We‚Äôve used semantic understanding of health queries and comprehensive product knowledge to create connections that help customers find the right healthcare solutions at the right time. 
Amazon Health Services Offerings 
Here is a little more information about three healthcare services you can use directly through Amazon: 
 
 Amazon Pharmacy (AP) provides a full-service, online pharmacy experience with transparent medication pricing, convenient home delivery at no additional cost, ongoing delivery updates, 24/7 pharmacist support, and insurance plan acceptance, which supports access and medication adherence. Prime members enjoy special savings with Prime Rx, RxPass, and automatic coupons, making medications more affordable. 
 One Medical Membership and Amazon One Medical Pay Per Visit offer flexible health solutions, from in-office and virtual primary care to condition-based telehealth. Membership offers convenient access to preventive, quality primary care and the option to connect with your care team virtually in the One Medical app. Pay-per-visit is a one-time virtual visit option to find treatment for more than 30 common conditions like acne, pink eye, and sinus infections. 
 Health Benefits Connector matches customers to digital health companies outside of Amazon that are covered by their employer. This program has been expanding over the past year, offering access to specialized care through partners like Hinge Health for musculoskeletal care, Rula and Talkspace for mental health support, and Omada for diabetes treatment. 
 
Key takeaways 
As we reflect on our journey to enhance healthcare discovery on Amazon, several key insights stand out that might be valuable for others working on similar challenges: 
 
 Using domain-specific ontology ‚Äì We began by developing a deep understanding of customer health searches, specifically identifying what kinds of conditions, symptoms, and treatments customers were seeking. By using established health ontology datasets, we enriched a NER model to detect these entities in search queries, providing a foundation for better matching. 
 Similarity search on product knowledge ‚Äì We used existing product knowledge along with LLM-augmented real-world knowledge to build a comprehensive corpus of data that could be mapped to our offerings. Through this approach, we created semantic connections between customer queries and relevant healthcare solutions without relying on individual customer data. 
 Generative AI is more than just chatbots ‚Äì Throughout this project, we relied on various AWS services that proved instrumental to our success. Amazon SageMaker provided the infrastructure for our ML models. However, using Amazon Bedrock batch inference was a key differentiator. It provided us with powerful LLMs for knowledge augmentation and relevance labeling, and services such as Amazon S3 and Amazon EMR supported our data storage and processing needs. Scaling this process manually would have required orders of magnitude more financial budget. Consider generative AI applications at scale beyond merely chat assistants. 
 
By combining these approaches, we‚Äôve created a more intuitive and effective way for customers to discover healthcare offerings on Amazon. 
Implementation considerations 
If you‚Äôre looking to implement a similar solution for healthcare or search, consider the following: 
 
 Security and compliance: Make sure your solution adheres to healthcare data privacy regulations like Health Insurance Portability and Accountability Act (HIPAA). Our approach doesn‚Äôt use individual customer data. 
 Cost optimization: 
   
   Use Amazon EMR on EC2 Spot Instances for batch processing jobs 
   Implement caching for frequently searched queries 
   Choose appropriate instance types for your workload 
    
 Scalability: 
   
   Design your vector search infrastructure to handle peak traffic 
   Use auto scaling for your inference endpoints 
   Implement proper monitoring and alerting 
    
 Maintenance: 
   
   Regularly update your health ontology datasets 
   Monitor model performance and retrain as needed 
   Keep your product knowledge base current 
    
 
Conclusion 
In this post, we demonstrated how Amazon Health Services used AWS ML and generative AI services to solve the unique challenges of healthcare discovery on Amazon.com, illustrating how you can build sophisticated domain-specific search experiences using Amazon SageMaker, Amazon Bedrock, and Amazon EMR. We showed how to create a query understanding pipeline to identify health-related searches, build comprehensive product knowledge bases enhanced with LLM capabilities, and implement semantic matching using vector search and the ESCI relevance framework to connect customers with relevant healthcare offerings. 
This scalable, AWS based approach demonstrates how ML and generative AI can transform specialized search experiences, advancing our mission to make healthcare more straightforward for customers to find, choose, afford, and engage with. We encourage you to explore how these AWS services can address similar challenges in your own healthcare or specialized search applications. For more information about implementing healthcare solutions on AWS, visit the AWS for Healthcare &amp; Life Sciences page. 
 
About the authors 
K. Faryab Haye is an Applied Scientist II at Amazon Health located in Seattle, WA, where he leads search and query understanding initiatives for healthcare AI. His work spans the complete ML lifecycle from large-scale data processing to deploying production systems that serve millions of customers. Faryab earned his MS in Computer Science with a Machine Learning specialization from the University of Michigan and co-founded the Applied Science Club at Amazon Health. When not building ML systems, he can be found hiking mountains, cycling, skiing, or playing volleyball. 
Vineeth Harikumar is a Principal Engineer at Amazon Health Services working on growth and engagement tech initiatives for Amazon One Medical (primary care and telehealth services), Pharmacy prescription delivery, and Health condition programs. Prior to working in healthcare, he worked on building large-scale backend systems in Amazon‚Äôs global inventory, supply chain and fulfillment network, Kindle devices, and Digital commerce businesses (such as Prime Video, Music, and eBooks).

‚∏ª