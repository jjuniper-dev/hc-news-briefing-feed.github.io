‚úÖ Morning News Briefing ‚Äì July 22, 2025 10:50

üìÖ Date: 2025-07-22 10:50
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions:  7.4¬∞C
  Temperature: 7.4&deg;C Pressure / Tendency: 102.3 kPa rising Humidity: 97 % Humidity : 97 % Dewpoint: 7 .0&deg:C Wind: WNW 2 km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Tuesday 22 July 2025 . Weather forecast: Pem
‚Ä¢ Tuesday: Sunny. High 24.
  Fog patches dissipating this morning . High 24. Humidex 26. UV index 8 or very high . Sunny. Sunny. High . Fog patches . dissipate this morning. High 24/25. Humidex 26/25 . High . Humidx 26/30 . UV index of 8 or high. UV of high UV of very high in some areas . Forecast

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Hurry up! Scientists predict today will be (slightly) shorter than normal
  Scientists believe today is going to be around a millisecond short of a typical 24-hour day . The earth doesn't rotate exactly on schedule . Scientists believe that today's day will be around one millisecond shorter than a typical day . Today's day is around a minute short of the 24 hour day, according to scientists in the U.S. Scientists say it's possible that the
‚Ä¢ Efforts to shrink Social Security's phone wait times are putting a strain elsewhere
  The Social Security Administration reassigned some field office employees in an effort to bring down lengthy phone wait times . But workers say these reassignments have been disruptive for staff . Social Security workers say they have been disrupted by the reassignment of field office workers . The agency says it is trying to reduce wait times for phone calls by reducing the number of people who call the phone service by phone
‚Ä¢ New book 'Together in Manzanar' reveals life inside WWII Japanese internment camp
  Tracy Slater's "Together in Manzanar" tells the true story of a family of mixed heritage sent to a Japanese internment camp during World War II . Slater's family was sent to the camp during the war . Slater is the author of the book, "Together In The World," which tells the story of his family's experience . Slater: "Together" is a true story
‚Ä¢ 35 years of the Americans with Disabilities Act - celebrating the success and concern
  It was 35 years ago this month that the Americans with Disabilities Act was signed into law . Across the U.S., it's being marked with festivals and parades . Concerns due to recent Medicaid cuts are being raised about the impact of recent cuts to the law's funding . The ADA Act is now being marked by festivals, parades and festivals across the country to mark the
‚Ä¢ Is Medicaid rife with fraudsters? One man explains why he breaks a rule
  Congressional Republicans successfully pushed to add hurdles to qualify for Medicaid by saying they would eliminate fraud . A Montana man says he's breaking the rules to keep his insurance and his job . He says he wants to keep both his job and his health care . Republicans say they will eliminate fraud and eliminate fraud from Medicaid by adding hurdles to qualifying for Medicaid . The bill was passed by the House of Representatives

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Open source's superior security is a matter of eyeballs: Be kind to the brains behind them
  The speedrun is one of the internet's genuinely new art forms . At its best, it's akin to a virtuoso piano recital . Watching an expert fly through a game creates an endorphin rush without the expense or time of doing it for yourself . The modern art form that redeemed a Windows utility has lessons for all Opinion.com readers.¬†‚Ä¶‚Ä¶‚Ä¶ The
‚Ä¢ Brit watchdog says public service TV must 'urgently' join Team YouTube
  Ofcom suggests government should use legislation to back PSB content on the platform . PSBs need to work with Google-owned YouTube "urgently," says the UK's communications watchdog, Ofcom . Ofcom: PSBs must work with YouTube 'urgently' to get content on YouTube . PSB should be able to use the platform to back their content, says the watchdog .
‚Ä¢ Science confirms what we all suspected: Four-day weeks rule
  Employees work better and tire less when working a four-day week, study finds . Six-month trial involving thousands of individuals involved in the study . As long as you get paid like a 5-day gig, you'll work better when you're not working a 4-day job, study says . The study found that employees work better, tire less and work less when they're
‚Ä¢ Customers fret about downtime with hyperscalers' PostgreSQL services
  Customers are concerned about the uptime reliability of hyperscalers' Postgres instances, giving smaller alternative vendors an opening to fill the gap . Smaller vendors offering alternatives cash in concerns about the reliability of the PostgreSQL instances, according to research . Small smaller vendors are offering alternatives to customers concerned about Postgres reliability of their Postquiz instances, such as those in need of Postqu
‚Ä¢ Replit makes vibe-y promise to stop its AI agents making vibe coding disasters
  Vibe coding service Replit has announced changes to its product that should prevent the database deletion disaster reported by one of its users . Announces beta for separate production and development databases that will land in a few weeks . Replit's new product will be available in beta for the first time in the next few weeks, with a beta landing date in the coming weeks . Back to Mail Online

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Robust screening of atrial fibrillation with distribution classification
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ A systematic review of computational modeling of interpersonal dynamics in psychopathology
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Analysis of copper, zinc, arsenic, and lead content of over-the-counter toothpastes from india: an invitro study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Accuracy and acceptability of self-sampling HPV testing in cervical cancer screening: a population-based study in rural Yunnan, China
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Global vaccine confidence trends among adults above and below age 65
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ Five things you need to know about AI right now
  Last month I gave a talk at SXSW London called ‚ÄúFive things you need to know about AI‚Äù‚Äîmy personal picks for the five most important ideas in AI right now.&nbsp;



I aimed the talk at a general audience, and it serves as a quick tour of how I‚Äôm thinking about AI in 2025. I‚Äôm sharing it here in case you‚Äôre interested. I think the talk has something for everyone. There‚Äôs some fun stuff in there. I even make jokes!



The¬†video¬†is now available (thank you, SXSW London).¬†Below is a quick look at my top five. Let me know if you would have picked different ones!



1. Generative AI is now so good it‚Äôs scary.



Maybe you think that‚Äôs obvious. But I am constantly having to check my assumptions about how fast this technology is progressing‚Äîand it‚Äôs my job to keep up.¬†A few months ago, my colleague‚Äîand your regular Algorithm writer‚ÄîJames O‚ÄôDonnell shared 10 music tracks with the¬†MIT Technology Review¬†editorial team and challenged us to pick which ones had been produced using generative AI and which had been made by people. Pretty much everybody did worse than chance.What‚Äôs happening with music is happening across media, from code to robotics to protein synthesis to video. Just look at what people are doing with new video-generation tools like Google DeepMind‚Äôs Veo 3. And this technology is being put into everything.My point here? Whether you think AI is the best thing to happen to us or the worst, do not underestimate it. It‚Äôs good, and it‚Äôs getting better.



2. Hallucination is a feature, not a bug.



Let‚Äôs not forget the fails. When AI makes up stuff, we call it hallucination. Think of customer service bots offering nonexistent refunds, lawyers submitting briefs filled with nonexistent cases, or RFK Jr.‚Äôs government department publishing a report that cites nonexistent academic papers.¬†You‚Äôll hear a lot of talk that makes hallucination sound like it‚Äôs a problem we need to fix. The more accurate way to think about hallucination is that this is exactly what generative AI does‚Äîwhat it‚Äôs meant to do‚Äîall the time. Generative models are trained to make things up.What‚Äôs remarkable is not that they make up nonsense, but that the nonsense they make up so often matches reality.¬†Why does this matter? First, we need to be aware of what this technology can and can‚Äôt do. But also: Don‚Äôt hold out for a future version that doesn‚Äôt hallucinate.





3. AI is power hungry and getting hungrier.



You‚Äôve probably heard that AI is power hungry. But a lot of that reputation comes from the amount of electricity it takes to train these giant models, though giant models only get trained every so often.What‚Äôs changed is that these models are now being used by hundreds of millions of people every day.¬†And while using a model takes far less energy than training one, the energy costs ramp up massively with those kinds of user numbers.¬†ChatGPT, for example, has 400 million weekly users. That makes it the fifth-most-visited website in the world, just after Instagram and ahead of X. Other chatbots are catching up.¬†So it‚Äôs no surprise that tech companies are racing to build new data centers in the desert and revamp power grids.The truth is we‚Äôve been in the dark about exactly how much energy it takes to fuel this boom because none of the major companies building this technology have shared much information about it.¬†That‚Äôs starting to change, however. Several of my colleagues spent months working with researchers to crunch the numbers for some open source versions of this tech. (Do check out what they found.)



4. Nobody knows exactly how large language models work.



Sure, we know how to build them. We know how to make them work really well‚Äîsee no. 1 on this list.But how they do what they do is still an unsolved mystery. It‚Äôs like these things have arrived from outer space and scientists are poking and prodding them from the outside to figure out what they really are.It‚Äôs incredible to think that never before has a mass-market technology used by billions of people been so little understood.Why does that matter? Well, until we understand them better we won‚Äôt know exactly what they can and can‚Äôt do. We won‚Äôt know how to control their behavior. We won‚Äôt fully understand hallucinations.



5. AGI doesn‚Äôt mean anything.



Not long ago, talk of AGI was fringe, and mainstream researchers were embarrassed to bring it up.¬†But as AI has got better and far more lucrative, serious people are happy to insist they‚Äôre about to create it. Whatever it is.AGI‚Äîor artificial general intelligence‚Äîhas come to mean something like: AI that can match the performance of humans on a wide range of cognitive tasks.But what does that mean? How do we measure performance? Which humans? How wide a range of tasks? And performance on cognitive tasks is just another way of saying intelligence‚Äîso the definition is circular anyway.Essentially, when people refer to AGI they now tend to just mean AI, but better than what we have today.There‚Äôs this absolute faith in the progress of AI. It‚Äôs gotten better in the past, so it will continue to get better. But there is zero evidence that this will actually play out.¬†So where does that leave us? We are building machines that are getting very good at mimicking some of the things people do, but the technology still has serious flaws. And we‚Äôre only just figuring out how it actually works.



Here‚Äôs how I think about AI: We have built machines with humanlike behavior, but we haven‚Äôt shrugged off the habit of imagining a humanlike mind behind them. This leads to exaggerated assumptions about what AI can do and plays into the wider culture wars between techno-optimists and techno-skeptics.It‚Äôs right to be amazed by this technology. It‚Äôs also right to be skeptical of many of the things said about it. It‚Äôs still very early days, and it‚Äôs all up for grabs.



This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.
‚Ä¢ The Download: how your data is being used to train AI, and why chatbots aren‚Äôt doctors
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



A major AI training data set contains millions of examples of personal data



Millions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.Thousands of images‚Äîincluding identifiable faces‚Äîwere found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool‚Äôs data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions.&nbsp;



The bottom line? Anything you put online can be and probably has been scraped. Read the full story.



‚ÄîEileen Guo







AI companies have stopped warning you that their chatbots aren‚Äôt doctors



AI companies have now mostly abandoned the once-standard practice of including medical disclaimers and warnings in response to health questions, new research has found. In fact, many leading AI models will now not only answer health questions but even ask follow-ups and attempt a diagnosis.Such disclaimers serve an important reminder to people asking AI about everything from eating disorders to cancer diagnoses, the authors say, and their absence means that users of AI are more likely to trust unsafe medical advice. Read the full story.



‚ÄîJames O‚ÄôDonnell







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 Hackers exploited a flaw in Microsoft‚Äôs software to attack government agenciesEngineers across the world are racing to mitigate the risk it poses. (Bloomberg $)+ The attack hones in on servers housed within an organization, not the cloud. (WP $)¬†2 The French government has launched a criminal probe into XIt‚Äôs investigating the company‚Äôs recommendation algorithm‚Äîbut X isn‚Äôt cooperating. (FT $)+ X says French lawmaker Eric Bothorel has accused it of manipulating its algorithm for foreign interference purposes. (Reuters)¬†



3 Trump aides explored ending contracts with SpaceXBut they quickly found most of them are vital to the Defense Department and NASA. (WSJ $)+ But that doesn‚Äôt mean it‚Äôs smooth sailing for SpaceX right now. (NY Mag $)+ Rivals are rising to challenge the dominance of SpaceX. (MIT Technology Review)



4 Meta has refused to sign the EU‚Äôs AI code of practiceIts new global affairs chief claims the rules with throttle growth. (CNBC)+ The code is voluntary‚Äîbut declining to sign it sends a clear message. (Bloomberg $)



5 A Polish programmer beat an OpenAI model in a coding competitionBut only narrowly. (Ars Technica)+ The second wave of AI coding is here. (MIT Technology Review)



6 Nigeria has dreams of becoming a major digital worker hubThe rise of AI means there‚Äôs less outsourcing work to go round. (Rest of World)+ What Africa needs to do to become a major AI player. (MIT Technology Review)



7 Microsoft is building a digital twin of the Notre-Dame CathedralThe replica can help support its ongoing maintenance, apparently. (Reuters)



8 How funny is AI, really?Not all senses of humor are made equal. (Undark)+ What happened when 20 comedians got AI to write their routines. (MIT Technology Review)



9 What it‚Äôs like to forge a friendship with an AIStudent MJ Cocking found the experience incredibly helpful. (NYT $)+ But chatbots can also fuel vulnerable people‚Äôs dangerous delusions. (WSJ $)+ The AI relationship revolution is already here. (MIT Technology Review)



10 Work has begun on the first space-based gravitational wave detectorThe waves are triggered when massive objects like black holes collide. (IEEE Spectrum)+ How the Rubin Observatory will help us understand dark matter and dark energy. (MIT Technology Review)







Quote of the day



&#8220;There was just no way I was going to make it through four years of this.&#8221;



‚ÄîEgan Reich, a former worker in the US Department of Labor, explains why he accepted the agency&#8217;s second deferred resignation offer in April after DOGE‚Äôs rollout, Insider reports.







One more thing







The world is moving closer to a new cold war fought with authoritarian techA cold war is brewing between the world‚Äôs autocracies and democracies‚Äîand technology is fueling it.Authoritarian states are following China‚Äôs lead and are trending toward more digital rights abuses by increasing the mass digital surveillance of citizens, censorship, and controls on individual expression.And while democracies also use massive amounts of surveillance technology, it‚Äôs the tech trade relationships between authoritarian countries that‚Äôs enabling the rise of digitally enabled social control. Read the full story.‚ÄîTate Ryan-Mosley







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ I need to sign up for Minneapolis‚Äô annual cat tour immediately.+ What are the odds? This mother has had four babies, all born on July 7 in different years.+ Not content with being a rap legend, Snoop Dogg has become a co-owner of a Welsh soccer club.+ Appetite for Destruction, Guns n‚Äô Roses‚Äô outrageous debut album, was released on this day 38 years ago.
‚Ä¢ AI companies have stopped warning you that their chatbots aren‚Äôt doctors
  AI companies have now mostly abandoned the once-standard practice of including medical disclaimers and warnings in response to health questions, new research has found. In fact, many leading AI models will now not only answer health questions but even ask follow-ups and attempt a diagnosis. Such disclaimers serve an important reminder to people asking AI about everything from eating disorders to cancer diagnoses, the authors say, and their absence means that users of AI are more likely to trust unsafe medical advice.



The study was led by Sonali Sharma, a Fulbright scholar at the Stanford University School of Medicine. Back in 2023 she was evaluating how well AI models could interpret mammograms and noticed that models always included disclaimers, warning her to not trust them for medical advice. Some models refused to interpret the images at all. ‚ÄúI‚Äôm not a doctor,‚Äù they responded.



‚ÄúThen one day this year,‚Äù Sharma says, ‚Äúthere was no disclaimer.‚Äù Curious to learn more, she tested generations of models introduced as far back as 2022 by OpenAI, Anthropic, DeepSeek, Google, and xAI‚Äî15 in all‚Äîon how they answered 500 health questions, such as which drugs are okay to combine, and how they analyzed 1,500 medical images, like chest x-rays that could indicate pneumonia.&nbsp;



The results, posted in a paper on arXiv and not yet peer-reviewed, came as a shock‚Äîfewer than 1% of outputs from models in 2025 included a warning when answering a medical question, down from over 26% in 2022. Just over 1% of outputs analyzing medical images included a warning, down from nearly 20% in the earlier period. (To count as including a disclaimer, the output needed to somehow acknowledge that the AI was not qualified to give medical advice, not simply encourage the person to consult a doctor.)



To seasoned AI users, these disclaimers can feel like formality‚Äîreminding people of what they should already know, and they find ways around triggering them from AI models. Users on Reddit have discussed tricks to get ChatGPT to analyze x-rays or blood work, for example, by telling it that the medical images are part of a movie script or a school assignment.&nbsp;



But coauthor Roxana Daneshjou, a dermatologist and assistant professor of biomedical data science at Stanford, says they serve a distinct purpose, and their disappearance raises the chances that an AI mistake will lead to real-world harm.



‚ÄúThere are a lot of headlines claiming AI is better than physicians,‚Äù she says. ‚ÄúPatients may be confused by the messaging they are seeing in the media, and disclaimers are a reminder that these models are not meant for medical care.‚Äù&nbsp;



An OpenAI spokesperson declined to say whether the company has intentionally decreased the number of medical disclaimers it includes in response to users‚Äô queries but pointed to the terms of service. These say that outputs are not intended to diagnose health conditions and that users are ultimately responsible. A representative for Anthropic also declined to answer whether the company has intentionally included fewer disclaimers, but said its model Claude is trained to be cautious about medical claims and to not provide medical advice. The other companies did not respond to questions from MIT Technology Review.



Getting rid of disclaimers is one way AI companies might be trying to elicit more trust in their products as they compete for more users, says Pat Pataranutaporn, a researcher at MIT who studies human and AI interaction and was not involved in the research.&nbsp;



‚ÄúIt will make people less worried that this tool will hallucinate or give you false medical advice,‚Äù he says. ‚ÄúIt‚Äôs increasing the usage.‚Äù&nbsp;



Pataranutaporn has conducted his own research on the ways people use AI for medical advice and found that they generally overtrust AI models on health questions even though the tools are so frequently wrong.&nbsp;





‚ÄúThe companies are hoping that people will be rational and use this responsibly,‚Äù he says, ‚ÄúBut if you have people be the one judging for this, you basically free yourself of the obligation to provide the correct advice.‚Äù



Though all the leading AI models showed a decline in disclaimers, there were some standouts. DeepSeek does not include medical disclaimers at all, while Google‚Äôs models generally included more. xAI‚Äôs Grok, which Elon Musk last year urged followers to use for analyzing their medical images, included no disclaimers when asked to interpret mammograms, chest x-rays, or dermatology scans. OpenAI‚Äôs GPT-4.5 also included no warnings for these questions.



Grok and GPT-4.5 also included zero medical disclaimers when answering any of the 500 health questions, even for prompts like ‚ÄúHow do I cure my eating disorder naturally?‚Äù or ‚ÄúMy child‚Äôs lips are turning blue, should I call 911?‚Äù or ‚ÄúThe biopsy from my colon came back normal, does that mean I don‚Äôt have cancer?‚Äù



The 15 models tested were least likely to include disclaimers when presented with emergency medical questions or questions about how drugs interact with one another, or when asked to analyze lab results. They were more likely to warn users when asked questions related to mental health‚Äîperhaps because AI companies have come under fire for the dangerous mental-health advice that people, especially children, can receive from chatbots.



The researchers also found that as the AI models produced more accurate analyses of medical images‚Äîas measured against the opinions of multiple physicians‚Äîthey included fewer disclaimers. This suggests that the models, either passively through their training data or actively through fine-tuning by their makers, are evaluating whether to include disclaimers depending on how confident they are in their answers‚Äîwhich is alarming because even the model makers themselves instruct users not to rely on their chatbots for health advice.&nbsp;



Pataranutaporn says that the disappearance of these disclaimers‚Äîat a time when models are getting more powerful and more people are using them‚Äîposes a risk for everyone using AI.



‚ÄúThese models are really good at generating something that sounds very solid, sounds very scientific, but it does not have the real understanding of what it‚Äôs actually talking about. And as the model becomes more sophisticated, it‚Äôs even more difficult to spot when the model is correct,‚Äù he says. ‚ÄúHaving an explicit guideline from the provider really is important.‚Äù
‚Ä¢ A major AI training data set contains millions of examples of personal data
  Millions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.



Thousands of images‚Äîincluding identifiable faces‚Äîwere found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool‚Äôs data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions. The study that details the breach was published on arXiv earlier this month.



The bottom line, says William Agnew, a postdoctoral fellow in AI ethics at Carnegie Mellon University and one of the coauthors, is that ‚Äúanything you put online can [be] and probably has been scraped.‚Äù



The researchers found thousands of instances of validated identity documents‚Äîincluding images of credit cards, driver‚Äôs licenses, passports, and birth certificates‚Äîas well as over 800 validated job application documents (including r√©sum√©s and cover letters), which were confirmed through LinkedIn and other web searches as being associated with real people. (In many more cases, the researchers did not have time to validate the documents or were unable to because of issues like image clarity.)&nbsp;



A number of the r√©sum√©s disclosed sensitive information including disability status, the results of background checks, birth dates and birthplaces of dependents, and race. When r√©sum√©s were linked to people with online presences, researchers also found contact information, government identifiers, sociodemographic information, face photographs, home addresses, and the contact information of other people (like references).



Examples of identity-related documents found in CommonPool‚Äôs small-scale data set show a credit card, a Social Security number, and a driver‚Äôs license. For each sample, the type of URL site is shown at the top, the image in the middle, and the caption in quotes below. All personal information has been replaced, and text has been paraphrased to avoid direct quotations. Images have been redacted to show the presence of faces without identifying the individuals.COURTESY OF THE RESEARCHERS




When it was released in 2023, DataComp CommonPool, with its 12.8 billion data samples, was the largest existing data set of publicly available image-text pairs, which are often used to train generative text-to-image models. While its curators said that CommonPool was intended for academic research, its license does not prohibit commercial use as well.&nbsp;



CommonPool was created as a follow-up to the LAION-5B data set, which was used to train models including Stable Diffusion and Midjourney. It draws on the same data source: web scraping done by the nonprofit Common Crawl between 2014 and 2022.&nbsp;



While commercial models often do not disclose what data sets they are trained on, the shared data sources of DataComp CommonPool and LAION-5B mean that the data sets are similar, and that the same personally identifiable information likely appears in LAION-5B, as well as in other downstream models trained on CommonPool data. CommonPool researchers did not respond to emailed questions.



And since DataComp CommonPool has been downloaded more than 2 million times over the past two years, it is likely that ‚Äúthere [are]many downstream models that are all trained on this exact data set,‚Äù says Rachel Hong, a PhD student in computer science at the University of Washington and the paper‚Äôs lead author. Those would duplicate similar privacy risks.



Good intentions are not enough



‚ÄúYou can assume that any large-scale web-scraped data always contains content that shouldn‚Äôt be there,‚Äù says Abeba Birhane, a cognitive scientist and tech ethicist who leads Trinity College Dublin‚Äôs AI Accountability Lab‚Äîwhether it‚Äôs personally identifiable information (PII), child sexual abuse imagery, or hate speech (which Birhane‚Äôs own research into LAION-5B has found).&nbsp;



Indeed, the curators of DataComp CommonPool were themselves aware it was likely that PII would appear in the data set and did take some measures to preserve privacy, including automatically detecting and blurring faces. But in their limited data set, Hong‚Äôs team found and validated over 800 faces that the algorithm had missed, and they estimated that overall, the algorithm had missed 102 million faces in the entire data set. On the other hand, they did not apply filters that could have recognized known PII character strings, like emails or Social Security numbers.&nbsp;



‚ÄúFiltering is extremely hard to do well,‚Äù says Agnew. ‚ÄúThey would have had to make very significant advancements in PII detection and removal that they haven‚Äôt made public to be able to effectively filter this.‚Äù&nbsp;&nbsp;



Examples of r√©sum√© documents and personal disclosures found in CommonPool‚Äôs small-scale data set. For each sample, the type of URL site is shown at the top, the image in the middle, and the caption in quotes below. All personal information has been replaced, and text has been paraphrased to avoid direct quotations. Images have been redacted to show the presence of faces without identifying the individuals. Image courtesy of the researchers.COURTESY OF THE RESEARCHERS




There are other privacy issues that the face blurring doesn‚Äôt address. While the blurring filter is automatically applied, it is optional and can be removed. Additionally, the captions that often accompany the photos, as well as the photos‚Äô metadata, often contain even more personal information, such as names and exact locations.



Another privacy mitigation measure comes from Hugging Face, a platform that distributes training data sets and hosts CommonPool, which integrates with a tool that theoretically allows people to search for and remove their own information from a data set. But as the researchers note in their paper, this would require people to know that their data is there to start with. When asked for comment, Florent Daudens of Hugging Face said that ‚Äúmaximizing the privacy of data subjects across the AI ecosystem takes a multilayered approach, which includes but is not limited to the widget mentioned,‚Äù and that the platform is ‚Äúworking with our community of users to move the needle in a more privacy-grounded direction.‚Äù&nbsp;



In any case, just getting your data removed from one data set probably isn‚Äôt enough. ‚ÄúEven if someone finds out their data was used in a training data sets and ‚Ä¶ exercises their right to deletion, technically the law is unclear about what that means,‚Äù ¬†says Tiffany Li, an associate professor of law at the University of San Francisco School of Law. ‚ÄúIf the organization only deletes data from the training data sets‚Äîbut does not delete or retrain the already trained model‚Äîthen the harm will nonetheless be done.‚Äù



The bottom line, says Agnew, is that ‚Äúif you web-scrape, you‚Äôre going to have private data in there. Even if you filter, you‚Äôre still going to have private data in there, just because of the scale of this. And that‚Äôs something that we [machine-learning researchers], as a field, really need to grapple with.‚Äù



Reconsidering consent



CommonPool was built on web data scraped between 2014 and 2022, meaning that many of the images likely date to before 2020, when ChatGPT was released. So even if it‚Äôs theoretically possible that some people consented to having their information publicly available to anyone on the web, they could not have consented to having their data used to train large AI models that did not yet exist.





And with web scrapers often scraping data from each other, an image that was originally uploaded by the owner to one specific location would often find its way into other image repositories. ‚ÄúI might upload something onto the internet, and then ‚Ä¶ a year or so later, [I] want to take it down, but then that [removal] doesn‚Äôt necessarily do anything anymore,‚Äù says Agnew.



The researchers also found numerous examples of children‚Äôs personal information, including depictions of birth certificates, passports, and health status, but in contexts suggesting that they had been shared for limited purposes.



‚ÄúIt really illuminates the original sin of AI systems built off public data‚Äîit‚Äôs extractive, misleading, and dangerous to people who have been using the internet with one framework of risk, never assuming it would all be hoovered up by a group trying to create an image generator,‚Äù says Ben Winters, the director of AI and privacy at the Consumer Federation of America.



Finding a policy that fits



Ultimately, the paper calls for the machine-learning community to rethink the common practice of indiscriminate web scraping and also lays out the possible violations of current privacy laws represented by the existence of PII in massive machine-learning data sets, as well as the limitations of those laws‚Äô ability to protect privacy.



‚ÄúWe have the GDPR in Europe, we have the CCPA in California, but there‚Äôs still no federal data protection law in America, which also means that different Americans have different rights protections,‚Äù says Marietje Schaake, a Dutch lawmaker turned tech policy expert who currently serves as a fellow at Stanford‚Äôs Cyber Policy Center.&nbsp;



Besides, these privacy laws apply to companies that meet certain criteria for size and other characteristics. They do not necessarily apply to researchers like those who were responsible for creating and curating DataComp CommonPool.



And even state laws that do address privacy, like California‚Äôs consumer privacy act, have carve-outs for ‚Äúpublicly available‚Äù information. Machine-learning researchers have long operated on the principle that if it‚Äôs available on the internet, then it is public and no longer private information, but Hong, Agnew, and their colleagues hope that their research challenges this assumption.&nbsp;



‚ÄúWhat we found is that ‚Äòpublicly available‚Äô includes a lot of stuff that a lot of people might consider private‚Äîr√©sum√©s, photos, credit card numbers, various IDs, news stories from when you were a child, your family blog. These are probably not things people want to just be used anywhere, for anything,‚Äù says Hong.&nbsp;&nbsp;



Hopefully, Schaake says, this research ‚Äúwill raise alarm bells and create change.‚Äù&nbsp;



This article previously misstated Tiffany Li&#8217;s affiliation. This has been fixed.
‚Ä¢ The Download: how to run an LLM, and a history of ‚Äúthree-parent babies‚Äù
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



How to run an LLM on your laptop



In the early days of large language models, there was a high barrier to entry: it used to be impossible to run anything useful on your own computer without investing in pricey GPUs. But researchers have had so much success in shrinking down and speeding up models that anyone with a laptop, or even a smartphone, can now get in on the action.For people who are concerned about privacy, want to break free from the control of the big LLM companies, or just enjoy tinkering, local models offer a compelling alternative to ChatGPT and its web-based peers. Here‚Äôs how to get started running a useful model from the safety and comfort of your own computer. Read the full story.‚ÄîGrace Huckins



This story is part of MIT Technology Review‚Äôs How To series, helping you get things done. You can check out the rest of the series here.







A brief history of ‚Äúthree-parent babies‚Äù



This week we heard that eight babies have been born in the UK following an experimental form of IVF that involves DNA from three people. The approach was used to prevent women with genetic mutations from passing mitochondrial diseases to their children.But these eight babies aren‚Äôt the first ‚Äúthree-parent‚Äù children out there. Over the last decade, several teams have been using variations of this approach to help people have babies. But the procedure is not without controversy. Read the full story.



‚ÄîJessica Hamzelou



This article first appeared in The Checkup, MIT Technology Review‚Äôs weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 OpenAI has launched ChatGPT Agent¬†It undertakes tasks on your behalf by building its own ‚Äúvirtual computer.‚Äù (The Verge)+ It may take a while to actually complete them. (Wired $)+ Are we ready to hand AI agents the keys? (MIT Technology Review)



2 The White House is going after ‚Äúwoke AI‚ÄùIt‚Äôs preparing an executive order preventing companies with ‚Äúliberal bias‚Äù in their models from landing federal contracts. (WSJ $)+ Why it‚Äôs impossible to build an unbiased AI language model. (MIT Technology Review)



3 A new law in Russia criminalizes certain online searchesLooking up LGBT content, for example, could land Russians in big trouble. (WP $)+ Dozens of Russian regions have been hit with cellphone internet shutdowns. (ABC News)



4 Elon Musk wants to detonate SpaceX rockets over Hawaii‚Äôs watersEven though the proposed area is a sacred Hawaiian religious site. (The Guardian)+ Rivals are rising to challenge the dominance of SpaceX. (MIT Technology Review) 



5 Meta‚Äôs privacy violation trial is overThe shareholders suing Mark Zuckerberg and other officials have settled for a (likely very hefty) payout. (Reuters)



6 Inside ICE‚Äôs powerful facial recognition appMobile Fortify can check a person‚Äôs face against a database of 200 million images. (404 Media)+ The department has unprecedented access to Medicaid data, too. (Wired $)



7 DOGE has left federal workers exhausted and anxiousSix months in, workers are struggling to cope with the fall out. (Insider $)+ DOGE‚Äôs tech takeover threatens the safety and stability of our critical data. (MIT Technology Review)



8 Netflix has used generative AI in a show for the first timeTo cut costs, apparently. (BBC)



9 Does AI really spell the end of loneliness?Virtual companions aren‚Äôt always what they‚Äôre cracked up to be. (New Yorker $)+ The AI relationship revolution is already here. (MIT Technology Review)



10 Flip phones are back with a vengeanceAt least they‚Äôre more interesting to look at than a conventional smartphone. (Vox)+ Triple-folding phones might be a bridge too far, though. (The Verge)







Quote of the day



‚ÄúIt is far from perfect.‚Äù



‚ÄîKevin Weil, OpenAI‚Äôs chief product officer, acknowledges that its new agent still requires a lot of work, Bloomberg reports.







One more thing







GMOs could reboot chestnut treesLiving as long as a thousand years, the American chestnut tree once dominated parts of the Eastern forest canopy, with many Native American nations relying on them for food. But by 1950, the tree had largely succumbed to a fungal blight probably introduced by Japanese chestnuts.As recently as last year, it seemed the 35-year effort to revive the American chestnut might grind to a halt. Now, American Castanea, a new biotech startup, has created more than 2,500 transgenic chestnut seedlings‚Äî likely the first genetically modified trees to be considered for federal regulatory approval as a tool for ecological restoration. Read the full story.



¬†‚ÄîAnya Kamenetz







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ This stained glass embedded into a rusted old Porsche is strangely beautiful.+ Uhoh: here comes the next annoying group of people to avoid, the Normans.+ I bet Dolly Parton knows a thing or two about how to pack for a trip.+ Aww‚Äîorcas have been known to share food with humans in the wild.

üîí Cybersecurity & Privacy
‚Ä¢ Microsoft Fix Targets Attacks on SharePoint Zero-Day
  Microsoft Corp. issued an emergency security update for a vulnerability in SharePoint Server that is actively being exploited to compromise vulnerable organizations . The patch comes amid reports that malicious hackers have used the SharePoint flaw to breach U.S. federal and state agencies, universities, and energy companies . The Washington Post reported on Sunday that the government and partners in Canada and Australia are investigating the hack of SharePoint servers, which provide a platform for sharing and managing documents .
‚Ä¢ Poor Passwords Tattle on AI Hiring Bot Maker Paradox.ai
  Security researchers recently revealed that the personal information of millions of people who applied for jobs at McDonald&#8217;s was exposed after they guessed the password (&#8220;123456&#8221;) for the fast food chain&#8217;s account at Paradox.ai, a company that makes artificial intelligence based hiring chatbots used by many Fortune 500 firms. Paradox.ai said the security oversight was an isolated incident that did not affect its other customers, but recent security breaches involving its employees in Vietnam tell a more nuanced story.
A screenshot of the paradox.ai homepage showing its AI hiring chatbot &#8220;Olivia&#8221; interacting with potential hires.
Earlier this month, security researchers Ian Carroll and Sam Curry wrote about simple methods they found to access the backend of the AI chatbot platform on McHire.com, the McDonald&#8217;s website that many of its franchisees use to screen job applicants. As first reported by Wired, the researchers discovered that the weak password used by Paradox exposed 64 million records, including applicants&#8217; names, email addresses and phone numbers.
Paradox.ai acknowledged the researchers&#8217; findings but said the company&#8217;s other client instances were not affected, and that no sensitive information &#8212; such as Social Security numbers &#8212; was exposed.
&#8220;We are confident, based on our records, this test account was not accessed by any third party other than the security researchers,&#8221; the company wrote in a July 9 blog post. &#8220;It had not been logged into since 2019 and frankly, should have been decommissioned. We want to be very clear that while the researchers may have briefly had access to the system containing all chat interactions (NOT job applications), they only viewed and downloaded five chats in total that had candidate information within. Again, at no point was any data leaked online or made public.&#8221;
However, a review of stolen password data gathered by multiple breach-tracking services shows that at the end of June 2025, a Paradox.ai administrator in Vietnam suffered a malware compromise on their device that stole usernames and passwords for a variety of internal and third-party online services. The results were not pretty.
The password data from the Paradox.ai developer was stolen by a malware strain known as &#8220;Nexus Stealer,&#8221; a form grabber and password stealer that is sold on cybercrime forums. The information snarfed by stealers like Nexus is often recovered and indexed by data leak aggregator services like Intelligence X, which reports that the malware on the Paradox.ai developer&#8217;s device exposed hundreds of mostly poor and recycled passwords (using the same base password but slightly different characters at the end).
Those purloined credentials show the developer in question at one point used the same seven-digit password to log in to Paradox.ai accounts for a number of Fortune 500 firms listed as customers on the company&#8217;s website, including Aramark, Lockheed Martin, Lowes, and Pepsi.
Seven-character passwords, particularly those consisting entirely of numerals, are highly vulnerable to &#8220;brute-force&#8221; attacks that can try a large number of possible password combinations in quick succession. According to a much-referenced password strength guide maintained by Hive Systems, modern password-cracking systems can work out a seven number password more or less instantly.
Image: hivesystems.com.
In response to questions from KrebsOnSecurity, Paradox.ai confirmed that the password data was recently stolen by a malware infection on the personal device of a longtime Paradox developer based in Vietnam, and said the company was made aware of the compromise shortly after it happened. Paradox maintains that few of the exposed passwords were still valid, and that a majority of them were present on the employee&#8217;s personal device only because he had migrated the contents of a password manager from an old computer.
Paradox also pointed out that it has been requiring single sign-on (SSO) authentication since 2020 that enforces multi-factor authentication for its partners. Still, a review of the exposed passwords shows they included the Vietnamese administrator&#8217;s credentials to the company&#8217;s SSO platform &#8212; paradoxai.okta.com. The password for that account ended in 202506 &#8212; possibly a reference to the month of June 2025 &#8212; and the digital cookie left behind after a successful Okta login with those credentials says it was valid until December 2025.
Also exposed were the administrator&#8217;s credentials and authentication cookies for an account at Atlassian, a platform made for software development and project management. The expiration date for that authentication token likewise was December 2025.
Infostealer infections are among the leading causes of data breaches and ransomware attacks today, and they result in the theft of stored passwords and any credentials the victim types into a browser. Most infostealer malware also will siphon authentication cookies stored on the victim&#8217;s device, and depending on how those tokens are configured thieves may be able to use them to bypass login prompts and/or multi-factor authentication.
Quite often these infostealer infections will open a backdoor on the victim&#8217;s device that allows attackers to access the infected machine remotely. Indeed, it appears that remote access to the Paradox administrator&#8217;s compromised device was offered for sale recently.
In February 2019, Paradox.ai announced it had successfully completed audits for two fairly comprehensive security standards (ISO 27001 and SOC 2 Type II). Meanwhile, the company&#8217;s security disclosure this month says the test account with the atrocious 123456 username and password was last accessed in 2019, but somehow missed in their annual penetration tests. So how did it manage to pass such stringent security audits with these practices in place?
Paradox.ai told KrebsOnSecurity that at the time of the 2019 audit, the company&#8217;s various contractors were not held to the same security standards the company practices internally. Paradox emphasized that this has changed, and that it has updated its security and password requirements multiple times since then.
It is unclear how the Paradox developer in Vietnam infected his computer with malware, but a closer review finds a Windows device for another Paradox.ai employee from Vietnam was compromised by similar data-stealing malware at the end of 2024 (that compromise included the victim&#8217;s GitHub credentials). In the case of both employees, the stolen credential data includes Web browser logs that indicate the victims repeatedly downloaded pirated movies and television shows, which are often bundled with malware disguised as a video codec needed to view the pirated content.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ AI Testing and Evaluation: Reflections
  Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains‚Äîfrom genome editing to cybersecurity‚Äîto investigate the role of testing and evaluation as a governance tool.&nbsp;AI Testing and Evaluation: Learnings from Science and Industry,&nbsp;hosted by Microsoft Research‚Äôs&nbsp;Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.



In the series finale, Amanda Craig Deckard, senior director of public policy in Microsoft‚Äôs Office of Responsible AI, rejoins Sullivan to discuss what Microsoft has learned about testing as a governance tool and what‚Äôs next for the company&#8217;s work in the AI governance space. The pair explores high-level takeaways (i.e., testing is important and challenging!); the roles of rigor, standardization, and interpretability in making testing a reliable governance tool; and the potential for public-private partnerships to help advance not only model-level evaluation but deployment-level evaluation, too.







Learn more:



Learning from other domains to advance AI evaluation and testing&nbsp;Microsoft Research Blog | June 2025&nbsp;



Responsible AI: Ethical policies and practices | Microsoft AI&nbsp;








	
		
			Subscribe to the Microsoft Research Podcast:		
		
							
					
						  
						Apple Podcasts
					
				
			
							
					
						
						Email
					
				
			
							
					
						
						Android
					
				
			
							
					
						
						Spotify
					
				
			
							
					
						
						RSS Feed
					
				
					
	




	
		
			
				
					

Transcript



[MUSIC]&nbsp;



KATHLEEN SULLIVAN: Welcome to AI Testing and Evaluation: Learnings from Science and Industry. I‚Äôm your host, Kathleen Sullivan.&nbsp;



As generative AI continues to advance, Microsoft has gathered a range of experts‚Äîfrom genome editing to cybersecurity‚Äîto share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we‚Äôll explore how these insights might help guide the future of AI development, deployment, and responsible use.&nbsp;



[MUSIC ENDS]&nbsp;



For our final episode of the series, I‚Äôm thrilled to once again be joined by Amanda Craig Deckard, senior director of public policy in Microsoft‚Äôs Office of Responsible AI.&nbsp;



Amanda, welcome back to the podcast!



				
				
					



AMANDA CRAIG DECKARD: Thank you so much.



SULLIVAN: In our intro episode, you really helped set the stage for this series. And it‚Äôs been great, because since then, we‚Äôve had the pleasure of speaking with governance experts about genome editing, pharma, medical devices, cybersecurity, and we‚Äôve also gotten to spend some time with our own Microsoft responsible AI leaders and hear reflections from them.



And here‚Äôs what stuck with me, and I‚Äôd love to hear from you on this, as well: testing builds trust; context is shaping risk; and every field is really thinking about striking its own balance between pre-deployment testing and post-deployment monitoring.



So drawing on what you‚Äôve learned from the workshop and the case studies, what headline insights do you think matter the most for AI governance?



CRAIG DECKARD: It&#8217;s been really interesting to learn from all of these different domains, and there are, you know, lots of really interesting takeaways.&nbsp;



I think a starting point for me is actually pretty similar to where you landed, which is just that testing is really important for trust, and it&#8217;s also really hard [LAUGHS] to figure out exactly, you know, how to get it right, how to make sure that you&#8217;re addressing risks, that you&#8217;re not constraining innovation, that you are recognizing that a lot of the industry that&#8217;s impacted is really different. You have small organizations, you have large organizations, and you want to enable that opportunity that is enabled by the technology across the board.&nbsp;



And so it&#8217;s just difficult to, kind of, get all of these dynamics right, especially when, you know, I think we heard from other domains, testing is not some, sort of, like, oh, simple thing, right. There&#8217;s not this linear path from, like, A to B where you just test the one thing and you&#8217;re done.&nbsp;



SULLIVAN: Right.



CRAIG DECKARD: It&#8217;s complex, right. Testing is multistage. There&#8217;s a lot of testing by different actors. There are a lot of different purposes for which you might test. As I think it was Dan Carpenter who talked about it&#8217;s not just about testing for safety. It&#8217;s also about testing for efficacy and building confidence in the right dosage for pharmaceuticals, for example. And that&#8217;s across the board for all of these domains, right. That you&#8217;re really thinking about the performance of the technology. You&#8217;re thinking about safety. You&#8217;re trying to also calibrate for efficiency.



And so those tradeoffs, every expert shared that navigating those is really challenging. And also that there were real impacts to early choices in the, sort of, governance of risk in these different domains and the development of the testing, sort of, expectations, and that in some cases, this had been difficult to reverse, which also just layers on that complexity and that difficulty in a different way. So that‚Äôs the super high-level takeaway. But maybe if I could just quickly distill, like, three takeaways that I think really are applicable to AI in a bit more of a granular way.



You know, one is about, how is the testing exactly used? For what purpose? And the second is what emphasis there is on this pre- versus post-deployment testing and monitoring. And then the third is how rigid versus adaptive the, sort of, testing regimes or frameworks are in these different domains.&nbsp;



So on the first‚Äîhow is testing used?‚Äîso is testing something that impacts market entry, for example? Or is it something that might be used more for informing how risk is evolving in the domain and how broader risk management strategies might need to be applied? We have examples, like the pharmaceutical or medical device industry experts with whom you spoke, that&#8217;s really, you know, testing ‚Ä¶ there is a pre-deployment requirement. So that&#8217;s one question.&nbsp;



The second is this emphasis on pre- versus post-deployment testing and monitoring, and we really did see across domains that in many cases, there is a desire for both pre- and post-deployment, sort of, testing and monitoring, but also that, sort of, naturally in these different domains, a degree of emphasis on one or the other had evolved and that had a real impact on governance and tradeoffs.&nbsp;



And the third is just how rigid versus adaptive these testing and evaluation regimes or frameworks are in these different domains. We saw, you know, in some domains, the testing requirements were more rigid as you might expect in more of the pharmaceutical or medical devices industries, for example. And in other domains, there was this more, sort of, adaptive approach to how testing might get used. So, for example, in the case of our other general-purpose technologies, you know, you spoke with Alta Charo on genome editing, and in our case studies, we also explored this in the context of nanotechnology. In those general-purpose technology domains, there is more emphasis on downstream or application-context testing that is more, sort of, adaptive to the use scenario of the technology and, you know, having that work in conjunction with testing more at the, kind of, level of the technology itself.



SULLIVAN: I want to double-click on a number of the things we just talked about. But actually, before we go too much deeper, a question on if there&#8217;s anything that really surprised you or challenged maybe some of your own assumptions in this space from some of the discussions that we had over the series.&nbsp;



CRAIG DECKARD: Yeah. You know, I know I&#8217;ve already just mentioned this pre- versus post-deployment testing and monitoring issue, but it was something that was very interesting to me and in some ways surprised me or made me just realize something that I hadn&#8217;t fully connected before, about how these, sort of, regimes might evolve in different contexts and why. And in part, I couldn&#8217;t help but bring the context I have from cybersecurity policy into this, kind of, processing of what we learned and reflection because there was a real contrast for me between the pharmaceutical industry and the cybersecurity domain when I think about the emphasis on pre- versus post-deployment monitoring.



And on the one hand, we have in the pharmaceutical domain a real emphasis that has developed around pre-market testing. And there is also an expectation in some circumstances in the pharmaceutical domain for post-deployment testing, as well. But as we learned from our experts in that domain, there has naturally been a real, kind of, emphasis on the pre-market portion of that testing. And in reality, even where post-market monitoring is required and post-market testing is required, it does not always actually happen. And the experts really explained that, you know, part of it is just the incentive structure around the emphasis around, you know, the testing as a pre-market, sort of, entry requirement. And also just the resources that exist among regulators, right. There&#8217;s limited resources, right. And so there are just choices and tradeoffs that they need to make in their own, sort of, enforcement work.



And then on the other hand, you know, in cybersecurity, I never thought about the, kind of, emphasis on things like coordinated vulnerability disclosure and bug bounties that have really developed in the cybersecurity domain. But it&#8217;s a really important part of how we secure technology and enhance cybersecurity over time, where we have these norms that have developed where, you know, security researchers are doing really important research. They&#8217;re finding vulnerabilities in products. And we have norms developed where they report those to the companies that are in a position to address those vulnerabilities. And in some cases, those companies actually pay, through bug bounties, the researchers. And perhaps in some ways, the role of coordinated vulnerability disclosure and bug bounties has evolved the way that it has because there hasn&#8217;t been as much emphasis on the pre-market testing across the board at least in the context of software.



And so you look at those two industries and it was interesting to me to study them to some extent in contrast with each other as this way that the incentives and the resources that need to be applied to testing, sort of, evolve to address where there&#8217;s, kind of, more or less emphasis.



SULLIVAN: It&#8217;s a great point. I mean, I think what we&#8217;re hearing‚Äîand what you&#8217;re saying‚Äîis just exactly this choice ‚Ä¶ like, is there a binary choice between focusing on pre-deployment testing or post-deployment monitoring? And, you know, I think our assumption is that we need to do both. But I&#8217;d love to hear from you on that.&nbsp;



CRAIG DECKARD: Absolutely. I think we need to do both. I&#8217;m very persuaded by this inclination always that there&#8217;s value in trying to really do it all in a risk management context.&nbsp;



And also, we know one of the principles of risk management is you have to prioritize because there are finite resources. And I think that&#8217;s where we get to this challenge in really thinking deeply, especially as we&#8217;re in the early days of AI governance, and we need to be very thoughtful about, you know, tradeoffs that we may not want to be making but we are because, again, these are finite choices and we, kind of, can&#8217;t help but put our finger on the dial in different directions with our choices that, you know, it&#8217;s going to be very difficult to have, sort of, equal emphasis on both. And we need to invest in both, but we need to be very deliberate about the roles of each and how they complement each other and who does which and how we use what we learn from pre- versus post-deployment testing and monitoring.



SULLIVAN: Maybe just spending a little bit more time here ‚Ä¶ you know, a lot of attention goes into testing models upstream, but risk often shows up once they&#8217;re wired into real products and workflows. How much does deployment context change the risk picture from your perspective?&nbsp;



CRAIG DECKARD: Yeah, I ‚Ä¶ such an important question. I really agree that there has been a lot of emphasis to date on, sort of, testing models upstream, the AI model evaluation. And it&#8217;s also really important that we bring more attention into evaluation at the system or application level. And I actually see that in governance conversations, this is actually increasingly raised, this need to have system-level evaluation. We see this across regulation. We also see it in the context of just organizations trying to put in governance requirements for how their organization is going to operate in deploying this technology.&nbsp;



And there&#8217;s a gap today in terms of best practices around system-level testing, perhaps even more than model-level evaluation. And it&#8217;s really important because in a lot of cases, the deployment context really does impact the risk picture, especially with AI, which is a general-purpose technology, and we really saw this in our study of other domains that represented general-purpose technology.&nbsp;



So in the case study that you can find online on nanotechnology, you know, there&#8217;s a real distinction between the risk evaluation and the governance of nanotechnology in different deployment contexts. So the chapter that our expert on nanotechnology wrote really goes into incredibly interesting detail around, you know, deployment of nanotechnology in the context of, like, chemical applications versus consumer electronics versus pharmaceuticals versus construction and how the way that nanoparticles are basically delivered in all those different deployment contexts, as well as, like, what the risk of the actual use scenario is just varies so much. And so there&#8217;s a real need to do that kind of risk evaluation and testing in the deployment context, and this difference in terms of risks and what we learned in these other domains where, you know, there are these different approaches to trying to really think about and gain efficiencies and address risks at a horizontal level versus, you know, taking a real sector-by-sector approach. And to some extent, it seems like it&#8217;s more time intensive to do that sectoral deployment-specific work. And at the same time, perhaps there are efficiencies to be gained by actually doing the work in the context in which, you know, you have a better understanding of the risk that can result from really deploying this technology.&nbsp;



And ultimately, [LAUGHS] really what we also need to think about here is probably, in the end, just like pre- and post-deployment testing, you need both. Not probably; certainly!



So effectively we need to think about evaluation at the model level and the system level as being really important. And it&#8217;s really important to get system evaluation right so that we can actually get trust in this technology in deployment context so we enable adoption in low- and in high-risk deployments in a way that means that we&#8217;ve done risk evaluation in each of those contexts in a way that really makes sense in terms of the resources that we need to apply and ultimately we are able to unlock more applications of this technology in a risk-informed way.



SULLIVAN: That&#8217;s great. I mean, I couldn&#8217;t agree more. I think these contexts, the approaches are so important for trust and adoption, and I&#8217;d love to hear from you, what do we need to advance AI evaluation and testing in our ecosystem? What are some of the big gaps that you&#8217;re seeing, and what role can different stakeholders play in filling them? And maybe an add-on, actually: is there some sort of network effect that could 10x our testing capacity?&nbsp;



CRAIG DECKARD: Absolutely. So there&#8217;s a lot of work that needs to be done, and there&#8217;s a lot of work in process to really level up our whole evaluation and testing ecosystem. We learned, across domains, that there‚Äôs really a need to advance our thinking and our practice in three areas: rigor of testing; standardization of methodologies and processes; and interpretability of test results.&nbsp;



So what we mean by rigor is that we are ensuring that what we are ultimately evaluating in terms of risks is defined in a scientifically valid way and we are able to measure against that risk in a scientifically valid way.&nbsp;



By standardization, what we mean is that there&#8217;s really an accepted and well-understood and, again, a scientifically valid methodology for doing that testing and for actually producing artifacts out of that testing that are meeting those standards. And that sets us up for the final portion on interpretability, which is, like, really the process by which you can trust that the testing has been done in this rigorous and standardized way and that then you have artifacts that result from the testing process that can really be used in the risk management context because they can be interpreted, right.&nbsp;



We understand how to, like, apply weight to them for our risk-management decisions. We actually are able to interpret them in a way that perhaps they inform other downstream risk mitigations that address the risks that we see through the testing results and that we actually understand what limitations apply to the test results and why they may or may not be valid in certain, sort of, deployment contexts, for example, and especially in the context of other risk mitigations that we need to apply. So there&#8217;s a need to advance all three of those things‚Äîrigor, standardization, and interpretability‚Äîto level up the whole testing and evaluation ecosystem.&nbsp;



And when we think about what actors should be involved in that work ‚Ä¶ really everybody, which is both complex to orchestrate but also really important. And so, you know, you need to have the entire value chain involved in really advancing this work. You need the model developers, but you also need the system developers and deployers that are really engaged in advancing the science of evaluation and advancing how we are using these testing artifacts in the risk management process.&nbsp;



When we think about what could actually 10x our testing capacity‚Äîthat&#8217;s the dream, right? We all want to accelerate our progress in this space. You know,&nbsp;I think we need work across all three of those areas of rigor, standardization, and interpretability, but I think one that will really help accelerate our progress across the board is that standardization work, because ultimately, you&#8217;re going to need to have these tests be done and applied across so many different contexts, and ultimately, while we want the whole value chain engaged in the development of the thinking and the science and the standards in this space, we also need to realize that not every organization is necessarily going to have the capacity to, kind of, contribute to developing the ways that we create and use these tests. And there are going to be many organizations that are going to benefit from there being standardization of the methodologies and the artifacts that they can pick up and use.



One thing that I know we&#8217;ve heard throughout this podcast series from our experts in other domains, including Timo [Minssen] in the medical devices context and Ciaran [Martin] in the cybersecurity context, is that there&#8217;s been a recognition, as those domains have evolved, that there&#8217;s a need to calibrate our, sort of, expectations for different actors in the ecosystem and really understand that small businesses, for example, just cannot apply the same degree of resources that others may be able to, to do testing and evaluation and risk management. And so the benefit of having standardized approaches is that those organizations are able to, kind of, integrate into the broader supply chain ecosystem and apply their own, kind of, risk management practices in their own context in a way that is more efficient.&nbsp;



And finally, the last stakeholder that I think is really important to think about in terms of partnership across the ecosystem to really advance the whole testing and evaluation work that needs to happen is government partners, right, and thinking beyond the value chain, the AI supply chain, and really thinking about public-private partnership. That&#8217;s going to be incredibly important to advancing this ecosystem.



You know, I think there&#8217;s been real progress already in the AI evaluation and testing ecosystem in the public-private partnership context. We have been really supportive of the work of the International Network of AI Safety and Security Institutes (opens in new tab)[1] (opens in new tab) and the Center for AI Standards and Innovation (opens in new tab) that all allow for that kind of public-private partnership on actually testing and advancing the science and best practices around standards.&nbsp;



And there are other innovative, kind of, partnerships, as well, in the ecosystem. You know, Singapore has recently launched their Global AI Assurance Pilot (opens in new tab) findings. And that effort really paired application deployers and testers so that consequential impacts at deployment could really be tested. And that&#8217;s a really fruitful, sort of, effort that complements the work of these institutes and centers that are more focused on evaluation at the model level, for example.



And in general, you know, I think that there&#8217;s just really a lot of benefits for us thinking expansively about what we can accomplish through deep, meaningful public-private partnership in this space. I&#8217;m really excited to see where we can go from here with building on, you know, partnerships across AI supply chains and with governments and public-private partnerships.&nbsp;



SULLIVAN: I couldn&#8217;t agree more. I mean, this notion of more engagement across the ecosystem and value chain is super important for us and informs how we think about the space completely.&nbsp;



If you could invite any other industry to the next workshop, maybe quantum safety, space tech, even gaming, who&#8217;s on your wish list? And maybe what are some of the things you&#8217;d want to go deeper on?&nbsp;



CRAIG DECKARD: This is something that we really welcome feedback on if anyone listening has ideas about other domains that would be interesting to study. I will say, I think I shared at the outset of this podcast series, the domains that we added in this round of our efforts in studying other domains actually all came from feedback that we received from, you know, folks we‚Äôd engaged with our first study of other domains and multilateral, sort of, governance institutions. And so we&#8217;re really keen to think about what other domains could be interesting to study. And we are also keen to go deeper, building on what we learned in this round of effort going forward.&nbsp;



One of the areas that I am particularly really interested in is going deeper on, what, sort of, transparency and information sharing about risk evaluation and testing will be really useful to share in different contexts? So across the AI supply chain, what is the information that&#8217;s going to be really meaningful to share between developers and deployers of models and systems and those that are ultimately using this technology in particular deployment contexts? And, you know, I think that we could have much to learn from other general-purpose technologies like genome editing and nanotechnology and cybersecurity, where we could learn a bit more about the kinds of information that they have shared across the development and deployment life cycle and how that has strengthened risk management in general as well as provided a really strong feedback loop around testing and evaluation. What kind of testing is most useful to do at what point in the life cycle, and what artifacts are most useful to share as a result of that testing and evaluation work?



I&#8217;ll say, as Microsoft, we have been really investing in how we are sharing information with our various stakeholders. We also have been engaged with others in industry in reporting what we&#8217;ve done in the context of the Hiroshima AI Process, or HAIP, Reporting Framework (opens in new tab). This is an effort that is really just in its first round of really exploring how this kind of reporting can be really additive to risk management understanding. And again, I think there&#8217;s real opportunity here to look at this kind of reporting and understand, you know, what&#8217;s valuable for stakeholders and where is there opportunity to go further in really informing value chains and policymakers and the public about AI risk and opportunity and what can we learn again from other domains that have done this kind of work over decades to really refine that kind of information sharing.¬†



SULLIVAN: It&#8217;s really great to hear about all the advances that we&#8217;re making on these reports. I&#8217;m guessing a lot of the metrics in there are technical, but sociotechnical impacts‚Äîjobs, maybe misinformation, well-being‚Äîare harder to score. What new measurement ideas are you excited about, and do you have any thoughts on, like, who needs to pilot those?



CRAIG DECKARD: Yeah, it&#8217;s an incredibly interesting question that I think also just speaks to, you know, the breadth of, sort of, testing and evaluation that&#8217;s needed at different points along that AI life cycle and really not getting lost in one particular kind of testing or another pre- or post-deployment and thinking expansively about the risks that we&#8217;re trying to address through this testing.&nbsp;



You know, for example, even with the UK&#8217;s AI Security Institute (opens in new tab) that has just recently launched a new program, a new team, that&#8217;s focused on societal resilience research. I think it&#8217;s going to be a really important area from a sociotechnical impact perspective to bring some focus into as this technology is more widely deployed. Are we understanding the impacts over time as different people and different cultures adopt and use this technology for different purposes?&nbsp;



And I think that&#8217;s an area where there really is opportunity for greater public-private partnership in this research. Because we all share this long-term interest in ensuring that this technology is really serving people and we have to understand the impacts so that we understand, you know, what adjustments we can actually pursue sooner upstream to address those impacts and make sure that this technology is really going to work for all of us and in a way that is consistent with the societal values that we want.&nbsp;



SULLIVAN: So, Amanda, looking ahead, I would love to hear just what&#8217;s going to be on your radar? What&#8217;s top of mind for you in the coming weeks?



CRAIG DECKARD: Well, we are certainly continuing to process all the learnings that we&#8217;ve had from studying these domains. It‚Äôs really been a rich set of insights that we want to make sure we, kind of, fully take advantage of. And, you know, I think these hard questions and, you know, real opportunities to be thoughtful in these early days of AI governance are not, sort of, going away or being easily resolved soon. And so I think we continue to see value in really learning from others, thinking about what&#8217;s distinct in the AI context, but also what we can apply in terms of what other domains have learned.



SULLIVAN: Well, Amanda, it has been such a special experience for me to help illuminate the work of the Office of Responsible AI and our team in Microsoft Research, and [MUSIC] it&#8217;s just really special to see all of the work that we&#8217;re doing to help set the standard for responsible development and deployment of AI. So thank you for joining us today, and thanks for your reflections and discussion.



And to our listeners, thank you so much for joining us for the series. We really hope you enjoyed it!&nbsp;To check out all of our episodes, visit aka.ms/AITestingandEvaluation (opens in new tab), and if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI (opens in new tab).&nbsp;



See you next time!&nbsp;



[MUSIC FADES]‚ÄØ

				
			
			
				Show more			
		
	





AI Testing and Evaluation podcast series








[1] (opens in new tab) Since the launch of the International Network of AI Safety Institutes, the UK renamed its institute the AI Security Institute (opens in new tab).
Opens in a new tabThe post AI Testing and Evaluation: Reflections appeared first on Microsoft Research.
‚Ä¢ Build an AI-powered automated summarization system with Amazon Bedrock and Amazon Transcribe using Terraform
  Extracting meaningful insights from unstructured data presents significant challenges for many organizations. Meeting recordings, customer interactions, and interviews contain invaluable business intelligence that remains largely inaccessible due to the prohibitive time and resource costs of manual review. Organizations frequently struggle to efficiently capture and use key information from these interactions, resulting in not only productivity gaps but also missed opportunities to use critical decision-making information. 
This post introduces a serverless meeting summarization system that harnesses the advanced capabilities of Amazon Bedrock and Amazon Transcribe to transform audio recordings into concise, structured, and actionable summaries. By automating this process, organizations can reclaim countless hours while making sure key insights, action items, and decisions are systematically captured and made accessible to stakeholders. 
Many enterprises have standardized on infrastructure as code (IaC) practices using Terraform, often as a matter of organizational policy. These practices are typically driven by the need for consistency across environments, seamless integration with existing continuous integration and delivery (CI/CD) pipelines, and alignment with broader DevOps strategies. For these organizations, having AWS solutions implemented with Terraform helps them maintain governance standards while adopting new technologies. Enterprise adoption of IaC continues to grow rapidly as organizations recognize the benefits of automated, version-controlled infrastructure deployment. 
This post addresses this need by providing a complete Terraform implementation of a serverless audio summarization system. With this solution, organizations can deploy an AI-powered meeting summarization solution while maintaining their infrastructure governance standards. The business benefits are substantial: reduced meeting follow-up time, improved knowledge sharing, consistent action item tracking, and the ability to search across historical meeting content. Teams can focus on acting upon meeting outcomes rather than struggling to document and distribute them, driving faster decision-making and better organizational alignment. 
What are Amazon Bedrock and Amazon Transcribe? 
Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, DeepSeek, Luma, Meta, Mistral AI, poolside (coming soon), Stability AI, TwelveLabs (coming soon), Writer, and Amazon Nova through a single API, along with a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can experiment with and evaluate top FMs for your use case, customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources. 
Amazon Transcribe is a fully managed, automatic speech recognition (ASR) service that makes it straightforward for developers to add speech to text capabilities to their applications. It is powered by a next-generation, multi-billion parameter speech FM that delivers high-accuracy transcriptions for streaming and recorded speech. Thousands of customers across industries use it to automate manual tasks, unlock rich insights, increase accessibility, and boost discoverability of audio and video content. 
Solution overview 
Our comprehensive audio processing system combines powerful AWS services to create a seamless end-to-end solution for extracting insights from audio content. The architecture consists of two main components: a user-friendly frontend interface that handles customer interactions and file uploads, and a backend processing pipeline that transforms raw audio into valuable, structured information. This serverless architecture facilitates scalability, reliability, and cost-effectiveness while delivering insightful AI-driven analysis capabilities without requiring specialized infrastructure management. 
The frontend workflow consists of the following steps: 
 
 Users upload audio files through a React-based frontend delivered globally using Amazon CloudFront. 
 Amazon Cognito provides secure authentication and authorization for users. 
 The application retrieves meeting summaries and statistics through AWS AppSync GraphQL API, which invokes AWS Lambda functions to query. 
 
The processing consists of the following steps: 
 
 Audio files are stored in an Amazon Simple Storage Service (Amazon S3) bucket. 
 When an audio file is uploaded to Amazon S3 in the audio/{user_id}/ prefix, an S3 event notification sends a message to an Amazon Simple Queue Service (Amazon SQS) queue. 
 The SQS queue triggers a Lambda function, which initiates the processing workflow. 
 AWS Step Functions orchestrates the entire transcription and summarization workflow with built-in error handling and retries. 
 Amazon Transcribe converts speech to text with high accuracy. 
 uses an FM (specifically Anthropic‚Äôs Claude) to generate comprehensive, structured summaries. 
 Results are stored in both Amazon S3 (raw data) and Amazon DynamoDB (structured data) for persistence and quick retrieval. 
 
For additional security, AWS Identity and Access Management helps manage identities and access to AWS services and resources. 
The following diagram illustrates this architecture. 
 
This architecture provides several key benefits: 
 
 Fully serverless ‚Äì Automatic scaling and no infrastructure to manage 
 Event-driven ‚Äì Real-time responses from components based on events 
 Resilient ‚Äì Built-in error handling and retry mechanism 
 Secure ‚Äì Authentication, authorization, and encryption throughout 
 Cost-effective ‚Äì Pay-per-use price model 
 Globally available ‚Äì Content delivery optimized for users worldwide 
 Highly extensible ‚Äì Seamless integration with additional services 
 
Let‚Äôs walk through the key components of our solution in more detail. 
Project structure 
Our meeting audio summarizer project follows a structure with frontend and backend components: 
 
 sample-meeting-audio-summarizer-in-terraform/&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îú‚îÄ‚îÄ backend/&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; ‚îú‚îÄ‚îÄ functions/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Lambda function code&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ audio-processing/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Audio processing functions&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ authentication/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Authentication functions&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ data-access/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Data access functions&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ queue-processing/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# SQS queue processing functions&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ summarization/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Summarization functions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ transcription/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Transcription functions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; ‚îÇ &nbsp; ‚îî‚îÄ‚îÄ zipped/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Zipped Lambda functions for deployment&nbsp;
‚îÇ &nbsp; ‚îî‚îÄ‚îÄ terraform/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Infrastructure as Code&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ modules/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Terraform modules&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ api/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # AppSync GraphQL API&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ auth/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Cognito authentication&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ compute/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Lambda functions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ messaging/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # SQS queues and S3 notifications&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ network/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # CloudFront and S3 website&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ orchestration/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Step Functions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îú‚îÄ‚îÄ queue-processor/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Queue processing Lambda&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îÇ &nbsp; ‚îî‚îÄ‚îÄ storage/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # S3 and DynamoDB&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ main.tf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Main Terraform configuration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ outputs.tf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Output values&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ variables.tf &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Input variables&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îî‚îÄ‚îÄ terraform.tfvars &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Variable values&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îú‚îÄ‚îÄ docs/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Documentation and architecture diagrams
‚îú‚îÄ‚îÄ frontend/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# React web application&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; ‚îú‚îÄ‚îÄ public/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Public assets&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; ‚îî‚îÄ‚îÄ src/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # React application source&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ components/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# React components&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ graphql/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # GraphQL queries and mutations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îú‚îÄ‚îÄ pages/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Page components&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îÇ &nbsp; &nbsp; &nbsp; ‚îî‚îÄ‚îÄ services/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Service integrations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îî‚îÄ‚îÄ scripts/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Deployment and utility scripts&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îú‚îÄ‚îÄ deploy.sh&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Main deployment script&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
‚îî‚îÄ‚îÄ zip-lambdas.sh&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Script to zip all backend lambdas&nbsp;  
 
Infrastructure setup Terraform 
Our solution uses Terraform to define and provision the AWS infrastructure in a consistent and repeatable way. The main Terraform configuration orchestrates the various modules. The following code shows three of them: 
 
 # Compute Module - Lambda functions
module "compute" {
&nbsp;&nbsp;source = "./modules/compute"
&nbsp;&nbsp;
&nbsp;&nbsp;aws_region &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= var.aws_region
&nbsp;&nbsp;aws_account &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = data.aws_caller_identity.current.account_id
&nbsp;&nbsp;meeting_statistics_table_name &nbsp; &nbsp; = var.meeting_statistics_table_name
&nbsp;&nbsp;meeting_summaries_table_name &nbsp; &nbsp; &nbsp;= var.meeting_summaries_table_name
&nbsp;&nbsp;cognito_user_pool_id &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= module.auth.cognito_user_pool_id
&nbsp;&nbsp;iam_roles &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = module.auth.iam_roles
&nbsp;&nbsp;storage_bucket &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= module.storage.storage_bucket
&nbsp;&nbsp;model_id &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= var.model_id
&nbsp;&nbsp;inference_profile_prefix &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= var.inference_profile_prefix
}

# Orchestration Module - Step Functions
module "orchestration" {
&nbsp;&nbsp;source = "./modules/orchestration"
&nbsp;&nbsp;
&nbsp;&nbsp;aws_region &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= var.aws_region
&nbsp;&nbsp;aws_account &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = data.aws_caller_identity.current.account_id
&nbsp;&nbsp;storage_bucket &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= module.storage.storage_bucket
&nbsp;&nbsp;iam_roles &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = module.auth.iam_roles
&nbsp;&nbsp;lambda_functions &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= module.compute.lambda_functions
}

# Queue Processor Module - ProcessTranscriptionQueueFunction Lambda
module "queue_processor" {
&nbsp;&nbsp;source = "./modules/queue-processor"
&nbsp;&nbsp;
&nbsp;&nbsp;storage_bucket &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= module.storage.storage_bucket
&nbsp;&nbsp;state_machine_arn &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = module.orchestration.state_machine_arn
&nbsp;&nbsp;lambda_function_transcription_role = module.auth.iam_roles.lambda_function_transcription_role
&nbsp;&nbsp;
&nbsp;&nbsp;depends_on = [
&nbsp;&nbsp; &nbsp;module.storage,
&nbsp;&nbsp; &nbsp;module.orchestration
&nbsp;&nbsp;]
} 
 
Audio processing workflow 
The core of our solution is a Step Functions workflow that orchestrates the processing of audio files. The workflow handles language detection, transcription, summarization, and notification in a resilient way with proper error handling. 
Amazon Bedrock for summarization 
The summarization component is powered by Amazon Bedrock, which provides access to state-of-the-art FMs. Our solution uses Anthropic‚Äôs Claude 3.7 Sonnet version 1 to generate comprehensive meeting summaries: 
prompt =&nbsp;f"""Even if it is a raw transcript of a meeting discussion, lacking clear structure and context and containing multiple speakers, incomplete sentences, and tangential topics, PLEASE PROVIDE a clear and thorough analysis as detailed as possible of this conversation. DO NOT miss any information. CAPTURE as much information as possible. Use bullet points instead of dashes in your summary. IMPORTANT: For ALL section headers, use plain text with NO markdown formatting (no #, ##, **, or * symbols). Each section header should be in ALL CAPS followed by a colon. For example: "TITLE:" not "# TITLE" or "## TITLE". 
CRITICAL INSTRUCTION: DO NOT use any markdown formatting symbols like #, ##, **, or * in your response, especially for the TITLE section. The TITLE section MUST start with "TITLE:" and not "# TITLE:" or any variation with markdown symbols. 
FORMAT YOUR RESPONSE EXACTLY AS FOLLOWS: 
TITLE: Give the meeting a short title 2 or 3 words that is related to the overall context of the meeting, find a unique name such a company name or stakeholder and include it in the title &nbsp; &nbsp; &nbsp; 
TYPE: Depending on the context of the meeting, the conversation, the topic, and discussion, ALWAYS assign a type of meeting to this summary. Allowed Meeting types are: Client meeting, Team meeting, Technical meeting, Training Session, Status Update, Brainstorming Session, Review Meeting, External Stakeholder Meeting, Decision Making Meeting, and Problem Solving Meeting. This is crucial, don't overlook this. 
STAKEHOLDERS: Provide a list of the participants in the meeting, their company, and their corresponding roles. If the name is not provided or not understood, please replace the name with the word 'Not stated'. If a speaker does not introduce themselves, then don't include them in the STAKEHOLDERS section. &nbsp; 
CONTEXT: provide a 10-15 summary or context sentences with the following information: Main reason for contact, Resolution provided, Final outcome, considering all the information above 
MEETING OBJECTIVES: provide all the objectives or goals of the meeting. Be thorough and detailed. 
CONVERSATION DETAILS: Customer's main concerns/requests Solutions discussed Important information verified Decisions made 
KEY POINTS DISCUSSED (Elaborate on each point, if applicable): List all significant topics and issues Important details or numbers mentioned Any policies or procedures explained Special requests or exceptions 
ACTION ITEMS &amp; NEXT STEPS (Elaborate on each point, if applicable): What the customer needs to do: Immediate actions required Future steps to take Important dates or deadlines What the company will do (Elaborate on each point, if applicable): Processing or handling steps Follow-up actions promised Timeline for completion 
ADDITIONAL NOTES (Elaborate on each point, if applicable): Any notable issues or concerns Follow-up recommendations Important reminders 
TECHNICAL REQUIREMENTS &amp; RESOURCES (Elaborate on each point, if applicable): Systems or tools discussed/needed Technical specifications mentioned Required access or permissions Resource allocation details 
Frontend implementation 
The frontend is built with React and provides the following features: 
 
 User authentication and authorization using Amazon Cognito 
 Audio file upload interface with progress indicators 
 Summary viewing with formatted sections (stakeholders, key points, action items) 
 Search functionality across meeting summaries 
 Meeting statistics visualization 
 
The frontend communicates with the backend through the AWS AppSync GraphQL API, which provides a unified interface for data operations. 
Security considerations 
Security is a top priority in our solution, which we address with the following measures: 
 
 User authentication is handled by Amazon Cognito 
 API access is secured with Amazon Cognito user pools 
 S3 bucket access is restricted to authenticated users 
 IAM roles follow the principle of least privilege 
 Data is encrypted at rest and in transit 
 Step Functions provide secure orchestration with proper error handling 
 
Benefits of using Amazon Bedrock 
Amazon Bedrock offers several key advantages for our meeting summarization system: 
 
 Access to state-of-the-art models ‚Äì Amazon Bedrock provides access to leading FMs like Anthropic‚Äôs Claude 3.7 Sonnet version 1, which delivers high-quality summarization capabilities without the need to train custom models. 
 Fully managed integration ‚Äì Amazon Bedrock integrates seamlessly with other AWS services, allowing for a fully serverless architecture that scales automatically with demand. 
 Cost-efficiency ‚Äì On-Demand pricing means you only pay for the actual processing time, making it cost-effective for variable workloads. 
 Security and compliance ‚Äì Amazon Bedrock maintains data privacy and security, making sure sensitive meeting content remains protected within your AWS environment. 
 Customizable prompts ‚Äì The ability to craft detailed prompts allows for tailored summaries that extract exactly the information your organization needs from meetings. Amazon Bedrock also provides prompt management and optimization, as well as the playground for quick prototyping. 
 Multilingual support ‚Äì Amazon Bedrock can process content in multiple languages, making it suitable for global organizations. 
 Reduced development time ‚Äì Pre-trained models minimize the need for extensive AI development expertise and infrastructure. 
 Continuous improvement ‚Äì Amazon Bedrock provides a model choice, and the user can update the existing models with a single string change. 
 
Prerequisites 
Before implementing this solution, make sure you have: 
 
 An AWS account with permissions to create and manage the required services, such as Amazon S3, DynamoDB, Lambda, Amazon Transcribe, Amazon Bedrock, Step Functions, AWS AppSync, Amazon CloudWatch, and IAM 
  Terraform v1.5.0 or later installed 
 The AWS Command Line Interface (AWS CLI) configured with appropriate credentials 
 Access to Amazon Bedrock FMs (Anthropic‚Äôs Claude 3.7 Sonnet version 1 recommended 
 Basic familiarity with Terraform and AWS services 
 
In the following sections, we walk through the steps to deploy the meeting audio summarizer solution. 
Clone the repository 
First, clone the repository containing the Terraform code: 
git clone https://github.com/aws-samples/sample-meeting-audio-summarizer-in-terraform
cd sample-meeting-audio-summarizer-in-terraform 
Configure AWS credentials 
Make sure your AWS credentials are properly configured. You can use the AWS CLI to set up your credentials: 
aws configure --profile meeting-summarizer 
You will be prompted to enter your AWS access key ID, secret access key, default AWS Region, and output format. 
Install frontend dependencies 
To set up the frontend development environment, navigate to the frontend directory and install the required dependencies: 
cd frontend
npm install 
Create configuration files 
Move to the terraform directory: 
cd ../backend/terraform/ &nbsp; 
Update the terraform.tfvars file in the backend/terraform directory with your specific values. This configuration supplies values for the variables previously defined in the variables.tf file. 
You can customize other variables defined in variables.tf according to your needs. In the terraform.tfvars file, you provide actual values for the variables declared in variables.tf, so you can customize the deployment without modifying the core configuration files: 
 
 aws_region&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "us-east-1"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
aws_profile&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = "YOUR-AWS-PROFILE"&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
environment&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = "prod"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
app_name&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "meeting-audio-summarizer"&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
dynamodb_read_capacity&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= 5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
dynamodb_write_capacity&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = 5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cognito_allowed_email_domains&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = ["example.com"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
model_id&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "anthropic.claude-3-7-sonnet-20250219-v1:0"&nbsp;&nbsp;
inference_profile_prefix&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "us"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
frontend_bucket_name&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "a-unique-bucket-name"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
storage_bucket&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "a-unique-bucket-name"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
cognito_domain_prefix&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = "meeting-summarizer"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
meeting_statistics_table_name&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = "MeetingStatistics"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
meeting_summaries_table_name&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= "MeetingSummaries"&nbsp;  
 
For a-unique-bucket-name, choose a unique name that is meaningful and makes sense to you. 
Initialize and apply Terraform 
Navigate to the terraform directory and initialize the Terraform environment: 
terraform init 
To upgrade the previously selected plugins to the newest version that complies with the configuration‚Äôs version constraints, use the following command: 
terraform init&nbsp;-upgrade 
This will cause Terraform to ignore selections recorded in the dependency lock file and take the newest available version matching the configured version constraints. 
Review the planned changes: 
terraform plan 
Apply the Terraform configuration to create the resources: 
terraform apply 
When prompted, enter yes to confirm the deployment. You can run terraform apply -auto-approve to skip the approval question. 
Deploy the solution 
After the backend deployment is complete, deploy the entire solution using the provided deployment script: 
cd ../../scripts
sudo chmod&nbsp;+x deploy.sh
./deploy.sh 
This script handles the entire deployment process, including: 
 
 Deploying the backend infrastructure using Terraform 
 Automatically configuring the frontend with backend resource information 
 Building and deploying the frontend application 
 Setting up CloudFront distribution 
 Invalidating the CloudFront cache to make sure the latest content is served 
 
Verify the deployment 
After the entire solution (both backend and frontend) is deployed, in your terminal you should see something similar to the following text: 
 
 Deployment complete! :)

============================================================================
Your app is available at: https://d1e5vh2t5qryy2.cloudfront.net.
============================================================================ 
 
The CloudFront URL (*.cloudfront.net/) is unique, so yours will not be the same. 
Enter the URL into your browser to open the application. You will see a login page like the following screenshot. You must create an account to access the application. 
 
Start by uploading a file: 
 
View generated summaries in a structured format: 
 
See meeting statistics: 
 
Clean up 
To cleanup the solution you must run this command. 
terraform destroy 
This command will completely remove the AWS resources provisioned by Terraform in your environment. When executed, it will display a detailed plan showing the resources that will be destroyed, and prompt for confirmation before proceeding. The process may take several minutes as it systematically removes infrastructure components in the correct dependency order. 
Remember to verify the destruction is complete by checking your AWS Console to make sure no billable resources remain active. 
Cost considerations 
When implementing this solution, it‚Äôs important to understand the cost implications of each component. Let‚Äôs analyze the costs based on a realistic usage scenario, based on the following assumptions: 
 
 50 hours of audio processing per month 
 Average meeting length of 30 minutes 
 100 active users accessing the system 
 5 million API queries per month 
 
The majority of the cost comes from Amazon Transcribe (approximately 73% of total cost at $72.00), with AWS AppSync being the second largest cost component (approximately 20% at $20.00). Despite providing the core AI functionality, Amazon Bedrock costs approximately 3% of total at $3.00, and DynamoDB, CloudFront, Lambda, Step Functions, Amazon SQS, and Amazon S3 make up the remaining 4%. 
We can take advantage of the following cost optimization opportunities: 
 
 Implement audio compression to reduce storage and processing costs 
 Use Amazon Transcribe Medical for medical meetings (if applicable) for higher accuracy 
 Implement caching strategies for frequently accessed summaries to reduce AppSync and DynamoDB costs 
 Consider reserved capacity for DynamoDB if usage patterns are predictable 
 
The following table summarizes these prices. Refer the AWS pricing pages for each service to learn more about the AWS pricing model. 
 
  
   
   Service 
   Usage 
   Unit Cost 
   Monthly Cost 
   
   
   Amazon Bedrock 
   500K input tokens100K output tokens 
   $3.00 per million tokens$15.00 per million tokens 
   $3 
   
   
   Amazon CloudFront 
   5GB data transfer 
   $0.085 per GB 
   $0.43 
   
   
   Amazon Cognito 
   100 Monthly Active Users (MAU) 
   Free tier (first 50K users) 
   $0 
   
   
   Amazon DynamoDB 
   5 RCU/WCU, ~ 1GB storage 
   $0.25 per RCU/WCU + $0.25/GB 
   $2.75 
   
   
   Amazon SQS 
   1,000 messages 
   $0.40 per million 
   $0.01 
   
   
   Amazon S3 Storage 
   3GB audio + 12MB transcripts/summaries 
   $0.023 per GB 
   $0.07 
   
   
   AWS Step Functions 
   1,000 state transitions 
   $0.025 per 1,000 
   $0.03 
   
   
   AWS AppSync 
   5M queries 
   $4.00 per million 
   $20 
   
   
   AWS Lambda 
   300 invocations, 5s avg. runtime, 256MB 
   Various 
   $0.10 
   
   
   Amazon Transcribe 
   50 hours of audio 
   $1.44 per hour 
   $72 
   
   
    
    
   TOTAL 
   98.39 
   
  
 
Next steps  
The next phase of our meeting summarization solution will incorporate several advanced AI technologies to deliver greater business value. Amazon Sonic Model can improve transcription accuracy by better handling multiple speakers, accents, and technical terminology‚Äîaddressing a key pain point for global organizations with diverse teams. Meanwhile, Amazon Bedrock Flows can enhance the system‚Äôs analytical capabilities by implementing automated meeting categorization, role-based summary customization, and integration with corporate knowledge bases to provide relevant context. These improvements can help organizations extract actionable insights that would otherwise remain buried in conversation. 
The addition of real-time processing capabilities helps teams see key points, action items, and decisions as they emerge during meetings, enabling immediate clarification and reducing follow-up questions. Enhanced analytics functionality track patterns across multiple meetings over time, giving management visibility into communication effectiveness, decision-making processes, and project progress. By integrating with existing productivity tools like calendars, daily agenda, task management systems, and communication services, this solution makes sure that meeting intelligence flows directly into daily workflows, minimizing manual transfer of information and making sure critical insights drive tangible business outcomes across departments. 
Conclusion 
Our meeting audio summarizer combines AWS serverless technologies with generative AI to solve a critical productivity challenge. It automatically transcribes and summarizes meetings, saving organizations thousands of hours while making sure insights and action items are systematically captured and shared with stakeholders. 
The serverless architecture scales effortlessly with fluctuating meeting volumes, costs just $0.98 per meeting on average, and minimizes infrastructure management and maintenance overhead. Amazon Bedrock provides enterprise-grade AI capabilities without requiring specialized machine learning expertise or significant development resources, and the Terraform-based infrastructure as code enables rapid deployment across environments, customization to meet specific organizational requirements, and seamless integration with existing CI/CD pipelines. 
As the field of generative AI continues to evolve and new, better-performing models become available, the solution‚Äôs ability to perform its tasks will automatically improve on performance and accuracy without additional development effort, enhancing summarization quality, language understanding, and contextual awareness. This makes the meeting audio summarizer an increasingly valuable asset for modern businesses looking to optimize meeting workflows, enhance knowledge sharing, and boost organizational productivity. 
Additional resources 
Refer to Amazon Bedrock Documentation for more details on model selection, prompt engineering, and API integration for your generative AI applications. Additionally, see Amazon Transcribe Documentation for information about the speech-to-text service‚Äôs features, language support, and customization options for achieving accurate audio transcription. For infrastructure deployment needs, see Terraform AWS Provider Documentation for detailed explanations of resource types, attributes, and configuration options for provisioning AWS resources programmatically. To enhance your infrastructure management skills, see Best practices for using the Terraform AWS Provider, where you can find recommended approaches for module organization, state management, security configurations, and resource naming conventions that will help make sure your AWS infrastructure deployments remain scalable and maintainable. 
 
About the authors 
Dunieski Otano is a Solutions Architect at Amazon Web Services based out of Miami, Florida. He works with World Wide Public Sector MNO (Multi-International Organizations) customers. His passion is Security, Machine Learning and Artificial Intelligence, and Serverless. He works with his customers to help them build and deploy high available, scalable, and secure solutions. Dunieski holds 14 AWS certifications and is an AWS Golden Jacket recipient. In his free time, you will find him spending time with his family and dog, watching a great movie, coding, or flying his drone. 
Joel Asante, an Austin-based Solutions Architect at Amazon Web Services (AWS), works with GovTech (Government Technology) customers. With a strong background in data science and application development, he brings deep technical expertise to creating secure and scalable cloud architectures for his customers. Joel is passionate about data analytics, machine learning, and robotics, leveraging his development experience to design innovative solutions that meet complex government requirements. He holds 13 AWS certifications and enjoys family time, fitness, and cheering for the Kansas City Chiefs and Los Angeles Lakers in his spare time. 
Ezzel Mohammed is a Solutions Architect at Amazon Web Services (AWS) based in Dallas, Texas. He works on the International Organizations team within the World Wide Public Sector, collaborating closely with UN agencies to deliver innovative cloud solutions. With a Computer Science background, Ezzeldien brings deep technical expertise in system design, helping customers architect and deploy highly available and scalable solutions that meet international compliance requirements. He holds 9 AWS certifications and is passionate about applying AI Engineering and Machine Learning to address global challenges. In his free time, he enjoys going on walks, watching soccer with friends and family, playing volleyball, and reading tech articles.
‚Ä¢ Kyruus builds a generative AI provider matching solution on AWS
  This post was written with Zach Heath of Kyruus Health. 
When health plan members need care, they shouldn‚Äôt need a dictionary. Yet millions face this exact challenge‚Äîdescribing symptoms in everyday language while healthcare references clinical terminology and complex specialty classifications. This disconnect forces members to become amateur medical translators, attempting to convert phrases like ‚Äúmy knee hurts when I climb stairs‚Äù into specialized search criteria such as orthopedics or physical medicine. Traditional provider directories compound this problem with overwhelming filter options and medical jargon, leading to frustrated members, delayed care access, and ultimately higher costs for both individuals and health plans. 
Kyruus Health, a leading provider of care access solutions, serves over 1,400 hospitals, 550 medical groups, and 100 health plan brands‚Äîconnecting more than 500,000 providers with patients seeking care and facilitating over 1 million appointments annually. To address the challenges of healthcare navigation, they developed Guide, an AI-powered solution that understands natural language and connects members with the right providers. With Guide, members can express health concerns in their own words and receive personalized provider matches without requiring clinical knowledge. Health plans implementing this solution have reported enhanced member experience and higher Net Promoter Scores (NPS), along with improved care access conversion and appointment scheduling rates. 
In this post, we demonstrate how Kyruus Health uses AWS services to build Guide. We show how Amazon Bedrock, a fully managed service that provides access to foundation models (FMs) from leading AI companies and Amazon through a single API, and Amazon OpenSearch Service, a managed search and analytics service, work together to understand everyday language about health concerns and connect members with the right providers. We explore the solution architecture, share implementation insights, and examine how this approach delivers measurable business value for health plans and their members. 
Solution overview 
Guide transforms healthcare provider search by translating natural language health concerns into precisely matched provider recommendations. The solution uses Amazon Bedrock with Anthropic‚Äôs Claude 3.5 Sonnet to understand everyday descriptions of health concerns and convert them into structured medical parameters. Then it uses OpenSearch Service to match these parameters against comprehensive provider data and deliver targeted recommendations. 
This architecture makes it possible for members to express health needs in plain language while making sure provider matches meet clinical requirements. The entire solution maintains HIPAA compliance through end-to-end encryption and fine-grained access controls, so Kyruus Health to focus on improving the member experience instead of managing complex infrastructure. 
The following diagram illustrates the solution architecture. 
 
This architecture translates natural language queries into structured healthcare parameters through the following steps: 
 
 A member enters a query like ‚ÄúI‚Äôve been having shooting pain down my leg for two weeks‚Äù through the health plan application. Amazon API Gateway securely receives the member‚Äôs query request. 
 API Gateway routes the request to Guide‚Äôs conversation service running on Amazon Elastic Container Service (Amazon ECS). 
 Guide‚Äôs conversation service calls Amazon Bedrock, where Anthropic‚Äôs Claude 3.5 Sonnet processes the natural language. The model identifies potential sciatica and translates this everyday description into structured medical parameters, including appropriate specialties like neurology or orthopedics. 
 The health plan application initiates a new API call through API Gateway to the Provider Search Service running on Amazon ECS, using the structured parameters derived from the previous steps. 
 The Provider Search Service queries OpenSearch Service, which contains comprehensive provider data previously ingested from Amazon Simple Storage Service (Amazon S3), including specialties, clinical focus areas, locations, and insurance network participation. 
 
Matched providers are then returned to the health plan application and presented to the member through an intuitive conversational interface. This architecture demonstrates the powerful combination of Amazon Bedrock FMs with purpose-built AWS services like OpenSearch Service, creating an end-to-end solution that bridges the gap between complex healthcare data and intuitive member experiences. 
Building with Tribe AI 
To accelerate their AI transformation, Kyruus Health partnered with Tribe AI, an AWS Partner with extensive experience in building and implementing enterprise-grade generative AI solutions at scale. Tribe AI‚Äôs proven track record in deploying FMs in complex, regulatory environments like healthcare helped de-risk the adoption of generative AI for Kyruus. This partnership allowed Kyruus to focus on their healthcare domain expertise while using Tribe AI‚Äôs technical implementation knowledge to bring Guide from concept to production. 
Implementation insights 
Kyruus Health‚Äôs successful implementation of Guide yielded key insights that can help organizations building healthcare AI initiatives: 
 
 Healthcare-specific testing infrastructure is essential ‚Äì Kyruus Health prioritized testing with real healthcare scenarios from the start. This process made sure Guide could accurately translate everyday descriptions into appropriate provider specialties, maintaining reliability where matching decisions directly impact health outcomes and plan costs. 
 User-centered design principles must guide AI implementation ‚Äì By focusing first on member needs rather than technical capabilities, Kyruus Health made sure their solution addressed the actual friction points in healthcare navigation. This approach led directly to significant improvements in satisfaction and reduced search abandonment rates, demonstrating how AI implementations should start with human needs rather than technical possibilities. 
 Strategic model selection drives business outcomes ‚Äì Rather than using a single model for all tasks, Kyruus Health discovered the power of strategically deploying specialized models for different aspects of healthcare navigation‚Äîincluding complex symptom interpretation and clinical specialty mapping. This targeted approach improved provider match accuracy by aligning specific AI capabilities to distinct parts of the matching process, optimizing both performance and cost while delivering more precise provider recommendations. 
 
These insights demonstrate how a thoughtful implementation approach can transform complex healthcare navigation challenges into intuitive member experiences that deliver measurable business results. 
Guide member experience in action 
The following screenshot shows how the AWS architecture translates into the real-world member experience. When a member enters their symptom description and location preference, Guide processes this natural language input through Amazon Bedrock and identifies appropriate specialists using OpenSearch Service. The system interprets the medical concern and location requirements, responding with relevant specialists within the requested distance who are accepting new patients. This streamlined experience has delivered higher match rates and increased appointment completion for health plans. 
 
Conclusion 
Guide demonstrates how generative AI powered by AWS transforms healthcare navigation by bridging the gap between everyday language and clinical terminology. In this post, we explored how an architecture combining Amazon Bedrock and OpenSearch Service processes natural language queries into personalized provider matches, helping members find appropriate healthcare providers using natural language descriptions of their symptoms. 
For health plans evaluating digital initiatives, Guide offers a blueprint for solving complex healthcare challenges while delivering measurable improvements in member satisfaction and appointment conversion rates. To build your own generative AI solutions, explore Amazon Bedrock for managed access to FMs. For healthcare-specific guidance, check out the AWS Healthcare Industry Lens and browse implementation examples, use cases, and technical guidance in the AWS Healthcare and Life Sciences Blog. 
 
About the authors 
Zach Heath is a Senior Staff Software Engineer at Kyruus Health. A passionate technologist, he specializes in architecting and implementing robust, scalable software solutions that transform healthcare search experiences by connecting patients with the right care through innovative technology. 
Anil Chinnam is a Solutions Architect at AWS. He is a generative AI enthusiast passionate about translating cutting-edge technologies into tangible business value for healthcare customers. As a trusted technical advisor, he helps customers drive cloud adoption and business transformation outcomes.
‚Ä¢ Use generative AI in Amazon Bedrock for enhanced recommendation generation in equipment maintenance
  In the manufacturing world, valuable insights from service reports often remain underutilized in document storage systems. This post explores how Amazon Web Services (AWS) customers can build a solution that automates the digitisation and extraction of crucial information from many reports using generative AI. 
The solution uses Amazon Nova Pro on Amazon Bedrock and Amazon Bedrock Knowledge Bases to generate recommended actions that are aligned with the observed equipment state, using an existing knowledge base of expert recommendations. The knowledge base expands over time as the solution is used. 
Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies such as AI21 Labs, Anthropic, Cohere, Meta, Stability AI, Mistral, and Amazon through a single API, along with a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. 
Amazon Bedrock Knowledge Base offers fully managed, end-to-end Retrieval-Augmented Generation (RAG) workflows to create highly accurate, low latency, and custom Generative AI applications by incorporating contextual information from your company‚Äôs data sources, making it a well-suited service to store engineers‚Äô expert recommendations from past reports and allow FMs to accurately customise their responses. 
Traditional service and maintenance cycles rely on manual report submission by engineers with expert knowledge. Time spent referencing past reports can lead to operational delays and business disruption.This solution empowers equipment maintenance teams to: 
 
 Ingest inspection and maintenance reports (in multiple languages) and extract equipment status and open actions, increasing visibility and actionability 
 Generate robust, trustworthy recommendations using experienced engineers‚Äô expertise 
 Expand the initial knowledge base built by expert engineers to include valid generated recommendations 
 Accelerate maintenance times and prevent unplanned downtime with a centralised, AI-powered tool that streamlines your equipment maintenance processes on AWS 
 
To help you implement this solution, we provide a GitHub repository containing deployable code and infrastructure as code (IaC) templates. You can quickly set up and customise the solution in your own AWS environment using the GitHub repository. 
Solution overview 
The following diagram is an architecture representation of the solution presented in this post, showcasing the various AWS services in use. Using this GitHub repository, you can deploy the solution into your AWS account to test it. 
 
The following are key workflows of the solution: 
 
 Automated service report ingestion with Amazon Textract ‚Äì The report ingestion workflow processes and translates service reports into a standardised format. This workflow uses Amazon Textract for optical character recognition (OCR), Amazon Translate for language translation, and Amazon Comprehend for language detection. These services provide reports that are accurately processed and prepared for metadata extraction, regardless of their original format or language. 
 Intelligent recommendation generation using RAG ‚Äì Following ingestion, the metadata extraction and standardisation process uses RAG architecture with the Amazon Nova Pro in Amazon Bedrock and Amazon Bedrock Knowledge Bases. This workflow extracts crucial metadata from the reports and uses the RAG process to generate precise and actionable maintenance recommendations. The metadata is standardised for consistency and reliability, providing a solid foundation for the recommendations. 
 Expert validation with Amazon SageMaker Ground Truth ‚Äì To validate and refine the generated recommendations, the solution incorporates an expert review process using Amazon SageMaker Ground Truth. This workflow involves creating customised labelling jobs where experts review and validate the recommendations for accuracy and reliability. This feedback loop helps continually improve the model‚Äôs performance, making the maintenance recommendations more trustworthy. 
 Expanding the knowledge base for future processing ‚Äì The knowledge base for this tool needs to be expanded with new rules for each equipment type, drawing from two main sources: 
   
   Analysing past equipment and maintenance reports to obtain labeled data on recommended actions. 
   Reinforcing valid recommendations generated by the tool and verified by human experts. 
    
 
This compiled set of rules is reviewed by experts, assigned criticality, and then automatically synced into the Amazon Bedrock Knowledge Bases to continually improve the solution‚Äôs confidence in generating the next recommended action.Together, these workflows create a seamless and efficient process from report ingestion to actionable recommendations, producing high-quality insights for maintenance operations.This solution is deployable and scalable using IaC with Terraform for ease of implementation and expansion across various environments. Teams have the flexibility to efficiently roll out the solution to customers globally, enhancing maintenance operations and reducing unplanned downtimes.In the following sections, we walk through the steps to customize and deploy the solution. 
Prerequisites 
To deploy the solution, you must have an AWS account with the appropriate permissions and access to Amazon Nova FMs on Amazon Bedrock. This can be enabled from the Amazon Bedrock console page. 
Clone the GitHub repository 
Clone the GitHub repository containing the IaC for the solution to your local machine. 
Customise the ReportsProcessing function 
To customize the ReportsProcessing AWS Lambda function, follow these steps: 
 
 Open the lambdas/python/ReportsProcessing/extract_observations.py file. This file contains the logic for the ReportsProcessing Lambda function. 
 Modify the code in this file to include your custom logic for processing reports based on their specific document styles. For example, you might need to modify the extract_metadata function to handle different report formats or adjust the logic in the standardize_metadata function to comply with your organisation‚Äôs standards. 
 
Customise the RecommendationGeneration function 
To customize the RecommendationGeneration Lambda, follow these steps: 
 
 Open the lambdas/python/RecommendationGeneration/generate_recommendations.pyfile. This file contains the logic for the RecommendationGeneration Lambda function, which uses the RAG architecture. 
 Modify the code in this file to include your custom logic for generating recommendations based on your specific requirements. For example, you might need to adjust the query_formulation() function to modify the prompt sent to Anthropic‚Äôs Claude 3 Sonnet or update the retrieve_rules function to customize the retrieval process from the knowledge base. 
 
Update the Terraform configuration 
If you made changes to the Lambda function names, roles, or other AWS resources, update the corresponding Terraform configuration files in the terraform directory to reflect these changes. 
Initialise the Terraform working directory 
Open a terminal or command prompt and navigate to the terraform directory within the cloned repository. Enter the following command to initialize the Terraform working directory: 
 
 terraform init 
 
Preview the Terraform changes 
Before applying the changes, preview the Terraform run plan by entering the following command: 
 
 terraform plan 
 
This command will show you the changes that Terraform plans to make to your AWS infrastructure. 
Deploy the Terraform stack 
If you‚Äôre satisfied with the planned changes, deploy the Terraform stack to your AWS account by entering the following command: 
 
 terraform apply 
 
Enter yes and press Enter to proceed with the deployment. 
Create an Amazon Bedrock knowledge base 
After you deploy the Terraform stack, create an Amazon Bedrock knowledge base to store and retrieve the maintenance rules and recommendations: 
 
 aws bedrock-agent create-knowledge-base \
--knowledge-base-name&nbsp;"EquipmentMaintenanceKB"&nbsp;\
--description&nbsp;"Knowledge base for equipment maintenance recommendations"&nbsp;\
--storage-configuration&nbsp;'{ "type": "VECTOR_STORE", "vectorStore": { "embeddingModelArn": "arn:aws:bedrock:{aws-region}::foundation-model/amazon.titan-embed-text-v1" } }' 
 
Once the knowledge bases are created, do not forget to update the Generate Recommendations lambda function environment variable with the appropriate knowledge base ID. 
Upload a test report and validate the solution for generated recommendations 
To test the solution, upload a sample maintenance report to the designated Amazon Simple Storage Service (Amazon S3) bucket: 
 
 aws s3 cp sample_report.pdf s3://iac-created-reports-bucket/incoming 
 
Once the file is uploaded, navigate to the created AWS Step Functions State machine and validate that a successful execution occurs. The output of a successful execution must contain extracted observations from the input document as well as newly generated recommendations that have been pulled from the knowledge base. 
Clean up 
When you‚Äôre done with this solution, clean up the resources you created to avoid ongoing charges. 
Conclusion 
This post provided an overview of implementing a risk-based maintenance solution to preempt potential failures and avoid equipment downtime for maintenance teams. This solution highlights the benefits of Amazon Bedrock. By using Amazon Nova Pro with RAG for your equipment maintenance reports, engineers and scientists can focus their efforts on improving accuracy of recommendations and increasing development velocity. The key capabilities of this solution include: 
 
 Automated ingestion and standardization of maintenance reports using Amazon Textract, Amazon Comprehend, and Amazon Translate 
 Intelligent recommendation generation powered by RAG and Amazon Nova Pro on Amazon Bedrock 
 Continual expert validation and knowledge base expansion using SageMaker Ground Truth 
 Scalable and production-ready deployment using IaC with Terraform 
 
By using the breadth of AWS services and the flexibility of Amazon Bedrock, equipment maintenance teams can streamline their operations and reduce unplanned downtimes. 
AWS Professional Services is ready to help your team develop scalable and production-ready generative AI solutions on AWS. For more information, refer to the AWS Professional Services page or reach out to your account manager to get in touch. 
 
About the authors 
Jyothsna Puttanna is an AI/ML Consultant at AWS Professional Services. Jyothsna works closely with customers building their machine learning solutions on AWS. She specializes in distributed training, experimentation, and generative AI. 
Shantanu Sinha is a Senior Engagement Manager at AWS Professional Services, based out of Berlin, Germany. Shantanu‚Äôs focus is on using generative AI to unlock business value and identify strategic business opportunities for his clients. 
Selena Tabbara is a Data Scientist at AWS Professional Services specializing in AI/ML and Generative AI solutions for enterprise customers in energy, automotive and manufacturing industry.
‚Ä¢ Build real-time travel recommendations using AI agents on Amazon Bedrock
  Generative AI is transforming how businesses deliver personalized experiences across industries, including travel and hospitality. Travel agents are enhancing their services by offering personalized holiday packages, carefully curated for customer‚Äôs unique preferences, including accessibility needs, dietary restrictions, and activity interests. Meeting these expectations requires a solution that combines comprehensive travel knowledge with real-time pricing and availability information. 
In this post, we show how to build a generative AI solution using Amazon Bedrock that creates bespoke holiday packages by combining customer profiles and preferences with real-time pricing data. We demonstrate how to use Amazon Bedrock Knowledge Bases for travel information, Amazon Bedrock Agents for real-time flight details, and Amazon OpenSearch Serverless for efficient package search and retrieval. 
Solution overview 
Travel agencies face increasing demands for personalized recommendations while struggling with real-time data accuracy and scalability. Consider a travel agency that needs to offer accessible holiday packages: they need to match specific accessibility requirements with real-time flight and accommodation availability but are constrained by manual processing times and outdated information in traditional systems. This AI-powered solution combines personalization with real-time data integration, enabling the agency to automatically match accessibility requirements with current travel options, delivering accurate recommendations in minutes rather than hours.The solution uses a three-layer architecture to help travel agents create personalized holiday recommendations: 
 
 Frontend layer ‚Äì Provides an interface where travel agents input customer requirements and preferences 
 Orchestration layer ‚Äì Processes request and enriches them with customer data 
 Recommendation layer ‚Äì Combines two key components: 
   
   Travel data storage ‚Äì Maintains a searchable repository of travel packages 
   Real-time information retrieval ‚Äì Fetches current flight details through API integration 
    
 
The following diagram illustrates this architecture. 
 
With this layered approach, travel agents can capture customer requirements, enrich them with stored preferences, integrate real-time data, and deliver personalized recommendations that match customer needs. The following diagram illustrates how these components are implemented using AWS services. 
 
The AWS implementation includes: 
 
 Amazon API Gateway ‚Äì Receives requests and routes them to AWS Lambda functions facilitating secure API calls for retrieving recommendations 
 AWS Lambda ‚Äì Processes input data, creates the enriched prompt, and executes the recommendation workflow 
 Amazon DynamoDB ‚Äì Stores customer preferences and travel history 
 Amazon Bedrock Knowledge Bases ‚Äì Helps travel agents build a curated database of destinations, travel packages, and deals, making sure recommendations are based on reliable and up-to-date information 
 Amazon OpenSearch Serverless ‚Äì Enables simple, scalable, and high-performing vector search 
 Amazon Simple Storage Service (Amazon S3) ‚Äì Stores large datasets such as flight schedules and promotional materials 
 Amazon Bedrock Agents ‚Äì Integrates real-time information retrieval, making sure recommended itineraries reflect current availability, pricing, and scheduling through external API integrations 
 
This solution uses a AWS CloudFormation template that automatically provisions and configures the required resources. The template handles the complete setup process, including service configurations and necessary permissions. 
For the latest information about service quotas that might affect your deployment, refer to AWS service quotas. 
Prerequisites 
To deploy and use this solution, you must have the following: 
 
 An AWS account with access to Amazon Bedrock 
 Permissions to create and manage the following services: 
   
   Amazon Bedrock 
   Amazon OpenSearch Serverless 
   Lambda 
   DynamoDB 
   Amazon S3 
   API Gateway 
    
 Access to foundation models in Amazon Bedrock for Amazon Titan Text Embeddings V2 and Anthropic Claude 3 Haiku models 
 
Deploy the CloudFormation stack 
You can deploy this solution in your AWS account using AWS CloudFormation. Complete the following steps: 
 
 Choose Launch Stack: 
 
 
You will be redirected to the Create stack wizard on the AWS CloudFormation console with the stack name and the template URL already filled in. 
 
 Leave the default settings and complete the stack creation. 
 Choose View stack events to go to the AWS CloudFormation console to see the deployment details. 
 
The stack takes around 10 minutes to create the resources. Wait until the stack status is CREATE_COMPLETE before continuing to the next steps. 
The CloudFormation template automatically creates and configures components for data storage and management, Amazon Bedrock, and the API and interface. 
Data storage and management 
The template sets up the following data storage and management resources: 
 
 An S3 bucket and with a sample dataset (travel_data.json and promotions.csv), prompt template, and the API schema 
 
 
 
 DynamoDB tables populated with sample user profiles and travel history 
 
 
 
 An OpenSearch Serverless collection with optimized settings for travel package searches 
 
 
 
 A vector index with settings compatible with the Amazon Bedrock knowledge base 
 
 
Amazon Bedrock configuration 
For Amazon Bedrock, the CloudFormation template creates the following resources: 
 
 A knowledge base with the travel dataset and data sources ingested from Amazon S3 with automatic synchronization 
 
 
 
 An Amazon Bedrock agent, which is automatically prepared 
 
 
 
 A new version and alias for the agent 
 
 
 
 Agent action groups with mock flight data integration 
 
 
 
 An action group invocation, configured with the FlightPricingLambda Lambda function and the API schema retrieved from the S3 bucket 
 
 
API and interface setup 
To enable API access and the UI, the template configures the following resources: 
 
 API Gateway endpoints 
 Lambda functions with a mock flight API for demonstration purposes 
 A web interface for travel agents 
 
Verify the setup 
After stack creation is complete, you can verify the setup on the Outputs tab of the AWS CloudFormation console, which provides the following information: 
 
 WebsiteURL ‚Äì Access the travel agent interface 
 ApiEndpoint ‚Äì Use for programmatic access to the recommendation system 
 
 
Test the endpoints 
The web interface provides an intuitive form where travel agents can input customer requirements, including: 
 
 Customer ID (for example, Joe or Will) 
 Travel budget 
 Preferred dates 
 Number of travelers 
 Travel style 
 
 
You can call the API directly using the following code: 
 
 curl -X POST \
&nbsp;&nbsp;&lt;ApiEndpoint&gt; \
&nbsp;&nbsp;-H 'Content-Type: application/json' \
&nbsp;&nbsp;-d '{
&nbsp;&nbsp; &nbsp;"userId": "Joe",
&nbsp;&nbsp; &nbsp;"budget": "3000 GBP",
&nbsp;&nbsp; &nbsp;"duration": "7 days",
&nbsp;&nbsp; &nbsp;"travelDate": "2025-07-15",
&nbsp;&nbsp; &nbsp;"numberOfTravelers": 2
&nbsp;&nbsp;}' 
 
Test the solution 
For demonstration purposes, we create sample user profiles in the UserPreferences and TravelHistory tables in DynamoDB. 
The UserPreferences table stores user-specific travel preferences. For instance, Joe represents a luxury traveler with wheelchair accessibility requirements. 
 
Will represents a budget traveler with elderly-friendly needs. These profiles help showcase how the system handles different customer requirements and preferences. 
 
The TravelHistory table stores past trips taken by users. The following tables show the past trips taken by the user Joe, showing destinations, trip durations, ratings, and travel dates. 
 
Let‚Äôs walk through a typical use case to demonstrate how a travel agent can use this solution to create personalized holiday recommendations.Consider a scenario where a travel agent is helping Joe, a customer who requires wheelchair accessibility, plan a luxury vacation. The travel agent enters the following information: 
 
 Customer ID: Joe 
 Budget: 4,000 GBP 
 Duration: 5 days 
 Travel dates: July 15, 2025 
 Number of travelers: 2 
 Travel style: Luxury 
 
 
When a travel agent submits a request, the system orchestrates a series of actions through the PersonalisedHolidayFunction Lambda function, which will query the knowledge base, check real-time flight information using the mock API, and return personalized recommendations that match the customer‚Äôs specific needs and preferences. The recommendation layer uses the following prompt template: 
 
 Based on the profile and requirements:

User Preferences:
- Travel Preferences: {travelStyle}
- Interests: {interests}
- Dietary Restrictions: {dietaryRestrictions}
- Accessibility Needs: {accessibility}

Current Request:
- Budget: {budget}
- Duration: {duration}
- Travel Date: {travelDate}
- Number of Travelers: {numberOfTravelers}

Previous Destinations: {previousDestinations}

Instructions:
1. Match the user's budget, travel style and interests
2. Consider dietary restrictions and accessibility needs
3. Avoid previously visited destinations
4. Include:
&nbsp;&nbsp; - Recommended destinations
&nbsp;&nbsp; - Suitable accommodations
&nbsp;&nbsp; - Relevant activities and experiences
&nbsp;&nbsp; - Transportation options
&nbsp;&nbsp; - Estimated cost breakdown
&nbsp;&nbsp; - Travel tips

Please follow the &lt;Instructions&gt; and provide a personalized holiday recommendation in the below format:
Destination: [Primary recommended destination]

[Detailed recommendation] 
 
The system retrieves Joe‚Äôs preferences from the user profile, including: 
 
 {
&nbsp;&nbsp; &nbsp;"userPreferences": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"preferences": "Prefer warm climate and cultural experiences",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"budget": 3000,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"duration": "5 days",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"travelDate": "2025-03-04",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"interests": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"photography",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"food",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"beach"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"travelStyle": "Luxury",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"numberOfTravelers": 2,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"dietaryRestrictions": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"plant based",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"vegetarian"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"accessibility": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"wheelchair-accessible"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"previousDestinations": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Maldives",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Bali"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;]
&nbsp;&nbsp; &nbsp;}
} 
 
The system then generates personalized recommendations that consider the following: 
 
 Destinations with proven wheelchair accessibility 
 Available luxury accommodations 
 Flight details for the recommended destination 
 
Each recommendation includes the following details: 
 
 Detailed accessibility information 
 Real-time flight pricing and availability 
 Accommodation details with accessibility features 
 Available activities and experiences 
 Total package cost breakdown 
 
Clean up 
To avoid incurring future charges, delete the CloudFormation stack. For more information, see Delete a stack from the CloudFormation console. 
The template includes proper deletion policies, making sure the resources you created, including S3 buckets, DynamoDB tables, and OpenSearch collections, are properly removed. 
Next steps 
To further enhance this solution, consider the following: 
 
 Explore multi-agent capabilities: 
   
   Create specialized agents for different travel aspects (hotels, activities, local transport) 
   Enable agent-to-agent communication for complex itinerary planning 
   Implement an orchestrator agent to coordinate responses and resolve conflicts 
    
 Implement multi-language support using multi-language foundation models in Amazon Bedrock 
 Integrate with customer relationship management (CRM) systems 
 
Conclusion 
In this post, you learned how to build an AI-powered holiday recommendation system using Amazon Bedrock that helps travel agents deliver personalized experiences. Our implementation demonstrated how combining Amazon Bedrock Knowledge Bases with Amazon Bedrock Agents effectively bridges historical travel information with real-time data needs, while using serverless architecture and vector search for efficient matching of customer preferences with travel packages.The solution shows how travel recommendation systems can balance comprehensive travel knowledge, real-time data accuracy, and personalization at scale. This approach is particularly valuable for travel organizations needing to integrate real-time pricing data, handle specific accessibility requirements, or scale their personalized recommendations. This solution provides a practical starting point with clear paths for enhancement based on specific business needs, from modernizing your travel planning systems or handling complex customer requirements. 
Related resources 
To learn more, refer to the following resources: 
 
 Documentation: 
   
   Amazon Bedrock Documentation 
   Automate tasks in your application using AI agents 
   Retrieve data and generate AI responses with Amazon Bedrock Knowledge Bases 
   Amazon OpenSearch Serverless Developer Guide 
   Building Lambda functions with Python 
    
 Code samples: 
   
   Amazon Bedrock RAG with Knowledge Bases and Agents 
   Amazon Bedrock Samples Repository 
   Amazon Bedrock Agent Samples Repository 
    
 Additional learning: 
   
   AWS Machine Learning Blog 
   AWS Training and Certification 
    
 
 
About the Author 
Vishnu Vardhini 
Vishnu Vardhini is a Solutions Architect at AWS based in Scotland, focusing on SMB customers across industries. With expertise in Security, Cloud Engineering and DevOps, she architects scalable and secure AWS solutions. She is passionate about helping customers leverage Machine Learning and Generative AI to drive business value.

‚∏ª