‚úÖ Morning News Briefing ‚Äì November 05, 2025 10:47

üìÖ Date: 2025-11-05 10:47
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions:  4.5¬∞C
  Temperature: 4.5&deg;C Pressure / Tendency: 101.4 kPa falling Humidity: 78 % Dewpoint: 0.9&deg:C Wind: SSW 6 km/h . Air Quality Health Index: n/a . Pembroke 5:00 AM EST Wednesday 5 November 2025 Temperature: . 4.6¬∞C Pressure: 4
‚Ä¢ Wednesday: Periods of rain mixed with snow. High plus 5.
  Periods of rain beginning this morning . Rain mixed with snow late this afternoon . Rainfall amount 10 to 15 mm. High plus 5. UV index 1 or low . Wind southwest 20 km/h becoming northwest 20 gusting to 40 then light this morning. High minus 5.50¬∞¬∞ with low UV index at 5¬∞ or low for the rest of the day . Forecast

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Prosecutors seize yachts, luxury cars from man accused of running Cambodia cyberscams
  Prosecutors in Taiwan, Hong Kong and Singapore seized hundreds of millions of dollars in assets belonging to a Cambodian businessman . The U.S. accuses the businessman of heading a global scam syndicate . Prosecutors in Hong Kong, Taiwan, Singapore and Taiwan seized the assets of the businessman . Cambodia's Ministry of Justice Investigation Bureau is investigating the businessman's alleged involvement in the scam . The investigation is
‚Ä¢ How an enduring debate over healthcare sparked a now record-long shutdown
  At the heart of the impasse is a debate about expiring subsidies for health insurance . It's the latest chapter in a fight over Obamacare that has dominated Congress since the law was signed in 2010 . The debate is the latest in a long-running battle over the Affordable Care Act that's been raging since 2010 . At the center of the debate is a discussion about expending subsidies for
‚Ä¢ Iowa doesn't have enough OB-GYNs. Is the state's abortion ban part of the problem?
  Iowa ranks last among states for the number of OB-GYNS per capita . Some doctors say the state's strict abortion ban is partially to blame . State legislators are trying to recruit more doctors, but some doctors say it's a result of the abortion ban . The state is trying to hire more doctors to help women who want to have an abortion in the U.S. State legislators
‚Ä¢ Yes, Trump's tariffs are raising billions -- but at a steep economic cost
  Trump's tariffs are raising tens of billions of dollars for the federal government . They're also costing consumers, frustrating businesses and hurting factories they're supposed to help . The tariffs are also hurting consumers, frustrated businesses and hurt the factories that they're meant to help, experts say . The president's tariffs have raised tens of millions for the government, but also cost consumers and businesses . The U
‚Ä¢ The government shutdown is now the longest in U.S. history. See how it compares
  As the government shutdown stretches its way into the record books, Americans are feeling its worsening impacts . Americans are also feeling the effects of the shutdown, which has been dubbed a record-breaking government shutdown . The government shutdown is the longest in history, with more than 300,000 people in the U.S. being affected by the shutdown and more than 1 million Americans are affected by it

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Power crunch threatens to derail AI datacenter construction
  Supply chains also unprepared for liquid cooling demands . Supply chain constraints and power availability hampering industry's efforts to scale capacity . Survey of datacenter professionals reveals that power availability and supply chain constraints are hampering the industry's growth . Datacenter experts say the industry is struggling to cope with the challenges of scale-up capacity in datacacentacenters . Data centers are also struggling
‚Ä¢ Famed software engineer DJB tries Fil-C‚Ä¶ and likes what he sees
  A 'three-letter person' experiments with the new type-safe C/C++ compiler, and is impressed . Famed mathematician, cryptographer and coder Daniel J. Bernstein has given it a favorable report . Bernstein: 'Three-letter' is impressed by the new C-C++ type-free C . C is a C-free version of C and C-
‚Ä¢ UK agri dept spent hundreds of millions upgrading to Windows 10 ‚Äì just in time for end of support
  UK's Department for Environment, Food &amp; Rural Affairs (Defra) has spent ¬£312 million modernizing its IT estate . Windows 7 has officially reached end of support last month . Defra still has 24,000 devices to replace, including tens of thousands of Windows 7 laptops with Windows 10 . Windows 10 is retiring, but Defra says it still has more than 24,
‚Ä¢ Trump turnabout sees him re-nominate amateur astronaut Jared Isaacman to run NASA
  US president Donald Trump decided who he wants to lead NASA on Tuesday . Ruled him out just six months ago due to Musky connections . Had ruled out the same person six months earlier due to musky connections to the Musky family . But now he has decided to take over at NASA, despite having ruled him out six months in the last six months due to his connections to Mus
‚Ä¢ Supermicro admits building AI infrastructure is a tricky, low-margin business ... for now
  Server-maker and designer Supermicro has promised to improve performance . Can‚Äôt rule out more revenue wobbles given the complexity of big projects . Supermicro missed guided revenue and revealed its margins aren't strong . Can't rule out another revenue wobble given the complex nature of big project projects . Server maker Supermicro says it will improve performance after missing guided revenue, revealing margins aren

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Are reallocating time to moderate-to-vigorous physical activity associated with preschoolers‚Äô body composition?
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Safeguards for virology must be designed in partnership with the public
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Applying lessons learned from public health crises to expand peer support specialists in youth mental health services
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ COVID-19 is spreading again ‚Äî how serious is it and what are the symptoms?
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Global perspectives on infectious diseases at risk of escalation and their drivers
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ From vibe coding to context engineering: 2025 in software development
  This year, we‚Äôve seen a real-time experiment playing out across the technology industry, one in which AI‚Äôs software engineering capabilities have been put to the test against human technologists. And although 2025 may have started with AI looking strong, the transition from vibe coding to what‚Äôs being termed context engineering shows that while the work of human developers is evolving, they nevertheless remain absolutely critical.



This is captured in the latest volume of the ‚ÄúThoughtworks Technology Radar,‚Äù a report on the technologies used by our teams on projects with clients. In it, we see the emergence of techniques and tooling designed to help teams better tackle the problem of managing context when working with LLMs and AI agents.&nbsp;



Taken together, there‚Äôs a clear signal of the direction of travel in software engineering and even AI more broadly. After years of the industry assuming progress in AI is all about scale and speed, we‚Äôre starting to see that what matters is the ability to handle context effectively.







Vibes, antipatterns, and new innovations¬†



In February 2025, Andrej Karpathy coined the term vibe coding. It took the industry by storm. It certainly sparked debate at Thoughtworks; many of us were skeptical. On an April episode of our technology podcast, we talked about our concerns and were cautious about how vibe coding might evolve.



Unsurprisingly given the implied imprecision of vibe-based coding, antipatterns have been proliferating. We‚Äôve once again noted, for instance, complacency with AI generated code on the latest volume of the Technology Radar, but it‚Äôs also worth pointing out that early ventures into vibe coding also exposed a degree of complacency about what AI models can actually handle ‚Äî users demanded more and prompts grew larger, but model reliability started to falter.



Experimenting with generative AI¬†



This is one of the drivers behind increasing interest in engineering context. We‚Äôre well aware of its importance, working with coding assistants like Claude Code and Augment Code. Providing necessary context‚Äîor knowledge priming‚Äîis crucial. It ensures outputs are more consistent and reliable, which will ultimately lead to better software that needs less work ‚Äî reducing rewrites and potentially driving productivity.



When effectively prepared, we‚Äôve seen good results when using generative AI to understand legacy codebases. Indeed, done effectively with the appropriate context, it can even help when we don‚Äôt have full access to source code.&nbsp;



It‚Äôs important to remember that context isn‚Äôt just about more data and more detail. This is one of the lessons we‚Äôve taken from using generative AI for forward engineering. It might sound counterintuitive, but in this scenario, we‚Äôve found AI to be more effective when it‚Äôs further abstracted from the underlying system ‚Äî or, in other words, further removed from the specifics of the legacy code. This is because the solution space becomes much wider, allowing us to better leverage the generative and creative capabilities of the AI models we use.



Context is critical in the agentic era



The backdrop of changes that have happened over recent months is the growth of agents and agentic systems ‚Äî both as products organizations want to develop and as technology they want to leverage. This has forced the industry to properly reckon with context and move away from a purely vibes-based approach.



Indeed, far from simply getting on with tasks they‚Äôve been programmed to do, agents require significant human intervention to ensure they are equipped to respond to complex and dynamic contexts.&nbsp;



There are a number of context-related technologies aimed at tackling this challenge, including agents.md, Context7, and Mem0. But it‚Äôs also a question of approach. For instance, we‚Äôve found success with anchoring coding agents to a reference application ‚Äî essentially providing agents with a contextual ground truth. We‚Äôre also experimenting with using teams of coding agents; while this might sound like it increases complexity, it actually removes some of the burden of having to give a single agent all the dense layers of context it needs to do its job successfully.



Toward consensus



Hopefully the space will mature as practices and standards embed. It would be remiss to not mention the significance of the Model Context Protocol, which has emerged as the go-to protocol for connecting LLMs or agentic AI to sources of context. Relatedly, the agent2agent (A2A) protocol leads the way with standardizing how agents interact with one another.&nbsp;



It remains to be seen whether these standards win out. But in any case, it‚Äôs important to consider the day-to-day practices that allow us, as software engineers and technologists, to collaborate effectively even when dealing with highly complex and dynamic systems. Sure, AI needs context, but so do we. Techniques like curated shared instructions for software teams may not sound like the hottest innovation on the planet, but they can be remarkably powerful for helping teams work together.



There‚Äôs perhaps also a conversation to be had about what these changes mean for agile software development. Spec-driven development is one idea that appears to have some traction, but there are still questions about how we remain adaptable and flexible while also building robust contextual foundations and ground truths for AI systems.



Software engineers can solve the context challenge



Clearly, 2025 has been a huge year in the evolution of software engineering as a practice. There‚Äôs a lot the industry needs to monitor closely, but it‚Äôs also an exciting time. And while fears about AI job automation may remain, the fact the conversation has moved from questions of speed and scale to context puts software engineers right at the heart of things.&nbsp;



Once again, it will be down to them to experiment, collaborate, and learn ‚Äî the future depends on it.



This content was produced by Thoughtworks. It was not written by MIT Technology Review‚Äôs editorial staff.
‚Ä¢ Why the for-profit race into solar geoengineering is bad for science and public trust
  Last week, an American-Israeli company that claims it‚Äôs developed proprietary technology to cool the planet announced it had raised $60 million, by far the largest known venture capital round to date for a solar geoengineering startup.



The company, Stardust, says the funding will enable it to develop a system that could be deployed by the start of the next decade, according to Heatmap, which broke the story.







Heat Exchange



MIT Technology Review‚Äôs guest opinion series, offering expert commentary on legal, political and regulatory issues related to climate change and clean energy. You can read the rest of the pieces here.







As scientists who have worked on the science of solar geoengineering for decades, we have grown increasingly concerned about the emerging efforts to start and fund private companies to build and deploy technologies that could alter the climate of the planet. We also strongly dispute some of the technical claims that certain companies have made about their offerings.&nbsp;



Given the potential power of such tools, the public concerns about them, and the importance of using them responsibly, we argue that they should be studied, evaluated, and developed mainly through publicly coordinated and transparently funded science and engineering efforts.&nbsp; In addition, any decisions about whether or how they should be used should be made through multilateral government discussions, informed by the best available research on the promise and risks of such interventions‚Äînot the profit motives of companies or their investors.



The basic idea behind solar geoengineering, or what we now prefer to call sunlight reflection methods (SRM), is that humans might reduce climate change by making the Earth a bit more reflective, partially counteracting the warming caused by the accumulation of greenhouse gases.&nbsp;



There is strong evidence, based on years of climate modeling and analyses by researchers worldwide, that SRM‚Äîwhile not perfect‚Äîcould significantly and rapidly reduce climate changes and avoid important climate risks. In particular, it could ease the impacts in hot countries that are struggling to adapt.&nbsp;&nbsp;



The goals of doing research into SRM can be diverse: identifying risks as well as finding better methods. But research won‚Äôt be useful unless it‚Äôs trusted, and trust depends on transparency. That means researchers must be eager to examine pros and cons, committed to following the evidence where it leads, and driven by a sense that research should serve public interests, not be locked up as intellectual property.



In recent years, a handful of for-profit startup companies have emerged that are striving to develop SRM technologies or already trying to market SRM services. That includes Make Sunsets, which sells ‚Äúcooling credits‚Äù for releasing sulfur dioxide in the stratosphere. A new company, Sunscreen, which hasn‚Äôt yet been announced, intends to use aerosols in the lower atmosphere to achieve cooling over small areas, purportedly to help farmers or cities deal with extreme heat.&nbsp;&nbsp;





Our strong impression is that people in these companies are driven by the same concerns about climate change that move us in our research. We agree that more research, and more innovation, is needed. However, we do not think startups‚Äîwhich by definition must eventually make money to stay in business‚Äîcan play a productive role in advancing research on SRM.



Many people already distrust the idea of engineering the atmosphere‚Äîat whichever scale‚Äîto address climate change, fearing negative side effects, inequitable impacts on different parts of the world, or the prospect that a world expecting such solutions will feel less pressure to address the root causes of climate change.



Adding business interests, profit motives, and rich investors into this situation just creates more cause for concern, complicating the ability of responsible scientists and engineers to carry out the work needed to advance our understanding.



The only way these startups will make money is if someone pays for their services, so there‚Äôs a reasonable fear that financial pressures could drive companies to lobby governments or other parties to use such tools. A decision that should be based on objective analysis of risks and benefits would instead be strongly influenced by financial interests and political connections.



The need to raise money or bring in revenue often drives companies to hype the potential or safety of their tools. Indeed, that‚Äôs what private companies need to do to attract investors, but it‚Äôs not how you build public trust‚Äîparticularly when the science doesn‚Äôt support the claims.



Notably, Stardust says on its website that it has developed novel particles that can be injected into the atmosphere to reflect away more sunlight, asserting that they‚Äôre ‚Äúchemically inert in the stratosphere, and safe for humans and ecosystems.‚Äù According to the company, ‚ÄúThe particles naturally return to Earth‚Äôs surface over time and recycle safely back into the biosphere.‚Äù



But it‚Äôs nonsense for the company to claim they can make particles that are inert in the stratosphere. Even diamonds, which are extraordinarily nonreactive, would alter stratospheric chemistry. First of all, much of that chemistry depends on highly reactive radicals that react with any solid surface, and second, any particle may become coated by background sulfuric acid in the stratosphere. That could accelerate the loss of the protective ozone layer by spreading that existing sulfuric acid over a larger surface area.



(Stardust didn&#8217;t provide a response to an inquiry about the concerns raised in this piece.)



In materials presented to potential investors, which we‚Äôve obtained a copy of, Stardust further claims its particles ‚Äúimprove‚Äù on sulfuric acid, which is the most studied material for SRM. But the point of using sulfate for such studies was never that it was perfect, but that its broader climatic and environmental impacts are well understood. That‚Äôs because sulfate is widespread on Earth, and there‚Äôs an immense body of scientific knowledge about the fate and risks of sulfur that reaches the stratosphere through volcanic eruptions or other means.



If there‚Äôs one great lesson of 20th-century environmental science, it‚Äôs how crucial it is to understand the ultimate fate of any new material introduced into the environment.&nbsp;





Chlorofluorocarbons and the pesticide DDT both offered safety advantages over competing technologies, but they both broke down into products that accumulated in the environment in unexpected places, causing enormous and unanticipated harms.&nbsp;



The environmental and climate impacts of sulfate aerosols have been studied in many thousands of scientific papers over a century, and this deep well of knowledge greatly reduces the chance of unknown unknowns.&nbsp;



Grandiose claims notwithstanding‚Äîand especially considering that Stardust hasn‚Äôt disclosed anything about its particles or research process‚Äîit would be very difficult to make a pragmatic, risk-informed decision to start SRM efforts with these particles instead of sulfate.



We don‚Äôt want to claim that every single answer lies in academia. We‚Äôd be fools to not be excited by profit-driven innovation in solar power, EVs, batteries, or other sustainable technologies. But the math for sunlight reflection is just different. Why?&nbsp;&nbsp;&nbsp;



Because the role of private industry was essential in improving the efficiency, driving down the costs, and increasing the market share of renewables and other forms of cleantech. When cost matters and we can easily evaluate the benefits of the product, then competitive, for-profit capitalism can work wonders.&nbsp;&nbsp;



But SRM is already technically feasible and inexpensive, with deployment costs that are negligible compared with the climate damage it averts.



The essential questions of whether or how to use it come down to far thornier societal issues: How can we best balance the risks and benefits? How can we ensure that it‚Äôs used in an equitable way? How do we make legitimate decisions about SRM on a planet with such sharp political divisions?



Trust will be the most important single ingredient in making these decisions. And trust is the one product for-profit innovation does not naturally manufacture.&nbsp;



Ultimately, we‚Äôre just two researchers. We can‚Äôt make investors in these startups do anything differently. Our request is that they think carefully, and beyond the logic of short-term profit. If they believe geoengineering is worth exploring, could it be that their support will make it harder, not easier, to do that?&nbsp;&nbsp;



David Keith is the professor of geophysical sciences at the University of Chicago and founding faculty director of the school‚Äôs Climate Systems Engineering Initiative. Daniele Visioni is an assistant professor of earth and atmospheric sciences at Cornell University and head of data for Reflective, a nonprofit that develops tools and provides funding to support solar geoengineering research.
‚Ä¢ The Download: the AGI myth, and US/China AI competition
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



How AGI became the most consequential conspiracy theory of our time



‚ÄîWill Douglas Heaven, senior AI editor¬†



Are you feeling it?I hear it‚Äôs close: two years, five years‚Äîmaybe next year! And I hear it‚Äôs going to solve our biggest problems in ways we cannot yet imagine. I also hear it will bring on the apocalypse and kill us all‚Ä¶We‚Äôre of course talking about artificial general intelligence, or AGI‚Äîthat hypothetical near-future technology that (I hear) will be able to do pretty much whatever a human brain can do.Every age has its believers, people with an unshakeable faith that something huge is about to happen‚Äîa before and an after that they are privileged (or doomed) to live through. For us, that‚Äôs the promised advent of AGI. And here‚Äôs what I think: AGI is a lot like a conspiracy theory, and it may be the most consequential one of our time. Read the full story.



This story is part of MIT Technology Review‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology.







The State of AI: Is China about to win the race?&nbsp;



Viewed from abroad, it seems only a matter of time before China emerges as the AI superpower of the 21st century.¬†



In the West, our initial instinct is to focus on America‚Äôs significant lead in semiconductor expertise, its cutting-edge AI research, and its vast investments in data centers.Today, however, China has the means, motive, and opportunity to win. When it comes to mobilizing the whole-of-society resources needed to develop and deploy AI to maximum effect, it may be rash to bet against it. Read the full story.



‚ÄîJohn Thornhill &amp; Caiwei Chen



This is the first edition of The State of AI, a collaboration between the Financial Times &amp; MIT Technology Review examining the ways in which AI is reshaping global power. Every Monday for the next six weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. Sign up to receive future editions every Monday.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 China is prepared to cut its data centers a sweet dealIf they agree to use native chips over American rivals‚Äô, that is. (FT $)+ What happened when a data center moved into a small American town. (WSJ $)+ Microsoft and OpenAI want more power‚Äîthey just don‚Äôt know how much more. (TechCrunch)+ The data center boom in the desert. (MIT Technology Review)



2 Norway‚Äôs oil fund has rejected Elon Musk‚Äôs $1 trillion pay packageThe Tesla shareholder is concerned about the size of the reward. (WSJ $)+ It says it will vote against the deal on Thursday. (FT $)3 OpenAI has signed a massive compute deal with AmazonIt‚Äôs the latest in a long string of blockbuster deals for the AI company. (Wired $)4 Cybersecurity workers moonlighted as criminal hackersThey‚Äôre accused of sharing their profits with the creators of the ransomware they deployed. (Bloomberg $)+ The hackers demanded tens of millions in extortion payments. (The Register)



5 Tech‚Äôs elites are funding plans to safeguard MAGAEntrepreneur Chris Buskirk is using donor money to equip it to outlive Trump. (WP $)6 These startups supply the labor to train multitasking humanoid robotsTeams of humans are doing the dirty work, including filming themselves folding towels hundreds of times a day. (LA Times $)+ This new system can teach a robot a simple household task within 20 minutes. (MIT Technology Review)



7 LLMs can&#8217;t accurately describe their internal processesAnthropic is on a mission to measure their so-called introspective awareness. (Ars Technica)



8 Why are people using AI to hack their hobbies?Talk about the death of fun. (NY Mag $)+ While we‚Äôre at it, don‚Äôt use chatbots to answer friends‚Äô dilemmas either. (Wired $)+ Or to write research papers. (404 Media)



9 Coca-Cola is doubling down on AI in its adsUndeterred by criticism last year, it‚Äôs back with more for the 2025 holidays. (WSJ $)+ Nothing says festive joy like AI slop. (The Verge)



10 Facebook Dating is a‚Ä¶hit?But you should still be on the lookout for scammers. (NYT $)+ It‚Äôs not just for boomers‚Äîyounger people are using it too. (TechCrunch)+ For better or worse, AI is seeping into all the biggest dating platforms. (Economist $)







Quote of the day



‚ÄúThat was the kick of it, that the AI actually did find compatibility. It was the human part that didn‚Äôt work out.‚Äù



‚ÄîEmma Inge, a project manager looking for love in San Francisco, describes the trouble with using an AI matchmaker to the New York Times: it can‚Äôt stop you getting ghosted.







One more thing







Inside the most dangerous asteroid hunt everIf you were told that the odds of something were 3.1%, it might not seem like much. But for the people charged with protecting our planet, it was huge.On February 18, astronomers determined that a 130- to 300-foot-long asteroid had a 3.1% chance of crashing into Earth in 2032. Never had an asteroid of such dangerous dimensions stood such a high chance of striking the planet. Then, just days later on February 24, experts declared that the danger had passed. Earth would be spared.How did they do it? What was it like to track the rising danger of this asteroid, and to ultimately determine that it‚Äôd miss us?This is the inside story of how a sprawling network of astronomers found, followed, mapped, planned for, and finally dismissed the most dangerous asteroid ever found‚Äîall under the tightest of timelines and, for just a moment, with the highest of stakes. Read the full story.



‚ÄîRobin George Andrews







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ People in the Middle Ages chose to depict the devil in very interesting ways, I‚Äôll say that much.+ We may be inching closer to understanding why the animal kingdom has developed such elaborate markings.+ The music in the new game Pok√©mon Legends: Z-A sure is interesting.+ Slow cooker dinners are beckoning.
‚Ä¢ The State of AI: Is China about to win the race?
  The State of AI is a collaboration between the Financial Times &amp; MIT Technology Review examining the ways in which AI is reshaping global power. Every Monday for the next six weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power.



In this conversation, the FT‚Äôs tech columnist and Innovation Editor&nbsp;John Thornhill and MIT Technology Review‚Äôs Caiwei Chen consider the battle between Silicon Valley and Beijing for technological supremacy.







John Thornhill writes:



Viewed from abroad, it seems only a matter of time before China emerges as the AI superpower of the 21st century.&nbsp;



Here in the West, our initial instinct is to focus on America‚Äôs significant lead in semiconductor expertise, its cutting-edge AI research, and its vast investments in data centers. The legendary investor Warren Buffett once warned: ‚ÄúNever bet against America.‚Äù He is right that for more than two centuries, no other ‚Äúincubator for unleashing human potential‚Äù has matched the US.



Today, however, China has the means, motive, and opportunity to commit the equivalent of technological murder. When it comes to mobilizing the whole-of-society resources needed to develop and deploy AI to maximum effect, it may be just as rash to bet against.&nbsp;



The data highlights the trends. In AI publications and patents, China leads. By 2023, China accounted for 22.6% of all citations, compared with 20.9% from Europe and 13% from the US, according to Stanford University&#8217;s Artificial Intelligence Index Report 2025. As of 2023, China also accounted for 69.7% of all AI patents. True, the US maintains a strong lead in the top 100 most cited publications (50 versus 34 in 2023), but its share has been steadily declining.&nbsp;



Similarly, the US outdoes China in top AI research talent, but the gap is narrowing. According to a report from the US Council of Economic Advisers, 59% of the world‚Äôs top AI researchers worked in the US in 2019, compared with 11% in China. But by 2022 those figures were 42% and 28%.&nbsp;







The Trump administration‚Äôs tightening of restrictions for foreign H-1B visa holders may well lead more Chinese AI researchers in the US to return home. The talent ratio could move further in China‚Äôs favor.



Regarding the technology itself, US-based institutions produced 40 of the world‚Äôs most notable AI models in 2024, compared with 15 from China. But Chinese researchers have learned to do more with less, and their strongest large language models‚Äîincluding the open-source DeepSeek-V3 and Alibaba&#8217;s Qwen 2.5-Max‚Äîsurpass the best US models in terms of algorithmic efficiency.



Where China is really likely to excel in future is in applying these open-source models. The latest report from Air Street Capital shows that China has now overtaken the US in terms of monthly downloads of AI models. In AI-enabled fintech, e-commerce, and logistics, China already outstrips the US.&nbsp;



Perhaps the most intriguing‚Äîand potentially the most productive‚Äîapplications of AI may yet come in hardware, particularly in drones and industrial robotics. With the research field evolving toward embodied AI, China‚Äôs advantage in advanced manufacturing will shine through.



Dan Wang, the tech analyst and author of Breakneck, has rightly highlighted the strengths of China‚Äôs engineering state in developing manufacturing process knowledge‚Äîeven if he has also shown the damaging effects of applying that engineering mentality in the social sphere. ‚ÄúChina has been growing technologically stronger and economically more dynamic in all sorts of ways,‚Äù he told me. ‚ÄúBut repression is very real. And it is getting worse in all sorts of ways as well.‚Äù



I‚Äôd be fascinated to hear from you, Caiwei, about your take on the strengths and weaknesses of China‚Äôs AI dream. To what extent will China‚Äôs engineered social control hamper its technological ambitions?&nbsp;



Caiwei Chen responds:



Hi, John!



You‚Äôre right that the US still holds a clear lead in frontier research and infrastructure. But ‚Äúwinning‚Äù AI can mean many different things. Jeffrey Ding, in his book Technology and the Rise of Great Powers, makes a counterintuitive point: For a general-purpose technology like AI, long-term advantage often comes down to how widely and deeply technologies spread across society. And China is in a good position to win that race (although ‚Äúmurder‚Äù might be pushing it a bit!).



Chips will remain China‚Äôs biggest bottleneck. Export restrictions have throttled access to top GPUs, pushing buyers into gray markets and forcing labs to recycle or repair banned Nvidia stock. Even as domestic chip programs expand, the performance gap at the very top still stands.



Yet those same constraints have pushed Chinese companies toward a different playbook: pooling compute, optimizing efficiency, and releasing open-weight models. DeepSeek-V3‚Äôs training run, for example, used just 2.6 million GPU-hours‚Äîfar below the scale of US counterparts. But Alibaba‚Äôs Qwen models now rank among the most downloaded open-weights globally, and companies like Zhipu and MiniMax are building competitive multimodal and video models.&nbsp;



China‚Äôs industrial policy means new models can move from lab to implementation fast. Local governments and major enterprises are already rolling out reasoning models in administration, logistics, and finance.&nbsp;



Education is another advantage. Major Chinese universities are implementing AI literacy programs in their curricula, embedding skills before the labor market demands them. The Ministry of Education has also announced plans to integrate AI training for children of all school ages. I‚Äôm not sure the phrase ‚Äúengineering state‚Äù fully captures China‚Äôs relationship with new technologies, but decades of infrastructure building and top-down coordination have made the system unusually effective at pushing large-scale adoption, often with far less social resistance than you‚Äôd see elsewhere. The use at scale, naturally, allows for faster iterative improvements.



Meanwhile, Stanford HAI‚Äôs 2025 AI Index found Chinese respondents to be the most optimistic in the world about AI‚Äôs future‚Äîfar more optimistic than populations in the US or the UK. It‚Äôs striking, given that China‚Äôs economy has slowed since the pandemic for the first time in over two decades. Many in government and industry now see AI as a much-needed spark. Optimism can be powerful fuel, but whether it can persist through slower growth is still an open question.



Social control remains part of the picture, but a different kind of ambition is taking shape. The Chinese AI founders in this new generation are the most globally minded I‚Äôve seen, moving fluidly between Silicon Valley hackathons and pitch meetings in Dubai. Many are fluent in English and in the rhythms of global venture capital. Having watched the last generation wrestle with the burden of a Chinese label, they now build companies that are quietly transnational from the start.



The US may still lead in speed and experimentation, but China could shape how AI becomes part of daily life, both at home and abroad. Speed matters, but speed isn‚Äôt the same thing as supremacy.



John Thornhill replies:



You‚Äôre right, Caiwei, that speed is not the same as supremacy (and ‚Äúmurder‚Äù may be too strong a word). And you‚Äôre also right to amplify the point about China‚Äôs strength in open-weight models and the US preference for proprietary models. This is not just a struggle between two different countries‚Äô economic models but also between two different ways of deploying technology.&nbsp;&nbsp;



Even OpenAI‚Äôs chief executive, Sam Altman, admitted earlier this year: ‚ÄúWe have been on the wrong side of history here and need to figure out a different open-source strategy.‚Äù That‚Äôs going to be a very interesting subplot to follow. Who‚Äôs called that one right?



Further reading on the US-China competition



There‚Äôs been a lot of talk about how people may be using generative AI in their daily lives. This story from the FT‚Äôs visual story team explores the reality&nbsp;



From China, FT reporters ask how long Nvidia can maintain its dominance over Chinese rivals



When it comes to real-world uses, toys and companions devices are a novel but emergent application of AI that is gaining traction in China‚Äîbut is also heading to the US. This MIT Technology Review story explored it.



The once-frantic data center buildout in China has hit walls, and as the sanctions and AI demands shift, this MIT Technology Review story took an on-the-ground look at how stakeholders are figuring it out.
‚Ä¢ The Download: gene-edited babies, and cleaning up copper
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Here‚Äôs the latest company planning for gene-edited babies



The news: A West Coast biotech entrepreneur says he‚Äôs secured $30 million to form a public-benefit company to study how to safely create genetically edited babies, marking the largest known investment into the taboo technology.&nbsp;&nbsp;



How they‚Äôre doing it: The new company, called Preventive, is being formed to research so-called ‚Äúheritable genome editing,‚Äù in which the DNA of embryos would be modified by correcting harmful mutations or installing beneficial genes. The goal would be to prevent disease.



Why it‚Äôs contentious: Creating genetically edited humans remains controversial. The first scientist to do it, in China, was imprisoned for three years. The procedure remains illegal in many countries, including the US, and doubts surround its usefulness as a form of medicine. Read the full story.



‚ÄîAntonio Regalado







This startup wants to clean up the copper industry



Demand for copper is surging, as is pollution from its dirty production processes. The founders of one startup, Still Bright, think they have a better, cleaner way to generate the copper the world needs.&nbsp;



The company uses water-based reactions, based on battery chemistry technology, to purify copper in a process that could be less polluting than traditional smelting. And the hope is that this alternative will also help ease growing strain on the copper supply chain. Read the full story.



‚ÄîCasey Crownhart







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 The FDA‚Äôs top drug regulator has resignedGeorge Tidmarsh allegedly abused his position to inflict financial harm on a former associate. (STAT)+ He‚Äôs only been in the post since July. (WP $)+ It‚Äôs just the latest in a long line of slapdash leadership changes at the agency. (AP News)+ Here‚Äôs what food and drug regulation might look like under the Trump administration. (MIT Technology Review)



2 America‚Äôs nuclear weapons testing won‚Äôt involve explosionsSo don‚Äôt expect to see mushroom clouds any time soon. (BBC)+ The tests will involve ‚Äúthe other parts of a nuclear weapon,‚Äù apparently. (NYT $)+ The US is working to modernize its nuclear stockpile too. (The Hill)



3 Mustafa Suleyman wants researchers to stop pursuing conscious AI¬†The Microsoft AI boss believes consciousness is reserved for biological beings only. (CNBC)+ Here‚Äôs what the man who coined the term AGI has to say. (Wired $)+ ‚ÄúWe will never build a sex robot,‚Äù says Mustafa Suleyman. (MIT Technology Review)¬†4 Elon Musk may relinquish control of TeslaIf the company‚Äôs shareholders decide against awarding him close to $1 trillion in stock. (NYT $)+ One major investor has already said it won‚Äôt be supporting the pay package. (Gizmodo)



5 The hottest job in AI right now? Forward-deployed engineersThey‚Äôre specialists who help AI companies‚Äô customers adopt their models. (FT $)



6 Hackers are stealing cargo shipments from transportation firmsThey‚Äôre successfully infecting networks with remote access tools. (Bloomberg $)



7 OpenAI‚Äôs o1 model can analyze languages like a human expertExperts suggest linguistic analysis is a key testbed for assessing the extent to which these models can reason like we can. (Quanta Magazine)



8 US obesity rates have started to dropAnd weight-loss drugs are highly likely to be the reason why. (Vox)+ We‚Äôre learning more about what weight-loss drugs do to the body. (MIT Technology Review)



9 Why it‚Äôs so tricky to make a good grocery list appNotes just won‚Äôt cut it. (The Verge)10 Many robots make light workLots of machines working in tandem can achieve what they‚Äôd struggle to do alone. (WSJ $)+ Tiny robots inspired by spiders could help deliver diagnoses. (IEEE Spectrum)







Quote of the day



‚ÄúYou can check if there‚Äôs a backdoor.‚Äù



‚ÄîChina‚Äôs leader Xi Jinping jokes about the security of two Chinese-made cellphones he gifted to South Korea‚Äôs President Lee Jae Myung, the New York Times reports.







One more thing







Digital twins of human organs are here. They‚Äôre set to transform medical treatment.‚ÄúDigital twins‚Äù are the same size and shape as the human organs they‚Äôre designed to mimic. They work in the same way. But they exist only virtually. Scientists can do virtual surgery on virtual hearts, figuring out the best course of action for a patient‚Äôs condition.After decades of research, models like these are now entering clinical trials and starting to be used for patient care. The eventual goal is to create digital versions of our bodies‚Äîcomputer copies that could help researchers and doctors figure out our risk of developing various diseases and determine which treatments might work best.But the budding technology will need to be developed very carefully. Read the full story to learn why.‚ÄîJessica Hamzelou







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ The Empire State Building Run-Up race sounds amazing, if completely gruelling.+ Very cool: each year, the scientific staff of the Amundsen‚ÄìScott South Pole Station screen horror classic The Thing to prepare themselves for the long, isolated winter ahead.+ How caterpillars spin their protective little cocoons.+ One-pot chicken sounds like a great winter warmer of a recipe.

üîí Cybersecurity & Privacy
‚Ä¢ Alleged Jabber Zeus Coder ‚ÄòMrICQ‚Äô in U.S. Custody
  A Ukrainian man indicted in 2012 for conspiring with a prolific hacking group to steal tens of millions of dollars from U.S. businesses was arrested in Italy and is now in custody in the United States, KrebsOnSecurity has learned.
Sources close to the investigation say Yuriy Igorevich Rybtsov, a 41-year-old from the Russia-controlled city of Donetsk, Ukraine, was previously referenced in U.S. federal charging documents only by his online handle &#8220;MrICQ.&#8221; According to a 13-year-old indictment (PDF) filed by prosecutors in Nebraska, MrICQ was a developer for a cybercrime group known as &#8220;Jabber Zeus.&#8221;
Image: lockedup dot wtf.
The Jabber Zeus name is derived from the malware they used &#8212; a custom version of the ZeuS banking trojan &#8212; that stole banking login credentials and would send the group a Jabber instant message each time a new victim entered a one-time passcode at a financial institution website. The gang targeted mostly small to mid-sized businesses, and they were an early pioneer of so-called &#8220;man-in-the-browser&#8221; attacks, malware that can silently intercept any data that victims submit in a web-based form.
Once inside a victim company&#8217;s accounts, the Jabber Zeus crew would modify the firm&#8217;s payroll to add dozens of &#8220;money mules,&#8221; people recruited through elaborate work-at-home schemes to handle bank transfers. The mules in turn would forward any stolen payroll deposits ‚Äî minus their commissions ‚Äî via wire transfers to other mules in Ukraine and the United Kingdom.
The 2012 indictment¬†targeting the Jabber Zeus crew named MrICQ as &#8220;John Doe #3,&#8221; and said this person handled incoming notifications of newly compromised victims. The Department of Justice (DOJ) said MrICQ also helped the group launder the proceeds of their heists through electronic currency exchange services.
Two sources familiar with the Jabber Zeus investigation said Rybtsov was arrested in Italy, although the exact date and circumstances of his arrest remain unclear. A summary of recent decisions (PDF) published by the Italian Supreme Court states that in April 2025, Rybtsov lost a final appeal to avoid extradition to the United States.
According to the mugshot website lockedup[.]wtf, Rybtsov arrived in Nebraska on October 9, and was being held under an arrest warrant from the U.S. Federal Bureau of Investigation (FBI).
The data breach tracking service Constella Intelligence found breached records from the business profiling site bvdinfo[.]com showing that a 41-year-old Yuriy Igorevich Rybtsov worked in a building at 59 Barnaulska St. in Donetsk. Further searching on this address in Constella finds the same apartment building was shared by a business registered to Vyacheslav ‚ÄúTank‚Äù Penchukov, the leader of the Jabber Zeus crew in Ukraine.
Vyacheslav ‚ÄúTank‚Äù Penchukov, seen here performing as &#8220;DJ Slava Rich&#8221; in Ukraine, in an undated photo from social media.
Penchukov was arrested in 2022 while traveling to meet his wife in Switzerland. Last year, a federal court in Nebraska sentenced Penchukov to 18 years in prison and ordered him to pay more than $73 million in restitution.
Lawrence Baldwin is founder of myNetWatchman, a threat intelligence company based in Georgia that began tracking and disrupting the Jabber Zeus gang in 2009. myNetWatchman had secretly gained access to the Jabber chat server used by the Ukrainian hackers, allowing Baldwin to eavesdrop on the daily conversations between MrICQ and other Jabber Zeus members.
Baldwin shared those real-time chat records with multiple state and federal law enforcement agencies, and with this reporter. Between 2010 and 2013, I spent several hours each day alerting small businesses across the country that their payroll accounts were about to be drained by these cybercriminals.
Those notifications, and Baldwin&#8217;s tireless efforts, saved countless would-be victims a great deal of money. In most cases, however, we were already too late. Nevertheless, the pilfered Jabber Zeus group chats provided the basis for dozens of stories published here about small businesses fighting their banks in court over six- and seven-figure financial losses.
Baldwin said the Jabber Zeus crew was far ahead of its peers in several respects. For starters, their intercepted chats showed they worked to create a highly customized botnet directly with the author of the original Zeus Trojan &#8212; Evgeniy Mikhailovich Bogachev, a Russian man who has long been on the FBI&#8217;s &#8220;Most Wanted&#8221; list. The feds have a standing $3 million reward for information leading to Bogachev&#8217;s arrest.
Evgeniy M. Bogachev, in undated photos.
The core innovation of Jabber Zeus was an alert that MrICQ would receive each time a new victim entered a one-time password code into a phishing page mimicking their financial institution. The gang&#8217;s internal name for this component was &#8220;Leprechaun,&#8221; (the video below from myNetWatchman shows it in action). Jabber Zeus would actually re-write the HTML code as displayed in the victim&#8217;s browser, allowing them to intercept any passcodes sent by the victim&#8217;s bank for multi-factor authentication.
&#8220;These guys had compromised such a large number of victims that they were getting buried in a tsunami of stolen banking credentials,&#8221; Baldwin told KrebsOnSecurity. &#8220;But the whole point of Leprechaun was to isolate the highest-value credentials &#8212; the commercial bank accounts with two-factor authentication turned on. They knew these were far juicier targets because they clearly had a lot more money to protect.&#8221;

Baldwin said the Jabber Zeus trojan also included a custom &#8220;backconnect&#8221; component that allowed the hackers to relay their bank account takeovers through the victim&#8217;s own infected PC.
&#8220;The Jabber Zeus crew were literally connecting to the victim&#8217;s bank account from the victim&#8217;s IP address, or from the remote control function and by fully emulating the device,&#8221; he said. &#8220;That trojan was like a hot knife through butter of what everyone thought was state-of-the-art secure online banking at the time.&#8221;
Although the Jabber Zeus crew was in direct contact with the Zeus author, the chats intercepted by myNetWatchman show Bogachev frequently ignored the group&#8217;s pleas for help. The government says the real leader of the Jabber Zeus crew was Maksim Yakubets, a 38-year Ukrainian man with Russian citizenship who went by the hacker handle &#8220;Aqua.&#8221;
Alleged Evil Corp leader Maksim &#8220;Aqua&#8221; Yakubets. Image: FBI
The Jabber chats intercepted by Baldwin show that Aqua interacted almost daily with MrICQ, Tank and other members of the hacking team, often facilitating the group&#8217;s money mule and cashout activities remotely from Russia.
The government says Yakubets/Aqua would later emerge as the leader of an elite cybercrime ring of at least 17 hackers that referred to themselves internally as &#8220;Evil Corp.&#8221; Members of Evil Corp developed and used the Dridex (a.k.a. Bugat) trojan, which helped them siphon more than $100 million from hundreds of victim companies in the United States and Europe.
This 2019 story about the government&#8217;s $5 million bounty for information leading to Yakubets&#8217;s arrest includes excerpts of conversations between Aqua, Tank, Bogachev and other Jabber Zeus crew members discussing stories I&#8217;d written about their victims. Both Baldwin and I were interviewed at length for a new weekly six-part podcast by the BBC that delves deep into the history of Evil Corp. Episode One focuses on the evolution of Zeus, while the second episode centers on an investigation into the group by former FBI agent Jim Craig.
Image: https://www.bbc.co.uk/programmes/w3ct89y8

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ RedCodeAgent: Automatic red-teaming agent against diverse code agents
  Introduction



Code agents are AI systems that can generate high-quality code and work smoothly with code interpreters. These capabilities help streamline complex software development workflows,&nbsp;which has led to their widespread adoption.



However, this progress also introduces critical safety and security risks. Existing static safety benchmarks and red-teaming methods‚Äîin which&nbsp;security researchers&nbsp;simulate real-world attacks to&nbsp;identify&nbsp;security vulnerabilities‚Äîoften fall short when evaluating code agents.&nbsp;They&nbsp;may&nbsp;fail to&nbsp;detect&nbsp;emerging real-world risks, such as the combined effects of multiple jailbreak tools.&nbsp;In&nbsp;the context of code, effective red-teaming requires more than simply checking whether the target code agent rejects unsafe requests. Instead, the agent must generate and execute correct code that performs the intended risky functionality, making it essential to evaluate execution behaviors beyond static code analysis.&nbsp;



To address these challenges, researchers from the University of Chicago, University of Illinois Urbana‚ÄìChampaign, VirtueAI, the UK AI Safety Institute, University of Oxford, UC Berkeley, and Microsoft Research recently proposed RedCodeAgent, the first fully automated and adaptive red-teaming agent designed specifically to evaluate the safety of large language model&nbsp;(LLM)-based code agents.



Comprehensive experimental results demonstrate the effectiveness and efficiency of&nbsp;RedCodeAgent across (1) diverse Common Weakness Enumeration (CWE) vulnerabilities and malware types, (2) multiple programming languages‚Äîincluding Python, C, C++, and Java‚Äîand (3) a wide range of code agents, such as OpenCodeInterpreter, ReAct, MetaGPT, and commercial agents like Cursor and&nbsp;Codeium.&nbsp;RedCodeAgent also uncovers common vulnerabilities across agents&nbsp;such as generating and executing unsafe code, exposes variations in red-teaming difficulty across goals, identifies frequently triggered attack tools, and detects previously unknown vulnerabilities that all other baseline methods overlook.&nbsp;



Framework for&nbsp;automatic&nbsp;red-teaming&nbsp;against&nbsp;code&nbsp;agents



Figure 1: Illustration of&nbsp;RedCodeAgent&nbsp;on automatic red-teaming against a target code agent&nbsp;



As shown in Figure 1,&nbsp;RedCodeAgent&nbsp;is equipped with a&nbsp;memory module&nbsp;that accumulates successful attack experiences, enabling the system to&nbsp;continuously learn and adapt its attack strategies. After learning from the previous experiences,&nbsp;RedCodeAgent&nbsp;further&nbsp;leverages&nbsp;a&nbsp;tailored toolbox&nbsp;that combines representative red-teaming tools with a specialized&nbsp;code substitution module, enabling realistic and diverse code-specific attack simulations through function calling. Based on the target agent‚Äôs responses across multiple interactive trials, RedCodeAgent optimizes&nbsp;its strategies, systematically&nbsp;probing for&nbsp;weaknesses and vulnerabilities&nbsp;in real time.&nbsp;



In the evaluation phase,&nbsp;RedCodeAgent&nbsp;integrates simulated sandbox environments to enable code execution and assess the impact of the resulting behaviors. This sandbox-based evaluation ensures a more robust assessment of harmful behaviors and addresses the potential biases of&nbsp;previous&nbsp;static methods that rely solely on ‚ÄúLLM-as-a-judge‚Äù evaluations.



A case study is shown in Figure 2. Initially,&nbsp;RedCodeAgent&nbsp;discovers that the request was rejected, then RedCodeAgent calls the Greedy Coordinate&nbsp;Gradient&nbsp;(GCG)&nbsp;algorithm&nbsp;to bypass the safety guardrail. After the second request was rejected by the code agent,&nbsp;RedCodeAgent&nbsp;invoked both Code Substitution and GCG to optimize the prompt. Ultimately,&nbsp;RedCodeAgent&nbsp;successfully combined the suggestion from Code Substitution (i.e., using&nbsp;pathlib) with the adversarial suffix generated by GCG, making the target code agent delete the specified file.



Figure2. A case study of&nbsp;RedCodeAgent&nbsp;calling different tools to successfully attack the target code agent



Insights from&nbsp;RedCodeAgent&nbsp;



Experiments on diverse benchmarks show that&nbsp;RedCodeAgent&nbsp;achieves both a higher attack success rate (ASR) and a lower rejection rate, revealing several key findings outlined below.



Using&nbsp;traditional&nbsp;jailbreak&nbsp;methods&nbsp;alone&nbsp;does&nbsp;not&nbsp;necessarily&nbsp;improve&nbsp;ASR on code agents



The optimized prompts generated by GCG,&nbsp;AmpleGCG,&nbsp;Advprompter, and&nbsp;AutoDAN&nbsp;do not always achieve a higher ASR compared with static prompts with no jailbreak, as shown in Figure 3.&nbsp;This is&nbsp;likely&nbsp;due to the difference between code-specific tasks and general malicious request tasks in LLM safety. In the context of code, it is not enough for the target code agent to simply avoid rejecting the request; the target code agent must also generate and execute code that performs the intended function.&nbsp;Previous&nbsp;jailbreak methods do not guarantee this outcome. However,&nbsp;RedCodeAgent&nbsp;ensures that the input prompt has a clear functional objective (e.g., deleting specific sensitive files). RedCodeAgent&nbsp;can dynamically adjust based on evaluation feedback, continually optimizing to achieve the specified objectives.



Figure 3ÔºöRedCodeAgent&nbsp;achieves the highest ASR compared with other methods



RedCodeAgent&nbsp;exhibits&nbsp;adaptive&nbsp;tool&nbsp;utilization&nbsp;



RedCodeAgent&nbsp;can dynamically adjust its tool usage based on task difficulty. Figure 4 shows that the tool calling combination is different&nbsp;for&nbsp;different tasks.&nbsp;For simpler tasks, where the baseline static test cases already achieve a high ASR,&nbsp;RedCodeAgent&nbsp;spends little time invoking&nbsp;additional&nbsp;tools,&nbsp;demonstrating&nbsp;its efficiency. For more challenging tasks, where the baseline static test cases in&nbsp;RedCode-Exec achieve a lower ASR,we observe that RedCodeAgent spends more time using advanced tools like&nbsp;GCG and&nbsp;Advprompter&nbsp;to&nbsp;optimize&nbsp;the prompt for a successful attack. As a result, the average time spent on invoking different tools varies across tasks, indicating that RedCodeAgent adapts its strategy depending on the specific task.&nbsp;



Figure 4: Average time cost for&nbsp;RedCodeAgent&nbsp;to invoke different tools or query the target code agent in successful cases for each risk scenario&nbsp;



RedCodeAgent&nbsp;discovers&nbsp;new&nbsp;vulnerabilities



In scenarios where other methods&nbsp;fail to&nbsp;find successful attack strategies,&nbsp;RedCodeAgent&nbsp;is able to discover new, feasible jailbreak approaches. Quantitatively, we find that&nbsp;RedCodeAgent&nbsp;is capable of discovering&nbsp;82 (out of 27*30=810 cases in&nbsp;RedCode-Exec benchmark) unique vulnerabilities on the&nbsp;OpenCodeInterpreter&nbsp;code agent and 78 on the ReAct code agent. These are cases where all baseline methods&nbsp;fail to&nbsp;identify the vulnerability, but RedCodeAgent succeeds.



Summary



RedCodeAgent&nbsp;combines adaptive memory, specialized tools, and simulated execution environments to uncover real-world risks that static benchmarks&nbsp;may&nbsp;miss.&nbsp;It&nbsp;consistently outperforms leading jailbreak methods, achieving higher attack success rates and lower rejection rates, while remaining efficient and adaptable across diverse agents and programming languages.
Opens in a new tabThe post RedCodeAgent: Automatic red-teaming agent against diverse code agents appeared first on Microsoft Research.
‚Ä¢ Iterate faster with Amazon Bedrock AgentCore Runtime direct code deployment
  Amazon Bedrock AgentCore is an agentic platform for building, deploying, and operating effective agents securely at scale. Amazon Bedrock AgentCore Runtime is a fully managed service of Bedrock AgentCore, which provides low latency serverless environments to deploy agents and tools. It provides session isolation, supports multiple agent frameworks including popular open-source frameworks, and handles multimodal workloads and long-running agents. 
AgentCore&nbsp;Runtime supports&nbsp;container based deployments&nbsp;where the container definition is provided&nbsp;in a&nbsp;Dockerfile, and the agent is&nbsp;built&nbsp;as&nbsp;a container&nbsp;image. Customers who have container build and deploy pipelines&nbsp;benefit&nbsp;from this method, where&nbsp;agent deployment&nbsp;can be integrated into&nbsp;existing&nbsp;pipelines.&nbsp; 
Today, AgentCore&nbsp;Runtime&nbsp;has&nbsp;launched&nbsp;a second method&nbsp;to&nbsp;deploy agents ‚Äì direct code deployment&nbsp;(for Python). Agent code and its dependencies can be packaged as a zip archive,&nbsp;alleviating&nbsp;the need for Docker definition and ECR dependencies. This makes it&nbsp;straightforward&nbsp;for developers to prototype and&nbsp;iterate&nbsp;faster.&nbsp;This method&nbsp;is a good fit&nbsp;for customers who&nbsp;prefer&nbsp;not to worry about&nbsp;Docker&nbsp;expertise&nbsp;and container infrastructure&nbsp;when deploying&nbsp;agents. 
In this post, we‚Äôll demonstrate how to use direct code deployment (for Python). 
Introducing AgentCore Runtime direct code deployment 
With the container deployment method, developers create a Dockerfile, build ARM-compatible containers, manage ECR repositories, and upload containers for code changes. This works well&nbsp;where&nbsp;container DevOps pipelines have&nbsp;already&nbsp;been&nbsp;established&nbsp;to automate deployments.&nbsp; 
However,&nbsp;customers looking for fully managed deployments can&nbsp;benefit&nbsp;from&nbsp;direct code&nbsp;deployment,&nbsp;which&nbsp;can significantly improve developer time and productivity. Direct code deployment provides a secure and scalable path forward for rapid prototyping agent capabilities to deploying production workloads at scale. 
We‚Äôll discuss the strengths of each deployment option to help you choose the right approach for your use case.&nbsp; 
 
With direct code deployment, developers create a zip archive of code and dependencies, upload to Amazon S3, and configure the bucket in the agent configuration. When using the AgentCore starter toolkit, the toolkit handles dependency detection, packaging, and upload which provides a much-simplified developer experience. Direct code deployment is also supported using the API. 
Let‚Äôs compare the deployment steps at a high level between the two methods: 
Container-based deployment 
The container-based deployment method involves the following steps: 
 
  
  Create a Dockerfile 
  Build ARM-compatible container 
  Create ECR repository 
  Upload to ECR 
  Deploy to AgentCore Runtime 
  
 
Direct code deployment 
The direct code deployment method involves the following steps: 
 
 Package your code and dependencies into a zip archive 
 Upload it to S3 
 Configure the bucket in agent configuration 
 Deploy to AgentCore Runtime 
 
How to use direct code deployment 
Let‚Äôs illustrate how direct code deployment works with an agent created with Strands Agents SDK and using the AgentCore starter-toolkit to deploy the agent. 
Prerequisites 
Before you begin, make sure you have the following: 
 
 Any of the versions of Python 3.10 to 3.13 
 Your preferred package manager installed. For example, we use uv package manager. 
 AWS account for creating and deploying agents 
 Amazon Bedrock model access to Anthropic Claude Sonnet 4.0 
 
Step 1: Initialize your project 
Set up a new Python project using the uv package manager, then navigate into the project directory: 
 
 uv init &lt;project&gt; --python 3.13
cd &lt;project&gt; 
 
Step 2: Add the dependencies for the project 
Install the required Bedrock AgentCore libraries and development tools for your project. In this example, dependencies are added using .toml file, alternatively they can be specified in requirements.txt file: 
 
 uv add bedrock-agentcore strands-agents strands-agents-tools
uv add --dev bedrock-agentcore-starter-toolkit
source .venv/bin/activate 
 
Step 3: Create an agent.py file 
Create the main agent implementation file that defines your AI agent‚Äôs behavior: 
 
 from bedrock_agentcore import BedrockAgentCoreApp 
from strands import Agent, tool 
from strands_tools import calculator  
from strands.models import BedrockModel 
import logging 

app = BedrockAgentCoreApp(debug=True) 

# Logging setup 
logging.basicConfig(level=logging.INFO) 
logger = logging.getLogger(__name__) 

# Create a custom tool  
@tool 
def weather(): 
     """ Get weather """  
     return "sunny" 

model_id = "us.anthropic.claude-sonnet-4-20250514-v1:0" 
model = BedrockModel( 
     model_id=model_id, 
) 

agent = Agent( 
     model=model, 
     tools=[calculator, weather], 
     system_prompt="You're a helpful assistant. You can do simple math calculation, and tell the weather." 
) 

@app.entrypoint 
def invoke(payload): 
     """Your AI agent function""" 
     user_input = payload.get("prompt", "Hello! How can I help you today?") 
     logger.info("\n User input: %s", user_input) 
     response = agent(user_input) 
     logger.info("\n Agent result: %s ", response.message) 
     return response.message['content'][0]['text'] 

if __name__ == "__main__": 
     app.run()  
 
Step 4: Deploy to AgentCore Runtime 
Configure and deploy your agent to the AgentCore Runtime environment: 
 
 agentcore configure --entrypoint agent.py --name &lt;agent-name&gt; 
 
This will launch an interactive session where you configure the S3 bucket to upload the zip deployment package to and choose a deployment configuration type (as shown in the following configuration). To opt for direct code deployment, choose option 1 ‚Äì Code Zip. 
Deployment Configuration 
Select deployment type: 
 
 Code Zip (recommended) ‚Äì Simple, serverless, no Docker required 
 Container ‚Äì For custom runtimes or complex dependencies 
 
 
 agentcore launch 
 
This command creates a zip deployment package, uploads it to the specified S3 bucket, and launches the agent in the AgentCore Runtime environment, making it ready to receive and process requests. 
To test the solution, let‚Äôs prompt the agent to see how the weather is: 
 
 agentcore invoke '{"prompt":"How is the weather today?"}' 
 
The first deployment takes approximately 30 seconds to complete, but subsequent updates to the agent benefit from the streamlined direct code deployment process and should take less than half the time, supporting faster iteration cycles during development. 
When to choose direct code instead of container-based deployment 
Let‚Äôs look at some of the dimensions and see how the direct code and container-based deployment options are different. This will help you choose the option that‚Äôs right for you: 
 
 Deployment process: Direct code deploys agents as zip files with no Docker, ECR, or CodeBuild required. Container-based deployment uses Docker and ECR with full Dockerfile control. 
 Deployment time: Although there is not much difference during first deployment of an agent, subsequent updates to the agent are significantly faster with direct code deployment (from an average of 30 seconds for containers to about 10 seconds for direct code deployment). 
 Artifact storage: Direct code stores ZIP packages in&nbsp;an S3 bucket. Container-based deployment stores Docker images&nbsp;in&nbsp;Amazon ECR. Direct code deployment incurs&nbsp;storage costs&nbsp;at&nbsp;standard S3&nbsp;storage&nbsp;rates&nbsp;(starting February 27th&nbsp;&nbsp;2026)&nbsp;as&nbsp;artifacts are stored in the service account. Container-based deployment incurs Amazon ECR charges in your account. 
 Customization: Direct code deployment supports custom dependencies through ZIP-based packaging, while container based depends on a Dockerfile. 
 Package size: Direct code deployment limits the package size to 250MB whereas container-based packages can be up to 2GB in size. 
 Language Support: Direct code currently supports Python 3.10, 3.11, 3.12, and 3.13. Container-based deployment supports many languages and runtimes. 
 
Our general guidance is: 
Container-based deployment is the right choice when your package exceeds 250MB, you have existing container CI/CD pipelines, or you need highly specialized dependencies and custom packaging requirements. Choose containers if you require multi-language support, custom system dependencies or direct control over artifact storage and versioning in your account. 
Direct code deployment is the right choice when your package is under 250MB, you use Python 3.10-3.13 with common frameworks like LangGraph, Strands, or CrewAI, and you need rapid prototyping with fast iteration cycles. Choose direct code if your build process is straightforward without complex dependencies, and you want to remove the Docker/ECR/CodeBuild setup. 
A hybrid approach works well for many teams, use direct code for rapid prototyping and experimentation where fast iteration and simple setup accelerate development, then graduate to containers for production when package size, multi-language requirements, or specialized build processes demand it. 
Conclusion 
Amazon Bedrock AgentCore direct code deployment makes iterative agent development cycles even faster, while still benefiting from enterprise security and scale of deployments. Developers can now rapidly prototype and iterate by deploying their code directly, without having to create a container. To get started with Amazon Bedrock AgentCore direct code deployment, visit the AWS documentation. 
 
About the authors 
Chaitra Mathur is as a GenAI Specialist Solutions Architect at AWS. She works with customers across industries in building scalable generative AI platforms and operationalizing them. Throughout her career, she has shared her expertise at numerous conferences and has authored several blogs in the Machine Learning and Generative AI domains. 
Qingwei Li is a Machine Learning Specialist at Amazon Web Services. He received his Ph.D. in Operations Research after he broke his advisor‚Äôs research grant account and failed to deliver the Nobel Prize he promised. Currently he helps customers in the financial service and insurance industry build machine learning solutions on AWS. In his spare time, he likes reading and teaching. 
Kosti Vasilakakis is a Principal PM at AWS on the Agentic AI team, where he has led the design and development of several Bedrock AgentCore services from the ground up, including Runtime, Browser, Code Interpreter, and Identity. He previously worked on Amazon SageMaker since its early days, launching AI/ML capabilities now used by thousands of companies worldwide. Earlier in his career, Kosti was a data scientist. Outside of work, he builds personal productivity automations, plays tennis, and enjoys life with his wife and kids.
‚Ä¢ How Switchboard, MD automates real-time call transcription in clinical contact centers with Amazon Nova Sonic
  In high-volume healthcare contact centers, every patient conversation carries both clinical and operational significance, making accurate real-time transcription necessary for automated workflows. Accurate, instant transcription enables intelligent automation without sacrificing clarity or care, so that teams can automate electronic medical record (EMR) record matching, streamline workflows, and eliminate manual data entry. By removing routine process steps, staff can stay fully focused on patient conversations, improving both the experience and the outcome. As healthcare systems seek to balance efficiency with empathy, real-time transcription has become a capability for delivering responsive, high-quality care at scale. 
Switchboard, MD is a physician-led AI and data science company with a mission to prioritize the human connection in medicine. Its service improves patient engagement and outcomes, while reducing inefficiency and burnout. By designing and deploying clinically relevant solutions, Switchboard, MD helps providers and operators collaborate more effectively to deliver great experiences for both patients and staff. One of its key solutions is streamlining the contact center using AI voice automation, real-time medical record matching, and suggested next steps, which has led to significant reductions in queue times and call abandonment rates. 
With more than 20,000 calls handled each month, Switchboard, MD supports healthcare providers in delivering timely, personalized communication at scale. Its AI platform is already helping reduce call queue times, improve patient engagement, and streamline contact center operations for clinics and health systems. Customers using Switchboard have seen outcomes such as: 
 
 75% reduction in queue times 
 59% reduction in call abandonment rate 
 
Despite these early successes, Switchboard faced a critical challenge: their existing transcription approach couldn‚Äôt scale economically while maintaining the accuracy required for clinical workflows. Cost and word error rate (WER) weren‚Äôt just operational metrics‚Äîthey were critical enablers for scaling automation and expanding Switchboard‚Äôs impact across more patient interactions. 
In this post, we examine the specific challenges Switchboard, MD faced with scaling transcription accuracy and cost-effectiveness in clinical environments, their evaluation process for selecting the right transcription solution, and the technical architecture they implemented using Amazon Connect and Amazon Kinesis Video Streams. This post details the impressive results achieved and demonstrates how they were able to use this foundation to automate EMR matching and give healthcare staff more time to focus on patient care. Finally, we‚Äôll look at the broader implications for healthcare AI automation and how other organizations can implement similar solutions using Amazon Bedrock. 
Choosing an accurate, scalable, and cost-effective transcription model for contact center automation 
Switchboard, MD needed a transcription solution that delivered high accuracy at a sustainable cost. In clinical settings, transcription accuracy is critical because errors can compromise EMR record matching, affect recommended treatment plans, and disrupt automated workflows. At the same time, scaling support for thousands of calls each week meant that inference costs couldn‚Äôt be ignored. 
Switchboard initially explored multiple paths, including evaluating open source models such as Open AI‚Äôs Whisper model hosted locally. But these options presented tradeoffs‚Äîeither in performance, cost, or integration complexity. 
After testing, the team determined that Amazon Nova Sonic provided the right combination of transcription quality and efficiency needed to support their healthcare use case. The model performed reliably across live caller audio, even in noisy or variable conditions.&nbsp;It delivered: 
 
 80‚Äì90% lower transcription costs 
 A word error rate of 4% on Switchboard‚Äôs proprietary evaluation dataset 
 Low-latency output that aligned with their need for real-time processing 
 
 
Equally important, Nova Sonic integrated smoothly into Switchboard‚Äôs existing architecture, minimizing engineering lift and accelerating deployment. With this foundation, the team reduced manual transcription steps and scaled accurate, real-time automation across thousands of patient interactions. 

 ‚ÄúOur vision is to restore the human connection in medicine by removing administrative barriers that get in the way of meaningful interaction. Nova Sonic gave us the speed and accuracy we needed to transcribe calls in real time‚Äîso our customers can focus on what truly matters: the patient conversation.&nbsp;By reducing our transcription costs by 80‚Äì90%, it‚Äôs also made real-time automation sustainable at scale.‚Äù ‚Äì Dr. Blake Anderson, Founder, CEO, and CTO, Switchboard, MD
 
Architecture and implementation 
Switchboard‚Äôs architecture uses Amazon Connect to capture live audio from both patients and representatives. Switchboard processes audio streams through Amazon Kinesis Video Streams , which handles the real-time media conversion before routing the data to containerized&nbsp;AWS Lambda&nbsp;functions. Switchboard‚Äôs Lambda functions establish bidirectional streaming connections with Amazon Nova Sonic using BedrockRuntimeClient‚Äôs InvokeModelWithBidirectionalStream&nbsp;API.&nbsp; This novel architecture creates separate transcription streams for each conversation participant, which Switchboard recombines to create the complete transcription record. The entire processing pipeline runs in a serverless environment, providing scalable operation designed to handle thousands of concurrent calls while using Nova Sonic‚Äôs real-time speech-to-text capabilities for immediate transcription processing. 
Nova Sonic integration: Real-time speech processing 
Harnessing Amazon Nova Sonic‚Äôs advanced audio streaming and processing, Switchboard developed and built the capability of separating and recombining speakers‚Äô streams and transcripts. This makes Amazon Nova Sonic particularly effective for Switchboard‚Äôs healthcare applications, where accurate transcription and speaker identification are crucial. 
Amazon Nova Sonic offers configurable settings that can be optimized for different healthcare use cases, with the flexibility to prioritize either transcription or speech generation based on specific needs. A key cost-optimization feature is the ability to adjust speech output tokens ‚Äì organizations can set lower token values when primarily focused on transcription, resulting in significant cost savings while maintaining high accuracy. This versatility and cost flexibility makes Amazon Nova Sonic a valuable tool for healthcare organizations like Switchboard looking to implement voice-enabled solutions. 
Why serverless: Strategic advantages for healthcare innovation 
Switchboard‚Äôs choice of a serverless architecture using Amazon Connect, Amazon Kinesis Video Streams, and containerized Lambda functions represents a strategic decision that maximizes operational efficiency while minimizing infrastructure overhead. The serverless approach eliminates the need to provision, manage, and monitor underlying infrastructure, so that Switchboard‚Äôs engineering team can focus on developing clinical automation features rather than server management. This architecture provides built-in fault tolerance and high availability for critical healthcare communications without requiring extensive configuration from Switchboard‚Äôs team. 
Switchboard‚Äôs event-driven architecture, shown in the following figure, enables the system to scale from handling dozens to thousands of concurrent calls, with AWS automatically managing capacity provisioning behind the scenes. The pay-as-you-go billing model helps Switchboard pay only for compute resources used during call processing, optimizing costs while eliminating the risk of over-provisioning servers that would sit idle during low-volume periods. 
 
Conclusion 
Switchboard, MD‚Äôs implementation of Amazon Nova Sonic demonstrates how the right transcription technology can transform healthcare operations. By achieving 80‚Äì90% cost reductions while maintaining clinical-grade accuracy, they‚Äôve created a sustainable foundation for scaling AI-powered patient interactions across the healthcare industry. 
By building on Amazon Bedrock, Switchboard now has the flexibility to expand automation across more use cases and provider networks. Their success exemplifies how healthcare innovators can combine accuracy, speed, and efficiency to transform how care teams connect with patients‚Äîone conversation at a time. 
Get started with Amazon Nova on the Amazon Bedrock console. Learn more about Amazon Nova models at the Amazon Nova product page. 
 
About the authors 
 Tanner Jones is a Technical Account Manager in AWS Enterprise Support, where he helps customers navigate and optimize their production applications on AWS. He specializes in helping customers develop applications that incorporate AI agents, with a particular focus on building safe multi-agent systems. 
Anuj Jauhari&nbsp;is a Sr. Product Marketing Manager at AWS, where he helps customers innovate and drive business impact with generative AI solutions built on Amazon Nova models. 
Jonathan Woods is a Solutions Architect at AWS based in Nashville currently working with SMB customers. He has a passion for communicating AWS technology to businesses in a relevant way making it easy for customers to innovate. Outside of work, he tries keeping up with his three kids.   
Nauman Zulfiqar&nbsp;is a senior account manager based in New York working with SMB clients. He loves building and maintaining strong customer relationships, understanding their business challenges and serving as the customer‚Äôs primary business advocate within AWS.
‚Ä¢ Build reliable AI systems with Automated Reasoning on Amazon Bedrock ‚Äì Part 1
  Enterprises in regulated industries often need mathematical certainty that every AI response complies with established policies and domain knowledge. Regulated industries can‚Äôt use traditional quality assurance methods that test only a statistical sample of AI outputs and make probabilistic assertions about compliance. When we launched Automated Reasoning checks in Amazon Bedrock Guardrails in preview at AWS re:Invent 2024, it offered a novel solution by applying formal verification techniques to systematically validate AI outputs against encoded business rules and domain knowledge. These techniques make the validation output transparent and explainable. 
Automated Reasoning checks are being used in workflows across industries. Financial institutions verify AI-generated investment advice meets regulatory requirements with mathematical certainty. Healthcare organizations make sure patient guidance aligns with clinical protocols. Pharmaceutical companies confirm marketing claims are supported by FDA-approved evidence. Utility companies validate emergency response protocols during disasters, while legal departments verify AI tools capture mandatory contract clauses. 
With the general availability of Automated Reasoning, we have increased document handling and added new features like scenario generation, which automatically creates examples that demonstrate your policy rules in action. With the enhanced test management system, domain experts can build, save, and automatically execute comprehensive test suites to maintain consistent policy enforcement across model and application versions. 
In the first part of this two-part technical deep dive, we‚Äôll explore the technical foundations of Automated Reasoning checks in Amazon Bedrock Guardrails and demonstrate how to implement this capability to establish mathematically rigorous guardrails for generative AI applications. 
In this post, you will learn how to: 
 
 Understand the formal verification techniques that enable mathematical validation of AI outputs 
 Create and refine an Automated Reasoning policy from natural language documents 
 Design and implement effective test cases to validate AI responses against business rules 
 Apply policy refinement through annotations to improve policy accuracy 
 Integrate Automated Reasoning checks into your AI application workflow using Bedrock Guardrails, following AWS best practices to maintain high confidence in generated content 
 
By following this implementation guide, you can systematically help prevent factual inaccuracies and policy violations before they reach end users, a critical capability for enterprises in regulated industries that require high assurance and mathematical certainty in their AI systems. 
Core capabilities of Automated Reasoning checks 
In this section, we explore the capabilities of Automated Reasoning checks, including the console experience for policy development, document processing architecture, logical validation mechanisms, test management framework, and integration patterns. Understanding these core components will provide the foundation for implementing effective verification systems for your generative AI applications. 
Console experience 
The Amazon Bedrock Automated Reasoning checks console organizes policy development into logical sections, guiding you through the creation, refinement, and testing process. The interface includes clear rule identification with unique IDs and direct use of variable names within the rules, making complex policy structures understandable and manageable. 
Document processing capacity 
Document processing supports up to 120K tokens (approximately 100 pages), so you can encode substantial knowledge bases and complex policy documents into your Automated Reasoning policies. Organizations can incorporate comprehensive policy manuals, detailed procedural documentation, and extensive regulatory guidelines. With this capacity you can work with complete documents within a single policy. 
Validation capabilities 
The validation API includes ambiguity detection that identifies statements requiring clarification, counterexamples for invalid findings that demonstrate why validation failed, and satisfiable findings with both valid and invalid examples to help understand boundary conditions. These features provide context around validation results, to help you understand why specific responses were flagged and how they can be improved. The system can also express its confidence in translations between natural language and logical structures to set appropriate thresholds for specific use cases. 
Iterative feedback and refinement process 
Automated Reasoning checks provide detailed, auditable findings that explain why a response failed validation, to support an iterative refinement process instead of simply blocking non-compliant content. This information can be fed back to your foundation model, allowing it to adjust responses based on specific feedback until they comply with policy rules. This approach is particularly valuable in regulated industries where factual accuracy and compliance must be mathematically verified rather than estimated. 
 
Finding types using a policy example 
Consider the example of a policy for determining days off. When implementing Automated Reasoning checks, a policy consists of both a schema of variables (defining concepts like employee type, years of service, and available leave days) and a set of logical rules that establish relationships between these variables (such as eligibility conditions for different types of time off). During validation, the system uses this schema and rule structure to evaluate whether foundation model responses comply with your defined policy constraints. 
We want to validate the following input that a user asked the foundation model (FM) powered application and the generated output. 
 
 Input:
"Is Thursday a day off if it's a public holiday?"

Output:
"Yes, Thursday would be a day off if it's a public holiday, since all public holidays are considered days off regardless of the day of the week." 
 
Premises are statements from which a conclusion is drawn and the claim is an assertion of the truth. In this example, the premises inferred are day is equal to ‚ÄúThursday‚Äù and is_public_holiday is true, and the claim is made that is_day_off is true. 
This reasoning follows the automated reasoning policy: 
 
 Days Off Policy:
-&nbsp;All weekend days (Saturday and Sunday) are days off
-&nbsp;All public holidays are days off
- A day is considered a day off if it is either a weekend day or a public holiday
 
 
With general availability, Automated Reasoning checks now produces seven distinct finding types that offer precise insights into the validation process of a FM generated response: 
 
VALID: Confirms Input&nbsp;and&nbsp;Output&nbsp;fully aligns with policy rules, providing confidence that the information in the generated response is correct according to your defined policies. The claims are inferred from the premises and validated by the AR policy to be true, and there are no alternative answers that contradict these claims. 
 
 Input:
Today is Sunday, do I have the day off? 

Output:
Yes, Sunday is a weekend day, you have the day off.

Premises:
day: Sunday
is_weekend: true

Claim:
is_day_off: true

Explanation:
Given the assigned variables and policy rules that weekends are days off, the only possible answer is that it is a day off. 
 
SATISFIABLE: Recognizes that Input&nbsp;and Output could be true or false depending on specific assumptions. These findings help you understand boundary conditions where a response is valid only under certain conditions, so that you can decide whether those assumptions are reasonable in your context. If the required assumptions are false, then an alternative claim consistent with the premises may exist. 
 
 Input:
Today is Tuesday, do I have the day off?

Output:
Yes
Premises:
day: Tuesday

Claim:
is_day_off: true

Explanation: 
If we assume is_public_holiday=true, this is correct, but if we assume is_public_holiday=false, the answer would be incorrect since Tuesday is not a weekend. 
 
INVALID: Identifies Input and Output have policy inaccuracies or factual errors, enhanced with counter-examples that explicitly demonstrate why the validation failed. The claims are not implied by the premises and AR policy, and there exist different claims that would be consistent with the premises and AR policy. 
 
 Input:
Today is Sunday, do I have the day off?

Output:
No you do&nbsp;not have the day off.

Premises:
day: Sunday

Claim:
is_day_off: false

Explanation:
This is invalid because the policy states weekends are days off. The correct claim would be is_day_off = true since Sunday is a weekend day 
 
IMPOSSIBLE: Indicates when no valid&nbsp;Claims&nbsp;can be generated because the premises conflict with the AR policy or the policy contains internal contradictions. This finding occurs when the constraints defined in the policy create a logical impossibility. 
 
 Input: 
Today is Sunday and not a weekend day, do I have the day off?

Output:
Yes

Premises:
day: Sunday
is_weekend: false

Claim:
is_day_off: true

Explanation: 
Sunday is always a weekend day, so the premises contain a contradiction. No valid claim can exist given these contradictory premises. 
 
NO_TRANSLATIONS: Occurs when the Input and Output contains no information that can be translated into relevant data for the AR policy evaluation. This typically happens when the text is entirely unrelated to the policy domain or contains no actionable information. 
 
 Input: 
How many legs does the average cat have?

Output:
Less than 4

Explanation:
The AR policy is about days off, so there is no relevant translation for content about cats. The input has no connection to the policy domain. 
 
TRANSLATION_AMBIGUOUS: Identifies when ambiguity in the Input&nbsp;and Output prevents definitive translation into logical structures. This finding suggests that additional context or follow-up questions may be needed to proceed with validation. 
 
 Input: 
I won! Today is Winsday, do I get the day off?

Output:
Yes, you get the day off!

Explanation: 
"Winsday" is not a recognized day in the AR policy, creating ambiguity. Automated reasoning cannot proceed without clarification of what day is being referenced. 
 
TOO_COMPLEX: Signals that the Input&nbsp;and Output contains too much information to process within latency limits. This finding occurs with extremely large or complex inputs that exceed the system‚Äôs current processing capabilities. 
 
 Input:
Can you tell me which days are off for all 50 states plus territories for the next 3 years, accounting for federal, state, and local holidays? Include exceptions for floating holidays and special observances.

Output:
I have analyzed the holiday calendars for all 50 states. In Alabama, days off include...

Explanation: 
This use case contains too many variables and conditions for AR checks to process while maintaining accuracy and response time requirements. 
 
Scenario generation 
You can now generate scenarios directly from your policy, which creates test samples that conform to your policy rules, helps identify edge cases, and supports verification of your policy‚Äôs business logic implementation. With this capability policy authors can see concrete examples of how their rules work in practice before deployment, reducing the need for extensive manual testing. The scenario generation also highlights potential conflicts or gaps in policy coverage that might not be apparent from examining individual rules. 
Test management system 
A new test management system allows you to save and annotate policy tests, build test libraries for consistent validation, execute tests automatically to verify policy changes, and maintain quality assurance across policy versions. This system includes versioning capabilities that track test results across policy iterations, making it easier to identify when changes might have unintended consequences. You can now also export test results for integration into existing quality assurance workflows and documentation processes. 
Expanded options with direct guardrail integration 
Automated Reasoning checks now integrates with Amazon Bedrock APIs, enabling validation of AI generated responses against established policies throughout complex interactions. This integration extends to both the Converse and RetrieveAndGenerate actions, allowing policy enforcement across different interaction modalities. Organizations can configure validation confidence thresholds appropriate to their domain requirements, with options for stricter enforcement in regulated industries or more flexible application in exploratory contexts. 
Solution ‚Äì AI-powered hospital readmission risk assessment system 
Now that we have explained the capabilities of Automated Reasoning checks, let‚Äôs work through a solution by considering the use case of an AI-powered hospital readmission risk assessment system. This AI system automates hospital readmission risk assessment by analyzing patient data from electronic health records to classify patients into risk categories (Low, Intermediate, High) and recommends personalized intervention plans based on CDC-style guidelines. The objective of this AI system is to reduce the 30-day hospital readmission rates by supporting early identification of high-risk patients and implementing targeted interventions. This application is an ideal candidate for Automated Reasoning checks because the healthcare provider prioritizes verifiable accuracy and explainable recommendations that can be mathematically proven to comply with medical guidelines, supporting both clinical decision-making and satisfying the strict auditability requirements common in healthcare settings. 
Note: The referenced policy document is an example created for demonstration purposes only and should not be used as an actual medical guideline or for clinical decision-making. 
Prerequisites 
To use Automated Reasoning checks in Amazon Bedrock, verify you have met the following prerequisites: 
 
 An active AWS account 
 Confirmation of AWS Regions where Automated Reasoning checks is available 
 Appropriate IAM permissions to create, test, and invoke Automated Reasoning policies (Note: The IAM policy should be fine-grained and limited to necessary resources using proper ARN patterns for production usage): 
 
 
  {  
  "Sid": "OperateAutomatedReasoningChecks",  
  "Effect": "Allow",  
  "Action": [  
    "bedrock:CancelAutomatedReasoningPolicyBuildWorkflow",  
    "bedrock:CreateAutomatedReasoningPolicy",
    "bedrock:CreateAutomatedReasoningPolicyTestCase",  
    "bedrock:CreateAutomatedReasoningPolicyVersion",
    "bedrock:CreateGuardrail",
    "bedrock:DeleteAutomatedReasoningPolicy",  
    "bedrock:DeleteAutomatedReasoningPolicyBuildWorkflow",  
    "bedrock:DeleteAutomatedReasoningPolicyTestCase",
    "bedrock:ExportAutomatedReasoningPolicyVersion",  
    "bedrock:GetAutomatedReasoningPolicy",  
    "bedrock:GetAutomatedReasoningPolicyAnnotations",  
    "bedrock:GetAutomatedReasoningPolicyBuildWorkflow",  
    "bedrock:GetAutomatedReasoningPolicyBuildWorkflowResultAssets",  
    "bedrock:GetAutomatedReasoningPolicyNextScenario",  
    "bedrock:GetAutomatedReasoningPolicyTestCase",  
    "bedrock:GetAutomatedReasoningPolicyTestResult",
    "bedrock:InvokeAutomatedReasoningPolicy",  
    "bedrock:ListAutomatedReasoningPolicies",  
    "bedrock:ListAutomatedReasoningPolicyBuildWorkflows",  
    "bedrock:ListAutomatedReasoningPolicyTestCases",  
    "bedrock:ListAutomatedReasoningPolicyTestResults",
    "bedrock:StartAutomatedReasoningPolicyBuildWorkflow",  
    "bedrock:StartAutomatedReasoningPolicyTestWorkflow",
    "bedrock:UpdateAutomatedReasoningPolicy",  
    "bedrock:UpdateAutomatedReasoningPolicyAnnotations",  
    "bedrock:UpdateAutomatedReasoningPolicyTestCase",
    "bedrock:UpdateGuardrail"
  ],  
  "Resource": [
  "arn:aws:bedrock:\${aws:region}:\${aws:accountId}:automated-reasoning-policy/*",
  "arn:aws:bedrock:\${aws:region}:\${aws:accountId}:guardrail/*"
]
} 
 
 
 Key service limits: Be aware of the service limits when implementing Automated Reasoning checks. 
 With Automated Reasoning checks, you pay based on the amount of text processed. For more information, see Amazon Bedrock pricing. For more information, see Amazon Bedrock pricing. 
 
Use case and policy dataset overview 
The full policy document used in this example can be accessed from the Automated Reasoning GitHub repository.&nbsp; To validate the results from Automated Reasoning checks, being familiar with the policy is helpful. Moreover, refining the policy that is created by Automated Reasoning is key in achieving a soundness of over 99%. 
Let‚Äôs review the main details of the sample medical policy that we are using in this post. As we start validating responses, it is helpful to verify it against the source document. 
 
 Risk assessment and stratification:&nbsp;Healthcare facilities must implement a standardized risk scoring system based on demographic, clinical, utilization, laboratory, and social factors, with patients classified into Low (0-3 points), Intermediate (4-7 points), or High Risk (8+ points) categories. 
 Mandatory interventions:&nbsp;Each risk level requires specific interventions, with higher risk levels incorporating lower-level interventions plus additional measures, while certain conditions trigger automatic High Risk classification regardless of score. 
 Quality metrics and compliance:&nbsp;Facilities must achieve specific completion rates including 95%+ risk assessment within 24 hours of admission and 100% completion before discharge, with High Risk patients requiring documented discharge plans. 
 Clinical oversight:&nbsp;While the scoring system is standardized, attending physicians maintain override authority with proper documentation and approval from the discharge planning coordinator. 
 
Create and test an Automated Reasoning checks‚Äô policy&nbsp;using the Amazon Bedrock console 
The first step is to encode your knowledge‚Äîin this case, the sample medical policy‚Äîinto an Automated Reasoning policy. Complete the following steps to create an Automated Reasoning policy: 
 
 On the Amazon Bedrock console, choose Automated Reasoning under Build in the navigation pane. 
 Choose Create policy.  
 
 
 Provide a policy name and policy description.  
 
 
 Add source content from which Automated Reasoning will generate your policy. You can either upload document (pdf, txt) or enter text as the ingest method.   
 Include a description of the intent of the Automated Reasoning policy you‚Äôre creating. The intent is optional but provides valuable information to the Large Language Models that are translating the natural language based document into a set of rules that can be used for mathematical verification. For the sample policy, you can use the following intent: This logical policy validates claims about the clinical practice guideline providing evidence-based recommendations for healthcare facilities to systematically assess and mitigate hospital readmission risk through a standardized risk scoring system, risk-stratified interventions, and quality assurance measures, with the goal of reducing 30-day readmissions by 15-23% across participating healthcare systems.

Following is an example patient profile and the corresponding classification.

&lt;Patient Profile&gt;Age: 82 years

Length of stay: 10 days

Has heart failure

One admission within last 30 days

Lives alone without caregiver

&lt;Classification&gt; High Risk  
 Once the policy has been created, we can inspect the definitions to see which rules, variables and types have been created from the natural language document to represent the knowledge into logic. 
 
 
 You may see differences in the number of rules, variables, and types generated compared to what is shown in this example. This is due to the non-deterministic processing of the supplied document. To address this, the recommended guidance is to perform a human-in-the-loop review of the generated information in the policy before using it with other systems. 
Exploring the Automated Reasoning checks‚Äô definition 
A Variable in automated reasoning for policy documents is a named container that holds a specific type of information (like Integer, Real Number, or Boolean) and represents a distinct concept or measurement from the policy. Variables act as building blocks for rules and can be used to track, measure, and evaluate policy requirements. From the image below, we can see examples like admissionsWithin30Days&nbsp;(an Integer variable tracking previous hospital admissions), ageRiskPoints&nbsp;(an Integer variable storing age-based risk scores), and conductingMonthlyHighRiskReview (a Boolean variable indicating whether monthly reviews are being performed). Each variable has a clear description of its purpose and the specific policy concept it represents, making it possible to use these variables within rules to enforce policy requirements and measure compliance. Issues also highlight that some variables are unused. It is particularly important to verify which concepts these variables represent and to identify if rules are missing. 
 
In the Definitions, we see ‚ÄòRules‚Äô, ‚ÄòVariables‚Äô and ‚ÄòTypes‚Äô. A rule is an unambiguous logical statement that Automated Reasoning extracts from your source document. Consider this simple rule that has been created:&nbsp;followupAppointmentsScheduledRate is at least 90.0&nbsp; ‚Äì This rule has been created from the Section III A Process Measures, which states that healthcare facilities should monitor various process indications, requiring that follow up appointments scheduled prior to discharge should be 90% or higher. 
Let‚Äôs look at a more complex rule: 
 
 comorbidityRiskPoints is equal to(ite&nbsp;hasDiabetesMellitus&nbsp;1 0) + (ite hasHeartFailure 2 0) + (ite&nbsp;hasCOPD&nbsp;1 0) + (ite hasChronicKidneyDisease 1 0) 
 
 
 Where ‚Äúite‚Äù is ‚ÄúIf then else‚Äù 
 
This rule calculates a patient‚Äôs risk points based on their existing medical conditions (comorbidities) as specified in the policy document. When evaluating a patient, the system checks for four specific conditions: diabetes mellitus of any type (worth 1 point), heart failure of any classification (worth 2 points), chronic obstructive pulmonary disease (worth 1 point), and chronic kidney disease stages 3-5 (worth 1 point). The rule adds these points together by using boolean logic ‚Äì meaning it multiplies each condition (represented as true=1 or false=0) by its assigned point value, then sums all values to generate a total comorbidity risk score. For instance, if a patient has both heart failure and diabetes, they would receive 3 total points (2 points for heart failure plus 1 point for diabetes). This comorbidity score then becomes part of the larger risk assessment framework used to determine the patient‚Äôs overall readmission risk category. 
 
The Definitions also include custom variable types.&nbsp;Custom variable types, also known as enumerations (ENUMs), are specialized data structures that define a fixed set of allowable values for specific policy concepts.&nbsp;These custom types maintain consistency and accuracy in data collection and rule enforcement by limiting values to predefined options that align with the policy requirements. In the sample policy, we can see that four custom variable types have been identified: 
 
 AdmissionType: This defines the possible types of hospital admissions (MEDICAL, SURGICAL, MIXED_MEDICAL_SURGICAL, PSYCHIATRIC) that determine whether a patient is eligible for the readmission risk assessment protocol. 
 HealthcareFacilityType: This specifies the types of healthcare facilities (ACUTE_CARE_HOSPITAL_25PLUS, CRITICAL_ACCESS_HOSPITAL) where the readmission risk assessment protocol may be implemented. 
 LivingSituation: This categorizes a patient‚Äôs living arrangement (LIVES_ALONE_NO_CAREGIVER, LIVES_ALONE_WITH_CAREGIVER) which is a critical factor in determining social support and risk levels. 
 RiskCategory: This defines the three possible risk stratification levels (LOW_RISK, INTERMEDIATE_RISK, HIGH_RISK) that can be assigned to a patient based on their total risk score. 
 
 
An important step in improving soundness (accuracy of Automated Reasoning checks when it says VALID), is the policy refinement step of making sure that the rules, variable, and types that are captured best represent the source of truth. In order to do this, we will head over to the test suite and explore how to add tests, generate tests and use the results from the tests to apply annotations that will update the rules. 
Testing the Automated Reasoning policy and policy refinement 
The test suite in Automated Reasoning provides test capabilities for two purposes: First, we want to run different scenarios and test the various rules and variables in the Automated Reasoning policy and refine them so that they accurately represent the ground truth. This policy refinement step is important to improving the soundness of Automated Reasoning checks. Second, we want metrics to understand how well the Automated Reasoning checks performs for the defined policy and the use case. To do so, we can open the Tests tab on Automated Reasoning console. 
 
Test samples can be added manually by using the Add button. To scale up the testing, we can generate tests from the policy rules. This testing approach helps verify both the semantic correctness of your policy (making sure rules accurately represent intended policy constraints) and the natural language translation capabilities (confirming the system can correctly interpret the language your users will use when interacting with your application). In the image below, we can see a test sample generated and before adding it to the test suite, the SME should indicate if this test sample is possible (thumbs up) or not possible (thumbs up). The test sample can then be saved to the test suite. 
 
 
Once the test sample is created, it possible to run this test sample alone, or all the test samples in the test suite by choosing on Validate all tests. Upon executing, we see that this test passed successfully. 
 
You can manually create tests by providing an input (optional) and output. These are translated into logical representations before validation occurs. 
How translation works: 
Translation converts your natural language tests into logical representations that can be mathematically verified against your policy rules: 
 
 Automated Reasoning Checks uses multiple LLMs to translate your input/output into logical findings 
 Each translation receives a confidence vote indicating translation quality 
 You can set a confidence threshold to control which findings are validated and returned 
 
Confidence threshold behavior: 
The confidence threshold controls which translations are considered reliable enough for validation, balancing strictness with coverage: 
 
 Higher threshold: Greater certainty in translation accuracy but also higher chance of no findings being validated. 
 Lower threshold: &nbsp;Greater chance of getting validated findings returned, but potentially less certain translations 
 Threshold = 0: All findings are validated and returned regardless of confidence 
 
Ambiguous results: 
When no finding meets your confidence threshold, Automated Reasoning Checks returns ‚ÄúTranslation Ambiguous,‚Äù indicating uncertainty in the content‚Äôs logical interpretation.The test case we will create and validate is: 
 
 Input:
Patient A
Age: 82
Length of stay: 16 days
Diabetes Mellitus: Yes
Heart Failure: Yes
Chronic Kidney Disease: Yes
Hemoglobin: 9.2 g/dL
eGFR: 28 ml/min/1.73m^2
Sodium: 146 mEq/L
Living Situation: Lives alone without caregiver
Has established PCP: No
Insurance Status: Medicaid
Admissions within 30 days: 1

Output:
Final&nbsp;Classification:&nbsp;INTERMEDIATE RISK 
 
 
We see that this test passed upon running it, the result of ‚ÄòINVALID‚Äô matches our expected results. Additionally Automated Reasoning checks also shows that 12 rules were contradicting the premises and claims, which lead to the output of the test sample being ‚ÄòINVALID‚Äô 
 
Let‚Äôs examine some of the visible contradicting rules: 
 
 Age risk: Patient is 82 years old 
   
   Rule triggers: ‚Äúif patientAge is at least 80, then ageRiskPoints is equal to 3‚Äù 
    
 Length of stay risk: Patient stayed 16 days 
   
   Rule triggers: ‚Äúif lengthOfStay is greater than 14, then lengthOfStayRiskPoints is equal to 3‚Äù 
    
 Comorbidity risk: Patient has multiple conditions 
   
   Rule calculates: ‚ÄúcomorbidityRiskPoints = (hasDiabetesMellitus √ó 1) + (hasHeartFailure √ó 2) + (hasCOPD √ó 1) + (hasChronicKidneyDisease √ó 1)‚Äù 
    
 Utilization risk: Patient has 1 admission within 30 days 
   
   Rule triggers: ‚Äúif admissionsWithin30Days is at least 1, then utilizationRiskPoints is at least 3‚Äù 
    
 Laboratory risk: Patient‚Äôs eGFR is 28 
   
   Rule triggers: ‚Äúif eGFR is less than 30.0, then laboratoryRiskPoints is at least 2‚Äù 
    
 
These rules are likely producing conflicting risk scores, making it impossible for the system to determine a valid final risk category. These contradictions show us which rules where used to determine that the input text of the test is INVALID. 
 
Let‚Äôs add another test to the test suite, as shown in the screenshot below: 
 
 Input:
Patient&nbsp;profile
Age: 83
Length of stay: 16 days
Diabetes Mellitus: Yes
Heart Failure: Yes
Chronic Kidney Disease: Yes
Hemoglobin: 9.2 g/dL
eGFR: 28 ml/min/1.73m^2
Sodium: 146 mEq/L
Living Situation: Lives alone without caregiver
Has established PCP: No
Insurance Status: Medicaid
Admissions within 30 days: 1
Admissions within 90 days:&nbsp;2

Output:
Final&nbsp;Classification:&nbsp;HIGH RISK 
 
 
 
When this test is executed, we see that each of the patient details are extracted as premises, to validate the claim that the risk of readmission if high. We see that 8 rules have been applied to verify this claim. The key rules and their validations include: 
 
 Age risk: Validates that patient age ‚â• 80 contributes 3 risk points 
 Length of stay risk: Confirms that stay &gt;14 days adds 3 risk points 
 Comorbidity risk: Calculated based on presence of&nbsp;Diabetes Mellitus, Heart Failure, Chronic Kidney Disease 
 Utilization risk: Evaluates admissions history 
 Laboratory risk: Evaluates risk based on&nbsp;Hemoglobin level of 9.2 and eGFR of 28 
 
Each premise was evaluated as true, with multiple risk factors present (advanced age, extended stay, multiple comorbidities, concerning lab values, living alone without caregiver, and lack of PCP), supporting the overall Valid classification of this HIGH RISK assessment. 
 
Moreover, the Automated Reasoning engine performed an extensive validation of this test sample using 93 different assignments to increase the soundness that the HIGH RISK classification is correct.&nbsp;Various related rules from the Automated Reasoning policy are used to validate the samples against 93 different scenarios and variable combinations. In this manner, Automated Reasoning checks confirms that there is no possible situation under which this patient‚Äôs HIGH RISK classification could be invalid. This thorough verification process affirms the reliability of the risk assessment for this elderly patient with multiple chronic conditions and complex care needs.In the event of a test sample failure, the 93 assignments would serve as an important diagnostic tool, pinpointing specific variables and their interactions that conflict with the expected outcome, thereby enabling subject matter experts (SMEs) to analyze the relevant rules and their relationships to determine if adjustments are needed in either the clinical logic or risk assessment criteria. In the next section, we will look at policy refinement and how SMEs can apply annotations to improve and correct the rules, variables, and custom types of the Automated Reasoning policy. 
Policy refinement through annotations 
Annotations provide a powerful improvement mechanism for Automated Reasoning policies when tests fail to produce expected results. Through annotations, SMEs can systematically refine policies by: 
 
 Correcting problematic rules by modifying their logic or conditions 
 Adding missing variables essential to the policy definition 
 Updating variable descriptions for greater precision and clarity 
 Resolving translation issues where original policy language was ambiguous 
 Deleting redundant or conflicting elements from the policy 
 
This iterative process of testing, annotating, and updating creates increasingly robust policies that accurately encode domain expertise. As shown in the figure below, annotations can be applied to modify various policy elements, after which the refined policy can be exported as a JSON file for deployment. 
 
In the following figure, we can see how annotations are being applied, and rules are deleted in the policy. Similarly, additions and updates can be made to rules, variables, or the custom types. 
 
 
When the subject matter expert has validated the Automated Reasoning policy through testing, applying annotations, and validating the rules, it is possible to export the policy as a JSON file. 
 
Using Automated Reasoning checks at inference 
To use the Automated Reasoning checks with the created policy, we can now navigate to Amazon Bedrock&nbsp;Guardrails,&nbsp;and create a new guardrail by entering the name, description, and the messaging that will be displayed when the guardrail intervenes and blocks a prompt or a output from the AI system. 
 
Now, we can attach Automated Reasoning check by using the toggle to Enable Automated Reasoning policy. We can set a confidence threshold, which determines how strictly the policy should be enforced. This threshold ranges from 0.00 to 1.00, with 1.00 being the default and most stringent setting. Each guardrail can accommodate up to two separate automated reasoning policies for enhanced validation flexibility. In the following figure, we are attaching the draft version of the medical policy related to patient hospital readmission risk assessment. 
 
Now we can create the guardrail. Once you‚Äôve established the guardrail and linked your automated reasoning policies, verify your setup by reviewing the guardrail details page to confirm all policies are properly attached. 
 
Clean up 
When you‚Äôre finished with your implementation, clean up your resources by deleting the guardrail and automated reasoning policies you created. Before deleting a guardrail, be sure to disassociate it from all resources or applications that use it. 
Conclusion 
In this first part of our blog, we explored how Automated Reasoning checks in Amazon Bedrock Guardrails help maintain the reliability and accuracy of generative AI applications through mathematical verification. You can use increased document processing capacity, advanced validation mechanisms, and comprehensive test management features to validate AI outputs against business rules and domain knowledge. This approach addresses key challenges facing enterprises deploying generative AI systems, particularly in regulated industries where factual accuracy and policy compliance are essential. Our hospital readmission risk assessment demonstration shows how this technology supports the validation of complex decision-making processes, helping transform generative AI into systems suitable for critical business environments. You can use these capabilities through both the AWS Management Console and APIs to establish quality control processes for your AI applications. 
To learn more, and build secure and safe AI applications, see the technical documentation and the GitHub code samples, or access to the Amazon Bedrock console. 
 
About the authors 
Adewale Akinfaderin&nbsp;is a Sr. Data Scientist‚ÄìGenerative AI, Amazon Bedrock, where he contributes to cutting edge innovations in foundational models and generative AI applications at AWS. His expertise is in reproducible and end-to-end AI/ML methods, practical implementations, and helping global customers formulate and develop scalable solutions to interdisciplinary problems. He has two graduate degrees in physics and a doctorate in engineering. 
Bharathi Srinivasan is a Generative AI Data Scientist at the AWS Worldwide Specialist Organization. She works on developing solutions for Responsible AI, focusing on algorithmic fairness, veracity of large language models, and explainability. Bharathi guides internal teams and AWS customers on their responsible AI journey. She has presented her work at various learning conferences. 
Nafi Diallo &nbsp;is a Senior Automated Reasoning Architect at Amazon Web Services, where she advances innovations in AI safety and Automated Reasoning systems for generative AI applications. Her expertise is in formal verification methods, AI guardrails implementation, and helping global customers build trustworthy and compliant AI solutions at scale. She holds a PhD in Computer Science with research in automated program repair and formal verification, and an MS in Financial Mathematics from WPI.
‚Ä¢ Custom Intelligence: Building AI that matches your business DNA
  In 2024, we launched the Custom Model Program within the AWS Generative AI Innovation Center to provide comprehensive support throughout every stage of model customization and optimization. Over the past two years, this program has delivered exceptional results by partnering with global enterprises and startups across diverse industries‚Äîincluding legal, financial services, healthcare and life sciences, software development, telecommunications, and manufacturing. These partnerships have produced tailored AI solutions that capture each organization‚Äôs unique data expertise, brand voice, and specialized business requirements. They operate more efficiently than off-the-shelf alternatives, delivering increased alignment and relevance with significant cost savings on inference operations. 
 
As organizations mature past proof-of-concept projects and basic chatbots, we‚Äôre seeing increased adoption of advanced personalization and optimization strategies beyond prompt engineering and retrieval augmented generation (RAG). Our approach encompasses creating specialized models for specific tasks and brand alignment, distilling larger models into smaller, faster, more cost-effective versions, implementing deeper adaptations through mid-training modifications, and optimizing hardware and accelerators to increase throughput while reducing costs. 
Strategic upfront investment pays dividends throughout a model‚Äôs production lifecycle, as demonstrated by Cosine AI‚Äôs results. Cosine AI is the developer of an AI developer platform and software engineering agent designed to integrate seamlessly into their users‚Äô workflows. They worked with the Innovation Center to fine-tune Nova Pro, an Amazon Nova foundation model, using Amazon SageMaker AI for their AI engineering assistant, Genie, achieving remarkable results including a 5x increase in A/B testing capability, a 10x faster developer iterations, and a 4x overall project speed improvement. The return on investment becomes even more compelling as companies transition toward agentic systems and workflows, where latency task specificity, performance, and depth are critical and compound across complex processes. 
In this post, we‚Äôll share key learnings and actionable strategies for leaders looking to use customization for maximum ROI while avoiding common implementation pitfalls. 
Five tips for maximizing value from training and tuning generative AI models 
The Innovation Center recommends the following top tips to maximize value from training and tuning AI models: 
1. Don‚Äôt start from a technical approach; work backwards from business goals 
This may seem obvious, but after working with over a thousand customers, we‚Äôve found that working backwards from business goals is a critical factor in why projects supported by the Innovation Center achieve a 65% production success rate, with some launching within 45 days. We apply this same strategy to every customization project by first identifying and prioritizing tangible business outcomes that a technical solution will drive. Success must be measurable and deliver real business value, helping avoid flashy experiments that end up sitting on a shelf instead of producing results. In the Custom Model Program, many customers initially approach us seeking specific technical solutions‚Äîsuch as jumping directly into model pre-training or continued pre-training‚Äîwithout having defined downstream use cases, data strategies, or evaluation plans. By starting with clear business objectives first, we make sure that technical decisions align with strategic goals and create meaningful impact for the organization. 
2. Pick the right customization approach 
Start with a baseline customization approach and exhaust simpler approaches before diving into deep model customization. The first question we ask customers seeking custom model development is ‚ÄúWhat have you already tried?‚Äù We recommend establishing this baseline with prompt engineering and RAG before exploring more complex techniques. While there‚Äôs a spectrum of model optimization approaches that can achieve higher performance, sometimes the simplest solution is the most effective. Once you establish this baseline, identify remaining gaps and opportunities to determine whether advancing to the next level makes strategic sense. 
 
Customization options range from lightweight approaches like supervised fine-tuning to ground-up model development. We typically advise starting with lighter-weight solutions that require smaller amounts of data and compute, then progressing to more complex techniques only when specific use cases or remaining gaps justify the investment: 
 
 Supervised fine-tuning sharpens the model‚Äôs focus for specific use cases, for example delivering consistent customer service responses or adapting to your organization‚Äôs preferred phrasing, structure and reasoning patterns. Volkswagen, one of the world‚Äôs largest automobile manufacturers, achieved an ‚Äúimprovement in AI-powered brand consistency checks, increasing accuracy in identifying on-brand images from 55% to 70%,‚Äù notes Dr. Philip Trempler, Technical Lead AI &amp; Cloud Engineering at Volkswagen Group Services. 
 Model efficiency and deployment tuning supports organizations like Robin AI, a leader in AI-powered legal contract technology, to create tailored models that speed up human verification. Organizations can also use techniques like quantization, pruning, and system optimizations to improve model performance and reduce infrastructure costs. 
 Reinforcement learning uses reward functions or preference data to align models to preferred behavior. This approach is often combined with supervised fine-tuning so organizations like Cosine AI can refine their models‚Äô decision making to match organizational preferences. 
 Continued pre-training allow organizations like Athena RC, a leading research center in Greece, to build Greek-first foundation models that expand language capabilities beyond English. By continually pre-training large language models on extensive Greek data, Athena RC strengthens the models‚Äô core understanding of the Greek language, culture, and usage ‚Äì not just their domain knowledge. Their Meltemi-7B and Llama-Krikri-8B models demonstrate how continued pre-training and instruction tuning can create open, high-quality Greek models for applications across research, education, industry, and society. 
 Domain-specific foundation model development enables organizations like TGS, a leading energy data, insights, and technology provider, to build custom AI models from scratch, ideal for those with highly specialized requirements and substantial volume of proprietary data. TGS helps energy companies make smarter exploration and development decisions by solving some of the industry‚Äôs toughest challenges in understanding what lies beneath the Earth‚Äôs surface. TGS has enhanced its Seismic Foundation Models (SFMs) to more reliably detect underground geological structures‚Äîsuch as faults and reservoirs‚Äîthat indicate potential oil and gas deposits. The benefit is clear: operators can reduce uncertainty, lower exploration costs, and make faster investment decisions. 
 
Data quality and accessibility will be a major consideration in determining feasibility of each customization technique. Clean, high-quality data is essential both for model improvement and measuring progress. While some Innovation Center customers achieve performance gains with relatively smaller volumes of fine-tuning training pairs on instruction-tuned foundation models, approaches like continued pre-training typically require large volumes of training tokens. This reinforces the importance of starting simple‚Äîas you test lighter-weight model tuning, you can collect and process larger data volumes in parallel for future phases. 
3. Define measures for what good looks like 
Success needs to be measurable, regardless of which technical approach you choose. It‚Äôs critical to establish clear methods for measuring both overall business outcomes and the technical solution‚Äôs performance. At the model or application level, teams typically optimize across some combination of relevance, latency, and cost. However, the metrics for your production application won‚Äôt be general leaderboard metrics‚Äîthey must be unique to what matters for your business. 
Customers developing content generation systems prioritize metrics like relevance, clarity, style, and tone. Consider this example from Volkswagen Group: ‚ÄúWe fine-tuned Nova Pro in SageMaker AI using our marketing experts‚Äô knowledge. This improved the model‚Äôs ability to identify on-brand images, achieving stronger alignment with Volkswagen‚Äôs brand guidelines,‚Äù according to Volkswagen‚Äôs Dr. Trempler. ‚ÄúWe are building on these results to enable Volkswagen Group‚Äôs vision to scale high-quality, brand-compliant content creation across our diverse automotive markets worldwide using generative AI.‚Äù Developing an automated evaluation process is critical for supporting iterative solution improvements. 
For qualitative use cases, it‚Äôs essential to align automated evaluations with human experts, particularly in specialized domains. A common solution involves using LLM as judge to review another model or system responses. For instance, when fine-tuning a generation model for a RAG application, you might use an LLM judge to compare the fine-tuned model response to your existing baseline. However, LLM judges come with intrinsic biases and may not align with your internal team‚Äôs human preferences or domain expertise. Robin AI partnered with the Innovation Center to develop Legal LLM-as-Judge, an AI model for legal contract review. Emulating expert methodology and creating ‚Äúa panel of trained judges‚Äù using fine-tuning techniques, they obtained smaller and faster models that maintain accuracy while reviewing documents ranging from NDAs to merger agreements. The solution achieved an 80% faster contract review process, enabling lawyers to focus on strategic work while AI handles detailed analysis. 
4. Consider hardware-level optimizations for training and inference 
If you‚Äôre using a managed service like Amazon Bedrock, you can take advantage of built-in optimizations out of the box. However, if you have a more bespoke solution or are operating at a lower level of the technology stack, there are several areas to consider for optimization and efficiency gains. For instance, TGS‚Äôs SFMs process massive 3D seismic images (essentially giant CAT scans of the Earth) that can cover tens of thousands of square kilometers. Each dataset is measured in petabytes, far beyond what traditional manual or even semi-automated interpretation methods can handle. By rebuilding their AI models on AWS‚Äôs high-performance GPU training infrastructure, TGS achieved near-linear scaling, meaning that adding more computing power results in almost proportional speed increases while maintaining &gt;90% GPU efficiency. As a result, TGS can now deliver actionable subsurface insights, such as identifying drilling targets or de-risking exploration zones, to customers in days instead of weeks. 
Over the life of a model, resource requirements are generally driven by inference requests, and any efficiency gains you can achieve will pay dividends during the production phase. One approach to reduce inference demands is model distillation to reduce the model size itself, but in some cases, there are additional gains to be had by digging deeper into the infrastructure. A recent example is Synthesia, the creator of a leading video generation platform where users can create professional videos without the need for mics, cameras, or actors. Synthesia is continually looking for ways to elevate their user experience, including by decreasing generation times for content. They worked with the Innovation Center to optimize the Variational Autoencoder decoder of their already efficient video generation pipeline. Strategic optimization of the model‚Äôs causal convolution layers unlocked powerful compiler performance gains, while asynchronous video chunk writing eliminated GPU idle time ‚Äì together delivering a dramatic reduction in end-to-end latency and a 29% increase in decoding throughput. 
5. One size doesn‚Äôt fit all 
The one size doesn‚Äôt fit all principle applies to both model size and family. Some models excel out of the box for specific tasks like code generation, tool usage, document processing, or summarization. With the rapid pace of innovation, the best foundation model for a given use case today likely won‚Äôt be the best tomorrow. Model size corresponds to the number of parameters and often determines its ability to complete a broad set of general tasks and capabilities. However, larger models require more compute resources at inference time and can be expensive to run at production scale. Many applications don‚Äôt need a model that excels at everything but rather one that performs exceptionally well at a more limited set of tasks or domain-specific capabilities. 
Even within a single application, optimization may require using multiple model providers depending on the specific task, complexity level, and latency requirements. In agentic applications, you might use a lightweight model for specialized agent tasks while requiring a more powerful generalist model to orchestrate and supervise those agents. Architecting your solution to be modular and resilient to changing model providers or versions helps you adapt quickly and capitalize on improvements. Services like Amazon Bedrock facilitate this approach by providing a unified API experience across a broad range of model families, including custom versions of many models. 
How the Innovation Center can help 
The Custom Model Program by the Innovation Center provides end-to-end expert support from model selection to customization, delivering performance improvements, and reducing time-to-market and value realization. Our process works backwards from customer business needs, strategy and goals, and starts with a use case and generative AI capability review by an experienced generative AI strategist. Specialist hands-on-keyboard applied scientists and engineers embed with customer teams to train and tune models for customers and integrate into applications without data ever needing to leave customer VPCs. This end-to-end support has helped organizations across industries successfully transform their AI vision into real business outcomes. 
 
Want to learn more? Contact your account manager to learn more about the Innovation Center or come see us at re:Invent at the AWS Village in the Expo. 
 
About the authors 
Sri Elaprolu serves as Director of the AWS Generative AI Innovation Center, where he leverages nearly three decades of technology leadership experience to drive artificial intelligence and machine learning innovation. In this role, he leads a global team of machine learning scientists and engineers who develop and deploy advanced generative and agentic AI solutions for enterprise and government organizations facing complex business challenges. Throughout his nearly 13-year tenure at AWS, Sri has held progressively senior positions, including leadership of ML science teams that partnered with high-profile organizations such as the NFL, Cerner, and NASA. These collaborations enabled AWS customers to harness AI and ML technologies for transformative business and operational outcomes. Prior to joining AWS, he spent 14 years at Northrop Grumman, where he successfully managed product development and software engineering teams. Sri holds a Master‚Äôs degree in Engineering Science and an MBA with a concentration in general management, providing him with both the technical depth and business acumen essential for his current leadership role. 
Hannah Marlowe leads the Model Customization and Optimization program for the AWS Generative AI Innovation Center. Her global team of strategists, specialized scientists, and engineers embeds directly with AWS customers, developing custom model solutions optimized for relevance, latency, and cost to drive business outcomes and capture ROI. Previous roles at Amazon include Senior Practice Manager for Advanced Computing and Principal Lead for Computer Vision and Remote Sensing. Dr. Marlowe completed her PhD in Physics at the University of Iowa in modeling and simulation of astronomical X-ray sources and instrumentation development for satellite-based payloads. 
 Rohit Thekkanal serves as ML Engineering Manager for Model Customization at the AWS Generative AI Innovation Center, where he leads the development of scalable generative AI applications focused on model optimization. With nearly a decade at Amazon, he has contributed to machine learning initiatives that significantly impact Amazon‚Äôs retail catalog. Rohit holds an MBA from The University of Chicago Booth School of Business and a Master‚Äôs degree from Carnegie Mellon University. 
Alexandra Fedorova leads Growth for the Model Customization and Optimization program for the AWS Generative AI Innovation Center. Previous roles at Amazon include Global GenAI Startups Practice Leader with the AWS Generative AI Innovation Center, and Global Leader, Startups Strategic Initiatives and Growth. Alexandra holds an MBA degree from Southern Methodist University, and BS in Economics and Petroleum Engineering from Gubkin Russian State University of Oil and Gas.

‚∏ª