‚úÖ Morning News Briefing ‚Äì September 06, 2025 10:40

üìÖ Date: 2025-09-06 10:40
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions:  8.5¬∞C
  Temperature: 8.5&deg;C Pressure / Tendency: 101.1 kPa rising Humidity: 96 % Dewpoint: 7.9&deg:C Wind: S 7 km/h Air Quality Health Index: n/a . Observed at: Pembroke 6:00 AM EDT Saturday 6 September 2025 Temperature: . Temperature:¬†8.5
‚Ä¢ Saturday: Chance of showers. High 18. POP 40%
  Mainly cloudy. 40 percent chance of showers this afternoon . High 18. UV index 6 or high. . Mainly sunny. Showery. High 18 or high . High 20.50C . Showers will be felt throughout the day . Forecast issued 5:00 AM EDT Saturday 6 September 2025. For more information on the National Weather Service, visit http://www.

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Amid debate about U.S. history, Harlem Hellfighters receive Congressional Gold Medal
  Harlem Hellfighters became legends for their service during World War I . They were honored this week with a Congressional Gold Medal . The Hellfighters were honored for their World War One service in the 1920s and '19th World War II . The Harlem Hellfighter is a World War War I veteran who served in the U.S. Army in the early years of the first World War .
‚Ä¢ HHS responds to report about autism and acetaminophen
  Many worry it will have claims unsupported by science . Health secretary Robert F. Kennedy Jr. has promised to come out this month . Report will look at the causes of autism, many fear it will be unproven science . Report is expected to be released by the end of the month, many worry it won't be science-based based on science . It will be released at the end
‚Ä¢ Concerned about federal vaccine policies, states are crafting their own
  As federal health agencies change their approach to vaccine policy leaving access for COVID shots uncertain, some states are taking things into their own hands . Some states are trying to take the issue of COVID vaccines to the brink of an uncertain future . The federal government is changing its approach to vaccination policy, leaving access to COVID vaccine shots uncertain for some states to take their own own steps .
‚Ä¢ India's honk-happy drivers are switching to even louder horns
  In India's bustling megacities, honking is a common form of communication among drivers . But in this case, one person's language is another person's noise pollution . In India, honkers are a common way of communicating with each other in the country's bustling cities . The video shows a group of people honking and honking in the midst of traffic congestion in India's
‚Ä¢ Where things stand with Trump's National Guard threats in Chicago and other cities
  Local officials and community members prepare for the possible arrival of National Guard troops under President Trump . The National Guard is currently stationed in Okinawa, Japan, on Okinawa, Okinawa, in Okinawa . Local officials say they are preparing for the arrival of the National Guard forces under the new president . The U.S. National Guard has been active in Okinawa since 1983 . The military has been involved in

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Reg hack attends job interview hosted by AI avatar, struggles to exit uncanny valley
  A startup called Job Bolt has created AI avatars that conduct job interviews . The Register couldn't help but give it a try and can report that it's an unnerving experience . If an employer asks you do to this, demand a trial run so you can learn the rules of this strange new world, it's unnerving to be asked to do so by the company . It's
‚Ä¢ OpenAI reorg at risk as Attorneys General push AI safety
  California, Delaware AGs blast ChatGPT shop over chatbot safeguards . Attorneys General of California and Delaware wrote to OpenAI's board of directors . They demanded that the AI company take steps to ensure its services are safe for children . The AGs wrote to the company's board demanding that its chatbot services were safe for kids . The AI company's chatbot chatbot is
‚Ä¢ US cuffs 475 at Hyundai‚ÄìLG battery plant ‚Äì feds tout largest single-site raid
  The Homeland Security Investigations (HSI) arm of US Immigration and Customs Enforcement says it executed its largest single-site raid to date, detaining 475 people at the Hyundai‚ÄìLG battery plant under construction in Georgia . South Korean government protests as workers left up s**t creek . The U.S. says it is the largest single site raid ever to detain people at a single-
‚Ä¢ Let us git rid of it, angry GitHub users say of forced Copilot features
  Unavoidable AI has developers looking for alternative code hosting options . Microsoft's Copilot, the company's AI service, is generating issues and pull requests in code repositories . The most popular community discussion in the past 12 months has been a request for a way to block Copilot from creating issues and pulling requests from code repositories in code repository . Copilot is a tool that Microsoft's AI
‚Ä¢ If Broadcom is helping OpenAI build AI chips, here's what they might look like
  OpenAI is allegedly developing a custom AI accelerator with the help of Broadcom in an apparent bid to curb its reliance on Nvidia and drive down the cost of its GPT family of models . Whatever happened to that Baltra thing Tan and crew were helping Apple cook up? Analysis: OpenAI 'developers' are working on a custom-built machine with Broadcom's Broadcom .

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Nature goes inside the world‚Äôs largest ‚Äòmosquito factory‚Äô ‚Äî here‚Äôs the buzz
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Feasibility and clinical utility of expanded genomic newborn screening in the Early Check program
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Longitudinal associations between 24-hour movement behaviors and physical fitness in preschoolers: a compositional isotemporal substitution analysis
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Association between atrial fibrillation and age-related macular degeneration: A nationwide cohort study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Inside a mosquito factory
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ The Download: longevity myths, and sewer-cleaning robots
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Putin says organ transplants could grant immortality. Not quite.



‚ÄîJessica Hamzelou



Earlier this week, my editor forwarded me a video of the leaders of Russia and China talking about immortality. ‚ÄúThese days at 70 years old you are still a child,‚Äù China‚Äôs Xi Jinping, 72, was translated as saying.



‚ÄúWith the developments of biotechnology, human organs can be continuously transplanted, and people can live younger and younger, and even achieve immortality,‚Äù Russia‚Äôs Vladimir Putin, also 72, is reported to have replied.



In reality, rounds of organ transplantation surgery aren‚Äôt likely to help anyone radically extend their lifespan anytime soon. And it‚Äôs a simplistic way to think about aging‚Äîa process so complicated that researchers can‚Äôt agree on what causes it, why it occurs, or even how to define it, let alone ‚Äútreat‚Äù it. Read the full story.



This article first appeared in The Checkup, MIT Technology Review‚Äôs weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.







India is using robots to clean sewer pipes so humans no longer have to



When Jitender was a child in New Delhi, both his parents worked as manual scavengers‚Äîa job that involved clearing the city‚Äôs sewers by hand. Now, he is among almost 200 contractors involved in the Delhi government‚Äôs effort to shift from this manual process to safer mechanical methods.Although it has been outlawed since 1993, manual scavenging‚Äîthe practice of extracting human excreta from toilets, sewers, or septic tanks‚Äîis still practiced widely in India. And not only is the job undignified, but it can be extremely dangerous.Now, several companies have emerged to offer alternatives at a wide range of technical complexity. Read the full story.



‚ÄîHamaad Habibullah



This story is from our new print edition, which is all about the future of security. Subscribe here to catch future copies when they land.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 RFK Jr buried a major study linking alcohol and cancerClearly, the alcohol industry‚Äôs intense lobbying of the Trump administration is working. (Vox)+ RFK Jr repeated health untruths during a marathon Senate hearing yesterday. (Mother Jones)+ His anti-vaccine stance alarmed Democrats and Republicans alike. (The Atlantic $)



2 US tech giants want to embed AI in educationThey‚Äôre backing a vaguely worded initiative to that effect launched by Melania Trump. (Rolling Stone $)+ Tech leaders took it in turns to praise Trump during dinner. (WSJ $)+ Elon Musk was nowhere to be seen. (The Guardian)+ AI‚Äôs giants want to take over the classroom. (MIT Technology Review)



3 The FTC will probe AI companies over their impact on children¬†In a bid to evaluate whether chatbots are harming their mental health. (WSJ $)+ An AI companion site is hosting sexually charged conversations with underage celebrity bots. (MIT Technology Review)



4 Podcasting giant Joe Rogan has been spreading climate misinformationHe‚Äôs grossly misinterpreted scientists‚Äô research‚Äîand they‚Äôre exasperated. (The Guardian)+ Rogan claims the Earth‚Äôs temperature is plummeting. It isn‚Äôt.¬† (Forbes)+ Why climate researchers are taking the temperature of mountain snow. (MIT Technology Review)



5 DeepSeek is working on its own advanced AI agentWatch out, OpenAI. (Bloomberg $)



6 OpenAI will start making its own AI chips next yearIn a bid to lessen its reliance on Nvidia. (FT $)



7 Warner Bros is suing MidjourneyThe AI startup used the likenesses of characters including Superman without permission, it alleges. (Bloomberg $)+ What comes next for AI copyright lawsuits? (MIT Technology Review)



8 Rivers and lakes are being used to cool down buildingsBut networks in Paris, Toronto, the US are facing a looming problem. (Wired $)+ The future of urban housing is energy-efficient refrigerators. (MIT Technology Review)



9 How high school reunions survive in the age of social mediaCuriosity is a powerful driving force, it seems. (The Atlantic $)



10 Facebook‚Äôs poke feature is back If I still used Facebook, I‚Äôd be thrilled. (TechCrunch)







Quote of the day



&#8220;Even if it doesn&#8217;t turn you into the alien if you eat this stuff, I guarantee you&#8217;ll grow an extra ear.&#8221;



‚ÄîSenator John Kennedy, a Republican from Louisiana, warns of dire consequences if Americans eat shrimp from countries other than the US, Gizmodo reports.







One more thing







Why one developer won‚Äôt quit fighting to connect the US‚Äôs gridsMichael Skelly hasn‚Äôt learned to take no for an answer. For much of the last 15 years, the energy entrepreneur has worked to develop long-haul transmission lines to carry wind power across the Great Plains, Midwest, and Southwest. But so far, he has little to show for the effort.Skelly has long argued that building such lines and linking together the nation‚Äôs grids would accelerate the shift from coal- and natural-gas-fueled power plants to the renewables needed to cut the pollution driving climate change. But his previous business shut down in 2019, after halting two of its projects and selling off interests in three more.Skelly contends he was early, not wrong. And he has a point: market and policymakers are increasingly coming around to his perspective. Read the full story.



‚ÄîJames Temple







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ The Paper, the new mockumentary from the makers of the American Office, looks interesting.+ Giorgio Armani was a true maestro of menswear.+ The phases of the moon are pretty fascinating + The Damien Hirst-directed video for Blur‚Äôs classic Country House has been given a 4K makeover.
‚Ä¢ Putin says organ transplants could grant immortality. Not quite.
  This week I‚Äôm writing from Manchester, where I‚Äôve been attending&nbsp;a conference on aging. Wednesday was full of talks and presentations by scientists who are trying to understand the nitty-gritty of aging‚Äîall the way down to the molecular level. Once we can understand the complex biology of aging, we should be able to slow or prevent the onset of age-related diseases, they hope.



Then my editor forwarded me a video of the leaders of Russia and China talking about immortality. ‚ÄúThese days at 70 years old you are still a child,‚Äù China‚Äôs Xi Jinping, 72, was translated as saying, according to footage livestreamed by CCTV to&nbsp;multiple&nbsp;media outlets.



‚ÄúWith the developments of biotechnology, human organs can be continuously transplanted, and people can live younger and younger, and even achieve immortality,‚Äù Russia‚Äôs Vladimir Putin, also 72, is reported to have replied.



SERGEI BOBYLEV, SPUTNIK, KREMLIN POOL PHOTO VIA AP




There‚Äôs a striking contrast between that radical vision and the incremental longevity science presented at the meeting. Repeated rounds of organ transplantation surgery aren‚Äôt likely to help anyone radically extend their lifespan anytime soon.





First, back to Putin‚Äôs proposal: the idea of continually replacing aged organs to stay young. It‚Äôs a simplistic way to think about aging. After all, aging is so complicated that researchers can‚Äôt agree on what causes it, why it occurs, or even how to define it, let alone ‚Äútreat‚Äù it.



Having said that, there may be some merit to the idea of repairing worn-out body parts with biological or synthetic replacements. Replacement therapies‚Äîincluding bioengineered organs‚Äîare being developed by multiple research teams. Some have already been tested in people. This week, let‚Äôs take a look at the idea of replacement therapies.



No one fully understands why our organs start to fail with age. On the face of it, replacing them seems like a good idea. After all, we already know how to do organ transplants. They‚Äôve been a part of medicine since the 1950s and have been used to&nbsp;save hundreds of thousands of lives in the US alone.



And replacing old organs with young ones might have more broadly beneficial effects. When a young mouse is stitched to an old one, the older mouse benefits from the arrangement, and its health seems to improve.



The problem is that we don‚Äôt really know why. We don‚Äôt know what it is about young body tissues that makes them health-promoting. We don‚Äôt know how long these effects might last in a person. We don‚Äôt know how different organ transplants will compare, either. Might a young heart be more beneficial than a young liver? No one knows.



And that‚Äôs before you consider the practicalities of organ transplantation. There is already a shortage of donor organs‚Äîthousands of people die on waiting lists. Transplantation requires major surgery and, typically, a lifetime of prescription drugs that damp down the immune system,&nbsp;leaving a person more susceptible to certain infections and diseases.





So the idea of repeated organ transplantations shouldn‚Äôt really be a particularly appealing one. ‚ÄúI don‚Äôt think that‚Äôs going to happen anytime soon,‚Äù says Jesse Poganik, who studies aging at Brigham and Women‚Äôs Hospital in Boston and is also in Manchester for the meeting.



Poganik has been collaborating with transplant surgeons in his own research. ‚ÄúThe surgeries are good, but they‚Äôre not simple,‚Äù he tells me. And they come with real risks. His own 24-year-old cousin developed a form of cancer after a liver and heart transplant. She died a few weeks ago, he says.



So when it comes to replacing worn-out organs, scientists are looking for both biological and synthetic alternatives.&nbsp;&nbsp;



We‚Äôve been replacing body parts for centuries. Wooden toes were used as far back as the 15th century. Joint replacements have been around for more than a hundred years. And major innovations over the last 70 years have given us devices like pacemakers, hearing aids, brain implants, and artificial hearts.



Scientists are exploring other ways to make tissues and organs, too. There are different approaches here, but they include everything from injecting stem cells to seeding ‚Äúscaffolds‚Äù with cells in a lab.



In 1999, researchers used volunteers‚Äô own cells to seed bladder-shaped collagen scaffolds. The resulting bioengineered bladders went on to be transplanted into seven people in&nbsp;an initial trial.&nbsp;



Now scientists are working on more complicated organs. Jean H√©bert, a program manager at the US government‚Äôs Advanced Research Projects Agency for Health, has been exploring ways to gradually replace the cells in a person‚Äôs brain. The idea is that, eventually, the recipient will end up with a young brain.



H√©bert&nbsp;showed my colleague Antonio Regalado how, in his early experiments, he removed parts of mice‚Äôs brains and replaced them with embryonic stem cells. That work seems a world away from the biochemical studies being presented at the British Society for Research on Ageing annual meeting in Manchester, where I am now.





On Wednesday, one scientist described how he‚Äôd been testing potential longevity drugs on the tiny nematode worm C. elegans. These worms live for only about 15 to 40 days, and his team can perform tens of thousands of experiments with them. About 40% of the drugs that extend lifespan in C. elegans also help mice live longer, he told us.



To me, that‚Äôs not an amazing hit rate. And we don‚Äôt know how many of those drugs will work in people. Probably less than 40% of that 40%.



Other scientists presented work on chemical reactions happening at the cellular level. It was deep, basic science, and my takeaway was that there‚Äôs a lot aging researchers still don‚Äôt fully understand.



It will take years‚Äîif not decades‚Äîto get the full picture of aging at the molecular level. And if we rely on a series of experiments in worms, and then mice, and then humans, we‚Äôre unlikely to make progress for a really long time. In that context, the idea of replacement therapy feels like a shortcut.



‚ÄúReplacement is a really exciting avenue because you don‚Äôt have to understand the biology of aging as much,‚Äù says Sierra Lore, who studies aging at the University of Copenhagen in Denmark and the Buck Institute for Research on Aging in Novato, California.



Lore says she started her research career studying aging at the molecular level, but she soon changed course. She now plans to focus her attention on replacement therapies. ‚ÄúI very quickly realized we‚Äôre decades away [from understanding the molecular processes that underlie aging],‚Äù she says. ‚ÄúWhy don‚Äôt we just take what we already know‚Äîreplacement‚Äîand try to understand and apply it better?‚Äù



So perhaps Putin‚Äôs straightforward approach to delaying aging holds some merit. Whether it will grant him immortality is another matter.



This article first appeared in The Checkup,&nbsp;MIT Technology Review‚Äôs&nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&nbsp;sign up here.
‚Ä¢ Imagining the future of banking with agentic AI
  Banks are increasingly employing agentic AI to optimize processes, navigate complex systems, and sift through vast quantities of unstructured data to make decisions and take actions . A 2025 survey of 250 banking executives by MIT Technology Review Insights found that 70% of leaders say their firm uses AI to some degree, either through existing deployments (16%) or pilot projects (52%) Agentic AI is already proving effective in a range of different functions .
‚Ä¢ The Download: unnerving AI avatars, and Trump‚Äôs climate gift to China
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Synthesia‚Äôs AI clones are more expressive than ever. Soon they‚Äôll be able to talk back.



‚ÄîRhiannon Williams



Earlier this summer, I visited the AI company Synthesia to give it what it needed to create a hyperrealistic AI-generated avatar of me. The company‚Äôs avatars are a decent barometer of just how dizzying progress has been in AI over the past few years, so I was curious just how accurately its latest AI model, introduced last month, could replicate me.I found my avatar as unnerving as it is technically impressive. It‚Äôs slick enough to pass as a high-definition recording of a chirpy corporate speech, and if you didn‚Äôt know me, you‚Äôd probably think that‚Äôs exactly what it was.&nbsp;



My avatar shows how it‚Äôs becoming ever-harder to distinguish the artificial from the real. And before long, these avatars will even be able to talk back to us. But how much better can they get? And what might interacting with AI clones do to us? Read the full story.







How Trump is helping China extend its massive lead in clean energy&nbsp;



On a spring day in 1954, Bell Labs researchers showed off the first practical solar panels at a press conference in New Jersey, using sunlight to spin a toy Ferris wheel before a stunned crowd.



The solar future looked bright. But in the race to commercialize the technology it invented, the US would lose resoundingly. Last year, China exported $40 billion worth of solar panels and modules, while America shipped just $69 million, according to the New York Times. It was a stunning forfeit of a huge technological lead.&nbsp;



Now, thanks to its policies propping up aging fossil-fuel industries, the US seems determined to repeat the mistake. Read the full story.



‚ÄîJames Temple



This article is from The Spark, MIT Technology Review‚Äôs newsletter all about the latest in climate and energy tech. To receive it in your inbox every Wednesday, sign up here.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 AI chatbots of celebrities sent risqu√© messages to teenagersVirtual versions of Timoth√©e Chalamet and Chappell Roan discussed sex and drugs. (WP $)+ An AI companion site is hosting sexually charged conversations with underage celebrity bots. (MIT Technology Review)2 Trump can‚Äôt make up his mind about US tech giantsWhile defending them against EU regulation, he‚Äôs also pushing to break them up. (FT $)+ He‚Äôs hosting tech leaders at the White House later today. (Reuters)+ Elon Musk doesn‚Äôt appear to have made the guest list. (CNBC)



3 Trump‚Äôs cuts have led to babies born with HIVClinics in East Africa are closing, and people are being forced to skip vital drug doses. (The Guardian)+ Artificial blood could save many lives. Why aren‚Äôt we using it? (Slate)



4 Germany has already met its 2028 goal for reducing coal-fired powerFor the second year running, it won‚Äôt have to shut any more plants as a result. (Bloomberg $)+ The UK is done with coal. How‚Äôs the rest of the world doing? (MIT Technology Review)



5 The risk of all-out nuclear war is growingBut we‚Äôve normalized nuclear competition so much, the risks aren‚Äôt always clear. (New Yorker $)+ Maybe it‚Äôs time to start burying nuclear reactors‚Äô cores. (Economist $)



6 xAI is hemorrhaging executivesThe CFO has left just months after joining. (WSJ $)



7 India‚Äôs chip industry is gaining momentumYears of investment are starting to pay off. But can it strike deals with overseas chip giants too? (Bloomberg $)+ Meanwhile, Taiwan‚Äôs chip hub is home to a baby boom. (Rest of World)+ Inside India‚Äôs scramble for AI independence. (MIT Technology Review)



8 Boston Dynamics‚Äô Atlas robot only needs one AI model to workIt‚Äôs all it requires to master humanlike movements successfully. (Wired $)+ How ‚Äòrobot ballet‚Äô could shake up factory production lines. (FT $)+ Humanoid robots still aren‚Äôt living up to their lofty promises. (IEEE Spectrum)+ Will we ever trust robots? (MIT Technology Review)



9 How studying astronauts could improve health on EarthThere‚Äôs still a huge amount we don‚Äôt know about space‚Äôs effects on humans. (Vox)+ Space travel is dangerous. Could genetic testing and gene editing make it safer? (MIT Technology Review)



10 The Caribbean island of Anguilla has hit upon an AI cash cowBy selling its .ai domain. (Semafor)+ How a tiny Pacific Island became the global capital of cybercrime. (MIT Technology Review)







Quote of the day



‚ÄúIf you are not being scammed yet, it‚Äôs because you haven‚Äôt encountered a scam designed just for you and only for you.‚Äù



‚ÄîJeff Kuo, chief executive of Taiwanese fraud prevention company Gogolook, warns the Financial Times about the endless possibilities generative AI presents to scammers.







One more thing







China built hundreds of AI data centers to catch the AI boom. Now many stand unused.Last year, China‚Äôs boom in data center construction was at its height, fueled by both government and private investors. Renting out GPUs to companies that need them for training AI models was seen as a sure bet.But with the rise of DeepSeek and a sudden change in the economics around AI, the industry is faltering. Prices for GPUs are falling and many newly built facilities are now sitting empty. Read the full story to find out why.



‚ÄîCaiwei Chen







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ The trailer for the forthcoming Wuthering Heights film is here and it looks‚Ä¶interesting.+ This fall‚Äôs crop of video games is outstanding.+ Textured walls are a surefire way to make your home look dated. Here‚Äôs some other faux pas to avoid.+The dogs of this year‚Äôs US Open are too cute ($)
‚Ä¢ Transforming CX with embedded real-time analytics
  During Black Friday in 2024, Stripe processed more than $31 billion in transactions, with processing rates peaking at 137,000 transactions per minute, the highest in the company‚Äôs history . Having the capability to collect and analyze data in real time correlates with companies‚Äô ability to grow . Business leaders that scored company in the top quartile for real-time operations saw 50% higher revenue growth and net margins .

üîí Cybersecurity & Privacy
‚Ä¢ GOP Cries Censorship Over Spam Filters That Work
  The chairman of the Federal Trade Commission (FTC) last week sent a letter to Google&#8217;s CEO demanding to know why Gmail was blocking messages from Republican senders while allegedly failing to block similar missives supporting Democrats. The letter followed media reports accusing Gmail of disproportionately flagging messages from the GOP fundraising platform WinRed and sending them to the spam folder. But according to experts who track daily spam volumes worldwide, WinRed&#8217;s messages are getting blocked more because its methods of blasting email are increasingly way more spammy than that of ActBlue, the fundraising platform for Democrats.
Image: nypost.com
On Aug. 13, The New York Post ran an &#8220;exclusive&#8221; story titled, &#8220;Google caught flagging GOP fundraiser emails as &#8216;suspicious&#8217; &#8212; sending them directly to spam.&#8221; The story cited a memo from Targeted Victory ‚Äì whose clients include the National Republican Senatorial Committee (NRSC), Rep. Steve Scalise and Sen. Marsha Blackburn ‚Äì which said it observed that the &#8220;serious and troubling&#8221; trend was still going on as recently as June and July of this year.
‚ÄúIf Gmail is allowed to quietly suppress WinRed links while giving ActBlue a free pass, it will continue to tilt the playing field in ways that voters never see, but campaigns will feel every single day,‚Äù the memo reportedly said.
In an August 28 letter to Google CEO Sundar Pichai, FTC Chairman Andrew Ferguson cited the New York Post story and warned that Gmail&#8217;s parent Alphabet may be engaging in unfair or deceptive practices.
&#8220;Alphabet‚Äôs alleged partisan treatment of comparable messages or messengers in Gmail to achieve political objectives may violate both of these prohibitions under the FTC Act,&#8221; Ferguson wrote. &#8220;And the partisan treatment may cause harm to consumers.&#8221;
However, the situation looks very different when you ask spam experts what&#8217;s going on with WinRed&#8217;s recent messaging campaigns. Atro Tossavainen and Pekka Jalonen are co-founders at Koli-L√µks O√ú, an email intelligence company in Estonia. Koli-L√µks taps into real-time intelligence about daily spam volumes by monitoring large numbers of &#8220;spamtraps&#8221; &#8212; email addresses that are intentionally set up to catch unsolicited emails.
Spamtraps are generally not used for communication or account creation, but instead are created to identify senders exhibiting spammy behavior, such as scraping the Internet for email addresses or buying unmanaged distribution lists. As an email sender, blasting these spamtraps over and over with unsolicited email is the fastest way to ruin your domain&#8217;s reputation online. Such activity also virtually ensures that more of your messages are going to start getting listed on spam blocklists that are broadly shared within the global anti-abuse community.
Tossavainen told KrebsOnSecurity that WinRed&#8217;s emails hit its spamtraps in the .com, .net, and .org space far more frequently than do fundraising emails sent by ActBlue. Koli-L√µks published a graph of the stark disparity in spamtrap activity for WinRed versus ActBlue, showing a nearly fourfold increase in spamtrap hits from WinRed emails in the final week of July 2025.
Image: Koliloks.eu
&#8220;Many of our spamtraps are in repurposed legacy-TLD domains (.com, .org, .net) and therefore could be understood to have been involved with a U.S. entity in their pre-zombie life,&#8221; Tossavainen explained in the LinkedIn post.
Raymond Dijkxhoorn is the CEO and a founding member of SURBL, a widely-used blocklist that flags domains and IP addresses known to be used in unsolicited messages, phishing and malware distribution. Dijkxhoorn said their spamtrap data mirrors that of Koli-L√µks, and shows that WinRed has consistently been far more aggressive in sending email than ActBlue.
Dijkxhoorn said the fact that WinRed&#8217;s emails so often end up dinging the organization&#8217;s sender reputation is not a content issue but rather a technical one.
&#8220;On our end we don‚Äôt really care if the content is political or trying to sell viagra or penis enlargements,&#8221; Dijkhoorn said. &#8220;It‚Äôs the mechanics, they should not end up in spamtraps. And that‚Äôs the reason the domain reputation is tempered. Not ‚Äòbecause domain reputation firms have a political agenda.&#8217; We really don&#8217;t care about the political situation anywhere. The same as we don&#8217;t mind people buying penis enlargements. But when either of those land in spamtraps it will impact sending experience.&#8221;
The FTC letter to Google&#8217;s CEO also referenced a debunked 2022 study (PDF) by political consultants who found Google caught more Republican emails in spam filters. Techdirt editor Mike Masnick notes that while the 2022 study also found that other email providers caught more Democratic emails as spam, &#8220;Republicans laser-focused on Gmail because it fit their victimization narrative better.&#8221;
Masnick said GOP lawmakers then filed both lawsuits and complaints with the Federal Election Commission (both of which failed easily), claiming this was somehow an ‚Äúin-kind contribution‚Äù to Democrats.
&#8220;This is political posturing designed to keep the White House happy by appearing to &#8216;do something&#8217; about conservative claims of &#8216;censorship,'&#8221; Masnick wrote of the FTC letter. &#8220;The FTC has never policed &#8216;political bias&#8217; in private companies‚Äô editorial decisions, and for good reason‚Äîthe First Amendment prohibits exactly this kind of government interference.&#8221;
WinRed did not respond to a request for comment.
The WinRed website says it is an online fundraising platform supported by a united front of the Trump campaign, the Republican National Committee (RNC), the NRSC,¬†and the National Republican Congressional Committee (NRCC).
WinRed has recently come under fire for aggressive fundraising via text message as well. In June, 404 Media reported on a lawsuit filed by a family in Utah against the RNC for allegedly bombarding their mobile phones with text messages seeking donations after they&#8217;d tried to unsubscribe from the missives dozens of times.
One of the family members said they received 27 such messages from 25 numbers, even after sending 20 stop requests. The plaintiffs in that case allege the texts from WinRed and the RNC &#8220;knowingly disregard stop requests and purposefully use different phone numbers to make it impossible to block new messages.&#8221;
Dijkhoorn said WinRed did inquire recently about why some of its assets had been marked as a risk by SURBL, but he said they appeared to have zero interest in investigating the likely causes he offered in reply.
&#8220;They only replied with, &#8216;You are interfering with U.S. elections,'&#8221; Dijkhoorn said, noting that many of SURBL&#8217;s spamtrap domains are only publicly listed in the registration records for random domain names.
&#8220;They‚Äôre at best harvested by themselves but more likely [they] just went and bought lists,&#8221; he said. &#8220;It&#8217;s not like ‚ÄòOh Google is filtering this and not the other,‚Äô the reason isn&#8217;t the provider. The reason is the fundraising spammers and the lists they send to.&#8221;
‚Ä¢ The Ongoing Fallout from a Breach at AI Chatbot Maker Salesloft
  The recent mass-theft of authentication tokens from Salesloft, whose AI chatbot is used by a broad swath of corporate America to convert customer interaction into Salesforce leads, has left many companies racing to invalidate the stolen credentials before hackers can exploit them. Now Google warns the breach goes far beyond access to Salesforce data, noting the hackers responsible also stole valid authentication tokens for hundreds of online services that customers can integrate with Salesloft, including Slack, Google Workspace, Amazon S3, Microsoft Azure, and OpenAI.
Salesloft says its products are trusted by 5,000+ customers. Some of the bigger names are visible on the company&#8217;s homepage.
Salesloft disclosed on August 20 that, &#8220;Today, we detected a security issue in the Drift application,&#8221; referring to the technology that powers an AI chatbot used by so many corporate websites. The alert urged customers to re-authenticate the connection between the Drift and Salesforce apps to invalidate their existing authentication tokens, but it said nothing then to indicate those tokens had already been stolen.
On August 26, the Google Threat Intelligence Group (GTIG) warned that unidentified hackers tracked as UNC6395 used the access tokens stolen from Salesloft to siphon large amounts of data from numerous corporate Salesforce instances. Google said the data theft began as early as Aug. 8, 2025 and lasted through at least Aug. 18, 2025, and that the incident did not involve any vulnerability in the Salesforce platform.
Google said the attackers have been sifting through the massive data haul for credential materials such as AWS keys, VPN credentials, and credentials to the cloud storage provider Snowflake.
&#8220;If successful, the right credentials could allow them to further compromise victim and client environments, as well as pivot to the victim&#8217;s clients or partner environments,&#8221; the GTIG report stated.
The GTIG updated its advisory on August 28 to acknowledge the attackers used the stolen tokens to access email from &#8220;a very small number of Google Workspace accounts&#8221; that were specially configured to integrate with Salesloft. More importantly, it warned organizations to immediately invalidate all tokens stored in or connected to their Salesloft integrations &#8212; regardless of the third-party service in question.
&#8220;Given GTIG&#8217;s observations of data exfiltration associated with the campaign, organizations using Salesloft Drift to integrate with third-party platforms (including but not limited to Salesforce) should consider their data compromised and are urged to take immediate remediation steps,&#8221; Google advised.
On August 28, Salesforce blocked Drift from integrating with its platform, and with its productivity platforms Slack and Pardot.
The Salesloft incident comes on the heels of a broad social engineering campaign that used voice phishing to trick targets into connecting a malicious app to their organization&#8217;s Salesforce portal. That campaign led to data breaches and extortion attacks affecting a number of companies including Adidas, Allianz Life and Qantas.
On August 5, Google disclosed that one of its corporate Salesforce instances was compromised by the attackers, which the GTIG has dubbed UNC6040 (&#8220;UNC&#8221; stands for &#8220;uncategorized threat group&#8221;). Google said the extortionists consistently claimed to be the threat group ShinyHunters,¬†and that the group appeared to be preparing to escalate its extortion attacks by launching a data leak site.
ShinyHunters is an amorphous threat group known for using social engineering to break into cloud platforms and third-party IT providers, and for posting dozens of stolen databases to cybercrime communities like the now-defunct Breachforums.
The ShinyHunters brand dates back to 2020, and the group has been credited with or taken responsibility for dozens of data leaks that exposed hundreds of millions of breached records. The group&#8217;s member roster is thought to be somewhat fluid, drawing mainly from active denizens of the Com, a mostly English-language cybercrime community scattered across an ocean of Telegram and Discord servers.
Recorded Future&#8217;s Alan Liska told Bleeping Computer that the overlap in the &#8220;tools, techniques and procedures&#8221; used by ShinyHunters and the Scattered Spider extortion group likely indicate some crossover between the two groups.
To muddy the waters even further, on August 28 a Telegram channel that now has nearly 40,000 subscribers was launched under the intentionally confusing banner &#8220;Scattered LAPSUS$ Hunters 4.0,&#8221; wherein participants have repeatedly claimed responsibility for the Salesloft hack without actually sharing any details to prove their claims.
The Telegram group has been trying to attract media attention by threatening security researchers at Google and other firms. It also is using the channel&#8217;s sudden popularity to promote a new cybercrime forum called &#8220;Breachstars,&#8221; which they claim will soon host data stolen from victim companies who refuse to negotiate a ransom payment.
The &#8220;Scattered Lapsus$ Hunters 4.0&#8221; channel on Telegram now has roughly 40,000 subscribers.
But Austin Larsen, a principal threat analyst at Google&#8217;s threat intelligence group, said there is no compelling evidence to attribute the Salesloft activity to ShinyHunters or to other known groups at this time.
&#8220;Their understanding of the incident seems to come from public reporting alone,&#8221; Larsen told KrebsOnSecurity, referring to the most active participants in the Scattered LAPSUS$ Hunters 4.0 Telegram channel.
Joshua Wright, a senior technical director at Counter Hack,¬†is credited with coining the term &#8220;authorization sprawl&#8221; to describe one key reason that social engineering attacks from groups like Scattered Spider and ShinyHunters so often succeed: They abuse legitimate user access tokens to move seamlessly between on-premises and cloud systems.
Wright said this type of attack chain often goes undetected because the attacker sticks to the resources and access already allocated to the user.
&#8220;Instead of the conventional chain of initial access, privilege escalation and endpoint bypass, these threat actors are using centralized identity platforms that offer single sign-on (SSO) and integrated authentication and authorization schemes,&#8221; Wright wrote in a June 2025 column. &#8220;Rather than creating custom malware, attackers use the resources already available to them as authorized users.&#8221;
It remains unclear exactly how the attackers gained access to all Salesloft Drift authentication tokens. Salesloft announced on August 27 that it hired Mandiant, Google Cloud&#8217;s incident response division, to investigate the root cause(s).
&#8220;We are working with Salesloft Drift to investigate the root cause of what occurred and then it‚Äôll be up to them to publish that,&#8221; Mandiant Consulting CTO Charles Carmakal told Cyberscoop. &#8220;There will be a lot more tomorrow, and the next day, and the next day.&#8221;

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Accelerating HPC and AI research in universities with Amazon SageMaker HyperPod
  This post was written with Mohamed Hossam of Brightskies. 
Research universities engaged in large-scale AI and high-performance computing (HPC) often face significant infrastructure challenges that impede innovation and delay research outcomes. Traditional on-premises HPC clusters come with long GPU procurement cycles, rigid scaling limits, and complex maintenance requirements. These obstacles restrict researchers‚Äô ability to iterate quickly on AI workloads such as natural language processing (NLP), computer vision, and foundation model (FM) training. Amazon SageMaker HyperPod alleviates the undifferentiated heavy lifting involved in building AI models. It helps quickly scale model development tasks such as training, fine-tuning, or inference across a cluster of hundreds or thousands of AI accelerators (NVIDIA GPUs H100, A100, and others) integrated with preconfigured HPC tools and automated scaling. 
In this post, we demonstrate how a research university implemented SageMaker HyperPod to accelerate AI research by using dynamic SLURM partitions, fine-grained GPU resource management, budget-aware compute cost tracking, and multi-login node load balancing‚Äîall integrated seamlessly into the SageMaker HyperPod environment. 
Solution overview 
Amazon SageMaker HyperPod is designed to support large-scale machine learning operations for researchers and ML scientists. The service is fully managed by AWS, removing operational overhead while maintaining enterprise-grade security and performance. 
The following architecture diagram illustrates how to access SageMaker HyperPod to submit jobs. End users can use AWS Site-to-Site VPN, AWS Client VPN, or AWS Direct Connect to securely access the SageMaker HyperPod cluster. These connections terminate on the Network Load Balancer that efficiently distributes SSH traffic to login nodes, which are the primary entry points for job submission and cluster interaction. At the core of the architecture is SageMaker HyperPod compute, a controller node that orchestrates cluster operations, and multiple compute nodes arranged in a grid configuration. This setup supports efficient distributed training workloads with high-speed interconnects between nodes, all contained within a private subnet for enhanced security. 
The storage infrastructure is built around two main components: Amazon FSx for Lustre provides high-performance file system capabilities, and Amazon S3 for dedicated storage for datasets and checkpoints. This dual-storage approach provides both fast data access for training workloads and secure persistence of valuable training artifacts. 
 
The implementation consisted of several stages. In the following steps, we demonstrate how to deploy and configure the solution. 
Prerequisites 
Before deploying Amazon SageMaker HyperPod, make sure the following prerequisites are in place: 
 
 AWS configuration: 
   
   The AWS Command Line Interface (AWS CLI) configured with appropriate permissions 
   Cluster configuration files prepared: cluster-config.json and provisioning-parameters.json 
    
 Network setup: 
   
   A virtual private cloud (VPC) configured for cluster resources. 
   Security groups with Elastic Fabric Adapter (EFA) communication enabled. 
   An Amazon FSx for Lustre file system for shared, high-performance storage 
    
 An AWS Identity and Management (IAM) role with permissions for the following: 
   
   Amazon Elastic Compute Cloud (Amazon EC2) instance and Amazon SageMaker cluster management 
   FSx for Lustre and Amazon Simple Storage Service (Amazon S3) access 
   Amazon CloudWatch Logs and AWS Systems Manager integration 
   EFA network configuration 
    
 
Launch the CloudFormation stack 
We launched an AWS CloudFormation stack to provision the necessary infrastructure components, including a VPC and subnet, FSx for Lustre file system, S3 bucket for lifecycle scripts and training data, and IAM roles with scoped permissions for cluster operation. Refer to the Amazon SageMaker HyperPod workshop for CloudFormation templates and automation scripts. 
Customize SLURM cluster configuration 
To align compute resources with departmental research needs, we created SLURM partitions to reflect the organizational structure, for example NLP, computer vision, and deep learning teams. We used the SLURM partition configuration to define slurm.conf with custom partitions. SLURM accounting was enabled by configuring slurmdbd and linking usage to departmental accounts and supervisors. 
To support fractional GPU sharing and efficient utilization, we enabled Generic Resource (GRES) configuration. With GPU stripping, multiple users can access GPUs on the same node without contention. The GRES setup followed the guidelines from the Amazon SageMaker HyperPod workshop. 
Provision and validate the cluster 
We validated the cluster-config.json and provisioning-parameters.json files using the AWS CLI and a SageMaker HyperPod validation script: 
 
 $curl -O https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/5.sagemaker-hyperpod/validate-config.py

$pip3 install boto3

$python3 validate-config.py --cluster-config cluster-config.json --provisioning-parameters provisioning-parameters.json 
 
Then we created the cluster: 
 
 $aws sagemaker create-cluster \
  --cli-input-json file://cluster-config.json \
  --region us-west-2 
 
Implement cost tracking and budget enforcement 
To monitor usage and control costs, each SageMaker HyperPod resource (for example, Amazon EC2, FSx for Lustre, and others) was tagged with a unique ClusterName tag. AWS Budgets and AWS Cost Explorer reports were configured to track monthly spending per cluster. Additionally, alerts were set up to notify researchers if they approached their quota or budget thresholds. 
This integration helped facilitate efficient utilization and predictable research spending. 
Enable load balancing for login nodes 
As the number of concurrent users increased, the university adopted a multi-login node architecture. Two login nodes were deployed in EC2 Auto Scaling groups. A Network Load Balancer was configured with target groups to route SSH and Systems Manager traffic. Lastly, AWS Lambda functions enforced session limits per user using Run-As tags with Session Manager, a capability of Systems Manager. 
For details about the full implementation, see Implementing login node load balancing in SageMaker HyperPod for enhanced multi-user experience. 
Configure federated access and user mapping 
To facilitate secure and seamless access for researchers, the institution integrated AWS IAM Identity Center with their on-premises Active Directory (AD) using AWS Directory Service. This allowed for unified control and administration of user identities and access privileges across SageMaker HyperPod accounts. The implementation consisted of the following key components: 
 
 Federated user integration ‚Äì We mapped AD users to POSIX user names using Session Manager run-as tags, allowing fine-grained control over compute node access 
 Secure session management ‚Äì We configured Systems Manager to make sure users access compute nodes using their own accounts, not the default ssm-user 
 Identity-based tagging ‚Äì Federated user names were automatically mapped to user directories, workloads, and budgets through resource tags 
 
For full step-by-step guidance, refer to the Amazon SageMaker HyperPod workshop. 
This approach streamlined user provisioning and access control while maintaining strong alignment with institutional policies and compliance requirements. 
Post-deployment optimizations 
To help prevent unnecessary consumption of compute resources by idle sessions, the university configured SLURM with Pluggable Authentication Modules (PAM). This setup enforces automatic logout for users after their SLURM jobs are complete or canceled, supporting prompt availability of compute nodes for queued jobs. 
The configuration improved job scheduling throughput by freeing idle nodes immediately and reduced administrative overhead in managing inactive sessions. 
Additionally, QoS policies were configured to control resource consumption, limit job durations, and enforce fair GPU access across users and departments. For example: 
 
 MaxTRESPerUser ‚Äì Makes sure GPU or CPU usage per user stays within defined limits 
 MaxWallDurationPerJob ‚Äì Helps prevent excessively long jobs from monopolizing nodes 
 Priority weights ‚Äì Aligns priority scheduling based on research group or project 
 
These enhancements facilitated an optimized, balanced HPC environment that aligns with the shared infrastructure model of academic research institutions. 
Clean up 
To delete the resources and avoid incurring ongoing charges, complete the following steps: 
 
 Delete the SageMaker HyperPod cluster: 
 
 
 $aws sagemaker delete-cluster --cluster-name &lt;name&gt; 
 
 
 Delete the CloudFormation stack used for the SageMaker HyperPod infrastructure: 
 
 
 $aws cloudformation delete-stack --stack-name &lt;stack-name&gt; --region &lt;region&gt; 
 
This will automatically remove associated resources, such as the VPC and subnets, FSx for Lustre file system, S3 bucket, and IAM roles. If you created these resources outside of CloudFormation, you must delete them manually. 
Conclusion 
SageMaker HyperPod provides research universities with a powerful, fully managed HPC solution tailored for the unique demands of AI workloads. By automating infrastructure provisioning, scaling, and resource optimization, institutions can accelerate innovation while maintaining budget control and operational efficiency. Through customized SLURM configurations, GPU sharing using GRES, federated access, and robust login node balancing, this solution highlights the potential of SageMaker HyperPod to transform research computing, so researchers can focus on science, not infrastructure. 
For more details on making the most of SageMaker HyperPod, check out the SageMaker HyperPod workshop and explore further blog posts about SageMaker HyperPod. 
 
About the authors 
Tasneem Fathima is Senior Solutions Architect at AWS. She supports Higher Education and Research customers in the United Arab Emirates to adopt cloud technologies, improve their time to science, and innovate on AWS. 
Mohamed Hossam is a Senior HPC Cloud Solutions Architect at Brightskies, specializing in high-performance computing (HPC) and AI infrastructure on AWS. He supports universities and research institutions across the Gulf and Middle East in harnessing GPU clusters, accelerating AI adoption, and migrating HPC/AI/ML workloads to the AWS Cloud. In his free time, Mohamed enjoys playing video games.
‚Ä¢ Exploring the Real-Time Race Track with Amazon Nova
  This post is co-written by Jake Friedman, President + Co-founder of Wildlife. 
Amazon Nova is enhancing sports fan engagement through an immersive Formula 1 (F1)-inspired experience that turns traditional spectators into active participants. This post explores the Real-Time Race Track (RTRT), an interactive experience built using Amazon Nova in Amazon Bedrock, that lets fans design, customize, and share their own racing circuits. We highlight how generative AI capabilities come together to deliver strategic racing insights such as pit timing and tire choices, and interactive features like an AI voice assistant and a retro-style racing poster. 
Evolving fan expectations and the technical barriers to real-time, multimodal engagement 
Today‚Äôs sports audiences expect more than passive viewing‚Äîthey want to participate, customize, and share. As fan expectations evolve, delivering engaging and interactive experiences has become essential to keeping audiences invested. Static digital content no longer holds attention; fans are drawn to immersive formats that make it possible to influence or co-create aspects of the event. For brands and rights holders, this shift presents both an opportunity and a challenge: how to deliver dynamic, meaningful engagement at scale. Delivering this level of interactivity comes with a unique set of technical challenges. It requires support for multiple modalities‚Äîtext, speech, image, and data‚Äîworking together in real time to create a seamless and immersive experience. Because fan-facing experiences are often offered for free, cost-efficiency becomes critical to sustain engagement at scale. And with users expecting instant responses, maintaining low-latency performance across interactions is essential to avoid disrupting the experience. 
Creating immersive fan engagement with the RTRT using Amazon Nova 
To foster an engaging and immersive experience, we developed the Real-Time Race Track, allowing F1 fans to design their own custom racing circuit using Amazon Nova. You can draw your track in different lengths and shapes while receiving real-time AI recommendations to modify your racing conditions. You can choose any location around the world for your race track and Amazon Nova Pro will use it to generate your track‚Äôs name and simulate realistic track conditions using that region‚Äôs weather and climate data. When your track is complete, Amazon Nova Pro analyzes the track to produce metrics like top speed and projected lap time, and offers two viable race strategies focused on tire management. You can also consult with Amazon Nova Sonic, a speech-to-speech model, for strategic track design recommendations. The experience culminates with Amazon Nova Canvas generating a retro-inspired racing poster of your custom track design that you can share or download. The following screenshots show some examples of the RTRT interface. 
 
  
   
    
    
   
  
 
Amazon Nova models are cost-effective and deliver among the best price-performance in their respective class, helping enterprises create scalable fan experiences while managing costs effectively. With fast speech processing and high efficiency, Amazon Nova provides seamless, real-time, multimodal interactions that meet the demands of interactive fan engagement. Additionally, Amazon Nova comes with built-in controls to maintain the safe and responsible use of AI. Combining comprehensive capabilities, cost-effectiveness, low latency, and trusted reliability, Amazon Nova is the ideal solution for applications requiring real-time, dynamic engagement. 
Prompts, inputs, and system design behind the RTRT experience 
The RTRT uses the multimodal capabilities of Amazon Nova Pro to effectively lead users from a single line path drawing to a fully viable race track design, including strategic racing recommendations and a bold visual representation of their circuit in the style of a retro racing poster. 
The following diagram gives an overview of the system architecture. 
 
Prompt engineering plays a crucial role in delivering structured output that can flow seamlessly into the UI, which has been optimized for at-a-glance takeaways that use Amazon Nova Pro to quickly analyze multiple data inputs to accelerate users‚Äô decision making. In the RTRT, this extends to the input images provided to Amazon Nova Pro for vision analysis. Each time the user adds new segments to their racing circuit, a version of the path is relayed to Amazon Nova Pro with visible coordinate markers that produce accurate path analysis (see the following screenshot) and corresponding output data, which can be visually represented back to users with color-coded track sectors. 
 
This is paired with multiple system prompts to define the role of Amazon Nova Pro at each stage of the app, as well as to return responses that are ready to be consumed by the front end. 
The following is a prompt example: 
 
 The system is designed to analyze the input image of a completed racetrack path outline.
You must always return valid JSON. 
 
The prompts also use sets of examples to produce consistent results across a diverse range of possible track designs and locations: 
 
 Using the input data craft a track title for a fictional Formula 1 track. 
    Use the names of existing tracks from &lt;example/&gt; as a framework of how to format the
      title.
  The title must not infringe on any existing track names or copyrighted material.
    The title should take into account the location of the track when choosing what
      language certain components of the track title are in. 
 
 This is also a key stage in which to employ responsible use of AI, instructing the model not to generate content that might infringe on existing race tracks or other copyrighted material.
 
These considerations are essential when working with creative models like Amazon Nova Canvas. Race cars commonly feature liveries that contain a dozen or more sponsor logos. To avoid concern, and to provide the cleanest, most aesthetically appealing retro racing poster designs, Amazon Nova Canvas was given a range of conditioning images that facilitate vehicle accuracy and consistency. The images work in tandem with our prompt for a bold illustration style featuring cinematic angles. 
The following is a prompt example: 
 
 Use a bold vector-style illustration approach with flat color fills, bold outlines,
    stylized gradients. Maintain a vintage racing poster aesthetic with minimal texture.
    Position the viewer to emphasize motion and speed. 
 
The following images show the output. 
 
  
   
    
    
   
  
 
Conclusion 
The Real-Time Race Track showcases how generative AI can deliver personalized, interactive moments that resonate with modern sports audiences. Amazon Nova models power each layer of the experience, from speech and image generation to strategy and analysis, delivering rich, low-latency interactions at scale. This collaboration highlights how brands can use Amazon Nova to build tailored and engaging experiences. 
 
About the authors 
Raechel Frick is a Sr. Product Marketing Manager at AWS. With over 20 years of experience in the tech industry, she brings a customer-first approach and growth mindset to building integrated marketing programs. 
Anuj Jauhari is a Sr. Product Marketing Manager at AWS, enabling customers to innovate and achieve business impact with generative AI solutions built on Amazon Nova models. 
Jake Friedman is the President and Co-founder at Wildlife, where he leads a team launching interactive experiences and content campaigns for global brands. His work has been recognized with the Titanium Grand Prix at the Cannes Lions International Festival of Creativity for ‚Äúboundary-busting, envy-inspiring work that marks a new direction for the industry and moves it forward.‚Äù
‚Ä¢ Build character consistent storyboards using Amazon Nova in Amazon Bedrock ‚Äì Part 2
  Although careful prompt crafting can yield good results, achieving professional-grade visual consistency often requires adapting the underlying model itself. Building on the prompt engineering and character development approach covered in Part 1 of this two-part series, we now push the consistency level for specific characters by fine-tuning an Amazon Nova Canvas foundation model (FM). Through fine-tuning techniques, creators can instruct the model to maintain precise control over character appearances, expressions, and stylistic elements across multiple scenes. 
In this post, we take an animated short film, Picchu, produced by FuzzyPixel from Amazon Web Services (AWS), prepare training data by extracting key character frames, and fine-tune a character-consistent model for the main character Mayu and her mother, so we can quickly generate storyboard concepts for new sequels like the following images. 
 
  
   
    
    
    
   
  
 
Solution overview 
To implement an automated workflow, we propose the following comprehensive solution architecture that uses AWS services for an end-to-end implementation. 
 
The workflow consists of the following steps: 
 
 The user uploads a video asset to an Amazon Simple Storage Service (Amazon S3) bucket. 
 Amazon Elastic Container Service (Amazon ECS) is triggered to process the video asset. 
 Amazon ECS downsamples the frames, selects those containing the character, and then center-crops them to produce the final character images. 
 Amazon ECS invokes an Amazon Nova model (Amazon Nova Pro) from Amazon Bedrock to create captions from the images. 
 Amazon ECS writes the image captions and metadata to the S3 bucket. 
 The user uses a notebook environment in Amazon SageMaker AI to invoke the model training job. 
 The user fine-tunes a custom Amazon Nova Canvas model by invoking Amazon Bedrock create_model_customization_job and create_model_provisioned_throughput API calls to create a custom model available for inference. 
 
This workflow is structured in two distinct phases. The initial phase, in Steps 1‚Äì5, focuses on preparing the training data. In this post, we walk through an automated pipeline to extract images from an input video and then generate labeled training data. The second phase, in Steps 6‚Äì7, focuses on fine-tuning the Amazon Nova Canvas model and performing test inference using the custom-trained model. For these latter steps, we provide the preprocessed image data and comprehensive example code in the following GitHub repository to guide you through the process. 
Prepare the training data 
Let‚Äôs begin with the first phase of our workflow. In our example, we build an automated video object/character extraction pipeline to extract high-resolution images with accurate caption labels using the following steps. 
Creative character extraction 
We recommend first sampling video frames at fixed intervals (for example, 1 frame per second). Then, apply Amazon Rekognition label detection and face collection search to identify frames and characters of interest. Label detection can identify over 2,000 unique labels and locate their positions within frames, making it ideal for initial detection of general character categories or non-human characters. To distinguish between different characters, we then use the Amazon Rekognition feature to search faces in a collection. This feature identifies and tracks characters by matching their faces against a pre-populated face collection. If these two approaches aren‚Äôt precise enough, we can use Amazon Rekognition Custom Labels to train a custom model for detecting specific characters. The following diagram illustrates this workflow. 
 
After detection, we center-crop each character with appropriate pixel padding and then run a deduplication algorithm using the Amazon Titan Multimodal Embeddings model to remove semantically similar images above a threshold value. Doing so helps us build a diverse dataset because redundant or nearly identical frames could lead to model overfitting (when a model learns the training data too precisely, including its noise and fluctuations, making it perform poorly on new, unseen data). We can calibrate the similarity threshold to fine-tune what we consider to be identical images, so we can better control the balance between dataset diversity and redundancy elimination. 
Data labeling 
We generate captions for each image using Amazon Nova Pro in Amazon Bedrock and then upload the image and label manifest file to an Amazon S3 location. This process focuses on two critical aspects of prompt engineering: character description to help the FM identify and name the characters based on their unique attributes, and varied description generation that avoids repetitive patterns in the caption (for example, ‚Äúan animated character‚Äù). The following is an example prompt template used during our data labeling process: 
 
 system_prompt = """ 
    You are an expert image description specialist who creates concise, natural alt
    text that makes visual content accessible while maintaining clarity and focus.
    Your task is to analyze the provided image and provide a creative description
    (20-30 words) that emphasizes the Three main characters, capturing the essential
    elements of their interaction while avoiding unnecessary details.
"""

prompt = """
    
    1. Identify the main characters in the image: Character 1, Character 2, and
        Character 3 at least one will be in the picture so provide at a minimum a
        description with at least one character name.
      - "Character 1" describe the first character, key traits, background, attributes.
      - "Character 2" describe the second character, key traits, background, attributes.
      - "Character 3" describe the third character, key traits, background, attributes. 
    2. Just state their name WITHOUT adding any standard characteristics.
    3. Only capture visual element outside the standard characteristics
    4. Capture the core interaction between them
    5. Include only contextual details that are crucial for understanding the scene
    6. Create a natural, flowing description using everyday language
    
    Here are some examples
    
       ...
    
    
    
    [Identify the main characters]
    [Assessment of their primary interaction]
    [Selection of crucial contextual elements]
    [Crafting of concise, natural description]
    
    
    {
        "alt_text": "[Concise, natural description focusing on the main characters]"
    }
    
    
    Note: Provide only the JSON object as the final response. 
 
The data labeling output is formatted as a JSONL file, where each line pairs an image reference Amazon S3 path with a caption generated by Amazon Nova Pro. This JSONL file is then uploaded to Amazon S3 for training. The following is an example of the file: 
 
 {"image_ref": "s3://media-ip-dataset/characters/blue_character_01.jpg", "alt_text": "This
    animated character features a round face with large expressive eyes. The character
    has a distinctive blue color scheme with a small tuft of hair on top. The design is
    stylized with clean lines and a minimalist approach typical of modern animation."}
{"image_ref": "s3://media-ip-dataset/props/iconic_prop_series1.jpg", "alt_text": "This
    object appears to be an iconic prop from the franchise. It has a metallic appearance
    with distinctive engravings and a unique shape that fans would immediately recognize.
    The lighting highlights its dimensional qualities and fine details that make it
    instantly identifiable."} 
 
Human verification 
For enterprise use cases, we recommend incorporating a human-in-the-loop process to verify labeled data before proceeding with model training. This verification can be implemented using Amazon Augmented AI (Amazon A2I), a service that helps annotators verify both image and caption quality. For more details, refer to Get Started with Amazon Augmented AI. 
Fine-tune Amazon Nova Canvas 
Now that we have the training data, we can fine-tune the Amazon Nova Canvas model in Amazon Bedrock. Amazon Bedrock requires an AWS Identity and Access Management (IAM) service role to access the S3 bucket where you stored your model customization training data. For more details, see Model customization access and security. You can perform the fine-tuning task directly on the Amazon Bedrock console or use the Boto3 API. We explain both approaches in this post, and you can find the end-to-end code sample in picchu-finetuning.ipynb. 
Create a fine-tuning job on the Amazon Bedrock console 
Let‚Äôs start by creating an Amazon Nova Canvas fine-tuning job on the Amazon Bedrock console: 
 
 On the Amazon Bedrock console, in the navigation pane, choose Custom models under Foundation models. 
 Choose Customize model and then Create Fine-tuning job. 
 
 
 
 On the Create Fine-tuning job details page, choose the model you want to customize and enter a name for the fine-tuned model. 
 In the Job configuration section, enter a name for the job and optionally add tags to associate with it. 
 In the Input data section, enter the Amazon S3 location of the training dataset file. 
 In the Hyperparameters section, enter values for hyperparameters, as shown in the following screenshot. 
 
 
 
 In the Output data section, enter the Amazon S3 location where Amazon Bedrock should save the output of the job. 
 Choose Fine-tune model job to begin the fine-tuning process. 
 
This hyperparameter combination yielded good results during our experimentation. In general, increasing the learning rate makes the model train more aggressively, which often presents an interesting trade-off: we might achieve character consistency more quickly, but it might impact overall image quality. We recommend a systematic approach to adjusting hyperparameters. Start with the suggested batch size and learning rate, and try increasing or decreasing the number of training steps first. If the model struggles to learn your dataset even after 20,000 steps (the maximum allowed in Amazon Bedrock), then we suggest either increasing the batch size or adjusting the learning rate upward. These adjustments, through subtle, can make a significant difference in our model‚Äôs performance. For more details about the hyperparameters, refer to Hyperparameters for Creative Content Generation models. 
Create a fine-tuning job using the Python SDK 
The following Python code snippet creates the same fine-tuning job using the create_model_customization_job API: 
 
 bedrock = boto3.client('bedrock')
jobName =&nbsp;"picchu-canvas-v0"
# Set parameters
hyperParameters = {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"stepCount": "14000",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"batchSize": "64",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"learningRate": "0.000001",
&nbsp;&nbsp; &nbsp;}

# Create job
response_ft = bedrock.create_model_customization_job(
&nbsp;&nbsp; &nbsp;jobName=jobName,
&nbsp;&nbsp; &nbsp;customModelName=jobName,
&nbsp;&nbsp; &nbsp;roleArn=roleArn,
&nbsp;&nbsp; &nbsp;baseModelIdentifier="amazon.nova-canvas-v1:0",
&nbsp;&nbsp; &nbsp;hyperParameters=hyperParameters,
&nbsp;&nbsp; &nbsp;trainingDataConfig={"s3Uri": training_path},
&nbsp;&nbsp; &nbsp;outputDataConfig={"s3Uri": f"s3://{bucket}/{prefix}"}
)

jobArn = response_ft.get('jobArn')
print(jobArn) 
 
When the job is complete, you can retrieve the new customModelARN using the following code: 
 
 custom_model_arn = bedrock.list_model_customization_jobs(
&nbsp;&nbsp; &nbsp;nameContains=jobName
)["modelCustomizationJobSummaries"][0]["customModelArn"] 
 
Deploy the fine-tuned model 
With the preceding hyperparameter configuration, this fine-tuning job might take up to 12 hours to complete. When it‚Äôs complete, you should see a new model in the custom models list. You can then create provisioned throughput to host the model. For more details on provisioned throughput and different commitment plans, see Increase model invocation capacity with Provisioned Throughput in Amazon Bedrock. 
Deploy the model on the Amazon Bedrock console 
To deploy the model from the Amazon Bedrock console, complete the following steps: 
 
 On the Amazon Bedrock console, choose Custom models under Foundation models in the navigation pane. 
 Select the new custom model and choose Purchase provisioned throughput. 
 
 
 
 In the Provisioned Throughput details section, enter a name for the provisioned throughput. 
 Under Select model, choose the custom model you just created. 
 Then specify the commitment term and model units. 
 
 
After you purchase provisioned throughput, a new model Amazon Resource Name (ARN) is created. You can invoke this ARN when the provisioned throughput is in service. 
 
Deploy the model using the Python SDK 
The following Python code snippet creates provisioned throughput using the create_provisioned_model_throughput API: 
 
 custom_model_name =&nbsp;"picchu-canvas-v0"

# Create the provision throughput job and retrieve the provisioned model id
provisioned_model_id = bedrock.create_provisioned_model_throughput(
&nbsp;&nbsp; &nbsp;modelUnits=1,
&nbsp;&nbsp; &nbsp;# create a name for your provisioned throughput model
&nbsp;&nbsp; &nbsp;provisionedModelName=custom_model_name, 
&nbsp;&nbsp; &nbsp;modelId=custom_model_arn
)['provisionedModelArn'] 
 
Test the fine-tuned model 
When the provisioned throughput is live, we can use the following code snippet to test the custom model and experiment with generating some new images for a sequel to Picchu: 
 
 import json
import io
from PIL import Image
import base64

def decode_base64_image(img_b64):
    return Image.open(io.BytesIO(base64.b64decode(img_b64)))
    
def generate_image(prompt,
                   negative_prompt="text, ugly, blurry, distorted, low
                       quality, pixelated, watermark, text, deformed", 
                   num_of_images=3,
                   seed=1):
    """
    Generate an image using Amazon Nova Canvas.
    """

    image_gen_config = {
            "numberOfImages": num_of_images,
            "quality": "premium",
            "width": 1024,  # Maximum resolution 2048 x 2048
            "height": 1024,  # 1:1 ratio
            "cfgScale": 8.0,
            "seed": seed,
        }

    # Prepare the request body
    request_body = {
        "taskType": "TEXT_IMAGE",
        "textToImageParams": {
            "text": prompt,
            "negativeText": negative_prompt,  # List things to avoid
        },
        "imageGenerationConfig": image_gen_config
    } 

    response = bedrock_runtime.invoke_model(
        modelId=provisioned_model_id,
        body=json.dumps(request_body)
    )

    # Parse the response
    response_body = json.loads(response['body'].read())

    if "images" in response_body:
        # Extract the image
        return [decode_base64_image(img) for img in response_body['images']]
    else:
        return
seed = random.randint(1, 858993459)
print(f"seed: {seed}")

images = generate_image(prompt=prompt, seed=seed) 
 
 
  
   
    
    
    
   
   
   Mayu face shows a mix of nervousness and determination. Mommy kneels beside her, gently holder her. A landscape is visible in the background. 
   A steep cliff face with a long wooden ladder extending downwards. Halfway down the ladder is Mayu with a determined expression on her face. Mayu‚Äôs small hands grip the sides of the ladder tightly as she carefully places her feet on each rung. The surrounding environment shows a rugged, mountainous landscape. 
   Mayu standing proudly at the entrance of a simple school building. Her face beams with a wide smile, expressing pride and accomplishment. 
   
  
 
Clean up 
To avoid incurring AWS charges after you are done testing, complete the cleanup steps in picchu-finetuning.ipynb and delete the following resources: 
 
 Amazon SageMaker Studio domain 
 Fine-tuned Amazon Nova model and provision throughput endpoint 
 
Conclusion 
In this post, we demonstrated how to elevate character and style consistency in storyboarding from Part 1 by fine-tuning Amazon Nova Canvas in Amazon Bedrock. Our comprehensive workflow combines automated video processing, intelligent character extraction using Amazon Rekognition, and precise model customization using Amazon Bedrock to create a solution that maintains visual fidelity and dramatically accelerates the storyboarding process. By fine-tuning the Amazon Nova Canvas model on specific characters and styles, we‚Äôve achieved a level of consistency that surpasses standard prompt engineering, so creative teams can produce high-quality storyboards in hours rather than weeks. Start experimenting with Nova Canvas fine-tuning today, so you can also elevate your storytelling with better character and style consistency. 
 
About the authors 
Dr. Achin Jain is a Senior Applied Scientist at Amazon AGI, where he works on building multi-modal foundation models. He brings over 10+ years of combined industry and academic research experience. He has led the development of several modules for Amazon Nova Canvas and Amazon Titan Image Generator, including supervised fine-tuning (SFT), model customization, instant customization, and guidance with color palette. 
James Wu is a Senior AI/ML Specialist Solution Architect at AWS. helping customers design and build AI/ML solutions. James‚Äôs work covers a wide range of ML use cases, with a primary interest in computer vision, deep learning, and scaling ML across the enterprise. Prior to joining AWS, James was an architect, developer, and technology leader for over 10 years, including 6 years in engineering and 4 years in marketing &amp; advertising industries. 
Randy Ridgley is a Principal Solutions Architect focused on real-time analytics and AI. With expertise in designing data lakes and pipelines. Randy helps organizations transform diverse data streams into actionable insights. He specializes in IoT solutions, analytics, and infrastructure-as-code implementations. As an open-source contributor and technical leader, Randy provides deep technical knowledge to deliver scalable data solutions across enterprise environments.
‚Ä¢ Build character consistent storyboards using Amazon Nova in Amazon Bedrock ‚Äì Part 1
  The art of storyboarding stands as the cornerstone of modern content creation, weaving its essential role through filmmaking, animation, advertising, and UX design. Though traditionally, creators have relied on hand-drawn sequential illustrations to map their narratives, today‚Äôs AI foundation models (FMs) are transforming this landscape. FMs like Amazon Nova Canvas and Amazon Nova Reel offer capabilities in transforming text and image inputs into professional-grade visuals and short clips that promise to revolutionize preproduction workflows. 
This technological leap forward, however, presents its own set of challenges. Although these models excel at generating diverse concepts rapidly‚Äîa boon for creative exploration‚Äîmaintaining consistent character designs and stylistic coherence across scenes remains a significant hurdle. Even subtle modifications to prompts or model configurations can yield dramatically different visual outputs, potentially disrupting narrative continuity and creating additional work for content creators. 
To address these challenges, we‚Äôve developed this two-part series exploring practical solutions for achieving visual consistency. In Part 1, we deep dive into prompt engineering and character development pipelines, sharing tested prompt patterns that deliver reliable, consistent results with Amazon Nova Canvas and Amazon Nova Reel. Part 2 explores techniques like fine-tuning Amazon Nova Canvas to achieve exceptional visual consistency and precise character control. 
 
  
   
    
    
    
   
  
 
Consistent character design with Amazon Nova Canvas 
The foundation of effective storyboarding begins with establishing well-defined character designs. Amazon Nova Canvas offers several powerful techniques to create and maintain character consistency throughout your visual narrative. To help you implement these techniques in your own projects, we‚Äôve provided comprehensive code examples and resources in our GitHub repository. We encourage you to follow along as we walk through each step in detail. If you‚Äôre new to Amazon Nova Canvas, we recommend first reviewing Generating images with Amazon Nova to familiarize yourself with the basic concepts. 
Basic text prompting 
Amazon Nova Canvas transforms text descriptions into visual representations. Unlike large language models (LLMs), image generation models don‚Äôt interpret commands or engage in reasoning‚Äîthey respond best to descriptive captions. Including specific details in your prompts, such as physical attributes, clothing, and styling elements, directly influences the generated output. 
For example, ‚ÄúA 7-year-old Peruvian girl with dark hair in two low braids wearing a school uniform‚Äù provides clear visual elements for the model to generate an initial character concept, as shown in the following example image. 
 
Visual style implementation 
Consistency in storyboarding requires both character features and unified visual style. Our approach separates style information into two key components in the prompt: 
 
 Style description ‚Äì An opening phrase that defines the visual medium (for example, ‚ÄúA graphic novel style illustration of‚Äù) 
 Style details ‚Äì A closing phrase that specifies artistic elements (for example, ‚ÄúBold linework, dramatic shadows, flat color palettes‚Äù) 
 
This structured technique enables exploration of various artistic styles, including graphic novels, sketches, and 3D illustrations, while maintaining character consistency throughout the storyboard. The following is an example prompt template and some style information you can experiment with: 
 
 {style_description} A 7 year old peruvian girl with dark hair in two low braids wearing a
    school uniform. {style_details}
styles = [
    {
        "name": "graphic-novel",
        "description": "A graphic novel style illustation of",
        "details": "Bold linework, dramatic shadows, and flat color palettes. Use
            high contrast lighting and cinematic composition typical of comic book
            panels. Include expressive line work to convey emotion and movement.",
    },
    {
        "name": "sketch",
        "description": "A simple black and white line sketch of",
        "details": "Rough, sketch-like lines create a storyboard aesthetic. High
            contrast. No color",
    },
    {
        "name": "digital-illustration",
        "description": "A 3D digital drawing of",
        "details": "High contrast. Rounded character design. Smooth rendering.
            Soft texture. Luminous lighting",
    },
] 
 
 
Character variation through seed values 
The seed parameter serves as a tool for generating character variations while adhering to the same prompt. By keeping the text description constant and varying only the seed value, creators can explore multiple interpretations of their character design without starting from scratch, as illustrated in the following example images. 
 
  
   
    
   
   
    Seed = 1  
    Seed = 20  
    Seed = 57  
    Seed = 139  
    Seed = 12222  
   
  
 
Prompt adherence control with cfgScale 
The cfgScale parameter is another tool for maintaining character consistency, controlling how strictly Amazon Nova Canvas follows your prompt. Operating on a scale from 1.1‚Äì10, lower values give the model more creative freedom and higher values enforce strict prompt adherence. The default value of 6.5 typically provides an optimal balance, but as demonstrated in the following images, finding the right setting is crucial. Too low a value can result in inconsistent character representations, whereas too high a value might overemphasize prompt elements at the cost of natural composition. 
 
  
   
    
   
   
   Seed = 57, cfgScale = 1.1 
   Seed = 57, cfgScale = 3.5 
   Seed = 57, cfgScale = 6.5 
   Seed = 57, cfgScale = 8.0 
   Seed = 57, cfgScale = 10 
   
  
 
Scene integration with consistent parameters 
Now we can put these techniques together to test for character consistency across different narrative contexts, as shown in the following example images. We maintain consistent input for style, seed, and cfgScale, varying only the scene description to make sure character remains recognizable throughout the scene sequences. 
 
  
   
    
    
    
   
   
   Seed = 57, Cfg_scale: 6.5 
   Seed = 57, Cfg_scale: 6.5 
   Seed = 57, Cfg_scale: 6.5 
   
   
   A graphic novel style illustration of a 7 year old Peruvian girl with dark hair in two low braids wearing a school uniform riding a bike on a mountain pass Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement. 
   A graphic novel style illustation of a 7 year old Peruvian girl with dark hair in two low braids wearing a school uniform walking on a path through tall grass in the Andes Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement. 
   A graphic novel style illustration of a 7 year old Peruvian girl with dark hair in two low braids wearing a school uniform eating ice cream at the beach Bold linework, dramatic shadows, and flat color palettes. Use high contrast lighting and cinematic composition typical of comic book panels. Include expressive line work to convey emotion and movement. 
   
  
 
Storyboard development pipeline 
Building upon the character consistency techniques we‚Äôve discussed, we can now implement an end-to-end storyboard development pipeline that transforms written scene and character descriptions into visually coherent storyboards. This systematic approach uses our established parameters for style descriptions, seed values, and cfgScale values to provide character consistency while adapting to different narrative contexts. The following are some example scene and character descriptions: 
 
 "scenes":[
    {
        "description": "Mayu stands at the edge of a mountainous path, clutching
            a book. Her mother, Maya, kneels beside her, offering words of encouragement
            and handing her the book. Mayu looks nervous but determined as she prepares
            to start her journey."
    },
    {
        "description": "Mayu encounters a 'danger' sign with a drawing of a
            snake. She looks scared, but then remembers her mother's words. She takes a
            deep breath, looks at her book for reassurance, and then searches for a stick
            on the ground."
    },
    {
        "description": "Mayu bravely makes her way through tall grass, swinging
            her stick and making noise to scare off potential snakes. Her face shows a
            mix of fear and courage as she pushes forward on her journey."
    }
],
"characters":{
    "Mayu":  "A 7-year-old Peruvian girl with dark hair in two low braids wearing a
        school uniform",
    "Maya":  "An older Peruvian woman with long dark hair tied back in a bun, wearing
        traditional Peruvian clothing"
}
 
 
 
Our pipeline uses Amazon Nova Lite to first craft optimized image prompts incorporating our established best practices, which are then passed to Amazon Nova Canvas for image generation. By setting numberOfImages higher (typically three variations), while maintaining consistent seed and cfgScale values, we give creators multiple options that preserve character consistency. We used the following prompt for Amazon Nova Lite to generate optimized image prompts: 
 
 Describe an image that best represents the scene described. Here are some examples:
scene: Rosa is in the kitchen, rummaging through the pantry, looking for a snack. She
    hears a strange noise coming from the back of the pantry and becomes startled.
imagery: A dimly lit pantry with shelves stocked with various food items, and Rosa
    peering inside, her face expressing curiosity and a hint of fear.
scene: Rosa says goodbye to her mother, Maya. Maya offers her words of encouragement.
imagery: A wide shot of Rosa's determined face, facing Maya and receiving a small wrapped
    gift.
Only describe the imagery. Use no more than 60 words.
scene: {scene_description}
imagery:
 
 
Our pipeline generated the following storyboard panels. 
 
  
   
    
   Mayu stands at the edge of a mountainous path, clutching a book. Her mother, Maya, kneels beside her, offering words of encouragement and handing her the book. Mayu looks nervous but determined as she prepares to start her journey. 
   
   
    
   Mayu encounters a ‚Äòdanger‚Äô sign with a drawing of a snake. She looks scared, but then remembers her mother‚Äôs words. She takes a deep breath, looks at her book for reassurance, and then searches for a stick on the ground. 
   
   
    
   Mayu bravely makes her way through tall grass, swinging her stick and making noise to scare off potential snakes. Her face shows a mix of fear and courage as she pushes forward on her journey. 
   
  
 
Although these techniques noticeably improve character consistency, they aren‚Äôt perfect. Upon closer inspection, you will notice that even images within the same scene show variations in character consistency. Using consistent seed values helps control these variations, and the techniques outlined in this post significantly improve consistency compared to basic prompt engineering. However, if your use case requires near-perfect character consistency, we recommend proceeding to Part 2, where we explore advanced fine-tuning techniques. 
Video generation for animated storyboards 
If you want to go beyond static scene images to transform your storyboard into short, animated video clips, you can use Amazon Nova Reel. We use Amazon Nova Lite to convert image prompts into video prompts, adding subtle motion and camera movements optimized for the Amazon Nova Reel model. These prompts, along with the original images, serve as creative constraints for Amazon Nova Reel to generate the final animated sequences. The following is the example prompt and its resulting animated scene in GIF format: 
 
 A sunlit forest path with a 'Danger' sign featuring a snake. A 7-year-old Peruvian girl
    stands, visibly scared but resolute. Bold linework, dramatic shadows, and flat color
    palettes. High contrast lighting and cinematic composition. Mist slowly drifting.
    Camera dolly in. 
 
 
  
   
    
    
   
   
   Input Image 
   Output Video 
   
  
 
Conclusion 
In this first part of our series, we explored fundamental techniques for achieving character and style consistency using Amazon Nova Canvas, from structured prompt engineering to building an end-to-end storyboarding pipeline. We demonstrated how combining style descriptions, seed values, and careful cfgScale parameter control can significantly improve character consistency across different scenes. We also showed how integrating Amazon Nova Lite with Amazon Nova Reel can enhance the storyboarding workflow, enabling both optimized prompt generation and animated sequences. 
Although these techniques provide a solid foundation for consistent storyboard generation, they aren‚Äôt perfect‚Äîsubtle variations might still occur. We invite you to continue to Part 2, where we explore advanced model fine-tuning techniques that can help achieve near-perfect character consistency and visual fidelity. 
 
About the authors 
Alex Burkleaux is a Senior AI/ML Specialist Solution Architect at AWS. She helps customers use AI Services to build media solutions using Generative AI. Her industry experience includes over-the-top video, database management systems, and reliability engineering. 
James Wu is a Senior AI/ML Specialist Solution Architect at AWS, helping customers design and build AI/ML solutions. James‚Äôs work covers a wide range of ML use cases, with a primary interest in computer vision, deep learning, and scaling ML across the enterprise. Prior to joining AWS, James was an architect, developer, and technology leader for over 10 years, including 6 years in engineering and 4 years in marketing &amp; advertising industries. 
Vladimir Budilov is a Principal Solutions Architect at AWS focusing on agentic &amp; generative AI, and software architecture. He leads large-scale GenAI implementations, bridging cutting-edge AI capabilities with production-ready business solutions, while optimizing for cost and solution resilience. 
Nora Shannon Johnson is a Solutions Architect at Amazon Music focused on discovery and growth through AI/ML. In the past, she supported AWS through the development of generative AI prototypes and tools for developers in financial services, health care, retail, and more. She has been an engineer and consultant in various industries including DevOps, fintech, industrial AI/ML, and edtech in the United States, Europe, and Latin America. 
Ehsan Shokrgozar is a Senior Solutions Architect specializing in Media and Entertainment at AWS. He is passionate about helping M&amp;E customers build more efficient workflows. He combines his previous experience as Technical Director and Pipeline Engineer at various Animation/VFX studios with his knowledge of building M&amp;E workflows in the cloud to help customers achieve their business goals.
‚Ä¢ Authenticate Amazon Q Business data accessors using a trusted token issuer
  Since its general availability in 2024, Amazon Q Business (Amazon Q) has enabled independent software vendors (ISVs) to enhance their Software as a Service (SaaS) solutions through secure access to customers‚Äô enterprise data by becoming Amazon Q Business data accessor. To find out more on data accessor, see this page. The data accessor now supports trusted identity propagation. With trusted token issuer (TTI) authorization support, ISVs as data accessor can integrate with Amazon Q index while maintaining enterprise-grade security standards for their software-as-a-service (SaaS) solutions. 
Prior to TTI support, data accessors needed to implement authorization code flow with AWS IAM Identity Center integration when accessing the Amazon Q index. With TTI support for data accessors, ISVs can now use their own OpenID Provider to authenticate enterprise users, alleviating the need for double authentication while maintaining security standards. 
In this blog post, we show you how to implement TTI authorization for data accessors, compare authentication options, and provide step-by-step guidance for both ISVs and enterprises. 
Prerequisites 
Before you begin, make sure you have the following requirements: 
 
 An AWS account with administrator access 
 Access to Amazon Q Business 
 For ISVs: 
   
   An OpenID Connect (OIDC) compatible authorization server 
    
 For enterprises: 
   
   Amazon Q Business administrator access 
   Permission to create trusted token issuers 
    
 
Solution Overview 
This solution demonstrates how to implement TTI authentication for Amazon Q Business data accessors. The following diagram illustrates the overall flow between different resources, from ISV becoming a data accessor, customer enabling ISV data accessor, to ISV accessing customer‚Äôs Amazon Q index: 
 
Understanding Trusted Token Issuer Authentication 
Trusted Token Issuer represents an advanced identity integration capability for Amazon Q. At its core, TTI is a token exchange API that propagates identity information into IAM role sessions, enabling AWS services to make authorization decisions based on the actual end user‚Äôs identity and group memberships. This mechanism allows AWS services to apply authorization and security controls based on the authenticated user context. The TTI support simplifies the identity integration process while maintaining robust security standards, making it possible for organizations to ensure that access to Amazon Q respects user-level permissions and group memberships. This enables fine-grained access control and maintains proper security governance within Amazon Q implementations. 
Trusted Token Issuer authentication simplifies the identity integration process for Amazon Q by enabling the propagation of user identity information into AWS IAM role sessions. Each token exchange allows AWS services to make authorization decisions based on the authenticated user‚Äôs identity and group memberships. The TTI support streamlines the integration process while maintaining robust security standards, enabling organizations to implement appropriate access controls within their Amazon Q implementations. 
Understanding Data Accessors 
A data accessor is an ISV that has registered with AWS and is authorized to use their customers‚Äô Amazon Q index for the ISV‚Äôs Large Language Model (LLM) solution. The process begins with ISV registration, where they provide configuration information including display name, business logo, and OpenID Connect (OIDC) configuration details for TTI support. 
During ISV registration, providers must specify their tenantId configuration ‚Äì a unique identifier for their application tenant. This identifier might be known by different names in various applications (such as Workspace ID in Slack or Domain ID in Asana) and is required for proper customer isolation in multi-tenant environments. 
Amazon Q customers then add the ISV as a data accessor to their environment, granting access to their Amazon Q index based on specific permissions and data source selections. Once authorized, the ISV can query the customers‚Äô index through API requests using their TTI authentication flow, creating a secure and controlled pathway for accessing customer data. 
Implementing TTI Authentication for Amazon Q index Access 
This section explains how to implement TTI authentication for accessing the Amazon Q index. The implementation involves initial setup by the customer and subsequent authentication flow implemented by data accessors for user access. 
TTI provides capabilities that enable identity-enhanced IAM role sessions through Trusted Identity Propagation (TIP), allowing AWS services to make authorization decisions based on authenticated user identities and group memberships. Here‚Äôs how it works: 
To enable data accessor access to a customer‚Äôs Amazon Q index through TTI, customers must perform an initial one-time setup by adding a data accessor on Amazon Q Business application. During setup, a TTI with the data accessor‚Äôs identity provider information is created in the customer‚Äôs AWS IAM Identity Center, allowing the data accessor‚Äôs identity provider to authenticate access to the customer‚Äôs Amazon Q index. 
 
The process to set up an ISV data accessor with TTI authentication consists of the following steps: 
 
 The customer‚Äôs IT administrator accesses their Amazon Q Business application and creates a trusted token issuer with the ISV‚Äôs OAuth information. This returns a TrustedTokenIssuer (TTI) Amazon Resource Name (ARN).  
 The IT administrator creates an ISV data accessor with the TTI ARN received in Step 1.  
 Amazon Q Business confirms the provided TTI ARN with AWS IAM Identity Center and creates a data accessor application. 
 Upon successful creation of the ISV data accessor, the IT administrator receives data accessor details to share with the ISV.  
 The IT administrator provides these details to the ISV application. 
 
Once the data accessor setup is complete in the customer‚Äôs Amazon Q environment, users can access the Amazon Q index through the ISV application by authenticating only against the data accessor‚Äôs identity provider. 
 
The authentication flow proceeds as follows: 
 
 A user authenticates against the data accessor‚Äôs identity provider through the ISV application. The ISV application receives an ID token for that user, generated from the ISV‚Äôs identity provider with the same client ID registered on their data accessor. 
 The ISV application needs to use the AWS Identity and Access Management (IAM) role that they created during the data accessor onboarding process by calling AssumeRole API, then make CreateTokenWithIAM API request to the customer‚Äôs AWS IAM Identity Center with the ID token. AWS IAM Identity Center validates the ID token with the ISV‚Äôs identity provider and returns an IAM Identity Center token. 
 The ISV application requests an AssumeRole API with: IAM Identity Center token, extracted identity context, and tenantId. The tenantId is a security control jointly established between the ISV and their customer, with the customer maintaining control over how it‚Äôs used in their trust relationships. This combination facilitates secure access to the correct customer environment. 
 The ISV application calls the SearchRelevantContent API with the session credentials and receives relevant content from the customer‚Äôs Amazon Q index. 
 
Choosing between TTI and Authorization Code 
When implementing Amazon Q integration, ISVs need to consider two approaches, each with its own benefits and considerations: 
 
  
   
    
   Trusted Token Issuer 
   Authorization Code 
   
   
   Advantages 
   Single authentication on the ISV system 
   Enhanced security through mandatory user initiation for each session 
   
   
   Enables backend-only access to SearchRelevantContent API without user interaction 
    
   
   
   Considerations 
   Some enterprises may prefer authentication flows that require explicit user consent for each session, providing additional control over API access timing and duration 
   Requires double authentication on the ISV system 
   
   
   Requires ISVs to host and maintain OpenID Provider 
    
   
  
 
TTI excels in providing a seamless user experience through single authentication on the ISV system and enables backend-only implementations for SearchRelevantContent API access without requiring direct user interaction. However, this approach requires ISVs to maintain their own OIDC authorization server, which may present implementation challenges for some organizations. Additionally, some enterprises might have concerns about ISVs having persistent ability to make API requests on behalf of their users without explicit per-session authorization. 
Next Steps 
For ISVs: Becoming a Data Accessor with TTI Authentication 
Getting started on Amazon Q data accessor registration process with TTI authentication is straightforward. If you already have an OIDC compatible authorization server for your application‚Äôs authentication, you‚Äôre most of the way there. 
To begin the registration process, you‚Äôll need to provide the following information: 
 
 Display name and business logo that will be displayed on AWS Management Console 
 OIDC configuration details (OIDC ClientId and discovery endpoint URL) 
 TenantID configuration details that specify how your application identifies different customer environments 
 
For details, see Information to be provided to the Amazon Q Business team. 
For ISVs using Amazon Cognito as their OIDC authorization server, here‚Äôs how to retrieve the required OIDC configuration details: 
 
 To get the OIDC ClientId:- Navigate to the Amazon Cognito console- Select your User Pool- Go to ‚ÄúApplications‚Äù &gt; ‚ÄúApp clients‚Äù- The ClientId is listed under ‚ÄúClient ID‚Äù for your app client 
 To get the discovery endpoint URL:- The URL follows this format:https://cognito-idp.{region}.amazonaws.com/{userPoolId}/.well-known/openid-configuration‚Äì Replace {region} with your AWS region (e.g., us-east-1)- Replace {userPoolId} with your Cognito User Pool IDFor example, if your User Pool is in us-east-1 with ID ‚Äòus-east-1_abcd1234‚Äô, your discovery endpoint URL would be: https://cognito-idp.us-east-1.amazonaws.com/us-east-1_abcd1234/.well-known/openid-configuration 
 
 
Note: While this example uses Amazon Cognito, the process will vary depending on your OIDC provider. Common providers like Auth0, Okta, or custom implementations will have their own methods for accessing these configuration details. 
Once registered, you can enhance your generative AI application with the powerful capabilities of Amazon Q, allowing your customers to access their enterprise knowledge base through your familiar interface. AWS provides comprehensive documentation and support to help you implement the authentication flow and API integration efficiently. 
For Enterprises: Enabling TTI-authenticated Data Accessor 
To enable a TTI-authenticated data accessor, your IT administrator needs to complete the following steps in the Amazon Q console: 
 
 Create a trusted token issuer using the ISV‚Äôs OAuth information 
 Set up the data accessor with the generated TTI ARN 
 Configure appropriate data source access permissions 
 
This streamlined setup allows your users to access Amazon Q index through the ISV‚Äôs application using their existing ISV application credentials, alleviating the need for multiple logins while maintaining security controls over your enterprise data. 
Both ISVs and enterprises benefit from AWS‚Äôs comprehensive documentation and support throughout the implementation process, facilitating a smooth and secure integration experience. 
Clean up resources 
To avoid unused resources, follow these steps if you no longer need the data accessor: 
 
 Delete the data accessor: 
   
   On the Amazon Q Business console, choose Data accessors in the navigation pane 
   Select your data accessor and choose Delete. 
    
 Delete the TTI: 
   
   On the IAM Identity Center console, choose Trusted Token Issuers in the navigation pane. 
   Select the associated issuer and choose Delete. 
    
 
Conclusion 
The introduction of Trusted Token Issuer (TTI) authentication for Amazon Q data accessors marks a significant advancement in how ISVs integrate with Amazon Q Business. By enabling data accessors to use their existing OIDC infrastructure, we‚Äôve alleviated the need for double authentication while maintaining enterprise-grade security standards through TTI‚Äôs robust tenant isolation mechanisms and secure multi-tenant access controls, making sure each customer‚Äôs data remains protected within their dedicated environment. This streamlined approach not only enhances the end-user experience but also simplifies the integration process for ISVs building generative AI solutions. 
In this post, we showed how to implement TTI authentication for Amazon Q data accessors. We covered the setup process for both ISVs and enterprises and demonstrated how TTI authentication simplifies the user experience while maintaining security standards. 
To learn more about Amazon Q Business and data accessor integration, refer to Share your enterprise data with data accessors using Amazon Q index and Information to be provided to the Amazon Q Business team. You can also contact your AWS account team for personalized guidance. Visit the Amazon Q Business console to begin using these enhanced authentication capabilities today. 
 
About the Authors 
Takeshi Kobayashi is a Senior AI/ML Solutions Architect within the Amazon Q Business team, responsible for developing advanced AI/ML solutions for enterprise customers. With over 14 years of experience at Amazon in AWS, AI/ML, and technology, Takeshi is dedicated to leveraging generative AI and AWS services to build innovative solutions that address customer needs. Based in Seattle, WA, Takeshi is passionate about pushing the boundaries of artificial intelligence and machine learning technologies. 
Siddhant Gupta is a Software Development Manager on the Amazon Q team based in Seattle, WA. He is driving innovation and development in cutting-edge AI-powered solutions. 
Akhilesh Amara is a Software Development Engineer on the Amazon Q team based in Seattle, WA. He is contributing to the development and enhancement of intelligent and innovative AI tools.

‚∏ª