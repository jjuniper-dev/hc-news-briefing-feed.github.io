âœ… Morning News Briefing â€“ August 13, 2025 10:48

ğŸ“… Date: 2025-08-13 10:48
ğŸ·ï¸ Tags: #briefing #ai #publichealth #digitalgov

â¸»

ğŸ§¾ Weather
â€¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
â€¢ Current Conditions: Light Rainshower, 22.6Â°C
  Temperature: 22.6&deg;C Pressure / Tendency: 100.9 kPa falling Visibility: 16 km Humidity: 82 % Humidex: 30 Dewpoint: 19.4&deg:C Wind:  calm km/h Air Quality Health Index: n/a . Rainfall: Light Rainshower, with a light rainfall of 22.
â€¢ Wednesday: Chance of showers. High 28. POP 70%
  A mix of sun and cloud with 70 percent chance of showers this morning . Risk of a thunderstorm. Clearing this afternoon. Risk of thunderstorm . High 28. Humidex 35. UV index 7 or high. Chance of showers changing to 30 percent for the rest of the day . Chance of rain is 70 percent, with risk of thunderstorms at risk of heavy rain .

ğŸŒ International News
No updates.

ğŸ Canadian News
No updates.

ğŸ‡ºğŸ‡¸ U.S. Top Stories
â€¢ With replay review and 'robot umps,' who is still trying to become an MLB umpire?
  The work of baseball umpires has been transformed by technology in recent years . But none of that has deterred aspiring Umpires from becoming a professional umpirator . Social media and replay review have also been used in the umpiring video game . The video game has been viewed as a viral hit on social media and as a result of a viral video game on social
â€¢ High prices and healthcare costs may turn Latino voters away from Republicans in 2026
  Latino voters helped deliver the White House to President Trump in the last election . Many of them already say they won't vote for Republicans next year, but they aren't yet turning to Democrats . Many Latino voters are already turning to Republicans, but not Democrats, they say they're not yet turning toward Democrats . They say they will not turn to Democrats in the next year's midterm elections .
â€¢ Inside one of the most understaffed immigration courts in the country
  The Chelmsford, Mass., court has hemorrhaged judges, a consequence of the Trump administration's seemingly contradictory efforts to downsize the federal government and increase immigration arrests . The court is hemorrhaging judges, as a result of the administration's efforts to reduce federal government size and make immigration arrests more difficult . The federal court has been reduced to a fraction of federal judges in less than a
â€¢ Why a good pep talk doesn't always need to include advice
  The authors of the book Tiny Pep Talks explain how to deliver a message that motivates and inspires . The book is available on Amazon.com for $99.99 . The authors say how to say a few words of encouragement to your loved one or yourself can be found at www.tiny.com/tinypontpont.com . For more information, visit tinyp
â€¢ Help is growing for the heavy emotional toll cancer takes on young men
  Coping with cancer and its aftermath isn't easy for anyone . But men tend to isolate more, seek less support and, alarmingly, die earlier than women . Young survivors are working to change that, especially among men, who tend to live longer . Young men are working hard to change the trend, especially in the U.S. and around the world, to do so .

ğŸ§  Artificial Intelligence
No updates.

ğŸ’» Digital Strategy
â€¢ Marc Andreessen wades into the UK's Online Safety Act furor
  Marc Andreessen accuses the UK government of leaking his input to the UK's Online Safety Act . The billionaire techpreneur is not a fan of the online safety act . Andreessen says the government leaked his opinion of the act to the government . He says the law was leaked by the government to the public, and that the government had been leaking it to him . The U.
â€¢ Microsoft wares may be UK public sector's only viable option
  Microsoft is in the spotlight for the UK government's Â£1.9 billion a year in software licensing, and roughly Â£9 billion over five years . Not surprisingly, there are plenty of voices challenging whether this is good use of public money . For now at least at least, even though government buying can improve, open source is not all it's cracked up to be Debate can improve .
â€¢ Secure chat darling Matrix admits pair of 'high severity' protocol flaws need painful fixes
  Foundation warns federated servers face biggest risk, but single-instance users can take their time . The maintainers of the federated secure chat protocol Matrix are warning users of a pair of "high severity protocol vulnerabilities" addressed in the latest version . They say patching them requires a breaking change in servers and clients, and patching it requires a new change in clients and servers and servers
â€¢ Some users report their Firefox browser is scoffing CPU power
  People are noticing Firefox gobbling extra CPU and electricity, apparently caused by an "inference engine" built into recent versions of Firefox . Don't say El Reg didn't try to warn you, it's a so-called AI built into the software . Firefox users are noticing it's causing extra CPU, electricity and CPU usage . It's not the first time El Reg has tried to
â€¢ I started losing my digital privacy in 1974, aged 11
  An encounter with the healthcare system reveals sickening decisions about data . We already live in a world where pretty much every public act - online or in the real world - leaves a mark in a database somewhere . But how far back does that record extend? I recently learned that record goes back further than I'd seriously imagined.â€¦â€¦â€¦ And how far further it extends? We need to

ğŸ¥ Public Health
No updates.

ğŸ”¬ Science
â€¢ Leveraging large language models for the deidentification and temporal normalization of sensitive health information in electronic health records
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Association between temperature rise from climate normal and sleep quality
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Biological and health effects of fire smoke exposure
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ â€˜A whole body of health-equity research is being disappearedâ€™ â€” why I resigned from the NIH
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Association between social capital and depressive symptoms in adolescents relocated for poverty alleviation in Shanxi, China: a cross-sectional study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

ğŸ§¾ Government & Policy
No updates.

ğŸ›ï¸ Enterprise Architecture & IT Governance
No updates.

ğŸ¤– AI & Emerging Tech
â€¢ Why Trumpâ€™s â€œgolden domeâ€ missile defense idea is another ripped straight from the movies
  In 1940, a fresh-faced Ronald Reagan starred as US Secret Service agent Brass Bancroft in Murder in the Air, an action film centered on a fictional â€œsuperweaponâ€ that could stop enemy aircraft midflight. A mock newspaper in the movie hails it as the â€œgreatest peace argument ever invented.â€ The experimental weapon is â€œthe exclusive property of Uncle Sam,â€ Reaganâ€™s character declares.



More than 40 years later, this cinematic visionâ€”an American superweapon capable of neutralizing assaults and ushering in global peaceâ€”became a real-life centerpiece of Reaganâ€™s presidency. Some have suggested that Reaganâ€™s Strategic Defense Initiative (SDI), a quixotic plan for a space-based missile shield, may have been partly inspired by his silver-screen past; indeed, the concept was so fantastical itâ€™s now better known by its Hollywood-referencing nickname, â€œStar Wars.â€



In January 2024, Donald Trump revived the space-shield dream at a primary campaign rally in Laconia, New Hampshire, using the Star Wars nickname that Reagan hated. It didnâ€™t work in the 1980s, Trump said, because the technology wasnâ€™t there. But times have changed.&nbsp;




Whether in Golden Age Hollywood or Trumpâ€™s impromptu dramatizations, the dream of a missile shield is animated by its sheer cinematic allure.




â€œIâ€™ve seen so many things. Iâ€™ve seen shots that you wouldnâ€™t even believe,â€ Trump said. He acted out a scene of missile defense experts triangulating the path of an incoming weapon. â€œDing, ding, ding, ding,â€ he said, as he mimed typing on a keyboard. â€œMissile launch? Psshing!!â€ He raised his hand to indicate the rising missile, then let it fall to signal the successful interception: â€œBoom.â€&nbsp;



Trump has often expressed admiration for Israelâ€™s Iron Dome, an air defense system that can intercept short-range rockets and artillery over the small nation and that is funded in part by the United States. At the rally, he pledged to â€œbuild an Iron Dome over our country, a state-of-the-art missile defense shield made in the USA â€¦ a lot of it right here in New Hampshire, actually.â€&nbsp;



Within a week of his inauguration, President Trump began working toward this promise by issuing an executive order to develop â€œThe Iron Dome for America,â€ which was rebranded the â€œGolden Domeâ€ a month later. The eruption of a revived conflict between Israel and Iran in Juneâ€”including Trumpâ€™s decision to strike Iranâ€™s nuclear facilitiesâ€”has only strengthened the case for an American version of the Iron Dome in the eyes of the administration.



CHIP SOMODEVILLA/GETTY IMAGES




The Golden Dome has often been compared to SDI for its futuristic sheen, its aggressive form of protection, and its reflection of the belief that an impenetrable shield is the cheat code to global peace. Both efforts demonstrate the performative power of spectacle in defense policy, especially when wielded by deft showmen like Reagan and Trump. Whether in Golden Age Hollywood or Trumpâ€™s impromptu dramatizations, the dream of a missile shield is animated by its sheer cinematic allure, often rendered in deceptively simple concept art depicting a society made immune to catastrophic strikes.&nbsp;



But in the complicated security landscape confronting the world today, is spectacle the same as safety?



â€œMissile defense is an area where facts and fiction blend,â€ says Anette Stimmer, a lecturer in international relations at the University of St Andrews who has researched SDI. â€œA lot is up to interpretation by all the actors involved.â€







Trumpâ€™s view is simple: Space is as much a warfighting domain as land, air, and ocean, and therefore the US must assert its dominance there with advanced technologies. This position inspired the creation of the US Space Force in his first term, and Trump has now redoubled his efforts with the ongoing development of the Golden Dome.&nbsp;&nbsp;





General Michael Guetlein, who Trump has appointed to lead the Golden Dome project, argued that Americaâ€™s foes, including China and Russia, have forced the nationâ€™s hand by continually pushing limits in their own weapons programs. â€œWhile we have been focused on peace overseas, our adversaries have been quickly modernizing their nuclear forces, building out ballistic missiles capable of hosting multiple warheads; building out hypersonic missiles capable of attacking the United States within an hour and traveling at 6,000 miles an hour; building cruise missiles that can navigate around our radar and our defenses; and building submarines that can sneak up on our shores; and, worse yet, building space weapons,â€ Guetlein said in May.



â€œIt is time that we change that equation and start doubling down on the protection of the homeland,â€ he said. â€œGolden Dome is a bold and aggressive approach to hurry up and protect the homeland from our adversaries. We owe it to our children and our childrenâ€™s children to protect them and afford them a quality of life that we have all grown up enjoying.â€



With that vision in mind, Trumpâ€™s executive order outlines a host of goals for missile defense, some of which support bipartisan priorities like protecting supply chains and upgrading sensor arrays. The specific architecture of the Golden Dome is still being hammered out, but the initial executive order envisions a multi-tiered system of new sensors and interceptorsâ€”on the ground, in the air, and in spaceâ€”that would work together to counter the threat of attacks from ballistic, hypersonic, and cruise missiles. The system would be coordinated in part by artificial-intelligence models trained for real-time threat detection and response.Â 



The technology that links the Golden Dome directly to SDI hinges on one key bullet point in the order that demands the â€œdevelopment and deployment of proliferated space-based interceptors capable of boost-phase intercept.â€ This language revives Reaganâ€™s dream of deploying hundreds of missile interceptors in orbit to target missiles in the boost phase right after liftoff, a window of just a few minutes when the projectiles are slower and still near the attackerâ€™s territory.



Space weapons are an attractive option for targeting the boost phase because interceptors need to be close enough to the launching missile to hit it. If a nation fired off long-range missiles from deep in its territory, the nearest ground- or air-based interceptors could be thousands of miles from the launch site. Space interceptors, in contrast, would be just a few hundred miles overhead of the ascending missiles, allowing for a much faster reaction time. But though the dream of boost-phase interception dates back decades, these maneuvers have never been operationally demonstrated from ground, air, or space.





â€œItâ€™s a really hard problem that hasnâ€™t been solved,â€ says Laura Grego, senior scientist and research director at the Union of Concerned Scientistsâ€™ global security program.



The US is currently protected by the Ground-Based Midcourse Defense (GMD), which consists of 44 interceptor missiles split between bases in Alaska and California, along with a network of early-Â­warning sensors on the ground, at sea, and in orbit. Tests suggest that the GMD would have about a 50% success rate at intercepting missiles.



Initiated by President Bill Clinton in the late â€™90s and accelerated by President George W. Bush in the 2000s, the GMD is intended mainly to defend against rogue states like North Korea, which has nuclear weapons and intercontinental ballistic missiles (ICBMs) capable of reaching the US. A secondary focus is Iran, which does not currently have a nuclear weapon or ICBMs. Still, the GMD is built to anticipate a possible future where it develops those capabilities.&nbsp;



The GMD is not designed to protect the US from the sort of large-scale and coordinated missile attacks that Russia and China could lob across the world. The Bush administration instead favored a focus on strategic deterrence with these peer nations, an approach that the Obama and Biden administrations continued. In addition to the GMD, the Pentagon and its international partners maintain regional defense systems to counter threats in conflict hot spots or attacks on critical infrastructure. All these networks are designed to intercept missiles during their midcourse cruise phase, as they hurtle through the sky or space, or during their terminal or reentry phase, as they approach their targets. The GMD has cost upward of $63 billion since it was initiated, and the US spends about an additional $20 billion to $30 billion annually on its array of other missile defense systems.&nbsp;



In May, Trump was presented with several design options for the Golden Dome and selected a plan with a price tag of $175 billion and a schedule for full deployment by the end of his term. The One Big Beautiful Bill, signed into law on July 4, approved an initial $24.4 billion in funding for it. Space technologies and launch access have become much more affordable since the 1980s, but many analysts still think the projected cost and timeline are not realistic. The Congressional Budget Office, a nonpartisan federal agency, projected that the cost of the space-based interceptors could total from $161 billion to $542 billion over the course of 20 years. The wide range can be explained by the current lack of specifics on those orbital interceptorsâ€™ design and number.



Reintroducing the idea of space-based interceptors is â€œprobably the most controversial piece of Golden Dome,â€ says Leonor Tomero, who served as deputy assistant secretary of defense for nuclear and missile defense policy in the Biden administration.&nbsp;



â€œThere are a lot of improvements that we can and should make on missile defense,â€ she continues. â€œThereâ€™s a lot of capability gaps I think we do need to address. My concern is the focus on reviving Star Wars and SDI. Itâ€™s got very significant policy implications, strategic stability implications, in addition to cost implications and technology feasibility challenges.â€&nbsp;



Indeed. Regardless of whether the Golden Dome materializes, the program is already raising geopolitical anxieties reminiscent of the Cold War era. Back then, the US had one main adversary: the Soviet Union. Now, it confronts a roiling multipolarity of established and nascent nuclear powers. Many of them have expressed dismay over the about-face on American missile defense strategy, which was previously predicated on arms reduction and deterrence.



â€œHere we are, despite years of saying we are not going to do thisâ€”that it is technically out of reach, economically unsustainable, and strategically unwise,â€ Grego says. â€œOvernight, weâ€™re like, â€˜No, actually, weâ€™re doing it.â€™â€&nbsp;





The fact that we â€œblew up that logicâ€ will â€œhave a big impact on whether or not the program actually succeeds in creating the vision that it lays out,â€ she adds.



Russian and Chinese officials called the Golden Dome â€œdeeply destabilizing in natureâ€ in a joint statement in May, and North Koreaâ€™s foreign ministry warned it could â€œturn outer space into a potential nuclear war field.â€&nbsp;&nbsp;



Reagan, by all accounts, believed that SDI would be the ultimate tool of peace for all nations, and he even offered to share the technology with the Soviet leader, Mikhail Gorbachev. Trump, in contrast, sees Golden Dome as part of his â€œAmerica Firstâ€ brand. He has lamented that past American leaders supported the development of other missile defense projects abroad while neglecting to build similar security measures for their own country. The Golden Dome is both an expression of Trumpâ€™s belief that the world is leeching off America and a bargaining chip in negotiations toward a new power balance; Canada could be covered by the shield for free, he has saidâ€”in exchange for becoming the 51st state.



Trump has argued that America has been both demographically diluted by unchecked immigration and financially depleted by freeloading allied nationsâ€”undermining its security on both internal and external fronts. His first termâ€™s marquee promise to build a wall on the southern US border, paid for by Mexico, aimed to address the former problem. That administration did build more physical barriers along the border (though US taxpayers, not Mexico, footed the bill). But just as important, the wall emerged as a symbolic shorthand for tougher immigration control.&nbsp;



The Golden Dome is the second-term amplification of that promise, a wall that expands the concept of the â€œborderâ€ to the entire American airspace. Trump has projected an image of his envisioned space missile shield as a literal dome that could ward off coordinated attacks, including boost-phase interceptors from space and cruise- and terminal-phase interception by ground and air assets. When he announced the selected plan from the Resolute Desk in May, he sat in front of a mockup that depicted a barrage of incoming missiles being thwarted by the nationwide shield, depicted with a golden glow.



The Golden Domeâ€™s orbital interceptors are supposedly there to target the early boost phase of missiles on or near the launch site, not over the United States. But the image of a besieged America, repelling enemy fire from the heavens, provides the visual and cinematic idea of both threat and security that Trump hopes to impress on the public.&nbsp;&nbsp;



â€œThis administration, and MAGA world, thinks about itself as being victimized by immigrants, government waste, leftist professors, and so on,â€ says Edward Tabor Linenthal, a historian who examined public narratives about SDI in his 1989 book Symbolic Defense: The Cultural Significance of the Strategic Defense Initiative. â€œItâ€™s not much of a jump to be victimized by too many nations getting nuclear weapons.â€&nbsp;







Even in our era of entrenched political polarization, there is support across party lines for upgrading and optimizing Americaâ€™s missile defense systems. No long-range missile has ever struck US soil, but an attack would be disastrous for the nation and the world.&nbsp;



â€œWeâ€™ve come a long way in terms of missile defense,â€ says Tomero. â€œThere has been a lot of bipartisan consensus on increasing regional missile defense, working with our allies, and making sure that the missile defense interceptors we have work.â€



SHOUT




Trump has challenged that consensus with his reversion to the dream of a space shield. He is correct that SDI failed to materialize in part because its envisioned technologies were out of reach, from a financial and engineering standpoint, in the 1980s. But the controversy that erupted around SDIâ€”and that tarnished it with the derisive name â€œStar Warsâ€â€”stemmed just as much from its potential geopolitical disruptiveness as from its fantastical techno-optimism.&nbsp;



â€œThis idea of a missile shield, also back when Reagan proposed it, has a huge popular appeal, because who wouldnâ€™t want to be able to defend your country from nuclear weapons? It is a universal dream,â€ says Stimmer. â€œIt requires a bit more digging in and understanding to see that actually, this vision depends a lot on technological feasibility and on how others perceive it.â€&nbsp;



Reagan maintained a steadfast conviction that this shield of space-based interceptors would render nuclear weapons â€œimpotent and obsolete,â€ ushering in â€œworld peace,â€ as he said in his March 1983 speech announcing SDI. The doctrine of mutually assured destruction could be replaced by mutually assured survival, he argued.




Amid nuclear tensions, J. Robert Oppenheimer compared the US and the Soviet Union to â€œtwo scorpions in a bottle.â€ Now there are many more scorpions.




But Gorbachev saw the space-based shield as an offensive weapon, since it would give the US a first-strike advantage. The imbalance, he warned, could spark a weapons race in space, a domain that had been spared from overt military conflicts. As a result, the initiative would only destabilize the world order and interrupt the progress of arms control and nuclear de-proliferation efforts.&nbsp;



Reaganâ€™s insistence on SDI as the only route to world peace may have blocked opportunities to advance that goal through more practical and cost-effective avenues, such as diplomacy and arms control. At the 1986 Reykjavik Summit, Reagan and Gorbachev came very close to an arms control agreement that might have eliminated all ballistic missiles and nuclear weapons. The sticking point was Reaganâ€™s refusal to give up SDI.&nbsp;





â€œIt is not the Strategic Defense Initiative; itâ€™s a strategic defense ideology,â€ says Linenthal. He mentions the famous metaphor used by J. Robert Oppenheimer, a central figure of the Manhattan Project, who compared the United States and the Soviet Union to â€œtwo scorpions in a bottle.â€ Either scorpion could kill the other, but only at the probable cost of its own life.&nbsp;



Reagan felt a â€œtremendously powerful impetusâ€ to escape Oppenheimerâ€™s metaphor, Linenthal noted: â€œIt was a new kind of deliverance that would resolve it all. Of course, now there are many more scorpions, so it has to be a bigger bottle.â€



A true believer, Reagan never abandoned SDI in spite of cost overruns and public backlash. President Bill Clinton redirected the program in 1993 by shifting gears from global to regional missile defense, a focus that remained fairly consistent for decadesâ€”until Trump took center stage. Now, the Golden Dome has flipped that logic on its head, risking a possible escalation of military tensions in outer space.



Tomero describes a â€œnightmare scenarioâ€ in which adversaries attack the Golden Domeâ€™s space infrastructure, leaving the orbital environment filled with debris that renders the defense system, among countless other space assets, inoperable.&nbsp;



â€œHaving a one-sided capability that is very threatening to our adversaries is obviously going to create very dangerous stability issues,â€ she says. It could â€œlead to inadvertent escalation and miscalculation and, I think, lower the threshold to conflict and nuclear war.â€&nbsp;







As president, Trump has channeled the boardroom antics that once resuscitated his celebrity status on The Apprentice. But armed adversaries, long wary of Americaâ€™s position on missile defense, donâ€™t have the luxury of wondering whether itâ€™s all real or just more stagecraft.&nbsp;



â€œWhat makes Trump so difficult to read for others is his unpredictability,â€ Stimmer says. â€œThis, just by itself, destabilizes things, because no one knows what heâ€™ll actually do.â€



Trump has described the Golden Dome as nearly impenetrable by missile attacks, evoking a clear symbolic return to an American golden age where we can all feel safe again.



â€œAll of them will be knocked out of the air,â€ as â€œthe success rate is very close to 100%,â€ he said at the projectâ€™s official launch in May. â€œWe will truly be completing the job that President Reagan started 40 years ago, forever ending the missile threat to the American homeland.â€



Becky Ferreira is a science reporter based in upstate New York, and author of First Contact, a book about the search for alien life, which will be published in September.&nbsp;
â€¢ The Download: meet the judges using AI, and GPT-5â€™s health promises
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Meet the early-adopter judges using AI



The propensity for AI systems to make mistakes that humans miss has been on full display in the US legal system as of late. The follies began when lawyers submitted documents citing cases that didnâ€™t exist. Similar mistakes soon spread to other roles in the courts. Last December, a Stanford professor submitted sworn testimony containing hallucinations and errors in a case about deepfakes, despite being an expert on AI and misinformation himself.Now, judges are experimenting with generative AI too. Some believe that with the right precautions, the technology can expedite legal research, summarize cases, draft routine orders, and overall help speed up the court system, which is badly backlogged in many parts of the US. Are they right to be so confident in it? Read the full story.



â€”James Oâ€™Donnell







What you may have missed about GPT-5



OpenAIâ€™s new GPT-5 model was supposed to give a glimpse of AIâ€™s newest frontier. It was meant to mark a leap toward the â€œartificial general intelligenceâ€ that techâ€™s evangelists have promised will transform humanity for the better.&nbsp;



Against those expectations, the model has mostly underwhelmed. But thereâ€™s one other thing to take from all this. Among other suggestions for potential uses of its models, OpenAI has begun explicitly telling people to use them for health advice. Itâ€™s a change in approach that signals the company is wading into dangerous waters. Read the full story.



â€”James Oâ€™Donnell



This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 The US has extended its China tariff truce by another 90 daysÂ Itâ€™s yet again another example of Trumpâ€™s on-again, off-again policies. (CNBC)+ China has succeeded in finding other markets to sell to anyway. (CNN)+ Now weâ€™ve got to wait until November 10 for the next round of tariffs. (BBC)2 Europeâ€™s arms factories are rapidly expandingAs EU governments debate how to sustain weapons deliveries to Ukraine. (FT $)+ Trump is due to meet with Vladimir Putin on Friday. (The Guardian)+ Generative AI is learning to spy for the US military. (MIT Technology Review)Â 



3 China has urged companies to avoid using Nvidiaâ€™s H20 chipsWhich comes as a blow to the firm after it made a deal with the US government. (Bloomberg $)+ Chinese officials fear that the US could embed â€œback doorsâ€ into them. (SCMP $)



4 Elon Musk has threatened legal action against AppleHe claims that OpenAI is the only AI firm able to top its App Store charts. (Reuters)+ Grok is ranked a lowly sixth on its free listings. (FT $)



5 AI is making sharing photos of children even riskierNudifying tools are making it easier than ever to manipulate images. (NYT $)+ You need to talk to your kid about AI. Here are 6 things you should say. (MIT Technology Review)



6 The future of food hinges on our land useCan factory farming ease the burden? (Vox)+ Africa fights rising hunger by looking to foods of the past. (MIT Technology Review)



7 What does Palantir really do?Even former workers donâ€™t seem entirely sure. (Wired $)



8 Interest in AI majors is explodingAmong young students and older workers alike. (WP $)+ Weâ€™re reliving a new dot com bubble updated for the AI age. (New Yorker $)



9 The in-person job interview is staging a comebackAI has made it too easy to cheat remotely. (WSJ $)



10 This YouTube show attempts to turn internet discourse into live debateSounds absolutely terrible. (New Yorker $)







Quote of the day



â€œItâ€™s not banned but has kind of become a politically incorrect thing to do.â€



â€”An anonymous Chinese data center operator tells the Financial Times why purchasing Nvidiaâ€™s H20 chips has become so fraught in China.







One more thing







The search for extraterrestrial life is targeting Jupiterâ€™s icy moon EuropaEuropa, Jupiterâ€™s fourth-largest moon, is nothing like ours. Its surface is a vast saltwater ocean, encased in a blanket of cracked ice, one that seems to occasionally break open and spew watery plumes into the moonâ€™s thin atmosphere.For these reasons, Europa captivates planetary scientists. All that water and energyâ€”and hints of elements essential for building organic molecules â€”point to another extraordinary possibility. Jupiterâ€™s big, bright moon could host life.They may eventually get some answers thanks to Europa Clipper, scheduled to reach Jupiter in 2030. Read the full story.



â€”Stephen Ornes







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ Thereâ€™s still plenty of time to decide on a song of the summer.+ Why we love to love horrendously bad filmsâ€”particularly The Room.+ Lock up your daughters: these medieval bards were dangerously charismatic.+ How to instantly become better at pretty much anything.
â€¢ What you may have missed about GPT-5
  Before OpenAI released GPT-5 last Thursday, CEO Sam Altman said its capabilities made him feel â€œuseless relative to the AI.â€ He said working on it carries a weight he imagines the developers of the atom bomb must have felt.



As tech giants converge on models that do more or less the same thing, OpenAIâ€™s new offering was supposed to give a glimpse of AIâ€™s newest frontier. It was meant to mark a leap toward the â€œartificial general intelligenceâ€ that techâ€™s evangelists have promised will transform humanity for the better.&nbsp;



Against those expectations, the model has mostly underwhelmed.Â 



People have highlighted glaring mistakes in GPT-5â€™s responses, countering Altmanâ€™s claim made at the launch that it works like â€œa legitimate PhD-level expert in anything any area you need on demand.â€ Early testers have also found issues with OpenAIâ€™s promise that GPT-5 automatically works out what type of AI model is best suited for your questionâ€”a reasoning model for more complicated queries, or a faster model for simpler ones. Altman seems to have conceded that this feature is flawed and takes away user control. However there is good news too: the model seems to have eased the problem of ChatGPT sucking up to users, with GPT-5 less likely to shower them with over the top compliments.



Overall, as my colleague Grace Huckins pointed out, the new release represents more of a product updateâ€”providing slicker and prettier ways of conversing with ChatGPTâ€”than a breakthrough that reshapes what is possible in AI.&nbsp;



But thereâ€™s one other thing to take from all this. For a while, AI companies didnâ€™t make much effort to suggest how their models might be used. Instead, the plan was to simply build the smartest model possibleâ€”a brain of sortsâ€”and trust that it would be good at lots of things. Writing poetry would come as naturally as organic chemistry. Getting there would be accomplished by bigger models, better training techniques, and technical breakthroughs.&nbsp;



That has been changing: The play now is to push existing models into more places by hyping up specific applications. Companies have been more aggressive in their promises that their AI models can replace human coders, for example (even if the early evidence suggests otherwise). A possible explanation for this pivot is that tech giants simply have not made the breakthroughs theyâ€™ve expected. We might be stuck with only marginal improvements in large language modelsâ€™ capabilities for the time being. That leaves AI companies with one option: Work with what youâ€™ve got.





The starkest example of this in the launch of GPT-5 is how much OpenAI is encouraging people to use it for health advice, one of AIâ€™s most fraught arenas.Â 



In the beginning, OpenAI mostly didnâ€™t play ball with medical questions. If you tried to ask ChatGPT about your health, it gave lots of disclaimers warning you that it was not a doctor, and for some questions, it would refuse to give a response at all. But as I recently reported, those disclaimers began disappearing as OpenAI released new models. Its models will now not only interpret x-rays and mammograms for you but ask follow-up questions leading toward a diagnosis.



In May, OpenAI signaled it would try to tackle medical questions head on. It announced HealthBench, a way to evaluate how good AI systems are at handling health topics as measured against the opinions of physicians. In July, it published a study it participated in, reporting that a cohort of doctors in Kenya made fewer diagnostic mistakes when they were helped by an AI model.Â 



With the launch of GPT-5, OpenAI has begun explicitly telling people to use its models for health advice. At the launch event, Altman welcomed on stage Felipe Millon, an OpenAI employee, and his wife, Carolina Millon, who had recently been diagnosed with multiple forms of cancer. Carolina spoke about asking ChatGPT for help with her diagnoses, saying that she had uploaded copies of her biopsy results to ChatGPT to translate medical jargon and asked the AI for help making decisions about things like whether or not to pursue radiation. The trio called it an empowering example of shrinking the knowledge gap between doctors and patients.



With this change in approach, OpenAI is wading into dangerous waters.Â 



For one, itâ€™s using evidence that doctors can benefit from AI as a clinical tool, as in the Kenya study, to suggest that people without any medical background should ask the AI model for advice about their own health. The problem is that lots of people might ask for this advice without ever running it by a doctor (and are less likely to do so now that the chatbot rarely prompts them to).



Indeed, two days before the launch of GPT-5, the Annals of Internal Medicine published a paper about a man who stopped eating salt and began ingesting dangerous amounts of bromide following a conversation with ChatGPT. He developed bromide poisoningâ€”which largely disappeared in the US after the Food and Drug Administration began curbing the use of bromide in over-the-counter medications in the 1970sâ€”and then nearly died, spending weeks in the hospital.&nbsp;



So whatâ€™s the point of all this? Essentially, itâ€™s about accountability. When AI companies move from promising general intelligence to offering humanlike helpfulness in a specific field like health care, it raises a second, yet unanswered question about what will happen when mistakes are made. As things stand, thereâ€™s little indication tech companies will be made liable for the harm caused.



â€œWhen doctors give you harmful medical advice due to error or prejudicial bias, you can sue them for malpractice and get recompense,â€ says Damien Williams, an assistant professor of data science and philosophy at the University of North Carolina Charlotte.&nbsp;



â€œWhen ChatGPT gives you harmful medical advice because itâ€™s been trained on prejudicial data, or because â€˜hallucinationsâ€™ are inherent in the operations of the system, whatâ€™s your recourse?â€



This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,Â sign up here.
â€¢ Sam Altman and the whale
  My colleague Grace Huckins has a great story on OpenAIâ€™s release of GPT-5, its long-awaited new flagship model. One of the takeaways, however, is that while GPT-5 may make for a better experience than the previous versions, it isnâ€™t something revolutionary. â€œGPT-5 is, above all else,â€ Grace concludes, â€œa refined product.â€



This is pretty much in line with my colleague Will Heavenâ€™s recent argument that the latest model releases have been a bit like smartphone releases: Increasingly, what we are seeing are incremental improvements meant to enhance the user experience. (Casey Newton made a similar point in Fridayâ€™s Platformer.) At GPT-5â€™s release on Thursday, OpenAI CEO Sam Altman himself compared it to when Apple released the first iPhone with a Retina display. Okay. Sure.Â 



But where is the transition from the BlackBerry keyboard to the touch-screen iPhone? Where is the assisted GPS and the API for location services that enables real-time directions and gives rise to companies like Uber and Grindr and lets me order a taxi for my burrito? Where are the real breakthroughs?&nbsp;



In fact, following the release of GPT-5, OpenAI found itself with something of a user revolt on its hands. Customers who missed GPT-4o&#8217;s personality successfully lobbied the company to bring it back as an option for its Plus users. If anything, that indicates the GPT-5 release was more about user experience than noticeable performance enhancements. 



And yet, hours before OpenAIâ€™s GPT-5 announcement, Altman teased it by tweeting an image of an emerging Death Star floating in space. On Thursday, he touted its PhD-level intelligence. He then went on the Mornings with Maria show to claim it would â€œsave a lot of lives.â€ (Forgive my extreme skepticism of that particular brand of claim, but weâ€™ve certainly seen it before.)&nbsp;



Itâ€™s a lot of hype, but Altman is not alone in his Flavor Flav-ing here. Last week Mark Zuckerberg published a long memo about how we are approaching AI superintelligence. Anthropic CEO Dario Amodei freaked basically everyone out earlier this year with his prediction that AI would harvest half of all entry-level jobs within, possibly, a year.&nbsp;



The people running these companies literally talk about the danger that the things they are building might take over the world and kill every human on the planet. GPT-5, meanwhile, still canâ€™t tell you how many bâ€™s there are in the word â€œblueberry.â€&nbsp;



This is not to say that the products released by OpenAI or Anthropic or what have you are not impressive. They are. And they clearly have a good deal of utility. But the hype cycle around model releases is out of hand.&nbsp;



I say that as one of those people who use ChatGPT or Google Gemini most days, often multiple times a day. This week, for example, my wife was surfing and encountered a whale repeatedly slapping its tail on the water. Despite having seen very many whales, often in very close proximity, she had never seen anything like this. She sent me a video, and I was curious about it too. So I asked ChatGPT, â€œWhy do whales slap their tails repeatedly on the water?â€ It came right back, confidently explaining that what I was describing was called â€œlobtailing,â€ along with a list of possible reasons why whales do that. Pretty cool.&nbsp;



But then again, a regular garden-variety Google search would also have led me to discover lobtailing. And while ChatGPTâ€™s response summarized the behavior for me, it was also too definitive about why whales do it. The reality is that while people have a lot of theories, we still canâ€™t really explain this weird animal behavior.&nbsp;



The reason Iâ€™m aware that lobtailing is something of a mystery is that I dug into actual, you know, search results. Which is where I encountered this beautiful, elegiac essay by Emily Boring. She describes her time at sea, watching a humpback slapping its tail against the water, and discusses the scientific uncertainty around this behavior. Is it a feeding technique? Is it a form of communication? Posturing? The action, as she notes, is extremely energy intensive. It takes a lot of effort from the whale. Why do they do it?&nbsp;



I was struck by one passage in particular, in which she cites another biologistâ€™s work to draw a conclusion of her own:&nbsp;



Surprisingly, the complex energy trade-off of a tail-slap might be the exact reason why itâ€™s used. Biologist Hal Whitehead suggests, â€œBreaches and lob-tails make good signals precisely because they are energetically expensive and thus indicative of the importance of the message and the physical status of the signaler.â€ A tail-slap means that a whale is physically fit, traveling at nearly maximum speed, capable of sustaining powerful activity, and carrying a message so crucial it is willing to use a huge portion of its daily energy to share it. â€œPay attention!â€ the whale seems to say. â€œI am important! Notice me!â€







In some ways, the AI hype cycle has to be out of hand. It has to justify the ferocious level of investment, the uncountable billions of dollars in sunk costs. The massive data center buildouts with their massive environmental consequences created at massive expense that are seemingly keeping the economy afloat and threatening to crash it. There is so, so, so much money at stake.&nbsp;



Which is not to say there arenâ€™t really cool things happening in AI. And certainly there have been a number of moments when I have been floored by AI releases. ChatGPT 3.5 was one. Dall-E, NotebookLM, Veo 3, Synthesia. They can amaze. In fact there was an AI product release just this week that was a little bit mind-blowing. Genie 3, from Google DeepMind, can turn a basic text prompt into an immersive and navigable 3D world. Check it outâ€”itâ€™s pretty wild. And yet Genie 3 also makes a case that the most interesting things happening right now in AI arenâ€™t happening in chatbots.&nbsp;



Iâ€™d even argue that at this point, most of the people who are regularly amazed by the feats of new LLM chatbot releases are the same people who stand to profit from the promotion of LLM chatbots.



Maybe Iâ€™m being cynical, but I donâ€™t think so. I think itâ€™s more cynical to promise me the Death Star and instead deliver a chatbot whose chief appeal seems to be that it automatically picks the model for you. To promise me superintelligence and deliver shrimp Jesus. Itâ€™s all just a lot of lobtailing. â€œPay attention! I am important! Notice me!â€



This article is from The Debrief, MIT Technology Reviewâ€™s subscriber-only weekly email newsletter from editor in chief Mat Honan. Subscribers can sign up here to receive it in your inbox.
â€¢ Meet the early-adopter judges using AI
  The propensity for AI systems to make mistakes and for humans to miss those mistakes has been on full display in the US legal system as of late. The follies began when lawyersâ€”including some at prestigious firmsâ€”submitted documents citing cases that didnâ€™t exist. Similar mistakes soon spread to other roles in the courts. In December, a Stanford professor submitted sworn testimony containing hallucinations and errors in a case about deepfakes, despite being an expert on AI and misinformation himself.



The buck stopped with judges, whoâ€”whether they or opposing counsel caught the mistakesâ€”issued reprimands and fines, and likely left attorneys embarrassed enough to think twice before trusting AI again.



But now judges are experimenting with generative AI too. Some are confident that with the right precautions, the technology can expedite legal research, summarize cases, draft routine orders, and overall help speed up the court system, which is badly backlogged in many parts of the US. This summer, though, weâ€™ve already seen AI-generated mistakes go undetected and cited by judges. A federal judge in New Jersey had to reissue an order riddled with errors that may have come from AI, and a judge in Mississippi refused to explain why his order too contained mistakes that seemed like AI hallucinations.&nbsp;



The results of these early-adopter experiments make two things clear. One, the category of routine tasksâ€”for which AI can assist without requiring human judgmentâ€”is slippery to define. Two, while lawyers face sharp scrutiny when their use of AI leads to mistakes, judges may not face the same accountability, and walking back their mistakes before they do damage is much harder.



Drawing boundaries



Xavier Rodriguez, a federal judge for the Western District of Texas, has good reason to be skeptical of AI. He started learning about artificial intelligence back in 2018, four years before the release of ChatGPT (thanks in part to the influence of his twin brother, who works in tech). But heâ€™s also seen AI-generated mistakes in his own court.&nbsp;



In a recent dispute about who was to receive an insurance payout, both the plaintiff and the defendant represented themselves, without lawyers (this is not uncommonâ€”nearly a quarter of civil cases in federal court involve at least one unrepresented party). The two sides wrote their own filings and made their own arguments.&nbsp;



â€œBoth sides used AI tools,â€ Rodriguez says, and both submitted filings that referenced made-up cases. He had authority to reprimand them, but given that they were not lawyers, he opted not to.&nbsp;



â€œI think thereâ€™s been an overreaction by a lot of judges on these sanctions. The running joke I tell when Iâ€™m on the speaking circuit is that lawyers have been hallucinating well before AI,â€ he says. Missing a mistake from an AI model is not wholly different, to Rodriguez, from failing to catch the error of a first-year lawyer. â€œIâ€™m not as deeply offended as everybody else,â€ he says.&nbsp;



In his court, Rodriguez has been using generative AI tools (he wouldnâ€™t publicly name which ones, to avoid the appearance of an endorsement) to summarize cases. Heâ€™ll ask AI to identify key players involved and then have it generate a timeline of key events. Ahead of specific hearings, Rodriguez will also ask it to generate questions for attorneys based on the materials they submit.



These tasks, to him, donâ€™t lean on human judgment. They also offer lots of opportunities for him to intervene and uncover any mistakes before theyâ€™re brought to the court. â€œItâ€™s not any final decision being made, and so itâ€™s relatively risk free,â€ he says. Using AI to predict whether someone should be eligible for bail, on the other hand, goes too far in the direction of judgment and discretion, in his view.



Erin Solovey, a professor and researcher on human-AI interaction at Worcester Polytechnic Institute in Massachusetts, recently studied how judges in the UK think about this distinction between rote, machine-friendly work that feels safe to delegate to AI and tasks that lean more heavily on human expertise.&nbsp;



â€œThe line between what is appropriate for a human judge to do versus what is appropriate for AI tools to do changes from judge to judge and from one scenario to the next,â€ she says.



Even so, according to Solovey, some of these tasks simply donâ€™t match what AI is good at. Asking AI to summarize a large document, for example, might produce drastically different results depending on whether the model has been trained to summarize for a general audience or a legal one. AI also struggles with logic-based tasks like ordering the events of a case. â€œA very plausible-sounding timeline may be factually incorrect,â€ Solovey says.&nbsp;



Rodriguez and a number of other judges crafted guidelines that were published in February by the Sedona Conference, an influential think tank that issues principles for particularly murky areas of the law. They outline a host of potentially â€œsafeâ€ uses of AI for judges, including conducting legal research, creating preliminary transcripts, and searching briefings, while warning that judges should verify outputs from AI and that â€œno known GenAI tools have fully resolved the hallucination problem.â€





Dodging AI blunders



Judge Allison Goddard, a federal magistrate judge in California and a coauthor of the guidelines, first felt the impact that AI would have on the judiciary when she taught a class on the art of advocacy at her daughterâ€™s high school. She was impressed by a studentâ€™s essay and mentioned it to her daughter. â€œShe said, â€˜Oh, Mom, thatâ€™s ChatGPT.â€™â€



â€œWhat I realized very quickly was this is going to really transform the legal profession,â€ she says. In her court, Goddard has been experimenting with ChatGPT, Claude (which she keeps &#8220;open all day&#8221;), and a host of other AI models. If a case involves a particularly technical issue, she might ask AI to help her understand which questions to ask attorneys. Sheâ€™ll summarize 60-page orders from the district judge and then ask the AI model follow-up questions about it, or ask it to organize information from documents that are a mess.Â 



â€œItâ€™s kind of a thought partner, and it brings a perspective that you may not have considered,â€ she says.



Goddard also encourages her clerks to use AI, specifically Anthropicâ€™s Claude, because by default it does not train on user conversations. But it has its limits. For anything that requires law-specific knowledge, sheâ€™ll use tools from Westlaw or Lexis, which have AI tools built specifically for lawyers, but she finds general-purpose AI models to be faster for lots of other tasks. And her concerns about bias have prevented her from using it for tasks in criminal cases, like determining if there was probable cause for an arrest.



In this, Goddard appears to be caught in the same predicament the AI boom has created for many of us. Three years in, companies have built tools that sound so fluent and humanlike they obscure the intractable problems lurking underneathâ€”answers that read well but are wrong, models that are trained to be decent at everything but perfect for nothing, and the risk that your conversations with them will be leaked to the internet. Each time we use them, we bet that the time saved will outweigh the risks, and trust ourselves to catch the mistakes before they matter. For judges, the stakes are sky-high: If they lose that bet, they face very public consequences, and the impact of such mistakes on the people they serve can be lasting.&nbsp;



â€œIâ€™m not going to be the judge that cites hallucinated cases and orders,â€ Goddard says. â€œItâ€™s really embarrassing, very professionally embarrassing.â€



Still, some judges donâ€™t want to get left behind in the AI age. With some in the AI sector suggesting that the supposed objectivity and rationality of AI models could make them better judges than fallible humans, it might lead some on the bench to think that falling behind poses a bigger risk than getting too far out ahead.&nbsp;



A â€˜crisis waiting to happenâ€™



The risks of early adoption have raised alarm bells with Judge Scott Schlegel, who serves on the Fifth Circuit Court of Appeal in Louisiana. Schlegel has long blogged about the helpful role technology can play in modernizing the court system, but he has warned that AI-generated mistakes in judgesâ€™ rulings signal a â€œcrisis waiting to happen,â€ one that would dwarf the problem of lawyersâ€™ submitting filings with made-up cases.&nbsp;



Attorneys who make mistakes can get sanctioned, have their motions dismissed, or lose cases when the opposing party finds out and flags the errors. â€œWhen the judge makes a mistake, thatâ€™s the law,â€ he says. â€œI canâ€™t go a month or two later and go â€˜Oops, so sorry,â€™ and reverse myself. It doesnâ€™t work that way.â€



Consider child custody cases or bail proceedings, Schlegel says: â€œThere are pretty significant consequences when a judge relies upon artificial intelligence to make the decision,â€ especially if the citations that decision relies on are made-up or incorrect.



This is not theoretical. In June, a Georgia appellate court judge issued an order that relied partially on made-up cases submitted by one of the parties, a mistake that went uncaught. In July, a federal judge in New Jersey withdrew an opinion after lawyers complained it too contained hallucinations.&nbsp;



Unlike lawyers, who can be ordered by the court to explain why there are mistakes in their filings, judges do not have to show much transparency, and there is little reason to think theyâ€™ll do so voluntarily. On August 4, a federal judge in Mississippi had to issue a new decision in a civil rights case after the original was found to contain incorrect names and serious errors. The judge did not fully explain what led to the errors even after the state asked him to do so. â€œNo further explanation is warranted,â€ the judge wrote.



These mistakes could erode the publicâ€™s faith in the legitimacy of courts, Schlegel says. Certain narrow and monitored applications of AIâ€”summarizing testimonies, getting quick writing feedbackâ€”can save time, and they can produce good results if judges treat the work like that of a first-year associate, checking it thoroughly for accuracy. But most of the job of being a judge is dealing with what he calls the white-page problem: Youâ€™re presiding over a complex case with a blank page in front of you, forced to make difficult decisions. Thinking through those decisions, he says, is indeed the work of being a judge. Getting help with a first draft from an AI undermines that purpose.



â€œIf youâ€™re making a decision on who gets the kids this weekend and somebody finds out you use Grok and you should have used Gemini or ChatGPTâ€”you know, thatâ€™s not the justice system.â€

ğŸ”’ Cybersecurity & Privacy
â€¢ Microsoft Patch Tuesday, August 2025 Edition
  Microsoft today released updates to fix more than 100 security flaws in its Windows operating systems and other software. At least 13 of the bugs received Microsoft&#8217;s most-dire &#8220;critical&#8221; rating, meaning they could be abused by malware or malcontents to gain remote access to a Windows system with little or no help from users.

August&#8217;s patch batch from Redmond includes an update for CVE-2025-53786, a vulnerability that allows an attacker to pivot from a compromised Microsoft Exchange Server directly into an organization&#8217;s cloud environment, potentially gaining control over Exchange Online and other connected Microsoft Office 365 services. Microsoft first warned about this bug on Aug. 6, saying it affects Exchange Server 2016 and Exchange Server 2019, as well as its flagship Exchange Server Subscription Edition.
Ben McCarthy, lead cyber security engineer at Immersive, said a rough search reveals approximately 29,000 Exchange servers publicly facing on the internet that are vulnerable to this issue, with many of them likely to have even older vulnerabilities.
McCarthy said the fix for CVE-2025-53786 requires more than just installing a patch, such as following Microsoft&#8217;s manual instructions for creating a dedicated service to oversee and lock down the hybrid connection.
&#8220;In effect, this vulnerability turns a significant on-premise Exchange breach into a full-blown, difficult-to-detect cloud compromise with effectively living off the land techniques which are always harder to detect for defensive teams,&#8221; McCarthy said.
CVE-2025-53779 is a weakness in the Windows Kerberos authentication system that allows an unauthenticated attacker to gain domain administrator privileges. Microsoft credits the discovery of the flaw to Akamai researcher Yuval Gordon, who dubbed it &#8220;BadSuccessor&#8221; in a May 2025 blog post. The attack exploits a weakness in &#8220;delegated Managed Service Account&#8221; or dMSA &#8212; a feature that was introduced in Windows Server 2025.
Some of the critical flaws addressed this month with the highest severity (between 9.0 and 9.9 CVSS scores) include a remote code execution bug in the Windows GDI+ component that handles graphics rendering (CVE-2025-53766) and CVE-2025-50165, another graphics rendering weakness. Another critical patch involves CVE-2025-53733, a vulnerability in Microsoft Word that can be exploited without user interaction and triggered through the Preview Pane.
One final critical bug tackled this month deserves attention: CVE-2025-53778, a bug in Windows NTLM, a core function of how Windows systems handle network authentication. According to Microsoft, the flaw could allow an attacker with low-level network access and basic user privileges to exploit NTLM and elevate to SYSTEM-level access â€” the highest level of privilege in Windows. Microsoft rates the exploitation of this bug as &#8220;more likely,&#8221; although there is no evidence the vulnerability is being exploited at the moment.
Feel free to holler in the comments if you experience problems installing any of these updates. As ever, the SANS Internet Storm Center has its useful breakdown of the Microsoft patches indexed by severity and CVSS score, and AskWoody.com is keeping an eye out for Windows patches that may cause problems for enterprises and end users.
GOOD MIGRATIONS
Windows 10 users out there likely have noticed by now that Microsoft really wants you to upgrade to Windows 11. The reason is that after the Patch Tuesday on October 14, 2025, Microsoft will stop shipping free security updates for Windows 10 computers. The trouble is, many PCs running Windows 10 do not meet the hardware specifications required to install Windows 11Â (or they do, but just barely).
If the experience with Windows XP is any indicator, many of these older computers will wind up in landfills or else will be left running in an unpatched state. But if your Windows 10 PC doesn&#8217;t have the hardware chops to run Windows 11 and you&#8217;d still like to get some use out of it safely, consider installing a newbie-friendly version of Linux, like Linux Mint.
Like most modern Linux versions, Mint will run on anything with a 64-bit CPU that has at least 2GB of memory, although 4GB is recommended. In other words, it will run on almost any computer produced in the last decade.
There are many versions of Linux available, but Linux Mint is likely to be the most intuitive interface for regular Windows users, and it is largely configurable without any fuss at the text-only command-line prompt. Mint and other flavors of Linux come with LibreOffice, which is an open source suite of tools that includes applications similar to Microsoft Office, and it can open, edit and save documents as Microsoft Office files.
If you&#8217;d prefer to give Linux a test drive before installing it on a Windows PC, you can always just download it to a removable USB drive. From there, reboot the computer (with the removable drive plugged in) and select the option at startup to run the operating system from the external USB drive. If you don&#8217;t see an option for that after restarting, try restarting again and hitting the F8 button, which should open a list of bootable drives. Here&#8217;s a fairly thorough tutorial that walks through exactly how to do all this.
And if this is your first time trying out Linux, relax and have fun: The nice thing about a &#8220;live&#8221; version of Linux (as it&#8217;s called when the operating system is run from a removable drive such as a CD or a USB stick) is that none of your changes persist after a reboot. Even if you somehow manage to break something, a restart will return the system back to its original state.
â€¢ KrebsOnSecurity in New â€˜Most Wantedâ€™ HBO Max Series
  A new documentary series about cybercrime airing next month on HBO Max features interviews with Yours Truly. The four-part series follows the exploits of Julius KivimÃ¤ki, a prolific Finnish hacker recently convicted of leaking tens of thousands of patient records from an online psychotherapy practice while attempting to extort the clinic and its patients.
The documentary, &#8220;Most Wanted: Teen Hacker,&#8221; explores the 27-year-old KivimÃ¤ki&#8217;s lengthy and increasingly destructive career, one that was marked by cyber attacks designed to result in real-world physical impacts on their targets.

By the age of 14, KivimÃ¤ki had fallen in with a group of criminal hackers who were mass-compromising websites and milking them for customer payment card data. KivimÃ¤ki and his friends enjoyed harassing and terrorizing others by &#8220;swatting&#8221; their homes &#8212; calling in fake hostage situations or bomb threats at a target&#8217;s address in the hopes of triggering a heavily-armed police response to that location.
On Dec. 26, 2014, KivimÃ¤ki and fellow members of a group of online hooligans calling themselves the Lizard Squad launched a massive distributed denial-of-service (DDoS) attack against the Sony Playstation and Microsoft Xbox Live platforms, preventing millions of users from playing with their shiny new gaming rigs the day after Christmas. The Lizard Squad later acknowledged that the stunt was planned to call attention to their new DDoS-for-hire service, which came online and started selling subscriptions shortly after the attack.
Finnish investigators said KivimÃ¤ki also was responsible for a 2014 bomb threat against former Sony Online Entertainment President John Smedley that grounded an American Airlines plane. That incident was widely reported to have started with a Twitter post from the Lizard Squad, after Smedley mentioned some upcoming travel plans online. But according to Smedley and Finnish investigators, the bomb threat started with a phone call from KivimÃ¤ki.
Julius &#8220;Zeekill&#8221; Kivimaki, in December 2014.
The creaky wheels of justice seemed to be catching up with KivimÃ¤ki in mid-2015, when a Finnish court found him guilty of more than 50,000 cybercrimes, including data breaches, payment fraud, and operating a global botnet of hacked computers. Unfortunately, the defendant was 17 at the time, and received little more than a slap on the wrist: A two-year suspended sentence and a small fine.
KivimÃ¤ki immediately bragged online about the lenient sentencing, posting on Twitter that he was an &#8220;untouchable hacker god.&#8221; I wrote a column in 2015 lamenting his laughable punishment because it was clear even then that this was a person who enjoyed watching other people suffer, and who seemed utterly incapable of remorse about any of it. It was also abundantly clear to everyone who investigated his crimes that he wasn&#8217;t going to quit unless someone made him stop.
In response to some of my early reporting that mentioned KivimÃ¤ki, one reader shared that they had been dealing with non-stop harassment and abuse from KivimÃ¤ki for years, including swatting incidents, unwanted deliveries and subscriptions, emails to her friends and co-workers, as well as threatening phonecalls and texts at all hours of the night. The reader, who spoke on condition of anonymity, shared that KivimÃ¤ki at one point confided that he had no reason whatsoever for harassing her &#8212; that she was picked at random and that it was just something he did for laughs.
Five years after KivimÃ¤ki&#8217;s conviction, the Vastaamo Psychotherapy CenterÂ in Finland became the target of blackmail when a tormentor identified as â€œransom_manâ€ demanded payment of 40 bitcoins (~450,000 euros at the time) in return for a promise not to publish highly sensitive therapy session notes Vastaamo had exposed online.
Ransom_man, a.k.a. KivimÃ¤ki, announced on the dark web that he would start publishing 100 patient profiles every 24 hours. When Vastaamo declined to pay, ransom_man shifted to extorting individual patients. According to Finnish police, some 22,000 victims reported extortion attempts targeting them personally, targeted emails that threatened to publish their therapy notes online unless paid a 500 euro ransom.
In October 2022, Finnish authorities charged KivimÃ¤ki with extorting Vastaamo and its patients. But by that time he was on the run from the law and living it up across Europe, spending lavishly on fancy cars, apartments and a hard-partying lifestyle.
In February 2023, KivimÃ¤ki was arrested in FranceÂ after authorities there responded to a domestic disturbance call and found the defendant sleeping off a hangover on the couch of a woman heâ€™d met the night before. The French police grew suspicious when the 6â€² 3â€³ blonde, green-eyed man presented an ID that stated he was of Romanian nationality.
A redacted copy of an ID Kivimaki gave to French authorities claiming he was from Romania.
In April 2024, KivimÃ¤ki was sentenced to more than six years in prison after being convicted of extorting Vastaamo and its patients.
The documentary is directed by the award-winning Finnish producer and director Sami Kieski and co-written by Joni Soila. According to an August 6 press release, the four 43-minute episodes will drop weekly on Fridays throughout September across Europe, the U.S, Latin America, Australia and South-East Asia.

ğŸ“ University AI
No updates.

ğŸ¢ Corporate AI
â€¢ Dion: the distributed orthonormal update revolution is here
  Training AI models requires choosing an optimizer and for nearly a decade, Adam( (opens in new tab)&#8211;W) (opens in new tab) has been the optimizer of choice. Given that durability and success, it was fair to doubt that any further improvement was possible. And yet, last December, a new optimizer called Muon (opens in new tab) showed serious promise by powering a nanoGPT speedrun (opens in new tab). This proved out, with multiple AI labs (e.g., Kimi-AI (opens in new tab) and Essential-AI (opens in new tab)) reporting 2x scale improvements and the release of the 1T parameter Kimi K2 (opens in new tab) model.&nbsp;Restated: you can train a model to similar performance with half as many GPUs.



Thereâ€™s one fly in the ointment: Muon requires large matrix multiplications in the optimizer, which requires heavy communication in large models at the scale where FSDP and TP parallelization becomes desirable.&nbsp;Going back to the inspiration for Muon, the key idea is an orthonormal update, which sparked the search&nbsp;for more scalable alternative linear algebras realizing the same goal. Thatâ€™s exactly what Dion is. We have open-sourced this new optimizer to enable anyone to train large models more efficiently at scale. &nbsp;



Whatâ€™s an orthonormal update?



Figure1. Illustration of matrix parameters



At the core of Transformers, a set of input activations is multiplied by a learned weight matrix to produce a new set of output activations. When the weight matrix is updated during training, the resulting change in the output activations generally depends on the direction of the input activations. As a result, the learning rate must be chosen conservatively to accommodate the input direction that induces the largest change. Orthonormalized updates alter this behavior by (approximately) making the change in output activations invariant to the direction of the input. This is achieved by enforcing orthonormality (opens in new tab) on the update matrix, thereby equalizing its effect across all input directions.



What is Dion?



While Muon has shown strong empirical results, scaling it to very large models poses challenges. As reported by Essential AI (opens in new tab), applying Muon to large architectures like LLaMA-3 becomes compute-boundâ€”and potentially communication-boundâ€”due to the cost of the Newtonâ€“Schulz orthonormalization steps (opens in new tab).



Figure 2. Pseudocode of the centralized version of Dion



This is where Dion enters. At a high level, Dion introduces a new axis for scalability: the rank. Specifically, for a given rank r, Dion orthonormalizes only the top r of the singular vector space, reducing communication and compute overhead while preserving performance.&nbsp;Empirically, we observe that the necessary rank for good performance grows much more slowly than the number of parameters in larger models.




	
		
						Download
			
				Dion optimizer&nbsp;
			
					
	




Dion implements orthonormalization using amortized power iteration (opens in new tab).&nbsp;Power iteration typically pulls out the largest singular value by repeated matrix multiplication.&nbsp;By amortizing this process over optimization stepsâ€”applied to the slowly-evolving momentum matrixâ€”we reduce the cost to just two matrix multiplications per step. Incorporating a QR decomposition allows us to extract an approximate orthonormal basis spanning the top singular directions, rather than just the leading one.&nbsp;This amortized power iteration is fully compatible with standard distributed training techniques such as FSDP and tensor parallelism.&nbsp;Here, we show a simple centralized version, but the technique works for more complex forms of parallelization as presented in the paper. In other words, we can orthogonalize a matrix without ever seeing a full row or column of it.&nbsp;



Low-rank approximation would ordinarily introduce error, but Dion overcomes this through an error feedback mechanism. This keeps the residual of low rank approximation in the momentum matrix so that any systematic gradient structure not initially captured accumulates to eventually be applied in a future update.



	
		

		
		Spotlight: Event Series
	
	
	
						
				
					
				
			
			
			

									Microsoft Research Forum
				
								Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.
				
								
					
						
							Watch on-demand						
					
				
							
	
Opens in a new tab	
	


How does it work?



Something very strange happened in our experiments. Usually, adding an extra constraint on the way an algorithm works can be expected to decrease overall performance. And indeed, at the 120M parameter scale of the speedrun, we see Dionâ€™s update taking more time than Muon, while not yielding any significant gains. But at larger scales, we observed a different trend: Dion began to outperform Muon.



Figure 3. Wall-clock time speedup of Dion for 3B model training



Why would adding a constraint improve the update rule? The answer lies in what the constraint enforces. Dion achieves a much closer approximation to true orthonormalization than Muon. This precision, initially subtle, becomes increasingly important as the number of singular vectors grows. Over increasing model scale and training steps, this small advantage accumulatesâ€”leading to a measurable improvement in performance.



This edge further grows with batch sizeâ€”with larger batches the update quality tends to degrade, but notably more slowly with Dion than Muon (and Muon is already a significant improvement over AdamW).



Figure 4. Scaling of Dion across different batch sizes



Here you can see how the number of steps to reach a pretraining loss compared to AdamW varies as batch size grows with full rank and Â¼ rank Dion (in orange) and Muon (in blue).&nbsp;&nbsp;&nbsp;



In our experiments, these benefits extend to various post-training regimes as well.



We also experimented with rank, discovering empirically that larger models tolerate smaller rank well.



Figure 5. Low-rank Dion across different model sizes



Projecting this trend out to the scale of the LLaMA-3 (opens in new tab) 405B parameter models suggests that Dion is fully effective even with rank fractions as low as 1/16 or 1/64 for large dense models like LLaMA-3.&nbsp;&nbsp;&nbsp;&nbsp;



Using hardware timings of the individual update steps suggests a story that looks this:



Figure 6. Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon.



Weâ€™ve open-sourced a PyTorch FSDP2 + Tensor Parallel (TP) implementation of Dion, available via a simple pip install. Our goal is to make faster training with Dion accessible to everyone. As a bonus, the repository also includes a PyTorch FSDP2 implementation of Muon.




Dion optimizer




Acknowledgements



We thank Riashat Islam and Pratyusha Sharma for their helpful feedback on the writing and presentation.
Opens in a new tabThe post Dion: the distributed orthonormal update revolution is here appeared first on Microsoft Research.
â€¢ Train and deploy AI models at trillion-parameter scale with Amazon SageMaker HyperPod support for P6e-GB200 UltraServers
  Imagine harnessing the power of 72 cutting-edge NVIDIA Blackwell GPUs in a single system for the next wave of AI innovation, unlocking 360 petaflops of dense 8-bit floating point (FP8) compute and 1.4 exaflops of sparse 4-bit floating point (FP4) compute. Today, thatâ€™s exactly what Amazon SageMaker HyperPod delivers with the launch of support for P6e-GB200 UltraServers. Accelerated by NVIDIA GB200 NVL72, P6e-GB200 UltraServers provide industry-leading GPU performance, network throughput, and memory for developing and deploying trillion-parameter AI models at scale. By seamlessly integrating these UltraServers with the distributed training environment of SageMaker HyperPod, organizations can rapidly scale model development, reduce downtime, and simplify the transition from training to large-scale deployment. With the automated, resilient, and highly scalable machine learning infrastructure of SageMaker HyperPod, organizations can seamlessly distribute massive AI workloads across thousands of accelerators and manage model development end-to-end with unprecedented efficiency. Using SageMaker HyperPod with P6e-GB200 UltraServers marks a pivotal shift towards faster, more resilient, and cost-effective training and deployment for state-of-the-art generative AI models. 
In this post, we review the technical specifications of P6e-GB200 UltraServers, discuss their performance benefits, and highlight key use cases. We then walk though how to purchase UltraServer capacity through flexible training plans and get started using UltraServers with SageMaker HyperPod. 
Inside the UltraServer 
P6e-GB200 UltraServers are accelerated by NVIDIA GB200 NVL72, connecting 36 NVIDIA Grace CPUs and 72 Blackwell GPUs in the same NVIDIA NVLink domain. Each ml.p6e-gb200.36xlarge compute node within an UltraServer includes two NVIDIA GB200 Grace Blackwell Superchips, each connecting two high-performance NVIDIA Blackwell GPUs and an Arm-based NVIDIA Grace CPU with the NVIDIA NVLink chip-to-chip (C2C) interconnect. SageMaker HyperPod is launching P6e-GB200 UltraServers in two sizes. The ml.u-p6e-gb200x36 UltraServer includes a rack of 9 compute nodes fully connected with NVSwitch (NVS), providing a total of 36 Blackwell GPUs in the same NVLink domain, and the ml.u-p6e-gb200x72 UltraServer includes a rack-pair of 18 compute nodes with a total of 72 Blackwell GPUs in the same NVLink domain. The following diagram illustrates this configuration. 
 
Performance benefits of UltraServers 
In this section, we discuss some of the performance benefits of UltraServers. 
GPU and compute power 
With P6e-GB200 UltraServers, you can access up to 72 NVIDIA Blackwell GPUs within a single NVLink domain, with a total of 360 petaflops of FP8 compute (without sparsity), 1.4 exaflops of FP4 compute (with sparsity) and 13.4 TB of high-bandwidth memory (HBM3e). EachGrace Blackwell Superchip pairs two Blackwell GPUs with one Grace CPU through the NVLink-C2C interconnect, delivering 10 petaflops of dense FP8 compute, 40 petaflops of sparse FP4 compute, up to 372 GB HBM3e, and 850GB of cache-coherent fast memory per module. This co-location boosts bandwidth between GPU and CPU by an order of magnitude compared to previous-generation instances. Each NVIDIA Blackwell GPU features a second-generation Transformer Engine and supports the latest AI precision microscaling (MX) data formats such as MXFP6 and MXFP4, as well as NVIDIA NVFP4. When combined with frameworks like NVIDIA Dynamo, NVIDA TensorRT-LLM and NVIDIA NeMo, these Transformer Engines significantly accelerate inference and training for large language models (LLMs) and Mixture-of-Experts (MoE) models, supporting higher efficiency and performance for modern AI workloads. 
High-performance networking 
P6e-GB200 UltraServers deliver up to 130 TBps of low-latency NVLink bandwidth between GPUs for efficient large-scale AI workload communication. At double the bandwidth of its predecessor, the fifth-generation NVIDIA NVLink provides up to 1.8 TBps of bidirectional, direct GPU-to-GPU interconnect, greatly enhancing intra-server communication. Each compute node within an UltraServer can be configured with up to 17 physical network interface cards (NICs), each supporting up to 400 Gbps of bandwidth. P6e-GB200 UltraServers provide up to 28.8 Tbps of total Elastic Fabric Adapter (EFA) v4 networking, using the Scalable Reliable Datagram (SRD) protocol to intelligently route network traffic across multiple paths, providing smooth operation even during congestion or hardware failures. For more information, refer to EFA configuration for a P6e-GB200 instances. 
Storage and data throughput 
P6e-GB200 UltraServers support up to 405 TB of local NVMe SSD storage, ideal for large-scale datasets and fast checkpointing during AI model training. For high-performance shared storage, Amazon FSx for Lustre file systems can be accessed over EFA with GPUDirect Storage (GDS), providing direct data transfer between the file system and the GPU memory with TBps of throughput and millions of input/output operations per second (IOPS) for demanding AI training and inference. 
Topology-aware scheduling 
Amazon Elastic Compute Cloud (Amazon EC2) provides topology information that describes the physical and network relationships between instances in your cluster. For UltraServer compute nodes, Amazon EC2 exposes which instances belong to the same UltraServer, so youâ€™re training and inference algorithms can understand NVLink connectivity patterns. This topology information helps optimize distributed training by allowing frameworks like the NVIDIA Collective Communications Library (NCCL) to make intelligent decisions about communication patterns and data placement. For more information, see How Amazon EC2 instance topology works. 
With Amazon Elastic Kubernetes Service (Amazon EKS) orchestration, SageMaker HyperPod automatically labels UltraServer compute nodes with their respective AWS Region, Availability Zone, Network Node Layers (1â€“4), and UltraServer ID. These topology labels can be used with node affinities, and pod topology spread constraints to assign Pods to cluster nodes for optimal performance. 
With Slurm orchestration, SageMaker HyperPod automatically enables the topology plugin and creates a topology.conf file with the respective BlockName, Nodes, and BlockSizes to match your UltraServer capacity. This way, you can group and segment your compute nodes to optimize job performance. 
Use cases for UltraServers 
P6e-GB200 UltraServers can efficiently train models with over a trillion parameters due to their unified NVLink domain, ultrafast memory, and high cross-node bandwidth, making them ideal for state-of-the-art AI development. The substantial interconnect bandwidth makes sure even extremely large models can be partitioned and trained in a highly parallel and efficient manner without the performance setbacks seen in disjointed multi-node systems. This results in faster iteration cycles and higher-quality AI models, helping organizations push the boundaries of state-of-the-art AI research and innovation. 
For real-time trillion-parameter model inference, P6e-GB200 UltraServers enable 30 times faster inference on frontier trillion-parameter LLMs compared to prior platforms, achieving real-time performance for complex models used in generative AI, natural language understanding, and conversational agents. When paired with NVIDIA Dynamo, P6e-GB200 UltraServers deliver significant performance gains, especially for long context lengths. NVIDIA Dynamo disaggregates the compute-heavy prefill phase and the memory-heavy decode phase onto different GPUs, supporting independent optimization and resource allocation within the large 72-GPU NVLink domain. This enables more efficient management of large context windows and high-concurrency applications. 
P6e-GB200 UltraServers offer substantial benefits to startup, research, and enterprise customers with multiple teams that need to run diverse distributed training and inference workloads on shared infrastructure. When used in conjunction with SageMaker HyperPod task governance, UltraServers provide exceptional scalability and resource pooling, so different teams can launch simultaneous jobs without bottlenecks. Enterprises can maximize infrastructure utilization, reduce overall costs, and accelerate project timelines, all while supporting the complex needs of teams developing and serving advanced AI models, including massive LLMs for high-concurrency real-time inference, across a single, resilient platform. 
Flexible training plans for UltraServer capacity 
SageMaker AI currently offers P6e-GB200 UltraServer capacity through flexible training plans in the Dallas AWS Local Zone (us-east-1-dfw-2a). UltraServers can be used for both SageMaker HyperPod and SageMaker training jobs. 
To get started, navigate to the SageMaker AI training plans console, which includes a new UltraServer compute type, from which you can select your UltraServer type: ml.u-p6e-gb200x36 (containing 9 ml.p6e-gb200.36xlarge compute nodes) or ml.u-p6e-gb200x72 (containing 18 ml.p6e-gb200.36xlarge compute nodes). 
 
After finding the training plan that fits your needs, it is recommended that you configure at least one spare ml.p6e-gb200.36xlarge compute node to make sure faulty instances can be quickly replaced with minimal disruption. 
 
Create an UltraServer cluster with SageMaker HyperPod 
After purchasing an UltraServer training plan, you can add the capacity to an ml.p6e-gb200.36xlarge type instance group within your SageMaker HyperPod cluster and specify the quantity of instances that you want to provision up to the amount available within the training plan. For example, if you purchased a training plan for one ml.u-p6e-gb200x36 UltraServer, you could provision up to 9 compute nodes, whereas if you purchased a training plan for one ml.u-p6e-gb200x72 UltraServer, you could provision up to 18 compute nodes. 
 
By default, SageMaker will optimize the placement of instance group nodes within the same UltraServer so that GPUs across nodes are interconnected within the same NVLink domain to achieve the best data transfer performance for your jobs. For example, if you purchase two ml.u-p6e-gb200x72 UltraServers with 17 compute nodes available each (assuming you configured two spares), then create an instance group with 24 nodes, the first 17 compute nodes will be placed on UltraServer A, and the other 7 compute nodes will be placed on UltraServer B. 
Conclusion 
P6e-GB200 UltraServers help organizations train, fine-tune, and serve the worldâ€™s most ambitious AI models at scale. By combining extraordinary GPU resources, ultrafast networking, and industry-leading memory with the automation and scalability of SageMaker HyperPod, enterprises can accelerate the different stages of the AI lifecycle, from experimentation and distributed training through seamless inference and deployment. This powerful solution breaks new ground in performance and flexibility and reduces operational complexity and costs, so that innovators can unlock new possibilities and lead the next era of AI advancement. 
 
About the authors 
Nathan Arnold is a Senior AI/ML Specialist Solutions Architect at AWS based out of Austin Texas. He helps AWS customersâ€”from small startups to large enterprisesâ€”train and deploy foundation models efficiently on AWS. When heâ€™s not working with customers, he enjoys hiking, trail running, and playing with his dogs.
â€¢ How Indegeneâ€™s AI-powered social intelligence for life sciences turns social media conversations into insights
  This post is co-written with Rudra Kannemadugu and Shravan K S from Indegene Limited. 
In todayâ€™s digital-first world, healthcare conversations are increasingly happening online. Yet the life sciences industry has struggled to keep pace with this shift, facing challenges in effectively analyzing and deriving insights from complex medical discussions on a scale. This post will explore how Indegene is using services like Amazon Bedrock, Amazon SageMaker, and purpose-built AWS solutions for healthcare and life sciences to help pharmaceutical companies extract valuable, actionable intelligence from digital healthcare conversations. 
Indegene Limited is a digital-first, life sciences commercialization company. It helps pharmaceutical, emerging biotech, and medical device companies develop products, get them to customers, and grow their impact through the healthcare lifecycle in a more effective, efficient, and modern way. Trusted by global leaders in the pharma and biotech space, Indegene brings together healthcare domain expertise, fit-for-purpose technology, and an agile operating model to provide a diverse range of solutions. They aim to deliver a personalized, scalable and omnichannel experience for patients and physicians. 
Life sciences companies face unprecedented challenges in effectively understanding and engaging with healthcare professionals (HCPs) and patients. Indegeneâ€™s Digital-Savvy HCP Report reveals that 52% of HCPs now prefer receiving medical and promotional content from pharmaceutical companies through social media (such as LinkedIn, Twitter, YouTube, or Facebook). This number is up significantly from 41% in 2020. Despite this shift, pharma companies are struggling to deliver high-quality experiences. A study by DT Consulting (an Indegene company) shows the industry currently holds a Customer Experience Quality (CXQ) score of 58. Although this rating is considered good, it merely meets basic expectations and falls short of the excellence benchmark, defined by a CXQ score of 76â€“100. 
This post explores how Indegeneâ€™s Social Intelligence Solution uses advanced AI to help life sciences companies extract valuable insights from digital healthcare conversations. Built on AWS technology, the solution addresses the growing preference of HCPs for digital channels while overcoming the challenges of analyzing complex medical discussions on a scale. 
Digital transformation challenges in life sciences 
Consider the scenario in the following figure: A patient shares their healthcare journey on social media, including details about their medical condition, treatment protocol, healthcare provider, medication usage patterns, treatment efficacy, and experienced side effects. When such patient narratives are collected at scale and processed through analytical models, they provide valuable strategic insights for pharmaceutical companies. 
 
This has created an urgent need for sophisticated, healthcare-focused solutions that can automatically capture, analyze, and transform these digital conversations into actionable business intelligence.Social intelligence in healthcare can help companies achieve the following: 
 
 Monitor brand sentiment and reputation â€“ Track relevant conversations in real time (forward listening) and historically (backward listening) to monitor sentiment and trends around specific drugs or brands. 
 Gauge launch reactions and adjust strategies â€“ Monitor product launches to assess public reaction, identify leading indicators, and detect trends for brand switching, adverse events, or off-label drug use. 
 Identify and monitor key decision-makers â€“ Enhance outreach by identifying and engaging with key influencers, particularly HCPs, by analyzing their posts and interactions across social media channels. 
 Gain competitive intelligence â€“ Track brand sentiment and patient behavior patterns to identify emerging trends, gauge competitor performance, and adapt business strategies proactively. 
 
Key challenges in healthcare social listening 
Life sciences organizations recognize that customer-centricity becomes more attainable when decision-making is informed by data. Consequently, they are increasingly embracing strategies that use data to enhance customer experience and drive business outcomes. However, they face significant challenges: 
 
 Obsolete engagement methods â€“ Traditional in-person interactions are becoming less effective as medical conversations migrate to digital channels. 
 Complex healthcare terminology â€“ Standard social listening tools canâ€™t adequately process healthcare-specific language, regulatory considerations, and authentic HCP identification. 
 Real-time insight requirements â€“ Critical information about treatment preferences and product feedback emerges rapidly, outpacing manual analysis methods. 
 
Solution overview 
With over 25 years of industrial experience, Indegene has built and continues to evolve their specialized Social Intelligence Solution on AWS, adapting to emerging healthcare and life sciences (HCLS) needs and use cases. This solution aims to transform how life sciences companies understand and engage with their stakeholders by combining machine learning (ML), natural language processing (MLP), and generative AI capabilities. Key differentiators of the solution include: 
 
 Broad social media integration â€“ Provides automated data collection with comprehensive coverage across social media channels. 
 Healthcare-focused analytics â€“ Delivers deep insights into pharmaceutical-specific attributes, including stakeholder segmentation, safety, and efficacy. 
 Targeted HCP identification â€“ Uniquely detects and categorizes social media profiles of healthcare professionals for precision targeting. 
 Comprehensive insight capabilities â€“ Provides granular analysis of conversations with sentiment analysis for nuanced understanding. 
 
The following diagram illustrates an end-to-end life sciences system that integrates multiple functional layers. Starting from the bottom, it flows from data acquisition through data management layers, up to AI/ML core processing and customer-facing applications (such as HCP and DOL identification, and conference listening). The right side showcases supporting techno-functional services, including security, DevOps, and enterprise interfaces. 
 
The system employs a modular, extensible architecture that transforms unstructured social data into actionable healthcare insights while maintaining regulatory compliance. This layered design allows for continuous evolution, helping pharmaceutical companies implement diverse use cases beyond initial applications. 
Architecture layers 
The architecture consists of the following layers: 
 
 Data acquisition layer â€“ This foundation layer features specialized components for social media connectivity across channels like LinkedIn, Twitter, and YouTube, alongside sophisticated web scraping frameworks with rate limiting and randomization capabilities. A standout feature is the taxonomy-based query generator that uses healthcare terminology databases to create contextually relevant searches across medical conversations. 
 Data management layer â€“ This layer provides robust data lake functionality with comprehensive governance features, including personally identifiable information (PII) detection, retention policies, and lineage tracking to help maintain regulatory compliance. This layerâ€™s metadata repository and schema registry make sure complex healthcare data remains organized and discoverable, and extraction workers and data cleansers maintain data quality essential for reliable analytics. For more information, see Building and Scaling Robust and Effective Enterprise Data Governance in Life Sciences. 
 Core AI/ML service layer â€“ This layer represents the systemâ€™s intelligence center, offering healthcare-specific capabilities like medical entity recognition, credential verification for healthcare professionals, and specialized sentiment analysis tuned for medical contexts. The systemâ€™s context-aware analyzer and confidence scoring mechanisms make sure insights reflect the nuanced nature of healthcare discussions, and the HCP-KOL-DOL identifier provides critical stakeholder classification capabilities unavailable in generic social listening tools. For more information, see Five must-have AI capabilities to lead the commercial race in life sciences. 
 Customer-facing analytics layer â€“ This layer delivers actionable insights through specialized modules, including anomaly detection, predictive trend modeling, and adverse event detection, with medical side effect lexicons. Particularly valuable are the comparative analysis tools and share-of-voice calculators that provide competitive intelligence specific to the pharmaceutical industry. These components work together to power purpose-built applications like HCP identification, conference listening, brand reputation analysis, and patient sentiment trackingâ€”all designed to help pharmaceutical companies navigate the increasingly digital healthcare conversation landscape with precision and compliance alignment. 
 
A layered system-based modular approach offers the following benefits for healthcare use cases: 
 
 Reusability â€“ The dynamic nature of healthcare-digital engagement demands flexible customer-facing solutions (top-layer). A modular approach provides reusable components that adapt to changing business use cases without requiring core infrastructure rebuilds. This approach delivers controlled implementation costs, consistent scalability and reliability, and minimal time-to-market. 
 Extensibility and separation of concerns â€“ The solution separates four fundamental building blocks: data acquisition mechanisms, compliance-aligned data lifecycle management, healthcare-optimized AI/ML services, and domain-specific analytics. Given the accelerating pace of innovation in each area (from new social channels to advanced language models), these components must evolve independently with meticulously defined interfaces between them. This separation helps specialized teams update individual components without disrupting overall system performance or compliance requirements. 
 Standardization â€“ Enterprise-wide consistency forms the backbone of a reliable healthcare analytics solution. Authentication, authorization, integration with enterprise systems like ERP and CRM, observability mechanisms, and security controls must follow standardized patterns across the entire social listening channels. When dealing with HCP identification and medical conversations, these standardized guardrails become not just technical best practices but essential regulatory and compliance requirements. 
 Domain adaptation â€“ What fundamentally distinguishes our approach from generic social media channels is our deep domain-specific implementation tailored for life sciences. Whereas lower layers like data acquisition and management follow industry standards, our upper layers deliver specialized capabilities engineered specifically for healthcare contexts. Identifying healthcare professionals in social conversations with high precision, enabling taxonomy-based querying across complex medical hierarchies, and contextualizing medical terminology within appropriate clinical frameworks are capabilities with transformative utility in life sciences applications. This domain specialization creates unique value that generic solutions simply cannot match, providing Indegene with a distinctive competitive advantage in helping pharmaceutical companies bridge the digital engagement gap revealed in our research. 
 
Implementation on AWS 
Indegeneâ€™s Social Intelligence Solutionâ€™s layered architecture can be efficiently implemented using AWSâ€™s comprehensive suite of services, providing scalability, security, and specialized capabilities for life sciences analytics. 
Data acquisition layer 
The data acquisition layer orchestrates diverse data collection mechanisms to gather insights from multiple social and professional channels while facilitating compliance-aligned and efficient ingestion: 
 
 Amazon Managed Streaming for Apache Kafka (Amazon MSK) and Amazon Kinesis â€“ Provide the backbone for real-time data ingestion from social media channels, handling high-throughput event streams from Twitter, LinkedIn, and other sources with built-in fault tolerance and robust message retention. 
 AWS Lambda â€“ Powers the event-driven collection system, triggering data capture based on scheduled polling or webhook events. 
 Amazon AppFlow â€“ Simplifies integration with social media APIs through no-code connectors to social media channels like LinkedIn and Twitter. 
 AWS Glue crawlers â€“ Systematically extract data from web sources using headless browser capabilities, with rate limiting and randomization to facilitate ethical data collection. 
 Amazon Neptune â€“ Stores and traverses complex medical terminology relationships needed for taxonomy-based query generation. 
 
Data management layer 
The data management layer demands robust storage, cataloging, and governance solutions: 
 
 Amazon Simple Storage Service (Amazon S3) â€“ Serves as the cost-optimized data lake foundation, with intelligent tiering to automatically move less-accessed historical social data to lower-cost storage classes. 
 AWS Lake Formation â€“ Provides fine-grained access controls and governance for the data lake, which is critical for managing sensitive healthcare information. 
 AWS Glue Data Catalog â€“ Maintains the metadata repository and schema registry, making social media data discoverable and queryable. 
 Amazon EMR â€“ Powers the extract, transform, and load (ETL) pipeline for large-scale data transformation, particularly useful for processing historical social media archives. 
 Amazon Comprehend Medical â€“ Assists with PII detection in the data governance framework, identifying and helping protect sensitive healthcare information that might appear in social conversations. 
 
Core AI/ML service layer 
This critical layer uses AWSâ€™s advanced AI capabilities to transform raw social data into healthcare-specific insights: 
 
 Amazon Bedrock and Amazon SageMaker AI â€“ Form the centerpiece of the ML implementation with foundation models (FMs) fine-tuned for healthcare terminology. 
 Amazon ElastiCache for Redis â€“ Implements high-performance Retrieval Augmented Generation (RAG) caching, dramatically improving response times for common healthcare queries and reducing computational costs. 
 
Amazon Bedrock serves as the cornerstone of the solutionâ€™s AI capabilities, offering several advantages for life sciences applications. It is a fully managed service that offers a choice of industry-leading large language models (LLMs) to build generative AI applications. 
Amazon Bedrock minimizes the substantial infrastructure management burden typically associated with deploying LLMs, helping life sciences companies focus on insights rather than complex ML operations. Amazon Bedrock FMs can be specialized for healthcare terminology through domain adaptation, enabling accurate interpretation of complex medical discussions. 
The RAG capabilities of Amazon Bedrock Knowledge Bases are particularly valuable for incorporating medical ontologies and taxonomies, making sure AI responses reflect current medical understanding and regulatory contexts. 
Amazon Bedrock Custom Model Import helps pharmaceutical companies use their proprietary domain-specific models and intellectual property, which is critical for companies with established investments in specialized healthcare AI. 
For pharmaceutical companies monitoring product launches or adverse events, Amazon Bedrock Prompt Management allows for consistent, validated queries across different monitoring scenarios. Operational efficiency is significantly enhanced through Amazon Bedrock prompt caching mechanisms, which reduce redundant processing of similar queries and substantially lower costsâ€”particularly valuable when analyzing recurring patterns in healthcare conversations. Amazon Bedrock Intelligent Prompt Routing enables intelligent distribution of tasks across multiple state-of-the-art LLMs, helping teams seamlessly compare and select the optimal model for each specific use case, such as Anthropicâ€™s Claude for nuanced sentiment analysis, Meta Llama for rapid classification, or proprietary models for specialized pharmaceutical applications. 
The Amazon Bedrock comprehensive responsible AI framework is particularly crucial in healthcare applications. The built-in evaluation tools enable systematic assessment of model outputs for fairness, bias, and accuracy in medical contexts, which is essential when analyzing diverse patient populations. Amazon Bedrock transparency features provide detailed model cards and lineage tracking, helping pharmaceutical companies document and justify AI-driven decisions to regulatory authorities. The human-in-the-loop workflows facilitate expert review of critical healthcare insights before they influence business decisions, and comprehensive audit logging creates the documentation trail necessary for compliance in regulated industries. 
Amazon Bedrock Guardrails is especially valuable in the life sciences context, where guardrails can be configured with domain-specific constraints to help prevent the extraction or exposure of protected health information. These guardrails can be tailored to automatically block requests for individual patient information, personal details of healthcare professionals, or other sensitive data categories specific to pharmaceutical compliance requirements. This capability makes sure that even as the solution analyzes millions of healthcare conversations, it can maintain strict adherence to HIPAA, GDPR, and industry-specific privacy standards. The ability to implement these comprehensive guardrails makes sure the AI outputs comply with pharmaceutical marketing regulations and patient privacy requirements. 
Amazon Bedrock Agents can automate routine monitoring tasks while escalating potential adverse events or off-label discussions for human review. 
By implementing fine-tuning pipelines through Amazon Bedrock, the solution continuously improves its understanding of emerging medical terminology and evolving social media language patterns, making sure the insights remain relevant as digital healthcare conversations evolve. 
Customer-facing analytics and insights service layer 
The solutionâ€™s analytics capabilities transform processed data into actionable business intelligence: 
 
 Reporting â€“ Delivers interactive dashboards and visualizations of brand sentiment, competitor analysis, and trend detection with healthcare-specific visualizations and metrics. 
 Amazon Managed Service for Apache Flink â€“ Enables real-time trend detection and anomaly identification in streaming social media data, which is particularly valuable for monitoring adverse event signals. 
 AWS Step Functions â€“ Orchestrates complex analytics workflows like adverse event detection that require multiple processing steps and human review. 
 Amazon Athena â€“ Provides SQL queries against the processed social media data lake, helping business users explore patterns without complex data engineering. 
 Amazon Lex â€“ Powers natural language interfaces, helping users query and interact with social media insights through conversational AI. 
 
Supporting techno-functional services 
The solutionâ€™s enterprise integration and operational capabilities use AWSâ€™s comprehensive management tools: 
 
 AWS Control Tower and AWS Organizations â€“ Implement guardrails and compliance controls essential for life sciences applications. 
 Amazon CloudWatch and AWS X-Ray â€“ Provide comprehensive observability across the solution, with specialized monitoring for healthcare-specific metrics and compliance indicators. 
 AWS AppSync â€“ Builds the intuitive user experience layer with real-time data synchronization. 
 AWS AppFlow and Amazon API Gateway â€“ Enable enterprise interface integration with CRM and ERP systems. 
 Amazon Cognito â€“ Delivers secure user authentication and authorization, with role-based access controls appropriate for different stakeholder groups within pharmaceutical organizations. 
 
This AWS-powered implementation delivers the benefits we have discussedâ€”reusability, extensibility, standardization, and domain adaptationâ€”while providing the security, compliance-alignment, and performance capabilities essential for life sciences applications. 
Example use case 
Letâ€™s explore the implementation of a domain-specific, taxonomy-based query generation system for social media data analysis. A typical implementation comprises the following components: 
 
 Medical terminology database â€“ This repository stores standardized medical terminology from SNOMED CT, MeSH, and RxNorm. It returns detailed information about queried terms, including synonyms, parent categories, and codes. For example, querying â€œdiabetesâ€ returns alternatives like â€œdiabetes mellitusâ€ and â€œDMâ€ with classification data. The database maintains specialty-specific collections for fields such as oncology and cardiology, enabling precise medical language processing. 
 Synonym expansion engine â€“ This engine expands medical terms into sets of clinically equivalent expressions. For a term like â€œinsulin pump,â€ it retrieves medical synonyms such as â€œCSIIâ€ from the terminology database, supplements these with general language alternatives, and handles abbreviations. The resulting synonym list makes sure queries capture content regardless of terminology variations. 
 Context-aware query builder â€“ This component transforms medical term lists into optimized search queries. It uses the Synonym Expansion Engine for each term, formats synonym groups with Boolean operators, and applies system-specific syntax. When targeting healthcare professional content, it adds credential filters. The output balances comprehensiveness with system constraints to maximize relevant result retrieval. 
 Query effectiveness analyzer â€“ This analyzer evaluates query performance and provides improvement recommendations. It calculates metrics including result relevance, topic diversity, and healthcare professional content ratio. Using NLP to identify medical entities, it suggests specific improvements such as broadening queries with few results or adding professional filters when needed. 
 Taxonomy-based query generator â€“ This orchestrator manages the entire workflow as the main client interface. It coordinates with other components to construct optimized queries and packages results with expansion metadata. It also evaluates search results to provide performance metrics and improvement suggestions, delivering sophisticated search capabilities through a simplified interface. 
 
The following sequence diagram illustrates a typical use case for a taxonomy-driven query lookup. 
 A typical user journey narrative includes the following phases: 
 
 Step 1: User intent â€“ The user enters two simple terms, â€œdiabetesâ€ and â€œinsulin pump,â€ into the search interface. They specify they want to search on Twitter and only see content from healthcare professionals. This basic information is passed on to our query enhancement system, which begins the process of creating a more comprehensive search. 
 Step 2: Expand first term â€“ The system looks up â€œdiabetesâ€ in its medical terminology database (SNOMED CT). It identifies several related terms and technical variations, including â€œdiabetes mellitusâ€ (the formal medical term), â€œDMâ€ (common medical abbreviation), â€œT1DMâ€ (Type 1 diabetes mellitus), and â€œT2DMâ€ (Type 2 diabetes mellitus). The system incorporates these terms to make sure the search captures the full spectrum of diabetes-related discussions. 
 Step 3: Expand second term â€“ The system then consults its database (MeSH terminology) for â€œinsulin pumpâ€ and discovers related clinical terms such as â€œinsulin infusion pumpâ€ (formal medical device name), â€œcontinuous subcutaneous insulin infusionâ€ (clinical procedure name), and â€œCSIIâ€ (common medical abbreviation). These variations are integrated into the search query to capture the different terminology healthcare professionals might use when discussing this treatment approach. 
 Step 4: Build enhanced query â€“ The system intelligently combines the expanded terms into organized groups: Group 1 (diabetes OR diabetes mellitus OR DM OR T1DM OR T2DM) and Group 2 (insulin pump OR insulin infusion pump OR continuous subcutaneous insulin infusion OR CSII). It connects these groups with AND operators to make sure results contain references to both diabetes and insulin pump technologies, creating a focused yet comprehensive query structure. 
 Step 5: Add professional filters â€“ Because the user specifically wants content from healthcare professionals, the system adds specialized filters, including professional title indicators (doctor OR physician OR MD OR clinician OR nurse OR NP OR pharmacist OR PharmD OR healthcare professional OR HCP OR medical) and Twitterâ€™s verification filter (filter: verified). These filters work together to prioritize content from qualified medical experts while filtering out public discussions. 
 Step 6: Execution and analysis â€“ The system executes this enhanced query on Twitter and analyzes the returned results to evaluate their relevance and professional source quality. It provides the user with performance metrics such as: â€œFound 5 results with 80% from verified healthcare professionals.â€ The query effectiveness analyzer module then offers intelligent suggestions for further refinement, such as incorporating age-specific terms (pediatric, adult, elderly) to better target specific patient populations. 
 
The following diagram illustrates how the taxonomy-based query generation flow can be implemented on AWS using Amazon Bedrock Agents. 
 
Results and next steps 
Indegeneâ€™s Social Intelligence Solution demonstrates measurable impact across various dimensions: 
 
 Time-to-insight â€“ Reduction in insight generation time 
 Operational cost savings â€“ Reduced analytics outsourcing and FTE costs 
 Business outcomes â€“ Measured by the percentage of insights used in downstream decision-making 
 
Looking ahead, the solution is evolving to deliver even more comprehensive capabilities: 
 
 Omnichannel intelligence integration â€“ Unify insights across multiple channels, including social media, CRM systems, representative interactions, email campaigns, and HCP prescription behavior, creating a true 360-degree view of stakeholder sentiment and behavior. 
 Conference listening capabilities â€“ Use advanced audio/video analysis to extract valuable insights from podcasts, webinars, and live medical conference sessionsâ€”formats that have previously been difficult to analyze at scale. 
 Conversational insight assistant powered by generative AI â€“ Help users interact with the system through natural language queries and receive real-time, narrative-style summaries of social insights. 
 
Conclusion 
This post explored how advancements in generative AI have sparked a change in how pharmaceutical teams access and use social intelligence, transforming insights into instantly accessible and actionable resources across the organization. In future posts, we will explore specific use cases, such as conference listening, Key Opinion Leader (KOL) identification, and Digital Opinion Leader (DOL) identification.To learn more, refer to the following resources: 
 
 Guidance for Social Media Insights on AWS 
 Generative AI in Healthcare &amp; Life Sciences 
 AWS Skill Builder course: Building Generative AI Applications Using Amazon Bedrock 
 GitHub repo: Sample Healthcare and Life Sciences Agents on AWS 
 
 
 
About the authors 
Rudra Kannemadugu is a Senior Directorâ€“Data and Advanced Analytics at Indegene with 22+ years of experience, leading digital transformation across pharma, healthcare, and retail. He specializes in drug launches, sales force operations, and building enterprise data ecosystems. A strategic leader in GenAI adoption, he drives commercial analytics, predictive modeling, and marketing automation. Rudra is a proven people leader in spearheading AI transformation initiatives and talent development, and is also skilled in cross-functional collaboration and global stakeholder management to accelerate drug commercialization. 
Shravan K S is a Senior Managerâ€“Data Analytics at Indegene and an experienced GenAI Architect with 17+ years in analytics, data platforms, and system integration across life sciences and healthcare. He has led the delivery of secure, scalable solutions in Generative AI, data engineering, platform modernization, and emerging Agentic AI systems. Skilled in driving transformation through SAFe Agile, he advances innovation via cloud-native architectures and AI-driven data operations. He holds advanced certifications from AWS, Snowflake, and Dataiku, and combines cutting-edge technologies with real-world impact in pharma and healthcare analytics. 
Bhagyashree Chandak&nbsp;is a Solutions Architect in the APAC region. She works with customers to design and build innovative solutions in the AWS Cloud, bridging the gap between complex business requirements and technical solutions across various domains. As an AI/ML enthusiast, Bhagyashree has expertise in both traditional ML and advanced GenAI techniques. 
Punyabrota Dasgupta is a Principal Solutions Architect at AWS. His area of expertise includes machine learning applications for media and entertainment business. Beyond work, he loves tinkering and restoration of antique electronic appliances.
â€¢ Unlocking enhanced legal document review with Lexbe and Amazon Bedrock
  This post is co-authored with Karsten Weber and Rosary Wang from Lexbe. 
Legal professionals are frequently tasked with sifting through vast volumes of documents to identify critical evidence for litigation. This process can be time-consuming, prone to human error, and expensiveâ€”especially when tight deadlines loom. Lexbe, a leader in legal document review software, confronted these challenges head-on by using Amazon Bedrock. By integrating the advanced AI and machine learning services offered by Amazon, Lexbe streamlined its document review process, boosting both efficiency and accuracy. In this blog post, we explore how Lexbe used Amazon Bedrock and other AWS services to overcome business challenges and deliver a scalable, high-performance solution for legal document analysis. 
Business challenges and why they matter 
Legal professionals routinely face the daunting task of managing and analyzing massive sets of case documents, which can range anywhere from 100,000 to over a million. Rapidly identifying relevant information within these large datasets is often critical to building a strong caseâ€”or preventing a costly oversight. Lexbe addresses this challenge by using Amazon Bedrock in their custom application: Lexbe Pilot 
Lexbe Pilot is an AI-powered Q&amp;A assistant integrated into the Lexbe eDiscovery platform. It enables legal teams to instantly query and extract insights from the full body of documents in an entire case using generative AIâ€”eliminating the need for time-consuming manual research and analysis. Using Amazon Bedrock Knowledge Bases, users can query an entire dataset and retrieve grounded, contextually relevant results. This approach goes far beyond traditional keyword searches by helping legal teams identify critical or smoking gun documents that could otherwise remain hidden. As legal cases grow, keyword searches that previously returned a handful of documents might now produce hundreds or even thousands. Lexbe Pilot distills these large result sets into concise, meaningful answersâ€”giving legal teams the insights they need to make informed decisions. 
Failing to address these challenges can lead to missed evidence, possibly resulting in unfavorable outcomes. With Amazon Bedrock and its associated services, Lexbe provides a scalable, high-performance solution that empowers legal professionals to navigate the growing landscape of electronic discovery efficiently and accurately. 
Solution overview: Amazon Bedrock as the foundation 
Lexbe transformed its document review process by integrating Amazon Bedrock, a powerful suite of AI and machine learning (ML) services. With deep integration into the AWS ecosystem, Amazon Bedrock delivers the performance and scalability necessary to meet the rigorous demands of Lexbeâ€™s clients in the legal industry. 
Key AWS services used: 
 
 Amazon Bedrock. A fully managed service offering high-performing foundation models (FMs) for large-scale language tasks. By using these models, Lexbe can rapidly analyze vast amounts of legal documents with exceptional accuracy. 
 Amazon Bedrock Knowledge Bases. Provides fully managed support for an end-to-end Retrieval-Augmented Generation (RAG) workflow, enabling Lexbe to ingest documents, perform semantic searches, and retrieve contextually relevant information. 
 Amazon OpenSearch. Indexes all the document text and corresponding metadata. Both Vector and Text modes are used. This allows Lexbe to quickly locate specific documents or key information across large datasets by vector or by keyword. 
 AWS Fargate. Orchestrates the analysis and processing of large-scale workloads in a serverless container environment, allowing Lexbe to scale horizontally without the need to manage underlying server infrastructure. 
 
Amazon Bedrock Knowledge Bases architecture and workflow 
The integration of Amazon Bedrock within Lexbeâ€™s platform is shown in the following architecture diagram. The architecture is designed to handle both large-scale ingestion and retrieval of legal documents. 
 
 User access: A user accesses the frontend application through a web browser. 
 Request routing: The request is routed through Amazon CloudFront, which connects to the backend through an Application Load Balancer. 
 Backend processing: Backend services running on Fargate handle the request and interact with the system components. 
 Document handling: Legal documents are stored in an Amazon Simple Storage Service (Amazon S3) bucket, and Apache Tika extracts text from these documents. The extracted text is stored as individual text files in a separate S3 bucket. This bucket is used as the source repository for Amazon Bedrock. 
 Embedding creation: The extracted text is processed using Titan Text v2 to generate embeddings. Lexbe experimented with multiple embedding modelsâ€”including Amazon Titan and Cohereâ€”and tested configurations with varying token sizes (for example, 512 compared to 1024 tokens). 
 Embedding sorage: The generated embeddings are stored in a vector database for fast retrieval. 
 Query execution: Amazon Bedrock Knowledge Bases retrieves relevant data from the vector database for a given query. 
 LLM integration: The Amazon Bedrock Sonnet 3.5 large language model (LLM) processes the retrieved data to generate a coherent and accurate response. 
 Response delivery: The final response is returned to the user using the frontend application through CloudFront. 
 
Amazon and Lexbe collaboration 
Over an eight-month period, Lexbe worked hand-in-hand with the Amazon Bedrock Knowledge Bases team to enhance the performance and accuracy of its Pilot feature. This collaboration included weekly strategy meetings between senior teams from both organizations, enabling rapid iterations. From the outset, Lexbe established clear acceptance criteria focused on achieving specific recall rates. These metrics served as a benchmark for when the feature was ready for production. As illustrated in the following figure, the systemâ€™s performance underwent five significant milestones, each marking a leap toward production. We focused on Recall Rate because identifying the right documents is critical to getting the correct response. Unlike some use cases for Retrieval Augmented Generation (RAG) where the user has a specific question that can often be answered by a few documents, we are looking to generate finding-of-facts reports that require a large number of source documents. For this reason, we focused on Recall Rate to help ensure that Amazon Bedrock Knowledge Bases was not leaving out important information. 
First iteration: January 2024. The initial system only had a 5% Recall Rate showing that much work was needed to get to production. 
Second iteration: April 2024. New features were added to Amazon Bedrock Knowledge Bases leading to a noticeable boost in accuracy. We were now at 36% Recall Rate. 
Third iteration: June 2024. Parameter adjustment, particularly around token size, led to another jump in performance. This brought Recall Rate to 60%. 
Fourth iteration: August 2024. A Recall Rate of 66% was achieved using Titan Embed text-v2 models. 
Fifth iteration: December 2024. Introduction of Reranker technology proved invaluable and enabled up to 90% Recall Rate. 
 
The final outcome is impressive 
 
 Broad, human-style reporting. In an industrial-accident matter, Pilot was asked to conduct a full findings-of-fact analysis. It produced a polished, five-page report complete with clear section headings and hyperlinks back to every source document regardless of whether those documents were in English, Spanish, or any other language. 
 Deep, automated inference. In a case of tens of thousands of documents, we asked, â€œWho is Bobâ€™s son?â€ There was no explicit reference to his children anywhere. Yet Pilot zeroed in on an email that began â€œDear Fam,â€ closed with â€œLove, Mom/Linda,â€ and included the childrenâ€™s first and last names in the metadata. By connecting those dots, it accurately identified Bobâ€™s son and cited the exact email where the inference was made. 
 
Traditional techniques in eDiscovery are unable to do either of the above. With Pilot, legal teams can: 
 
 Generate actionable reports that attorneys can swiftly iterate for deeper analysis. 
 Streamline eDiscovery by surfacing critical connections that go far beyond simple text matches. 
 Unlock strategic insights in moments, even from multilingual data. 
 
Whether you need a comprehensive, human-readable report or laser-focused intelligence on the relationships lurking in your data, Lexbe Pilot, powered by Amazon Bedrock Knowledge Bases, delivers the precise information you needâ€”fast. 
Benefits of integrating Amazon Bedrock and AWS services 
By integrating Amazon Bedrock with other AWS services, Lexbe gained several strategic advantages in their document review process: 
Scalability. Using Amazon Elastic Container Service (Amazon ECS) and AWS Fargate, Lexbe can dynamically scale its processing infrastructure. 
Cost efficiency. Processing in Amazon ECS Linux Spot Market provides a significant cost advantage. 
Security. The robust security framework of AWS, including encryption and role-based access controls, safeguards sensitive legal documents. This is critical for Lexbeâ€™s clients, who must adhere to strict confidentiality requirements. 
Conclusion: A scalable, accurate, and cost-effective solution 
Through its integration of Amazon Bedrock, Lexbe has transformed its document review platform into a highly efficient, scalable, and accurate solution. By combining Amazon Bedrock, Amazon OpenSearch, and AWS Fargate, they achieved marked improvements in both retrieval accuracy and processing speedâ€”all while keeping costs under control. Lexbeâ€™s success illustrates the power of AWS AI/ML services to tackle complex, real-world challenges. By harnessing the flexible, scalable, and cost-effective offerings of AWS, Lexbe is well-equipped to meet the evolving needs of the legal industryâ€”both today and in the future. If your organization is facing complex challenges that could benefit from AI/ML-powered solutions, take the next step with AWS. Start by working closely with your AWS Solutions Architect to design a tailored strategy that aligns with your unique needs. Engage with the AWS product team to explore cutting-edge services to make sure that your solution is scalable, secure, and future-ready. Together, we can help you innovate faster, reduce costs, and deliver transformative outcomes. 
 
About the authors 
Wei Chen is a Senior Solutions Architect at Amazon Web Services, based in Austin, Texas. With over 20 years of experience, he specializes in helping customers design and implement solutions for complex technical challenges. In his role at AWS, Wei partners with organizations to modernize their applications and fully leverage cloud capabilities to meet strategic business goals. His area of expertise is AI/ML and AWS Security services. 
Gopikrishnan Anilkumar&nbsp;is a Principal Technical Product Manager in Amazon. He has over 10 years of product management experience across a variety of domains and is passionate about AI/ML. 
Sandeep Singh&nbsp;is a Senior Generative AI Data Scientist at Amazon Web Services, helping businesses innovate with generative AI. He specializes in generative AI, machine learning, and system design. He has successfully delivered state-of-the-art AI/ML-powered solutions to solve complex business problems for diverse industries, optimizing efficiency and scalability. 
Karsten Weber&nbsp;is the CTO and Co-founder of Lexbe, an eDiscovery provider, since January 2006. Based in Austin, Texas, Lexbe offers Lexbe Online, a cloud-based application for eDiscovery, litigation, and legal document processing, production, review, and case management. Under Karstenâ€™s leadership, Lexbe has developed a robust platform and comprehensive eDiscovery services that assist law firms and organizations with efficiently managing large ESI data sets for legal review and discovery production. Karstenâ€™s expertise in technology and innovation has been pivotal in driving Lexbeâ€™s success over the past 19 years. 
Rosary Wang&nbsp;is a Sr. Software Engineer at Lexbe, an eDiscovery software and services provider based in Austin, Texas.
â€¢ Automate AIOps with SageMaker Unified Studio Projects, Part 2: Technical implementation
  In Part 1 of our series, we established the architectural foundation for an enterprise artificial intelligence and machine learning (AI/ML) configuration with Amazon SageMaker Unified Studio projects. We explored the multi-account structure, project organization, multi-tenancy approaches, and repository strategies needed to create a governed AI development environment. 
In this post, we focus on implementing this architecture with step-by-step guidance and reference code. We provide a detailed technical walkthrough that addresses the needs of two critical personas in the AI development lifecycle: the administrator who establishes governance and infrastructure through automated templates, and the data scientist who uses SageMaker Unified Studio for model development without managing the underlying infrastructure. 
Our implementation guide covers the complete workflow from project initialization to production deployment, showing how the architectural components we discussed in Part 1 come together to create a seamless, secure, and efficient artificial intelligence operations (AIOps) environment. 
Solution overview 
In the following architecture, we explore an enterprise-grade machine learning operations implementation using SageMaker Unified Studio and other components that effectively addresses the distinct needs of two critical roles in the machine learning (ML) lifecycle. This approach bridges the gap between infrastructure management and data science, creating a streamlined workflow that maintains continuous integration and delivery (CI/CD) repeatability while accelerating model delivery. The implementation revolves around three personas: administrator, data scientist, and ML engineer. 
 
The architecture facilitates a seamless workflow that begins with project initialization and continues through development and deployment phases. Each step is engineered to minimize manual intervention while maximizing traceability, reproducibility, and compliance. 
Project initialization phase 
The project initialization phase (Steps 1â€“4) starts with the administrator configuring the SageMaker Unified Studio environment (for more details, see Domains in Amazon SageMaker Unified Studio), setting up the necessary AWS infrastructure, authentication configurations, GitHub connections, and project template repositories. 
 
When the SageMaker Unified Studio foundation is in place, the data scientist logs in to SageMaker Unified Studio and creates a new project. This action triggers a Create Project event that is captured by Amazon EventBridge, which invokes an AWS Lambda function responsible for automating the setup of project-specific resources. As a result, dedicated model build and model deploy repositories are created, configured, and prepopulated with seed code and CI/CD workflows like GitHub action secrets. 
Development phase 
During the development phase (Steps 5â€“8), data scientists use the SageMaker Unified Studio project to iteratively build, train, and evaluate ML models. Using SageMaker Unified Studio JupyterLab notebooks, they can write and refine the data preprocessing logic, feature engineering steps, and model training scripts. The SageMaker pipeline, defined in the model build repository, orchestrates the end-to-end workflow. Each pipeline execution is tracked, with metrics and artifacts logged for traceability and experiment management. Upon successful completion, models are registered in Amazon SageMaker Model Registry, where they await validation and approval for deployment. 
Deployment phase 
In the deployment phase (Steps 9â€“12), the approval of the model triggers an event that is captured by EventBridge, which invokes a deployment Lambda function. 
 
This function coordinates the execution of the deployment GitHub Actions workflow, which retrieves the latest approved model, applies infrastructure as code (IaC) definitions from the model deploy repository, and provisions or updates the SageMaker endpoint using the AWS Cloud Development Kit (AWS CDK). The deployment pipeline includes checks for configuration validation and rollback procedures, so only validated models are promoted to production. When the endpoint is active, the model is ready to serve predictions, completing the automated journey from development to production deployment. 
This architecture follows a comprehensive journey from ML use case project initiation to model deployment, illustrating how you can configure SageMaker Unified Studio projects to create a symbiotic relationship between these personas. The administrator establishes guardrails and automation, and data scientists gain a frictionless experience to rapidly develop, test, and deploy ML models with enterprise-grade governance built in. 
AIOps components 
The architecture implements a comprehensive AIOps environment that enables seamless operations with governance through three interconnected layers along with the three main personas, as illustrated in the previous diagram. In this section, we describe the layers that are used for describing and grouping the involved workflows for the readers. 
AIOps personas 
The administrator serves as the foundation builder, setting up the ML project infrastructure according to established organizational guidelines and governance or compliance rules. Their responsibilities include establishing organization-wide templates, security configurations, and infrastructure that enable consistent, secure, and compliant model development. Specifically, they complete the following tasks: 
 
 Create and configure SageMaker Unified Studio domains and other administrative configurations. See the SageMaker Unified Studio Administrator Guide for more information. 
 Configure custom ML use case templates for SageMaker Unified Studio ML use cases with GitHub integration. 
 Deploy infrastructure, including AWS Step Functions workflows and Lambda functions for automated project setup, which includes use case template selection based on project profile. 
 Set up AWS Identity and Access Management (IAM) policies and roles for secure access management. 
 Establish CI/CD pipelines (for example, using GitHub Actions) for automated workflows. 
 Create standardized model building and deployment patterns. 
 Manage access controls across repositories and other SageMaker resources. 
 
The following diagram illustrates the administrator workflow. 
 
The data scientist focuses on extracting value from data through model development without needing to manage infrastructure complexities. With proper AIOps foundations in place, they can efficiently accomplish the following: 
 
 Launch new projects with preconfigured environments and repositories. For more information, see Create a project. 
 Develop ML models using the familiar notebook interfaces. For more details, refer to Using the JupyterLab IDE in Amazon SageMaker Unified Studio. 
 Register models in SageMaker Model Registry for versioning and governance. 
 
ML engineer perform the following tasks: 
 
 Execute SageMaker pipelines for data preprocessing, training, and evaluation. For more details, see Machine learning. 
 Monitor deployment processes and model performance. 
 
Project-specific components 
At the core of our architecture are the project-specific repositories that contain the code, configurations, and infrastructure definitions needed for model development and deployment (such as the model build repository and model deployment repository). The model build repository stores the model development code like data preprocessing, feature engineering, and training scripts. The model build code is provided as seed code to help the data science team get started and contains the SageMaker Unified Studio pipeline definitions (for more details, see SageMaker Pipelines) for orchestrating the ML workflow. The following diagram shows this pipeline. 
 
You can extend this pipeline to include organizational best practices like unit tests, integration tests, validation scripts, and GitHub Actions workflow configurations for build automation. 
Similarly, the model deploy repository contains IaC for endpoint deployment, defining the endpoint configurations, instance types, and scaling policies. It includes monitoring configurations and alerting thresholds, and stores deployment validation tests and rollback procedures. The following screenshot shows the details of our example repository. 
 
Both repositories are automatically provisioned and seeded with template code when a data scientist initiates a new project through the SageMaker Unified Studio interface. 
Shared services layer 
The shared services layer provides the automation, orchestration, and integration capabilities that connect the various components. The CI/CD infrastructure provides the GitHub Actions workflows that execute when ML code is pushed to project repositories. You can replace GitHub Actions with your choice of tooling, like Gitlab or others. For this example, GitHub Actions is integrated using AWS credentials through OIDC/JWT for secure repository-to-AWS authentication. For more information about setting up an IAM OpenID Connect (OIDC) identity provider on GitHub, see Configuring OpenID Connect in Amazon Web Services. GitHub Actions build pipelines are used to orchestrate model training with data preprocessing, model training, evaluation, and model registration steps. Similarly, GitHub Actions deployment pipelines handle model selection and endpoint creation. 
The event-driven automation is integrated using Amazon EventBridge for event management and workflow orchestration. It manages the SageMaker Unified Studio project setup Lambda function, which responds to project creation events, and the deploy Lambda function, which coordinates model deployment activities. 
Development environment 
The development environment centers around the SageMaker Unified Studio project space, which provides data scientists with the tools and resources needed for effective model development. SageMaker Unified Studio JupyterLab notebooks or the Code Editor integrated development environment (IDE) enable interactive development and experimentation, and Amazon SageMaker Catalog organizes and manages ML data assets. A SageMaker Unified Studio project Amazon Simple Storage Service (Amazon S3) bucket is used for storing intermediary training data, validation datasets, and model artifacts. Amazon SageMaker Pipelines facilitates the orchestration of data preprocessing, model training, evaluation, and registration steps, making sure the ML workflow is both reproducible and traceable. The following screenshot shows an example of the pipeline. 
 
Throughout the workflow, experiment tracking is enabled using SageMaker managed MLflow integration, and model registration is managed through SageMaker Model Registry. After a model is approved, deployment is triggered, and the model is served through a SageMaker endpoint, completing the end-to-end lifecycle from development to production. This architecture provides a scalable, secure, and efficient foundation for ML model development and deployment, maintaining strong governance and control while enabling rapid innovation and collaboration between administrators and data scientists. 
Security and governance features 
Security and governance are embedded throughout the architecture to maintain compliance with organizational policies and regulatory requirements. Role-based access control is enforced using IAM, clearly separating administrative duties from data science activities. Code and configuration changes are tracked through version-controlled repositories, providing a comprehensive audit trail. Automated CI/CD pipelines incorporate security checks and validation steps, reducing the risk of misconfigurations or unauthorized changes. Centralized governance is maintained through the SageMaker Unified Studio domain project profile, which governs on-demand project configurations. 
Solution code 
You can follow and execute the full code from the GitHub repository. You will find detailed instructions in the repository readme documentation for setup, prerequisites, and execution steps. 
Set up a project with a template 
Before diving into the setup process, letâ€™s understand two key concepts in SageMaker Unified Studio: project profiles and projects. 
Project profiles define the template configurations for projects in your SageMaker Unified Studio domains. A project profile is a collection of environment blueprints that configure project data and compute assets and determine which capabilities are available to project users. Only domain administrators can create and manage these project profiles, maintaining organizational control over project configurations. For more information about project profiles, see Project profiles in Amazon SageMaker Unified Studio. 
Projects in SageMaker Unified Studio are containers where users organize their ML development work. Each project provides a collaboration space through source control repositories and creates permission boundaries for project artifacts and resources. Projects are created using templates defined in the project profile, which controls the tools and capabilities available within the project. For more information about project, see Projects. 
As described earlier in this post, the required infrastructure for project automation must be deployed in your AWS account before data scientists can create projects. After administrators have configured the SageMaker Unified Studio domain, established project templates, and deployed the Step Functions and Lambda functions responsible for project automation, the project creation process can begin. 
When a data scientist creates a new project in SageMaker Unified Studio, they select from available project templates defined in the project profile and configure the GitHub integration by selecting the Git connection and choosing to create a new repository and branch. SageMaker Unified Studio then initiates project creation based on the parameters defined during project creation. This project creation process generates a CreateProject API call that is logged in AWS CloudTrail. An EventBridge rule monitors these CloudTrail logs and triggers the pre-deployed Step Functions workflow when it detects the CreateProject event. The workflow waits for SageMaker Unified Studio to complete the initial project creation, then retrieves the project template ID and Git repository details from the event payload. 
The following diagram illustrates the Step Functions workflow. 
 
The Step Functions workflow makes API calls to the Amazon DataZone client to get the project profile name. SageMaker uses Amazon DataZone to manage underlying components of SageMaker Unified Studio projects. Based on the project template name from the event, it identifies and fetches the corresponding seed code from the source Git repository. For example, if the project template name is regression, the workflow locates and retrieves the regression-specific code from the source repository and pushes it to the newly created build repository. The workflow also creates and configures the required GitHub secrets for CI/CD pipeline operations. 
Next, the workflow creates a deployment repository using the naming format projectid-domainid-deploy-repo. It copies the template-specific deployment code from the source Git repository to this new repository. Administrators can modify this naming convention by updating the code associated with the deploy repository creation. 
The workflow is complete when the initial deployment is finished, providing a fully configured development environment aligned with the selected project template. 
This automation provides a consistent project setup while maintaining organizational standards. The project creation process configures two repositories with automated CI/CD workflows for model building and deployment, as illustrated in the following screenshot. 
 
Access the SageMaker Catalog dataset in the SageMaker pipeline 
SageMaker Catalog provides a streamlined mechanism for discovering, accessing, and using enterprise data assets within your ML pipelines. Before accessing datasets in SageMaker pipelines, data scientists must subscribe to datasets through SageMaker Catalog. This subscription process creates the necessary permissions and resource links to make the data accessible within the project boundary. Refer to Request subscription to assets in Amazon SageMaker Unified Studio to request subscription to a dataset in SageMaker Catalog. 
The following diagram illustrates this workflow. 
 
After the datasets are successfully subscribed, they can be accessed within the project by SageMaker Pipelines using AWS Glue Data Catalog integration for structured data published as AWS Glue tables. This approach offers advantages like SQL-based querying capabilities for pre-training data filtering, schema validation, and support for partitioned datasets. SageMaker Catalog handles the permission mapping between your project and the subscribed datasets. If you need access to unstructured data that isnâ€™t managed through AWS Glue tables, you can leverage the S3 Object collections feature supported in SageMaker Catalog as described in the documentation. 
After you configure data access, the next step is to integrate the data processing step into the pipeline. This step includes logic to read the dataset, perform required preprocessing, and save the processed data for subsequent steps in the pipeline, such as model training. After the pipeline is defined with these steps, it can be executed and monitored using SageMaker Unified Studio. You can navigate to the ML Pipelines section to view the status of each step, including the data processing step. 
Run the model build and deploy CI/CD pipelines 
The automation of ML workflows through CI/CD pipelines is crucial for maintaining consistent and reliable model development and deployment processes. In our implementation, we use GitHub Actions to create two distinct pipelines: one for model building and another for deployment. Both repositories come configured with the SageMaker Unified Studio project creation event. You can reconfigure this setup and architecture to function with your preferred CI/CD tooling, such as Gitlab. 
Model build pipeline 
The model build pipeline automatically triggers when code changes are pushed to the main branch or pull requests are created. For more details, see Performing Git operations. 
 
This pipeline uses AWS OIDC GitHub authentication for secure, token-based access to AWS services, alleviating the need to store long-term credentials in GitHub. Upon activation, the pipeline executes a series of steps, including code checkout, environment setup, dependency installation, and SageMaker pipeline updates. 
 
The build process validates the ML pipeline definition and makes sure the components are properly configured before initiating the training process. 
Model deployment pipeline 
Similarly for model deployment, weâ€™ve implemented a separate pipeline that activates either through manual triggers or automatically when a model receives approval in SageMaker Model Registry. This deployment pipeline handles the creation and updating of SageMaker endpoints, managing model versions, and configuring staging and production environments. It includes error handling with automatic rollback capabilities using AWS CDK code and logging to Amazon CloudWatch through the AWS CloudFormation stack. 
 
The deployment process can be altered to further suit your requirements with scenarios where additional model deployment steps and workflows are needed before serving a model on the endpoint. 
Both pipelines follow IaC principles, with modifications version-controlled in Git repositories. This approach provides transparency, reproducibility, and proper change management. The pipeline definitions include: 
 
 Specific IAM roles with least-privilege access 
 Environment-specific configurations 
 Resource provisioning scripts 
 
For teams adopting this setup, we recommend the following best practices: 
 
 Maintain separate roles and permissions for build and deploy pipelines. See Security best practices in IAM for more information. 
 Implement comprehensive testing at each stage. 
 Use environment-specific configurations through GitHub secrets and variables. 
 Enable detailed logging and monitoring. 
 Regularly audit and update pipeline configurations. 
 
This CI/CD implementation creates a streamlined, secure, and maintainable AIOps workflow that supports both rapid development and stable production deployments. The automation reduces manual intervention, minimizes errors, and accelerates the model development lifecycle while maintaining security and governance requirements. 
Validate project deployment 
After you create a project using SageMaker Unified Studio project templates, validate the successful setup of all components: 
 
 Your GitHub organization should contain two new repositories with the template-specific seed code and GitHub Actions workflows for automated model build and deployment pipelines. 
 In the SageMaker Unified Studio UI, on the Build menu, choose ML Pipelines under Orchestration to view your pipeline executions. You can verify the execution status and results of each pipeline run. 
 The SageMaker Unified Studio Model Registry in the AI OPS section contains your registered model package with status and version information. 
 Finally, verify the model inference endpoint by navigating to the SageMaker Unified Studio Model Registry. On the Build menu, choose Inference endpoints under Machine Learning &amp; Generative AI to view your endpoint name and its In Service status. 
 
These validations confirm successful project creation, model training, and deployment through the automated workflows. 
Clean up 
To avoid unnecessary costs, remember to delete resources such as the SageMaker MLflow tracking server, SageMaker pipelines and SageMaker endpoints. 
Conclusion 
In this two-part series, we provided a comprehensive framework for setting up and automating AIOps workflows with SageMaker Unified Studio projects. In Part 1, we established the architectural foundation, and in this post, we presented the practical implementation that addresses various concerns, including multi-tenancy, security, governance, scalability, repeatability, and reliability. 
We demonstrated how to scale your AIOps for build and deployment pipelines across a large number of projects. The automated workflows for project setup, model building, and deployment reduce manual bottlenecks while providing consistent application of best practices across your AI workloads. 
The AIOps solution weâ€™ve shared, along with implementation code, provides a good starting point for your own AIOps implementation. This approach can help organizations efficiently operationalize their AI initiatives, reducing the time from idea to production while maintaining appropriate security and governance controls. 
The flexibility of the framework accommodates various use cases, from traditional ML models to generative AI applications, making it a valuable foundation for any organizationâ€™s AI journey. We encourage you to experiment with the architectures presented in this post, scale it to multiple projects and accounts, adapt it to your specific needs, and share your feedback as you build your AIOps capabilities on AWS. See Getting Started documentation&nbsp;and the solution code for this blog from the&nbsp;GitHub repository&nbsp;to start building your ML use cases. 
 
  
 
 
About the Authors 
Ram Vittal is a GenAI/ML Specialist SA at AWS. He has over 3 decades of experience architecting and building distributed, hybrid, and cloud applications. He is passionate about building secure, scalable, reliable GenAI/ML solutions to help customers with their cloud adoption and optimization journey to improve their business outcomes. In his spare time, he rides motorcycle and walks with his sheep-a-doodle! 
Sandeep Raveesh is a GenAI Specialist Solutions Architect at AWS. He works with customer through their AIOps journey across model training, GenAI applications like Agents, and scaling GenAI use-cases. He also focuses on Go-To-Market strategies helping AWS build and align products to solve industry challenges in the GenerativeAI space. You can find Sandeep on&nbsp;LinkedIn. 
Koushik Konjeti is a Senior Solutions Architect at Amazon Web Services. He has a passion for aligning architectural guidance with customer goals, ensuring solutions are tailored to their unique requirements. Outside of work, he enjoys playing cricket and tennis. 
Vaibhav Sabharwal is a Senior Solutions Architect with Amazon Web Services (AWS) based out of New York. He is passionate about learning new cloud technologies and assisting customers in building cloud adoption strategies, designing innovative solutions, and driving operational excellence. As a member of the Financial Services Technical Field Community at AWS, he actively contributes to the collaborative efforts within the industry.

â¸»