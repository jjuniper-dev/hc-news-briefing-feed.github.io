‚úÖ Morning News Briefing ‚Äì August 24, 2025 10:42

üìÖ Date: 2025-08-24 10:42
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ Current Conditions:  16.9¬∞C
  Temperature: 16.9/deg;C Pressure / Tendency: 100.8 kPa rising Humidity: 93 % Dewpoint: 15.8&deg:C Wind: SSW 5 km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Sunday 24 August 2025 Temperature: . 16/9/C Pressure: 100
‚Ä¢ Sunday: Chance of showers. High 25. POP 30%
  A mix of sun and cloud with 30 percent chance of showers late this afternoon . Wind becoming southwest 20 km/h this morning . High 25. Humidex 27. UV index 7 or high, with a high UV index of 7 or very high . Rainy showers expected later this afternoon, with highs of 25.50 per cent chance of rain in the afternoon, forecasters predict
‚Ä¢ Sunday night: Chance of showers. Low 14. POP 30%
  Mainly cloudy with 30 percent chance of showers . Low 14. Southerlyly cloudy . Showery weather forecast for Sunday, August 24, 2025 . Forecast issued 5:00 AM EDT Sunday 24 August 2025 . Weather will be mostly cloudy in the morning, with rain likely to fall in a few hours, then cool again in the afternoon . Low temperatures expected to drop to

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ It was the costliest hurricane in U.S. history: Have we forgotten Katrina's lessons?
  Nearly 1,400 people died after Hurricane Katrina crashed into Louisiana and Mississippi . Most of the deaths were in New Orleans, which has had an uneven recovery in the past 20 years . New Orleans has had a very uneven recovery since Hurricane Katrina, with many still recovering from the disaster . The recovery has been uneven in the last 20 years, with the city still recovering slowly from Hurricane Katrina .
‚Ä¢ The state of Michigan hopes its scents will bring people to visit
  The state's tourism campaign offers a fragrance for the summer with notes of the beach, wineries and lavender . They struck a chord with some people relaxing by the water . The fragrance was created by the state's Tourism campaign . The campaign is based on a fragrance from the beach and wineries in the state of New Zealand . It is available on Amazon.com for more information .
‚Ä¢ Smithsonian artists and scholars respond to White House list of objectionable art
  A page published by the White House titled "President Trump Is Right About the Smithsonian" lists exhibits, educational sites and more that the administration seems to take issue with . The administration has taken issue with some of the Smithsonian exhibits and educational sites that they say the administration is right about . The White House says the Smithsonian is "right" about the Smithsonian's exhibits, education and other sites .
‚Ä¢ Fans across the country raise their voices at 'KPop Demon Hunters' singalongs
  Netflix's wildly popular movie about a fictitious all-girl rock band is hitting nearly 1,800 movie theaters around the country this weekend . A singalong version of the movie will be released in theaters this weekend as part of a singalong . The movie is based on a fictional fictional fictional band called the All-Girl Rockers, and is about to be released on Netflix this week .
‚Ä¢ Boxed in by shifting tariff rules, European shippers pause some U.S.-bound parcels
  Many European postal agencies and companies say until new systems are set up they can't ship some goods . Gifts worth less than $100 are not affected . New customs regulations take effect August 29, and many companies say they won't be able to ship some items until new system is set up . Gift money is not affected by the new customs regulations, and gifts worth under $100 aren't

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Bug bounties: The good, the bad, and the frankly ridiculous ways to do it
  Thirty years ago, Netscape kicked off the first commercial bug bounty program . Since then, companies large and small have bought into the idea, with mixed results . For incentives remember the three Fs ‚Äì finance, fame, and fixing it feature¬† For incentives, remember the 3 Fs: Remember the 3Fs ‚Äì Finance, Fame, and Fix it feature . For incentive, remember
‚Ä¢ Search-capable AI agents may cheat on benchmark tests
  Search-based AI models may cheat on benchmark tests by fetching the answers directly from online sources rather than deriving those answers through a "reasoning" process . Data contamination can make models seem more capable than they really are, says Scale AI . Researchers with Scale AI have found that search-based . AI models are more likely to cheat on benchmarks than they would otherwise be able to
‚Ä¢ VirtualBox 7.2 fixes flaky 3D guests and adds Arm-on-Arm support
  Oracle-backed FOSS hypervisor a worthy rival to Hyper-V and VMware hands on hands on . VirtualBox 7.2 is here, bringing improved Arm-on-Arm virtualization features and better 3D acceleration support . The new version of VirtualBox will be available in the wild for the first time in the U.S. VirtualBox is now available in beta beta .
‚Ä¢ The Unix Epochalypse might be sooner than you think
  Museum boffins find code that crashes in 2037 . System restorers discover unsetting issue while working on ancient systems . Epochalypse, also known as the "Year 2038 problem," has come from the past . National Museum Of Computing system restorers have discovered an unsetting error in an ancient computer system . Back to Mail Online home .Back to the page you came
‚Ä¢ US government snaps up 10% of Intel for $8.9B
  The funds were already allocated under the CHIPS Act and Secure Enclave program . Congratulations America, your government now owns 10 percent of troubled domestic chipmaker Intel .‚Ä¶‚Ä¶‚Ä¶ Your government now now owns ten percent of struggling domestic chipmakers Intel . The funds are already allocated in the CHIP Act and the Secure Connections Act and secure Enclave Program . The government is now trying to

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Genomic epidemiology of Mycobacterium tuberculosis in Wales
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Human activity-aware coverage path planning for robot-based mosquito control
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ U.S. trust in physicians as key public health messengers during the H5N1 avian influenza outbreak
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Knowledge, attitudes, and practices regarding home-based cardiac rehabilitation in patients with chronic heart failure
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ One Health approach uncovers emergence and dynamics of Usutu and West Nile viruses in the Netherlands
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ The Download: Google‚Äôs AI energy expenditure, and handing over DNA data to the police
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



In a first, Google has released data on how much energy an AI prompt uses



Google has just released a report detailing how much energy its Gemini apps use for each query. In total, the median prompt‚Äîone that falls in the middle of the range of energy demand‚Äîconsumes 0.24 watt-hours of electricity, the equivalent of running a standard microwave for about one second. The company also provided average estimates for the water consumption (five drops per query) and carbon emissions associated with a text prompt to Gemini.It‚Äôs the most transparent estimate yet from a Big Tech company with a popular AI product, and the report includes detailed information about how the company calculated its final estimate.



Earlier this year, MIT Technology Review published a comprehensive series on AI and energy, at which time none of the major AI companies would reveal their per-prompt energy usage. Google‚Äôs new publication, at last, allows for a peek behind the curtain that researchers and analysts have long hoped for. Read the full story.



‚ÄîCasey Crownhart







I gave the police access to my DNA‚Äîand maybe some of yours



Last year, I added my DNA profile to a private genealogical database, FamilyTreeDNA, and clicked ‚ÄúYes‚Äù to allow the police to search my genes.



In 2018, police in California announced they‚Äôd caught the Golden State Killer, a man who had eluded capture for decades. Once the police had ‚Äúmatches‚Äù to a few relatives of the killer, they built a large family tree from which they plucked the likely suspect.This process, called forensic investigative genetic genealogy, or FIGG, has since helped solve hundreds of murders and sexual assaults.



But I wasn‚Äôt really driven by some urge to capture distantly related serial killers. Rather, my spit had a less gallant and more quarrelsome motive: to troll privacy advocates whose fears around DNA I think are overblown and unhelpful. By giving up my saliva for inspection, I was going against the view that a person‚Äôs DNA is the individualized, sacred text that privacy advocates sometimes claim. Read the full story.



‚ÄîAntonio Regalado



This article appeared in The Checkup, MIT Technology Review‚Äôs weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.







Meet the researcher hosting a scientific conference by and for AI



In October, a new academic conference will debut that‚Äôs unlike any other. All of the work shared at Agents4Science will have been researched, written, and reviewed primarily by AI, and will be presented using text-to-speech technology.&nbsp;



That idea is not without its detractors. Among other issues, many feel AI is not capable of the creative thought needed in research, makes too many mistakes and hallucinations, and may limit opportunities for young researchers.&nbsp;



Nevertheless, a number of scientists and policymakers are very keen on the promise of AI scientists‚Äîand some even think they could unlock scientific discoveries that humans could never find alone. Read the full story.



‚ÄîPeter Hall







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 Elon Musk tried to persuade Mark Zuckerberg to buy OpenAIBut the bid was rejected earlier this year. (Insider $)+ OpenAI is asking Meta for evidence of any coordinated plans. (TechCrunch)+ I‚Äôm guessing the cage fight is still off then. (FT $)



2 AI giants are seeking real-world data that can‚Äôt be scraped from the internetIt‚Äôs a bid to make their models more accurate and to find new use cases. (Rest of World)



3 Russia‚Äôs state-backed messenger app will be preinstalled on all phonesCritics say the MAX app is essentially a government spy tool. (Reuters)+ Around 18 million people have registered to use it so far. (CNN)+ How Russia killed its tech industry. (MIT Technology Review)



4 The Trump administration is refusing to fully fund a major HIV programIt‚Äôs ignoring a directive from Congress to withhold around $3 billion. (NYT $)+ HIV could infect 1,400 infants every day because of US aid disruptions. (MIT Technology Review)



5 How Trump decides which chip companies may have to give up equityIncreasing your investments in the US? You‚Äôre off the hook. (WSJ $)+ America-first chipmaking remains a fantasy, though. (Economist $)+ Experts think Trump‚Äôs unconventional Intel deal may backfire. (Wired $)+ DeepSeek‚Äôs new AI model is compatible with Chinese-made chips. (FT $)



6 The EU is speeding up its plans for a digital euro It‚Äôs considering running it on a public blockchain, to experts‚Äô concern. (FT $)+ Is the digital dollar dead? (MIT Technology Review)



7 We don‚Äôt have to open new mines to obtain minerals for clean energyAlthough we have to get better at using the material we do mine. (New Scientist $)+ How one mine could unlock billions in EV subsidies. (MIT Technology Review)



8 This newly-discovered gene could usher in new chronic pain treatmentsOne day, cutting out certain foods could lessen discomfort. (Economist $)+ The pain is real. The painkillers are virtual reality. (MIT Technology Review)



9 Why Africa is buying so many solar panelsIt‚Äôs not just its more affluent nations snapping them up, either. (Wired $)+ The race to get next-generation solar technology on the market. (MIT Technology Review)



10 How families are using AI to run their householdsNo more quibbling over meal planning. (WP $)







Quote of the day



&#8220;If AGI doesn&#8217;t come to pass sometime soon, I wouldn&#8217;t be surprised if this whole thing pops.&#8221;



‚ÄîBhavya Kashyap, an angel investor, tells Insider why investors are fuelling a risky bubble by rushing to buy stocks in the hottest AI companies.







One more thing







How AI is changing gymnastics judgingThe 2023 World Championships last October marked the first time an AI judging system was used on every apparatus in a gymnastics competition. There are obvious upsides to using this kind of technology: AI could help take the guesswork out of the judging technicalities. It could even help to eliminate biases, making the sport both more fair and more transparent.At the same time, others fear AI judging will take away something that makes gymnastics special. Gymnastics is a subjective sport, like diving or dressage, and technology could eliminate the judges‚Äô role in crafting a narrative.For better or worse, AI has officially infiltrated the world of gymnastics. The question now is whether it really makes it fairer. Read the full story.



‚ÄîJessica Taylor Price







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Finally, some good news‚Äîa sweet little Australian marsupial called an ampurta is no longer endangered (thanks Glen!)+ What would a GTA set in London look like?+ Why glass houses aren‚Äôt all they‚Äôre cracked up to be (geddit?)+ Over in Denmark, there‚Äôs a national competition encouraging cities to get rid of their gray concrete tiles and replace them with peaceful green spaces (thanks Alice!)
‚Ä¢ Meet the researcher hosting a scientific conference by and for AI
  In October, a new academic conference will debut that‚Äôs unlike any other. Agents4Science is a one-day online event that will encompass all areas of science, from physics to medicine. All of the work shared will have been researched, written, and reviewed primarily by AI, and will be presented using text-to-speech technology.&nbsp;



The conference is the brainchild of Stanford computer scientist James Zou, who studies how humans and AI can best work together. Artificial intelligence has already provided many useful tools for scientists, like DeepMind‚Äôs AlphaFold, which helps simulate proteins that are difficult to make physically. More recently, though, progress in large language models and reasoning-enabled AI has advanced the idea that AI can work more or less as autonomously as scientists themselves‚Äîproposing hypotheses, running simulations, and designing experiments on their own.&nbsp;



James Zou&#8217;s Agents4Science conference will use text-to-speech to present the work of the AI researchers.COURTESY OF JAMES ZOU




That idea is not without its detractors. Among other issues, many feel AI is not capable of the creative thought needed in research, makes too many mistakes and hallucinations, and may limit opportunities for young researchers.&nbsp;



Nevertheless, a number of scientists and policymakers are very keen on the promise of AI scientists. The US government‚Äôs AI Action Plan describes the need to ‚Äúinvest in automated cloud-enabled labs for a range of scientific fields.‚Äù Some researchers think AI scientists could unlock scientific discoveries that humans could never find alone. For Zou, the proposition is simple: ‚ÄúAI agents are not limited in time. They could actually meet with us and work with us 24/7.‚Äù&nbsp;



Last month, Zou published an article in Nature with results obtained from his own group of autonomous AI workers. Spurred on by his success, he now wants to see what other AI scientists (that is, scientists that are AI) can accomplish. He describes what a successful paper at Agents4Science will look like: ‚ÄúThe AI should be the first author and do most of the work. Humans can be advisors.‚Äù



A virtual lab staffed by AI



As a PhD student at Harvard in the early 2010s, Zou was so interested in AI‚Äôs potential for science that he took a year off from his computing research to work in a genomics lab, in a field that has greatly benefited from technology to map entire genomes. His time in so-called wet labs taught him how difficult it can be to work with experts in other fields. ‚ÄúThey often have different languages,‚Äù he says.&nbsp;



Large language models, he believes, are better than people at deciphering and translating between subject-specific jargon. ‚ÄúThey‚Äôve read so broadly,‚Äù Zou says, that they can translate and generalize ideas across science very well. This idea inspired Zou to dream up what he calls the ‚ÄúVirtual Lab.‚Äù



At a high level, the Virtual Lab would be a team of AI agents designed to mimic an actual university lab group. These agents would have various fields of expertise and could interact with different programs, like AlphaFold. Researchers could give one or more of these agents an agenda to work on, then open up the model to play back how the agents communicated to each other and determine which experiments people should pursue in a real-world trial.&nbsp;





Zou needed a (human) collaborator to help put this idea into action and tackle an actual research problem. Last year, he met John E. Pak, a research scientist at the Chan Zuckerberg Biohub. Pak, who shares Zou‚Äôs interest in using AI for science, agreed to make the Virtual Lab with him.&nbsp;



Pak would help set the topic, but both he and Zou wanted to see what approaches the Virtual Lab could come up with on its own. As a first project, they decided to focus on designing therapies for new covid-19 strains. With this goal in mind, Zou set off training five AI scientists (including ones trained to act like an immunologist, a computational biologist, and a principal investigator) with different objectives and programs at their disposal.&nbsp;



Building these models took a few months, but Pak says they were very quick at designing candidates for therapies once the setup was complete: ‚ÄúI think it was a day or half a day, something like that.‚Äù



Zou says the agents decided to study anti-covid nanobodies, a cousin of antibodies that are much smaller in size and less common in the wild. Zou was shocked, though, at the reason. He claims the models landed on nanobodies after making the connection that these smaller molecules would be well-suited to the limited computational resources the models were given. ‚ÄúIt actually turned out to be a good decision, because the agents were able to design these nanobodies efficiently,‚Äù he says.&nbsp;



The nanobodies the models designed were genuinely new advances in science, and most were able to bind to the original covid-19 variant, according to the study. But Pak and Zou both admit that the main contribution of their article is really the Virtual Lab as a tool. Yi Shi, a pharmacologist at the University of Pennsylvania who was not involved in the work but made some of the underlying nanobodies the Virtual Lab modified, agrees. He says he loves the Virtual Lab demonstration and that ‚Äúthe major novelty is the automation.‚Äù&nbsp;



Nature accepted the article and fast-tracked it for publication preview‚ÄîZou knew leveraging AI agents for science was a hot area, and he wanted to be one of the first to test it.&nbsp;



The AI scientists host a conference



When he was submitting his paper, Zou was dismayed to see that he couldn‚Äôt properly credit AI for its role in the research. Most conferences and journals don‚Äôt allow AI to be listed as coauthors on papers, and many explicitly prohibit researchers from using AI to write papers or reviews. Nature, for instance, cites uncertainties over accountability, copyright, and inaccuracies among its reasons for banning the practice. ‚ÄúI think that‚Äôs limiting,‚Äù says Zou. ‚ÄúThese kinds of policies are essentially incentivizing researchers to either hide or minimize their usage of AI.‚Äù



Zou wanted to flip the script by creating the Agents4Science conference, which requires the primary author on all submissions to be an AI. Other bots then will attempt to evaluate the work and determine its scientific merits. But people won‚Äôt be left out of the loop entirely: A team of human experts, including a Nobel laureate in economics, will review the top papers.&nbsp;



Zou isn‚Äôt sure what will come of the conference, but he hopes there will be some gems among the hundreds of submissions he expects to receive across all domains. ‚ÄúThere could be AI submissions that make interesting discoveries,‚Äù he says. ‚ÄúThere could also be AI submissions that have a lot of interesting mistakes.‚Äù



While Zou says the response to the conference has been positive, some scientists are less than impressed.



‚ÄúHow do you get leaps of insight?&#8221;Lisa Messeri



Lisa Messeri, an anthropologist of science at Yale University, has loads of questions about AI‚Äôs ability to review science: ‚ÄúHow do you get leaps of insight? And what happens if a leap of insight comes onto the reviewer‚Äôs desk?‚Äù She doubts the conference will be able to give satisfying answers.



Last year, Messeri and her collaborator Molly Crockett investigated obstacles to using AI for science in another Nature article. They remain unconvinced of its ability to produce novel results, including those shared in Zou‚Äôs nanobodies paper.&nbsp;



‚ÄúI‚Äôm the kind of scientist who is the target audience for these kinds of tools because I‚Äôm not a computer scientist ‚Ä¶ but I am doing computationally oriented work,‚Äù says Crockett, a cognitive scientist at Princeton University. ‚ÄúBut I am at the same time very skeptical of the broader claims, especially with regard to how [AI scientists] might be able to simulate certain aspects of human thinking.‚Äù&nbsp;



And they‚Äôre both skeptical of the value of using AI to do science if automation prevents human scientists from building up the expertise they need to oversee the bots. Instead, they advocate for involving experts from a wider range of disciplines to design more thoughtful experiments before trusting AI to perform and review science.&nbsp;



‚ÄúWe need to be talking to epistemologists, philosophers of science, anthropologists of science, scholars who are thinking really hard about what knowledge is,‚Äù says Crockett.&nbsp;



But Zou sees his conference as exactly the kind of experiment that could help push the field forward. When it comes to AI-generated science, he says, ‚Äúthere‚Äôs a lot of hype and a lot of anecdotes, but there‚Äôs really no systematic data.‚Äù Whether Agents4Science can provide that kind of data is an open question, but in October, the bots will at least try to show the world what they‚Äôve got.&nbsp;
‚Ä¢ The case against humans in space
  Elon Musk and Jeff Bezos are bitter rivals in the commercial space race, but they agree on one thing: Settling space is an existential imperative. Space is the place. The final frontier. It is our human destiny to transcend our home world and expand our civilization to extraterrestrial vistas.



This belief has been mainstream for decades, but its rise has been positively meteoric in this new gilded age of astropreneurs. Expanding humanity beyond Earth is both our birthright and our duty to the future, they insist. Failing to do so would consign our species to certain extinction‚Äîeither by our own hand, perhaps through nuclear war or climate change, or in some cosmic disaster, like a massive asteroid impact.



But as visions of giant orbital stations and Martian cities dance in our heads, a case against human space colonization has found its footing in a number of recent books. The argument grows from many grounds: Doubts about the practical feasibility of off-Earth communities. Concerns about the exorbitant costs, including who would bear them and who would profit. Realism about the harsh environment of space and the enormous tax it would exact on the human body. Suspicion of the underlying ideologies and mythologies that animate the race to settle space.



And, more bluntly, a recognition that ‚Äúspace sucks‚Äù and a lot of people have ‚Äúunderestimated the scale of suckitude,‚Äù as Kelly and Zach Weinersmith put it in their book A City on Mars: Can We Settle Space, Should We Settle Space, and Have We Really Thought This Through?, which was released in paperback earlier this year.



A City on Mars: Can We Settle Space, ShouldWe Settle Space, and Have We Really Thought This Through?Kelly and Zach WeinersmithPENGUIN RANDOM HOUSE, 2023¬†(PAPERBACK RELEASE 2025)




The Weinersmiths, a husband-wife team, spent years thinking it through‚Äîin delightfully pragmatic detail. A City on Mars provides ground truth for our lofty celestial dreams by gaming out the medical, technical, legal, ethical, and existential consequences of space settlements.&nbsp;



Much to the authors‚Äô own dismay, the result is a grotesquery of possible outcomes including (but not limited to) Martian eugenics, interplanetary war, and‚Äî¬≠memorably‚Äî‚Äúspace cannibalism.‚Äù&nbsp;



The Weinersmiths puncture the gauzy fantasy of space cities by asking pretty basic questions, like how to populate them. Astronauts experience all kinds of medical challenges in space, such as radiation exposure and bone loss, which would increase risks to both parents and babies. Nobody wants their pregnant ‚Äúglow‚Äù to be a by-product of cosmic radiation.





Trying to bring forth babies in space ‚Äúis going to be tricky business, not just in terms of science, but from the perspective of scientific ethics,‚Äù they write. ‚ÄúAdults can consent to being in experiments. Babies can‚Äôt.‚Äù



You don‚Äôt even have to contemplate going to Mars to make some version of this case. In Ground Control: An Argument for the End of Human Space Exploration, Savannah Mandel chronicles how past and present generations have regarded human spaceflight as an affront to vulnerable children right here on Earth.



Ground Control: An Argument for the End of Human Space ExplorationSavannah MandelCHICAGO REVIEW PRESS, 2024




‚ÄúHungry Kids Can‚Äôt Eat Moon Rocks,‚Äù read signs at a protest outside Kennedy Space Center on the eve of the Apollo 11 launch in July 1969. Gil Scott-Heron‚Äôs 1970 poem ‚ÄúWhitey on the Moon‚Äù rose to become the de facto anthem of this movement, which insists, to this day, that until humans get our earthly house in order, we have no business building new ones in outer space.



Ground Control, part memoir and part manifesto, channels this lament: How can we justify the enormous cost of sending people beyond our planet when there is so much suffering here at home?&nbsp;



Advocates for human space exploration reject the zero-sum framing and point to the many downstream benefits of human spaceflight. Space exploration has catalyzed inventions from the CAT scan to baby formula. There is also inherent value in our shared adventure of learning about the vast cosmos.



Those upsides are real, but they are not remotely well distributed. Mandel predicts that the commercial space sector in its current form will only exacerbate inequalities on Earth, as profits from space ventures flow into the coffers of the already obscenely rich.&nbsp;



In her book, Mandel, a space anthropologist and scholar at Virginia Tech, describes a personal transformation from spacey dreamer to grounded critic. It began during fieldwork at Spaceport America, a commercial launch facility in New Mexico, where she began to see cracks in the dazzling future imagined by space billionaires. As her career took her from street protests in London to extravagant space industry banquets in Washington, DC, she writes, ‚Äúcrystal clear glasses‚Äù replaced ‚Äúthe rose-colored ones.‚Äù



Mandel remains enchanted by space but is skeptical that humans are the optimal trailblazers. Robots, rovers, probes, and other artificial space ambassadors could do the job for a fraction of the price and without risk to life, limb, and other corporeal vulnerabilities.&nbsp;&nbsp;



‚ÄúA decentralization of self needs to occur,‚Äù she writes. ‚ÄúA dissolution of anthropocentrism, so to speak. And a recognition that future space explorers may not be man, even if man moves through them.‚Äù&nbsp;



In other words, giant leaps for mankind no longer necessitate a man‚Äôs small steps; the wheels of a rover or the rotors of a copter offer a much better bang for our buck than boots on the ground.



In contrast to the Weinersmiths, Mandel devotes little attention to the physical dangers and limitations that space imposes on humans. She is more interested in a kind of psychic sickness that drives the impulse to abandon our planet and rush into new territories.



Mary-Jane Rubenstein, a scholar of religion at Wesleyan University, presents a thorough diagnosis of this exact pathology in her 2022 book Astrotopia: The Dangerous Religion of the Corporate Space Race, which came out in paperback last year. It all begins, appropriately enough, with the book of Genesis, where God creates Earth for the dominion of man. Over the years, this biblical brain worm has offered divine justification for the brutal colonization and environmental exploitation of our planet. Now it serves as the religious rocket fuel propelling humans into the next frontier, Rubenstein argues.



Astrotopia: The Dangerous Religion of the Corporate Space RaceMary-Jane RubensteinUNIVERSITY OF CHICAGO PRESS, 2022 ¬†(PAPERBACK RELEASE 2024)




‚ÄúThe intensifying ‚ÄòNewSpace race‚Äô is as much a mythological project as it is a political, economic, or scientific one,‚Äù she writes. ‚ÄúIt‚Äôs a mythology, in fact, that holds all these other efforts together, giving them an aura of duty, grandeur, and benevolence.‚Äù



Rubenstein makes a forceful case that malignant outgrowths of Christian ideas scaffold the dreams of space settlements championed by Musk, Bezos, and like-minded enthusiasts‚Äîeven if these same people might never describe themselves as religious. If Earth is man‚Äôs dominion, space is the next logical step. Earth is just a temporary staging ground for a greater destiny; we will find our deliverance in the heavens.&nbsp;&nbsp;&nbsp;



‚ÄúFuck Earth,‚Äù Elon Musk said in 2014. ‚ÄúWho cares about Earth? If we can establish a Mars colony, we can almost certainly colonize the whole solar system.‚Äù



Jeff Bezos, for one, claims to care about Earth; that‚Äôs among his best arguments for why humans should move beyond it. If heavy industries and large civilian populations cast off into the orbital expanse, our home world can be, in his words, ‚Äúzoned residential and light industry,‚Äù allowing it to recover from anthropogenic pressures. 



Bezos also believes that space settlements are essential for the betterment of humanity, in part on the grounds that they will uncork our population growth. He envisions an orbital archipelago of stations, sprawled across the solar system, that could support a collective population of a trillion people. ‚ÄúThat‚Äôs a thousand Mozarts. A thousand Einsteins,‚Äù Bezos has mused. ‚ÄúWhat a cool civilization that would be.‚Äù



It does sound cool. But it‚Äôs an easy layup for Rubenstein: This ‚Äúnumbers game‚Äù approach would also produce a thousand Hitlers and Stalins, she writes.&nbsp;



And that is the real crux of the argument against pushing hard torapidly expand human civilization into space: We will still be humans when we get there. We won‚Äôt escape our vices and frailties by leaving Earth‚Äîin fact, we may exacerbate them.&nbsp;



While all three books push back on the existential argument for space settlements, the Weinersmiths take the rebuttal one step further by proposing that space colonization might actually increase the risk of self-annihilation rather than neutralizing it.





‚ÄúGoing to space will not end war because war isn‚Äôt caused by anything that space travel is apt to change, even in the most optimistic scenarios,‚Äù they write. ‚ÄúHumanity going to space en masse probably won‚Äôt reduce the likelihood of war, but we should consider that it might increase the chance of war being horrific.‚Äù&nbsp;



The pair imagine rival space nations exchanging asteroid fire or poisoning whole biospheres. Proponents of space settlements often point to the fate of the dinosaurs as motivational grist, but what if a doomsday asteroid were deliberately flung between human cultures as a weapon? It may sound outlandish, but it‚Äôs no more speculative than a floating civilization with a thousand Mozarts. It follows the same logic of extrapolating our human future in space from our behavior on Earth in the past.



So should we just sit around and wait for our inevitable extinction? The three books have more or less the same response: What‚Äôs the rush? It is far more likely that humanity will be wiped out by our own activity in the near term than by any kind of cosmic threat. Worrying about the expansion of the sun in billions of years, as Musk has openly done, is frankly hysterical.&nbsp;



In the meantime, we have some growing up to do. Mandel and Rubenstein both argue that any worthy human future in space must adopt a decolonizing approach that emphasizes caretaking and stewardship of this planet and its inhabitants before we set off for others. They draw inspiration from science fiction, popular culture, and Indigenous knowledge, among other sources, to sketch out these alternative visions of an off-Earth future.&nbsp;



Mandel sees hope for this future in post-scarcity political theories. She cites various attempts to anticipate the needs of future generations‚Äîideas found in the work of the social theorist Aaron Benanav, or in the values expressed by the Green New Deal, or in the fictional Ministry for the Future imagined by Kim Stanley Robinson in his 2020 novel of the same name. Whatever you think of the controversial 2025 book Abundance, by Ezra Klein and Derek Thompson, it is also appealing to the same demand for a post-scarcity road map.&nbsp;&nbsp;



To that end, Mandel envisions ‚Äúthe creation of a governing body that would require that techno-scientific plans, especially those with a global reach, take into consideration multigenerational impacts and multigenerational voices.‚Äù&nbsp;&nbsp;



For Rubenstein, religion is the poison, but it may also offer the cure. She sees potential in a revival of pantheism, which is the belief that all the contents of the universe‚Äîfrom rocks to humans to galaxies‚Äîare divine and perhaps alive on some level. She hasn‚Äôt fully converted herself to this movement, let alone become an evangelist, but she says it‚Äôs a spiritual direction that could be an effective counterweight to dominionist views of the universe.



‚ÄúIt doesn‚Äôt matter whether ‚Ä¶ any sort of pantheism is ‚Äòtrue,‚Äô‚Äù she writes. ‚ÄúWhat matters is the way any given mythology prompts us to interact with the world we‚Äôre a part of‚Äîthe world each of our actions helps to make and unmake. And frankly, some mythologies prompt us to act better than others.‚Äù



All these authors ultimately conclude that it would be great if humans lived in space‚Äîsomeday, if and when we‚Äôve matured. But the three books all express concerns about efforts by commercial space companies, with the help of the US government, to bypass established space laws and norms‚Äîconcerns that have been thoroughly validated in 2025.&nbsp;&nbsp;



The combustible relationship between Elon Musk and Donald Trump has raised eyebrows about cronyism‚Äîand retribution‚Äîbetween governments and space companies. Space is rapidly becoming weaponized. And recent events have reminded us of the immense challenges of human spaceflight. SpaceX‚Äôs next-¬≠generation Starship vehicle has suffered catastrophic failures in several test flights, while Boeing‚Äôs Starliner capsule experienced malfunctions that kept two astronauts on the International Space Station for months longer than expected. Even space tourism is developing a bad rap: In April, a star-studded all-woman crew on a Blue Origin suborbital flight was met with widespread backlash as a symbol of out-of-touch wealth and privilege.



It is at this point that we must loop back to the issue of ‚Äúsuckitude,‚Äù which Mandel also channels in her book through the killer opening of M.T. Anderson‚Äôs novel Feed: ‚ÄúWe went to the moon to have fun, but the moon turned out to completely suck.‚Äù



The dreams of space settlements put forward by Musk and Bezos are insanely fun. The reality may well suck. But it‚Äôs doubtful that any degree of suckitude will slow down the commercial space race, and the authors do at times seem to be yelling into the cosmic void.&nbsp;



Still, the books challenge space enthusiasts of all stripes to imagine new ways of relating to space that aren‚Äôt so tactile and exploitative. Along those lines, Rubenstein shares a compelling anecdote in Astrotopia about an anthropologist who lived with an Inuit community in the early 1970s. When she told them about the Apollo moon landings, her hosts burst out in laughter.&nbsp;



‚ÄúWe didn‚Äôt know this was the first time you white people had been to the moon,‚Äù they said. ‚ÄúOur shamans go all the time ‚Ä¶ The issue is not whether we go to visit our relatives, but how we treat them and their homeland when we go.‚Äù¬†



Becky Ferreira is a science reporter based in upstate New York, and author of First Contact, a book about the search for alien life, which will be published in September.&nbsp;
‚Ä¢ I gave the police access to my DNA‚Äîand maybe some of yours
  Last year, I added my DNA profile to a private genealogical database, FamilyTreeDNA, and clicked ‚ÄúYes‚Äù to allow the police to search my genes.



In 2018, police in California announced they‚Äôd&nbsp;caught the Golden State Killer, a man who had eluded capture for decades. They did it by uploading crime-scene DNA to websites like the one I‚Äôd joined, where genealogy hobbyists share genetic profiles to find relatives and explore ancestry. Once the police had ‚Äúmatches‚Äù to a few relatives of the killer, they built a large family tree from which they plucked the likely suspect.





This process, called forensic investigative genetic genealogy, or FIGG, has since helped solve hundreds of murders and sexual assaults. Still, while the technology is potent, it‚Äôs incompletely realized. It operates via a mishmash of private labs and unregulated websites, like FamilyTree, which give users a choice to opt into or out of police searches. The number of profiles available for search by police hovers around 1.5 million, not yet enough to find matches in all cases.



To do my bit to increase those numbers, I traveled to Springfield, Massachusetts.



The staff of the local district attorney, Anthony D. Gulluni, was giving away free FamilyTree tests at a minor-league hockey game in an effort to widen its DNA net and help solve several cold-case murders. After glancing over a consent form, I spit into a tube and handed it back. According to the promotional material from Gulluni‚Äôs office, I‚Äôd ‚Äúbecome a hero.‚Äù



But I wasn‚Äôt really driven by some urge to capture distantly related serial killers. Rather, my spit had a less gallant and more quarrelsome motive: to troll privacy advocates whose fears around DNA I think are overblown and unhelpful. By giving up my saliva for inspection, I was going against the view that a person‚Äôs DNA is the individualized, sacred text that privacy advocates sometimes claim.



Indeed, the only reason FIGG works is that relatives share DNA: You share about 50% with a parent, 25% with a grandparent, about 12.5% with a first cousin, and so on. When I got my FamilyTree report back, my DNA had ‚Äúmatched‚Äù with 3,309 people.



Some people are frightened by FIGG or reject its punitive aims. One European genealogist I know says her DNA is kept private because she opposes the death penalty and doesn‚Äôt want to risk aiding US authorities in cases where lethal injection might be applied. But if enough people share their DNA, conscientious objectors won‚Äôt matter. Scientists estimate that a database including 2% of the US population, or 6 million people, could identify the source of nearly any crime-scene DNA, given how many distant relatives each of us has.





Scholars of big data have termed this phenomenon ‚Äútyranny of the minority.‚Äù One person‚Äôs voluntary disclosure can end up exposing the same information about many others. And that tyranny can be abused.



DNA information held in private genealogy websites like FamilyTree is lightly guarded by terms of service. These agreements have flip-flopped over time; at one point all users were included in law enforcement searches by default. Rules are easily ignored, too. Recent court filings indicate that the FBI, in its zeal to solve crimes, sometimes barges past restrictions to look for matches in databases whose policies exclude police.



‚ÄúNoble aims; no rules‚Äù is how one genetic genealogist described the overall situation in her field.



My uncertainty grew the more questions I asked. Who even controls my DNA file? That‚Äôs not easy to find out. FamilyTree is a brand operated by another company, Gene by Gene, which in 2021 was sold to a third company, MyDNA‚Äîultimately owned by an Australian mogul whose name appears nowhere on its website. When I reached FamilyTree‚Äôs general manager, the genealogist Dave Vance, he told me that three-quarters of the profiles on the site were ‚Äúopted in‚Äù to law enforcement searches.



One solution holds that the federal government should organize its own national DNA database for FIGG. But that would require new laws, new technical standards, and a debate about how our society wants to employ this type of big data‚Äînot just getting individual consent like mine. No such national project‚Äîor consensus‚Äîexists.



I‚Äôm still ready to join a national crime-fighting database, but I regret doing it the way I did‚Äîspitting in a tube on the sidelines of a hockey game and signing a consent form that affects not just me but all my thousands of genetic relatives. To them, I say: Whoops. Your DNA; my bad.



This article first appeared in The Checkup,&nbsp;MIT Technology Review‚Äôs&nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&nbsp;sign up here.
‚Ä¢ The Download: Ukraine‚Äôs Starlink repair shop, and predicting solar storms
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



On the ground in Ukraine‚Äôs largest Starlink repair shop



Starlink is absolutely critical to Ukraine‚Äôs ability to continue in the fight against Russia. It‚Äôs how troops in battle zones stay connected with faraway HQs; it‚Äôs how many of the drones essential to Ukraine‚Äôs survival hit their targets; it‚Äôs even how soldiers stay in touch with spouses and children back home.However, Donald Trump‚Äôs fickle foreign policy and reports suggesting Elon Musk might remove Ukraine‚Äôs access to the services have cast the technology‚Äôs future in the country into doubt.For now Starlink access largely comes down to the unofficial community of users and engineers, including the expert ‚ÄúDr. Starlink‚Äù‚Äîfamous for his creative ways of customizing the systems‚Äîwho have kept Ukraine in the fight, both on and off the front line. Together, they have repaired and customized more than 15,000 terminals since the war began.Despite the pressure, the chance that they may lose access to Starlink was not worrying volunteers at the time of my visit; in our conversations, it was clear they had more pressing concerns than the whims of a foreign tech mogul. Russia continues to launch frequent aerial bombardments of Ukrainian cities, sometimes sending more than 500 drones in a single night.&nbsp;



The threat of involuntary mobilization to the front line looms on every street corner. How can one plan for a hypothetical future crisis when crisis defines every minute of one‚Äôs day? Read the full story.



‚ÄîCharlie Metcalfe



This story is from our forthcoming print issue, which is all about security. If you haven‚Äôt already, subscribe now to receive future issues once they land.



This article is also part of the Big Story series: MIT Technology Review‚Äôs most important, ambitious reporting. The stories in the series take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. Check out the rest of them here.







NASA‚Äôs new AI model can predict when a solar storm may strike



NASA and IBM have released a new open-source machine learning model to help scientists better understand and predict the physics and weather patterns of the sun. Surya, trained on over a decade‚Äôs worth of NASA solar data, should help give scientists an early warning when a dangerous solar flare is likely to hit Earth.



Solar storms occur when the sun erupts energy and particles into space. They can produce solar flares and slower-moving coronal mass ejections that can disrupt radio signals, flip computer bits onboard satellites, and endanger astronauts with bursts of radiation.&nbsp;



While there‚Äôs no way to prevent these sorts of effects, being able to predict when a large solar flare will occur could let people work around them. Read the full story.



‚ÄîPeter Hall







Why recycling isn‚Äôt enough to address the plastic problem



I remember using a princess toothbrush when I was little. The handle was purple, teal, and sparkly. Like most of the other pieces of plastic that have ever been made, it‚Äôs probably still out there somewhere, languishing in a landfill. (I just hope it‚Äôs not in the ocean.)



I‚Äôve been thinking about that toothbrush again this week after UN talks about a plastic treaty broke down on Friday. Nations had gotten together to try and write a binding treaty to address plastic waste, but negotiators left without a deal.



Plastic is widely recognized as a huge source of environmental pollution‚Äîagain, I‚Äôm wondering where that toothbrush is‚Äîbut the material is also a contributor to climate change. Let‚Äôs dig into why talks fell apart and how we might address emissions from plastic.



‚ÄîCasey Crownhart



This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 Google is betting that AI can help you take better photos



So long as you don‚Äôt try zooming in on someone‚Äôs face, that is. (WP $)+ Gemini is getting a new audio model capable of detecting tone. (TechCrunch)+ Google‚Äôs AI efforts are certainly outpacing those of its hardware rival Apple. (Bloomberg $)



2 Meta‚Äôs AI hiring spree is on pauseInvestors are increasingly concerned by the mad sums being bandied about. (WSJ $)



3 China is preparing to show off its hypersonic missilesThe world will be watching its military parade closely next month. (FT $)+ Meanwhile, India has tested a missile that could hit deep into China. (The Guardian)+ Taiwan‚Äôs ‚Äúsilicon shield‚Äù could be weakening. (MIT Technology Review)



4 RFK Jr. wants to send you MAHA food boxesBut concrete details are light on the ground. (The Atlantic $)+ How MAHA is shaking up packaged goods‚Äô supply chains. (Fortune $)



5 Extreme heat is driving cases of Legionnaire‚Äôs disease in NYCOlder air conditioning infrastructure is helping to spread dangerous bacteria. (Vox)+ A fifth person has died in connection with the current outbreak. (ABC News)



6 What it‚Äôs like to vibecode for a massive startupManaging AI coding apps is a whole lot like herding interns, supposedly. (Wired $)+ What is vibe coding, exactly? (MIT Technology Review)



7 Starship‚Äôs rocket launch could delay flights in FloridaEven after the launch is completed. (TechCrunch)



8 This app will help you find the sunniest spots in Paris The community-driven Jveuxdusoleil is updated in real time. (The Guardian)



9 The world‚Äôs only public diamond mine is in Arkansas Visitors have unearthed more than 35,000 precious gems since it opened. (Ars Technica)



10 It turns out Uranus had a hidden moon all alongAnd many more may be discovered in the future. (NYT $)+ It‚Äôs the 29th known satellite to orbit the planet. (Scientific American $)+ The moon is just the beginning for this waterless concrete. (MIT Technology Review)







Quote of the day



‚ÄúIt jumbles my freaking nugget that people can look at a squat and not understand how it‚Äôs supposed to look. You don‚Äôt need AI to do that.‚Äù



‚ÄîAndrew Hiller, a CrossFit coach and critic of poorly-executed squats, tells the New York Times why doing away with vigilant human judges for the popular fitness race Hyrox would be a mistake.







One more thing







Are friends electric?Thankfully, the difference between humans and machines in the real world is easy to discern, at least for now. While machines tend to excel at things adults find difficult‚Äîplaying world-champion-level chess, say, or multiplying really big numbers‚Äîthey find it hard to accomplish stuff a five-year-old can do with ease, such as catching a ball or walking around a room without bumping into things.This fundamental tension‚Äîwhat is hard for humans is easy for machines, and what‚Äôs hard for machines is easy for humans‚Äîis at the heart of three new books delving into our complex and often fraught relationship with robots, AI, and automation. They force us to reimagine the nature of everything from friendship and love to work, health care, and home life. Read the full story.



‚ÄîBryan Gardiner







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Take a minute out of your day to admire these stunning images of the night sky.+ The remarkable story of how Sweden managed to transport an entire church five kilometers down the road.+ Are you a proud ugly shoe owner? (Birkenstock hive rise up)+ We have ways of making you talk, Stretch Armstrong.

üîí Cybersecurity & Privacy
‚Ä¢ SIM-Swapper, Scattered Spider Hacker Gets 10 Years
  A 20-year-old Florida man at the center of a prolific cybercrime group known as &#8220;Scattered Spider&#8221; was sentenced to 10 years in federal prison today, and ordered to pay roughly $13 million in restitution to victims.
Noah Michael Urban of Palm Coast, Fla. pleaded guilty in April 2025 to charges of wire fraud and conspiracy. Florida prosecutors alleged Urban conspired with others to steal at least $800,000 from five victims via SIM-swapping attacks that diverted their mobile phone calls and text messages to devices controlled by Urban and his co-conspirators.
A booking photo of Noah Michael Urban released by the Volusia County Sheriff.
Although prosecutors had asked for Urban to serve eight years, Jacksonville news outlet News4Jax.com reports the federal judge in the case today opted to sentence Urban to 120 months in federal prison, ordering him to pay $13 million in restitution and undergo three years of supervised release after his sentence is completed.
In November 2024 Urban was charged by federal prosecutors in Los Angeles as one of five members of Scattered Spider (a.k.a. &#8220;Oktapus,&#8221; &#8220;Scatter Swine&#8221; and &#8220;UNC3944&#8221;), which specialized in SMS and voice phishing attacks that tricked employees at victim companies into entering their credentials and one-time passcodes at phishing websites. Urban pleaded guilty to one count of conspiracy to commit wire fraud in the California case, and the $13 million in restitution is intended to cover victims from both cases.
The targeted SMS scams spanned several months during the summer of 2022, asking employees to click a link and log in at a website that mimicked their employer‚Äôs Okta authentication page. Some SMS phishing messages told employees their VPN credentials were expiring and needed to be changed; other missives advised employees about changes to their upcoming work schedule.
That phishing spree netted Urban and others access to more than 130 companies, including Twilio, LastPass, DoorDash, MailChimp, and Plex. The government says the group used that access to steal proprietary company data and customer information, and that members also phished people to steal millions of dollars worth of cryptocurrency.
For many years, Urban&#8217;s online hacker aliases &#8220;King Bob&#8221; and &#8220;Sosa&#8221; were fixtures of the Com, a mostly Telegram and Discord-based community of English-speaking cybercriminals wherein hackers boast loudly about high-profile exploits and hacks that almost invariably begin with social engineering. King Bob constantly bragged on the Com about stealing unreleased rap music recordings from popular artists, presumably through SIM-swapping attacks. Many of those purloined tracks or &#8220;grails&#8221; he later sold or gave away on forums.
Noah &#8220;King Bob&#8221; Urban, posting to Twitter/X around the time of his sentencing today.
Sosa also was active in a particularly destructive group of accomplished criminal SIM-swappers known as &#8220;Star Fraud.&#8221; Cyberscoop‚Äôs AJ Vicens reported in 2023 that individuals within Star Fraud were likely involved in the high-profile Caesars Entertainment and MGM Resorts extortion attacks that same year.
The Star Fraud SIM-swapping group gained the ability to temporarily move targeted mobile numbers to devices they controlled by constantly phishing employees of the major mobile providers. In February 2023, KrebsOnSecurity published data taken from the Telegram channels for Star Fraud and two other SIM-swapping groups showing these crooks focused on SIM-swapping T-Mobile customers, and that they collectively claimed internal access to T-Mobile on 100 separate occasions over a 7-month period in 2022.
Reached via one of his King Bob accounts on Twitter/X, Urban called the sentence unjust, and said the judge in his case discounted his age as a factor.
&#8220;The judge purposefully ignored my age as a factor because of the fact another Scattered Spider member hacked him personally during the course of my case,&#8221; Urban said in reply to questions, noting that he was sending the messages from a Florida county jail. &#8220;He should have been removed as a judge much earlier on. But staying in county jail is torture.&#8221;
A court transcript (PDF) from a status hearing in February 2025 shows Urban was telling the truth about the hacking incident that happened while he was in federal custody. It involved an intrusion into a magistrate judge&#8217;s email account, where a copy of Urban&#8217;s sealed indictment was stolen. The judge told attorneys for both sides that a co-defendant in the California case was trying to find out about Mr. Urban&#8217;s activity in the Florida case.
&#8220;What it ultimately turned into a was a big faux pas,&#8221; Judge Harvey E. Schlesinger said. &#8220;The Court&#8217;s password&#8230;business is handled by an outside contractor. And somebody called the outside contractor representing Judge Toomey saying, &#8216;I need a password change.&#8217; And they gave out the password change. That&#8217;s how whoever was making the phone call got into the court.&#8221;
‚Ä¢ Oregon Man Charged in ‚ÄòRapper Bot‚Äô DDoS Service
  A 22-year-old Oregon man has been arrested on suspicion of operating &#8220;Rapper Bot,&#8221; a massive botnet used to power a service for launching distributed denial-of-service (DDoS) attacks against targets &#8212; including a March 2025 DDoS that knocked Twitter/X offline. The Justice Department asserts the suspect and an unidentified co-conspirator rented out the botnet to online extortionists, and tried to stay off the radar of law enforcement by ensuring that their botnet was never pointed at KrebsOnSecurity.
The control panel for the Rapper Bot botnet greets users with the message &#8220;Welcome to the Ball Pit, Now with refrigerator support,&#8221; an apparent reference to a handful of IoT-enabled refrigerators that were enslaved in their DDoS botnet.
On August 6, 2025, federal agents arrested Ethan J. Foltz of Springfield, Ore. on suspicion of operating Rapper Bot, a globally dispersed collection of tens of thousands of hacked Internet of Things (IoT) devices.
The complaint against Foltz explains the attacks usually clocked in at more than two terabits of junk data per second (a terabit is one trillion bits of data), which is more than enough traffic to cause serious problems for all but the most well-defended targets. The government says Rapper Bot consistently launched attacks that were &#8220;hundreds of times larger than the expected capacity of a typical server located in a data center,&#8221; and that some of its biggest attacks exceeded six terabits per second.
Indeed, Rapper Bot was reportedly responsible for the March 10, 2025 attack that caused intermittent outages on Twitter/X. The government says Rapper Bot&#8217;s most lucrative and frequent customers were involved in extorting online businesses &#8212; including numerous gambling operations based in China.
The criminal complaint was written by Elliott Peterson, an investigator with the Defense Criminal Investigative Service (DCIS), the criminal investigative division of the Department of Defense (DoD) Office of Inspector General. The complaint notes the DCIS got involved because several Internet addresses maintained by the DoD were the target of Rapper Bot attacks.
Peterson said he tracked Rapper Bot to Foltz after a subpoena to an ISP in Arizona that was hosting one of the botnet&#8217;s control servers showed the account was paid for via PayPal. More legal process to PayPal revealed Foltz&#8217;s Gmail account and previously used IP addresses. A subpoena to Google showed the defendant searched security blogs constantly for news about Rapper Bot, and for updates about competing DDoS-for-hire botnets.
According to the complaint, after having a search warrant served on his residence the defendant admitted to building and operating Rapper Bot, sharing the profits 50/50 with a person he claimed to know only by the hacker handle &#8220;Slaykings.&#8221; Foltz also shared with investigators the logs from his Telegram chats, wherein Foltz and Slaykings discussed how best to stay off the radar of law enforcement investigators while their competitors were getting busted.
Specifically, the two hackers chatted about a May 20 attack against KrebsOnSecurity.com that clocked in at more than 6.3 terabits of data per second. The brief attack was notable because at the time it was the largest DDoS that Google had ever mitigated (KrebsOnSecurity sits behind the protection of Project Shield, a free DDoS defense service that¬†Google provides to websites offering news, human rights, and election-related content).
The May 2025 DDoS was launched by an IoT botnet called Aisuru, which I discovered was operated by a 21-year-old man in Brazil named Kaike Southier Leite. This individual was more commonly known online as &#8220;Forky,&#8221; and Forky told me he wasn&#8217;t afraid of me or U.S. federal investigators. Nevertheless, the complaint against Foltz notes that Forky&#8217;s botnet seemed to diminish in size and firepower at the same time that Rapper Bot&#8217;s infection numbers were on the upswing.
&#8220;Both FOLTZ and Slaykings were very dismissive of attention seeking activities, the most extreme of which, in their view, was to launch DDoS attacks against the website of the prominent cyber security journalist Brian Krebs,&#8221; Peterson wrote in the criminal complaint.
&#8220;You see, they‚Äôll get themselves [expletive],&#8221; Slaykings wrote in response to Foltz&#8217;s comments about Forky and Aisuru bringing too much heat on themselves.
&#8220;Prob cuz [redacted] hit krebs,&#8221; Foltz wrote in reply.
&#8220;Going against Krebs isn‚Äôt a good move,&#8221; Slaykings concurred. &#8220;It isn‚Äôt about being a [expletive] or afraid, you just get a lot of problems for zero money. Childish, but good. Let them die.&#8221;
&#8220;Ye, it‚Äôs good tho, they will die,&#8221; Foltz replied.
The government states that just prior to Foltz&#8217;s arrest, Rapper Bot had enslaved an estimated 65,000 devices globally. That may sound like a lot, but the complaint notes the defendants weren&#8217;t interested in making headlines for building the world&#8217;s largest or most powerful botnet.
Quite the contrary: The complaint asserts that the accused took care to maintain their botnet in a &#8220;Goldilocks&#8221; size &#8212; ensuring that &#8220;the number of devices afforded powerful attacks while still being manageable to control and, in the hopes of Foltz and his partners, small enough to not be detected.&#8221;
The complaint states that several days later, Foltz and Slaykings returned to discussing what that they expected to befall their rival group, with Slaykings stating, &#8220;Krebs is very revenge. He won‚Äôt stop until they are [expletive] to the bone.&#8221;
&#8220;Surprised they have any bots left,&#8221; Foltz answered.
&#8220;Krebs is not the one you want to have on your back. Not because he is scary or something, just because he will not give up UNTIL you are [expletive] [expletive]. Proved it with Mirai and many other cases.&#8221;
[Unknown expletives aside, that may well be the highest compliment I&#8217;ve ever been paid by a cybercriminal. I might even have part of that quote made into a t-shirt or mug or something. It&#8217;s also nice that they didn&#8217;t let any of their customers attack my site &#8212; if even only out of a paranoid sense of self-preservation.]
Foltz admitted to wiping the user and attack logs for the botnet approximately once a week, so investigators were unable to tally the total number of attacks, customers and targets of this vast crime machine. But the data that was still available showed that from April 2025 to early August, Rapper Bot conducted over 370,000 attacks, targeting 18,000 unique victims across 1,000 networks, with the bulk of victims residing in China, Japan, the United States, Ireland and Hong Kong (in that order).
According to the government, Rapper Bot borrows much of its code from fBot, a DDoS malware strain also known as Satori. In 2020, authorities in Northern Ireland charged a then 20-year-old man named Aaron &#8220;Vamp&#8221; Sterritt with operating fBot with a co-conspirator. U.S. prosecutors are still seeking Sterritt&#8217;s extradition to the United States. fBot is itself a variation of the Mirai IoT botnet¬†that has ravaged the Internet with DDoS attacks since its source code was leaked back in 2016.
The complaint says Foltz and his partner did not allow most customers to launch attacks that were more than 60 seconds in duration &#8212; another way they tried to keep public attention to the botnet at a minimum. However, the government says the proprietors also had special arrangements with certain high-paying clients that allowed much larger and longer attacks.
The accused and his alleged partner made light of this blog post about the fallout from one of their botnet attacks.
Most people who have never been on the receiving end of a monster DDoS attack have no idea of the cost and disruption that such sieges can bring. The DCIS&#8217;s Peterson wrote that he was able to test the botnet&#8217;s capabilities while interviewing Foltz, and that found that &#8220;if this had been a server upon which I was running a website, using services such as load balancers, and paying for both outgoing and incoming data, at estimated industry average rates the attack (2+ Terabits per second times 30 seconds) might have cost the victim anywhere from $500 to $10,000.&#8221;
&#8220;DDoS attacks at this scale often expose victims to devastating financial impact, and a potential alternative, network engineering solutions that mitigate the expected attacks such as overprovisioning, i.e. increasing potential Internet capacity, or DDoS defense technologies, can themselves be prohibitively expensive,&#8221; the complaint continues. &#8220;This &#8216;rock and a hard place&#8217; reality for many victims can leave them acutely exposed to extortion demands ‚Äì &#8216;pay X dollars and the DDoS attacks stop&#8217;.&#8221;
The Telegram chat records show that the day before Peterson and other federal agents raided Foltz&#8217;s residence, Foltz allegedly told his partner he&#8217;d found 32,000 new devices that were vulnerable to a previously unknown exploit.
Foltz and Slaykings discussing the discovery of an IoT vulnerability that will give them 32,000 new devices.
Shortly before the search warrant was served on his residence, Foltz allegedly told his partner that &#8220;Once again we have the biggest botnet in the community.&#8221; The following day, Foltz told his partner that it was going to be a great day &#8212; the biggest so far in terms of income generated by Rapper Bot.
&#8220;I sat next to Foltz while the messages poured in &#8212; promises of $800, then $1,000, the proceeds ticking up as the day went on,&#8221; Peterson wrote. &#8220;Noticing a change in Foltz&#8217; behavior and concerned that Foltz was making changes to the botnet configuration in real time, Slaykings asked him &#8216;What&#8217;s up?&#8217; Foltz deftly typed out some quick responses. Reassured by Foltz&#8217; answer, Slaykings responded, &#8216;Ok, I&#8217;m the paranoid one.&#8221;
The case is being prosecuted by Assistant U.S. Attorney Adam Alexander in the District of Alaska (at least some of the devices found to be infected with Rapper Bot were located there, and it is where Peterson is stationed). Foltz faces one count of aiding and abetting computer intrusions. If convicted, he faces a maximum penalty of 10 years in prison, although a federal judge is unlikely to award anywhere near that kind of sentence for a first-time conviction.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Applicability vs. job displacement: further notes on our recent research on AI and occupations
  Recently, we released a paper&nbsp;(Working with AI: Measuring the Occupational Implications of Generative AI)&nbsp;that studied what occupations might&nbsp;find&nbsp;AI chatbots&nbsp;useful, and to what degree.&nbsp;The paper sparked significant discussion,&nbsp;which is no&nbsp;surprise&nbsp;since&nbsp;people care&nbsp;deeply&nbsp;about&nbsp;the future of AI and&nbsp;jobs&#8211;that‚Äôs part of why we think&nbsp;it‚Äôs&nbsp;important to study these&nbsp;topics.



Unfortunately, not all the&nbsp;discussion&nbsp;was&nbsp;accurate&nbsp;in its portrayal of the&nbsp;study‚Äôs scope or conclusions.&nbsp;Specifically, our&nbsp;study&nbsp;does not&nbsp;draw any conclusions about jobs being eliminated; in the paper,&nbsp;we&nbsp;explicitly&nbsp;cautioned&nbsp;against using our findings to make that conclusion.&nbsp;



Given the importance&nbsp;of this&nbsp;topic, we&nbsp;want&nbsp;to&nbsp;clarify any misunderstandings and&nbsp;provide&nbsp;a more digestible summary of the paper,&nbsp;our&nbsp;methodology,&nbsp;and its limitations.&nbsp;



What&nbsp;did our research find?



We set out to better understand how people are using AI,¬†highlighting where AI might¬†be useful in different occupations.¬†To do this, we analyzed how people currently use generative AI‚Äîspecifically Microsoft Bing Copilot (now Microsoft Copilot)‚Äîto¬†assist¬†with¬†tasks.¬†We then compared these sets¬†of tasks against the O*NET database (opens in new tab), a widely used occupational classification system,¬†to understand potential applicability to various occupations.



We found&nbsp;that AI&nbsp;is most&nbsp;useful&nbsp;for&nbsp;tasks related to knowledge work and communication, particularly tasks such as writing, gathering information, and learning.



Those in occupations with these tasks&nbsp;may benefit by&nbsp;considering&nbsp;how AI&nbsp;can be used&nbsp;as a tool to help improve their workflows. On the&nbsp;flip side,&nbsp;it‚Äôs&nbsp;not surprising that physical tasks like performing surgeries or moving objects had less&nbsp;direct&nbsp;AI&nbsp;chatbot applicability.



So, to summarize, our paper is about&nbsp;identifying&nbsp;the occupations where&nbsp;AI may be most useful,&nbsp;by&nbsp;assisting&nbsp;or performing subtasks.&nbsp;&nbsp;Our data do&nbsp;not&nbsp;indicate, nor&nbsp;did&nbsp;we&nbsp;suggest, that certain jobs will be replaced by AI.



Methodological limitations are acknowledged‚Äîand important



The paper is transparent about the limitations of our approach.&nbsp;&nbsp;



We analyzed&nbsp;anonymized&nbsp;Bing Copilot conversations to see what&nbsp;activities&nbsp;users are seeking AI&nbsp;assistance&nbsp;with and what activities AI can perform when mapped to the O*NET database.&nbsp;While O*NET provides a structured list of&nbsp;activities&nbsp;associated with various occupations, it does&nbsp;not&nbsp;capture the full spectrum of skills, context, and nuance&nbsp;required&nbsp;in the real&nbsp;world.&nbsp;&nbsp;A job is far more than the collection of tasks that make&nbsp;it up.



For example, a task might involve ‚Äúwriting reports,‚Äù but O*NET&nbsp;won‚Äôt&nbsp;reflect the interpersonal judgment, domain&nbsp;expertise, or ethical considerations that go into doing that well. The paper acknowledges this gap and warns against over-interpreting the AI applicability scores as measures of AI‚Äôs ability to perform an occupation.



Additionally, the dataset is based on user queries from Bing Copilot (from January ‚Äì September 2024), which may be influenced by factors like awareness, access, or comfort with AI tools.&nbsp;&nbsp;Different people use different LLMs for different purposes and it also is&nbsp;very difficult&nbsp;(or&nbsp;nearly impossible) to&nbsp;determine&nbsp;what conversations are performed in a work context or for leisure.&nbsp;



Finally, we only evaluated AI chatbot usage, so this study does not evaluate the impact or applicability of other forms of AI.



Where do we go from here?



Given the intense interest in how AI will shape our collective future,&nbsp;it&#8217;s&nbsp;important we continue to study and better understand its societal and economic impact. As with&nbsp;all&nbsp;research on this topic,&nbsp;the findings&nbsp;are&nbsp;nuanced, and&nbsp;it‚Äôs&nbsp;important to pay attention to this nuance.&nbsp;



The public interest in our research is based, in large part, on the&nbsp;topic&nbsp;of AI&nbsp;and job displacement.&nbsp;However,&nbsp;our current&nbsp;methodology&nbsp;for this study&nbsp;is unlikely to lead to firm conclusions about this.&nbsp;&nbsp;AI may prove to be a useful tool for many occupations, and we believe the right balance lies in finding how to use the technology in a way that&nbsp;leverages&nbsp;its abilities while complementing human strengths and accounting for people&#8217;s preferences.&nbsp;&nbsp;&nbsp;&nbsp;



For more information from Microsoft on the future of work and AI skilling, check out Microsoft‚Äôs Annual&nbsp;Work Trend Index (opens in new tab)&nbsp;and&nbsp;Microsoft Elevate (opens in new tab).&nbsp;
Opens in a new tabThe post Applicability vs. job displacement: further notes on our recent research on AI and occupations appeared first on Microsoft Research.
‚Ä¢ Coauthor roundtable: Reflecting on healthcare economics, biomedical research, and medical education
  In November 2022, OpenAI‚Äôs ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4‚Äôs public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, The AI Revolution in Medicine, Revisited, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right‚Äîand what they didn‚Äôt foresee.&nbsp;



In this series finale, Lee welcomes back coauthors Carey Goldberg (opens in new tab) and Dr. Zak Kohane (opens in new tab) to discuss how their predictions stack up against key takeaways from guests in the second half of the series: experts on AI‚Äôs economic and societal impact; technologists on the cutting edge; leaders in AI-driven medicine; next-generation physicians; and heads of healthcare organizations. Lee, Goldberg, and Kohane explore thinking innovatively about existing healthcare processes, including the structure of care teams and the role of specialties, to take advantage of AI opportunities and consider what clinicians and patients might need these new AI tools to be to feel empowered when it comes to giving and receiving the best healthcare. They close the episode with their hopes for the future of AI in health.








Learn more:




Scalable emulation of protein equilibrium ensembles with generative deep learning&nbsp;Publication | July 2025



Sequential Diagnosis with Language Models&nbsp;Publication | July 2025



Developing next-generation cancer care management with multi-agent orchestration&nbsp;Microsoft Industry Blogs | May 2025



The AI Revolution in Medicine: GPT-4 and BeyondBook | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023&nbsp;










	
		
			Subscribe to the Microsoft Research Podcast:		
		
							
					
						  
						Apple Podcasts
					
				
			
							
					
						
						Email
					
				
			
							
					
						
						Android
					
				
			
							
					
						
						Spotify
					
				
			
							
					
						
						RSS Feed
					
				
					
	




	
		
			
				
					

Transcript



[MUSIC]‚ÄØ



[BOOK PASSAGE]&nbsp;



PETER LEE: ‚ÄúAs a society‚Äîindeed, as a species‚Äîwe have a choice to make. Do we constrain or even kill artificial intelligence out of fear of its risks and obvious ability to create new harms? Do we submit ourselves to Al and allow it to freely replace us, make us less useful and less needed? Or do we start, today, shaping our Al future together, with the aspiration to accomplish things that humans alone, and Al alone, can&#8217;t do but that humans+Al can? The choice is in our hands ‚Ä¶ .‚Äù&nbsp;



[END OF BOOK PASSAGE]



[THEME MUSIC]



This is The AI Revolution in Medicine, Revisited. I‚Äôm your host, Peter Lee.‚ÄØ



Shortly after OpenAI&#8217;s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published The AI Revolution in Medicine to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?‚ÄØ



In this series, we‚Äôll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.‚ÄØ



				
				
					



[THEME MUSIC FADES]&nbsp;



The book passage I read at the top is from the epilogue, and I think it‚Äôs a truly fitting closing sentiment for the conclusion of this podcast series‚Äîbecause it calls back to the very beginning.



As I‚Äôve mentioned before, Carey, Zak, and I wrote The AI Revolution in Medicine as a guide to help answer these big questions, particularly as they pertain to medicine. You know, we wrote the book to empower people to make a choice about AI‚Äôs development and use. Well, have they? Have we?



Perhaps we‚Äôll need more time to tell. But over the course of this podcast series, I‚Äôve had the honor of speaking with folks from across the healthcare ecosystem. And my takeaway? They‚Äôre all committed to shaping AI into a tool that can improve the industry for practitioners and patients alike.



In this final episode, I‚Äôm thrilled to welcome back my coauthors, Carey Goldberg and Dr. Zak Kohane. We‚Äôll examine the insights from the second half of the season.&nbsp;



[TRANSITION MUSIC]&nbsp;



Carey, Zak‚Äîit‚Äôs really great to have you here again!&nbsp;



CAREY GOLDBERG: Hey, Peter!&nbsp;



ZAK KOHANE: Hi, Peter.&nbsp;



LEE: So this is the second roundtable. And just to recap, you know, we had several early episodes of the podcast where we talked to some doctors, some technology developers, some people who think about regulation and public policy, patient advocates, a venture capitalist who invests in, kind of, consumer and patient-facing medical ventures, and some bioethicists.&nbsp;



And I think we had a great conversation there. I think, you know, it felt mostly validating. A lot of the things that we predicted might happen happened, and then we learned a lot of new things. But now we have five more episodes, and the mix of kinds of people that we talk to here is different than the original.&nbsp;



And so I thought it would be great for us to have a conversation and recap what we think we heard from all of them. So let&#8217;s just start at the top.&nbsp;



So in this first episode in the second half of this podcast series, we talked to economists Azeem Azhar and Ethan Mollick. And I thought those conversations were really interesting. Maybe there were, kind of, two things, two main topics. One was just the broader impact on the economy, on the cost of healthcare, on overall workforce issues.&nbsp;



One of the things that I thought was really interesting was something that Ethan Mollick brought up. And maybe just to refresh our memories, let&#8217;s play this little clip from Ethan.&nbsp;



ETHAN MOLLICK: So we‚Äôre in this really interesting period where there‚Äôs incredible amounts of individual innovation in productivity and performance improvements in this field, like very high levels of it. ‚Ä¶ We‚Äôre seeing that in nonmedical problems, the same kind of thing, which is, you know, we‚Äôve got research showing 20 and 40% performance improvements. ‚Ä¶ But then the organization doesn‚Äôt capture it; the system doesn‚Äôt capture it. Because the individuals are doing their own work, and the systems don‚Äôt have the ability to, kind of, learn or adapt as a result.&nbsp;



LEE: So let me start with you, Zak. Does that make sense to you? Are you seeing something similar?&nbsp;



KOHANE: I thought it was incredibly insightful because we discussed on our earlier podcast how a chief AI officer in one of the healthcare hospitals, in one of the healthcare systems, was highly regulating the use of AI, but yet in her own practice on her smartphone was using all these AI technologies.&nbsp;



And so it&#8217;s insightful that on the one hand, she is increasing her personal productivity, ‚Ä¶&nbsp;



LEE: Right.&nbsp;



KOHANE: ‚Ä¶ and perhaps she&#8217;s increasing her quality of her care. But it&#8217;s very hard for the healthcare system to actually realize any gains. It&#8217;s unlikely ‚Ä¶ let&#8217;s put it this way. It would be for her a defeat if they said, ‚ÄúNow you should see more patients.‚Äù&nbsp;



LEE: Yes. [LAUGHS]&nbsp;



KOHANE: Now, I&#8217;m not saying that won&#8217;t happen. It could happen. But, you know, gains of productivity are really at the individual level of the doctors. And that&#8217;s why they&#8217;re adopting it. That&#8217;s why the ambient dictation tools are so successful. But really turning it into things that matter in terms of productivity for healthcare, namely making sure that patients are getting healthy, requires that every piece of the puzzle works well together. You know, it&#8217;s well-tread ground to talk about how patients get very expensive procedures, like a cardiac transplant, and then go home, and they‚Äôre not put on blood thinners ‚Ä¶&nbsp;



LEE: Right.&nbsp;



KOHANE: ‚Ä¶ and then they get a stroke. You know, the chain is as strong as the weakest link. And just having AI in one part of it is not going to do it. And so hospitals, I think, are doubly burdened by the fact that, (A) they tend to not like innovation because they are high-revenue, low-margin companies. But if they want it implemented effectively, they have to do it across the entire processes of healthcare, which are vast and not completely under their control.&nbsp;



LEE: Yeah. Yep. You know, that was Sara Murray, who&#8217;s the chief health AI officer at UC San Francisco.&nbsp;



And then, you know, Carey, remember, we were puzzled by Chris Longhurst&#8217;s finding in a controlled study that the, you know, having an AI respond to patient emails didn&#8217;t seem to lead to any, I guess you would call it, productivity benefits. I remember we were both kind of puzzled by that. I wonder if that&#8217;s related to what Ethan is saying here.&nbsp;



GOLDBERG: I mean, possibly, but I think we&#8217;ve seen since then that there have been multiple studies showing that in fact using AI can be extremely effective or helpful, even, for example, for diagnosis.&nbsp;



And so I find just from the patient point of view, it kind of drives me crazy that you have individual physicians using AI because they know that it will improve the care that they&#8217;re offering. And yet you don&#8217;t have their institutions kind of stepping up and saying, ‚ÄúOK, these are the new norms.‚Äù&nbsp;



By the way, Ethan Mollick is a national treasure, right. Like, he is the classic example of someone who just stepped up at this moment ‚Ä¶&nbsp;



LEE: Yeah.&nbsp;



GOLDBERG: ‚Ä¶ when we saw this extraordinary technological advance. And he&#8217;s not only stepping up for himself. He&#8217;s spreading the word to the masses that this is what these things can do.&nbsp;



And so it&#8217;s frustrating to see the institutions not stepping up and instead the individual doctors having to do it.&nbsp;



KOHANE: But he made another very interesting point, which was that the reason that he could be so informative to not only the public but practitioners of AI is these things would emerge out of the shop, and they would not be aged too long, like a fine wine, before they were just released to the public.&nbsp;



And so he was getting exposure to these models just weeks after some of the progenitors had first seen it. And therefore, because he&#8217;s actually a really creative person in terms of how he exercises models, he sees uses and problems very early on. But the point is institutions, think about how much they are disadvantaged. They&#8217;re not Ethan Mollick. They&#8217;re not the progenitors. So they&#8217;re even further behind. So it&#8217;s very hard. If you talk to most of the C-suite of hospitals, they&#8217;d be delighted to know as much about the impact as Ethan Mollick.&nbsp;



LEE: Yeah. By the way, you know, I picked out this quote because within Microsoft, and I suspect every other software company, we&#8217;re seeing something very similar, where individual programmers are 20 to 30% more productive just in the number of lines of code they write per day or the number of pull requests per week. Any way you measure it, it&#8217;s very consistent. And yet by the time you get to, say, a 25-person software engineering team, the productivity of that whole team isn&#8217;t 25% more productive.&nbsp;



Now, that is starting to change because we&#8217;re starting to figure out that, well, maybe we should reshape how the team operates. And there&#8217;s more of an orientation towards having, you know, smaller teams of full-stack developers. And then you start to see the gains. But if you just keep the team organized in the usual way, there seems to be a loss. So there&#8217;s something about what Ethan was saying that resonated very strongly with me.&nbsp;



GOLDBERG: But I would argue that it&#8217;s not just productivity we&#8217;re talking about. There&#8217;s a moral imperative to improve the care. And if you have tools that will do that, you should be using them or trying harder to.&nbsp;



LEE: Right. Yep.&nbsp;



KOHANE: I think, yes, first of all, absolutely you would. Unfortunately, most of the short-term productivity measures will not measure improvements in the quality of care because it takes a long time to die even with bad care.&nbsp;



And so that doesn&#8217;t show up right away. But I think what Peter just said actually came across in several of the podcasts, which is that it&#8217;s very tricky trying to shoehorn these things into making what we&#8217;re already doing more productive.&nbsp;



GOLDBERG: Yeah. Existing structures.&nbsp;



KOHANE: Yeah. And I know, Carey, that you&#8217;ve raised this issue many times. But it really calls into question, what should we be doing with our time with doctors? And they are a scarce resource. And what is the most efficient way to use them?&nbsp;



You know, I remember we [The New England Journal of Medicine AI] published a paper of someone who was able to use AI to increase the throughput of their emergency room (opens in new tab) by actually more appropriately having the truly sick people in the sick queue, in the triage queue, for urgent care.&nbsp;



And so I think we&#8217;re going to have to think that way more broadly, about we don&#8217;t have to now look at every patient as an unknown with maybe a few pointers on diagnosis. We can have a fairly extensive profiling.&nbsp;



And I know that colleagues in Clalit [Health Services] in Israel, for example, are using the overall trajectory of the patient and some considerations about utilities to actually figure out who to see next week.&nbsp;



LEE: Yeah, you know, what you said brings up another maybe connection to one thing that we see also in software development. And it relates to also what we were discussing earlier: about the last thing a doctor wants is to have a tool that allows them to see even yet more patients per day.&nbsp;



So in software development, there&#8217;s always this tension. Like, how many lines of code can you write per day? That&#8217;s one productivity measure.&nbsp;



But sometimes we&#8217;re taught, well, don&#8217;t write more lines of code per day, but make sure that your code is well structured. Take the time to document it. Make sure it&#8217;s fully commented. Take the time to talk to your fellow software engineering team members to make sure that it&#8217;s well coordinated. And in the long run, even if you&#8217;re writing half the number of lines of code per day, the software process will be far more efficient.



And so I&#8217;ve wondered whether there&#8217;s a similar thing where doctors could see 20% fewer patients in a day, but if they take the time and also had AI help to coordinate, maybe a patient&#8217;s journey might be half as long. And therefore, the health system would be able to see twice as many patients in a year&#8217;s period or something like that.&nbsp;



KOHANE: So I think you&#8217;ve ‚Äúnerd sniped‚Äù me because you [LAUGHTER]‚Äîwhich is all too easy‚Äîbut I think there&#8217;s a central issue here. And I think this is the stumbling block between what Ethan&#8217;s telling us about between the individual productivity and the larger productivity, is the team&#8217;s productivity.&nbsp;



And there is actually a good analogy in computer science and that&#8217;s, uh, Brooks‚Äôs ‚Äúmythical man-month,‚Äù &#8230;&nbsp;



LEE: Yes, exactly.&nbsp;



KOHANE: ‚Ä¶ where he shows how you can have more and more resources, but when the coordination starts failing, because you have so many, uh, individuals on the team, you start falling apart. And so even if the, uh, individual doctors get that much better, yeah, they take better care of patients, make less stupid things.&nbsp;



But in terms of giving the ‚ÄúI get you into the emergency room, and I get you out of a hospital as fast as possible, as safely as possible, as effectively as possible,‚Äù that&#8217;s teamwork. And we don&#8217;t do it. And we&#8217;re not really optimizing our tools for that.&nbsp;



GOLDBERG: And just to throw in a little reality check, I&#8217;m not aware of any indication yet that AI is in any way shortening medical journeys or making physicians more efficient. Yet ‚Ä¶&nbsp;



LEE: Right.&nbsp;



GOLDBERG: ‚Ä¶ at least. Yeah.&nbsp;



LEE: Yes. So I think, you know, with respect to our book, critiquing our book, you know, I think it&#8217;s fair to say we were fairly focused or maybe even fixated on the individual doctor or nurse or patient, and we didn&#8217;t really, at least I never had a time where I stepped back to think about the whole care coordination team or the whole health system.&nbsp;



KOHANE: And I think that&#8217;s right. It&#8217;s because, first of all, you weren‚Äôt thinking about it? It&#8217;s not what we&#8217;re taught in medical school. We&#8217;re not taught to talk about team communication excellence. And I think it&#8217;s absolutely essential.&nbsp;



There‚Äôs a ‚Ä¶ what‚Äôs the ‚Ä¶ there was an early ‚Ä¶ [Terry] Winograd. And he was trying to capture what are the different kinds of actions related to pronouncements that you could expect and how could AI use that. And that was beginning to get at it.&nbsp;



But I actually think this is dark matter of human organizational technology that is not well understood. And our products don&#8217;t do well. You know, we can talk about all the groupware things that are out there. But they all don&#8217;t quite get to that thing.&nbsp;



LEE: Right.&nbsp;



KOHANE: And I can imagine an AI serving as a team leader, a really active team leader, a real quarterback of, let&#8217;s say, a care team.&nbsp;



LEE: Well, in fact, you know, we have been trying to experiment with this. My colleague, Matt Lungren, who was also one of the interviewees early on, has been working with Stanford Medicine on a tumor board AI agent‚Äîsomething that would facilitate tumor board meetings.&nbsp;



And the early experiences are pretty interesting. Whether it relates to efficiency or productivity I think remains to be seen, but it does seem pretty interesting.&nbsp;



But let&#8217;s move on.&nbsp;



GOLDBERG: Well, actually, Peter, ‚Ä¶&nbsp;



LEE: Oh, go ahead.&nbsp;



GOLDBERG: ‚Ä¶ if you&#8217;re willing to not quite move on yet ‚Ä¶&nbsp;



LEE: [LAUGHS] All right.&nbsp;



GOLDBERG: ‚Ä¶ this kind of segues into one of, I think, the most provocative questions that arose in the course of these episodes and that I&#8217;d love to have you answer, which was, remember, it was a question at a gathering that you were at, and you were asked, ‚ÄúWell, you&#8217;re focusing a lot on potential AI effects on individual patient and physician experiences. But what about the revolution, right? What about, like, can you be more big-picture and envision how generative AI could actually, kind of, overturn or fix the broken system, right?‚Äù&nbsp;



I&#8217;m sure you&#8217;ve thought about that a lot. Like, what&#8217;s your answer?&nbsp;



LEE: You know, I think ultimately, it will have to. For it to really make a difference, I think that the normal processes, our normal concept of how healthcare is delivered‚Äîhow new medical discoveries are made and brought into practice‚ÄîI think those things are going to have to change a lot.&nbsp;



You know, one of the things I think about a lot right at the moment is, you know, we tend to think about, let&#8217;s say, medical diagnosis as a problem-solving exercise. And I think, at least at the Kaiser Permanente School of Medicine, the instruction really treats it as a kind of detective thing based on a lot of knowledge about biology and biomedicine and human condition, and so on.&nbsp;



But there&#8217;s another way to think about it, given AI, which is when you see a patient and you develop some data, maybe through a physical exam, labs, and so on, you can just simply ask, ‚ÄúYou know, what did the 500 other people who are most similar to this experience, how were they diagnosed? How were they treated? What were their outcomes? What were their experiences?‚Äù&nbsp;



And that&#8217;s really a fundamentally different paradigm. And it just seems like at least the technical means will be there. And by the way, that also then relates to [the questions]: ‚ÄúAnd what was most efficacious cost-wise? What was most efficient in terms of the total length of the patient journey? How does this relate to my quality scores so I can get more money from Medicare and Medicaid?‚Äù&nbsp;



All of those things, I think, you know, we&#8217;re starting to confront.&nbsp;



One of the other episodes that we&#8217;re going to talk about, was my interview with two medical students. Actually, thinking of a Morgan Cheatham as just a medical student or medical resident [LAUGHTER] is a little strange. But he is.&nbsp;



One of the things he talks about is the importance that he placed in his medical training about adopting AI. So, Zak, I assume you see this also with some students at Harvard Medical School. And the other medical student we interviewed, Daniel Chen, seemed to indicate this, too, where it seems like it&#8217;s the students who are bringing AI into the medical education ahead of the faculty. Does that resonate with you?&nbsp;



KOHANE: It absolutely resonates with me. There are students I run into who, honestly, my first thought when I&#8217;m talking to them is, why am I teaching you [LAUGHTER], and why are you not starting a big AI company, AI medicine company, now and really change healthcare instead of going through the rest of the rigmarole? And I think broadly, higher education has a problem there, which is we have not embraced, again, going back to Ethan, a lot of the tools that can be used. And it&#8217;s because we don&#8217;t know necessarily the right way to teach them. And so far, the only lasting heuristic seems to be: use them and use them often.&nbsp;



And so it&#8217;s an awkward thing, where the person who knows how to use the AI tools now in the first-year medical school can teach themselves better and faster than anybody else in their class who is just relying on the medical school curriculum.&nbsp;



LEE: Now, the reason I brought up Morgan now after our discussion with Ethan Mollick is Morgan also talked about AI collapsing medical specialties.&nbsp;



GOLDBERG: Yes.&nbsp;



LEE: And so let&#8217;s hear this snippet from him.&nbsp;



MORGAN CHEATHAM: AI collapses medical specialties onto themselves, right. You have the canonical example of the cardiologist, you know, arguing that we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient‚Äôs clinical status? ‚Ä¶ So I‚Äôm interested in this question of whether medical specialties themselves need to evolve. And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve.



LEE: So on the specific question about specialties, Zak, do you have a point of view? And let me admit, first of all, for us, all three of us, we didn&#8217;t have any clue about this in our book. I don&#8217;t think.&nbsp;



KOHANE: Not much. Not much of a clue.&nbsp;



So I&#8217;m reminded of a New Yorker cartoon where you see a bunch of surgeons around the patient, and someone says, ‚ÄúIs that a spleen?‚Äù And it says, ‚ÄúI don&#8217;t know. I slept during the spleen lecture,‚Äù [LAUGHTER] and &#8230; or ‚ÄúI didn&#8217;t take the spleen course.‚Äù&nbsp;



And yet when we measure things, we measure things much more than we think we are doing. So for example, we [NEJM AI] just published a paper where echocardiograms were being done. And it turns out those ultrasound waves just happen to also permeate the liver. And you can actually diagnose on the way with AI all the liver disease (opens in new tab) that is in‚Äîand treatable liver disease‚Äîthat&#8217;s in those patients.&nbsp;



But if you&#8217;re a cardiologist, ‚ÄúLiver? You know, I slept through liver lecture.‚Äù [LAUGHTER] And so I do think that, (A) the natural, often guild/dollar-driven silos in medicine are less obvious to AI, despite the fact that they do exist in departments and often in chapters.&nbsp;



But Morgan&#8217;s absolutely right. I can tell you as an endocrinologist, if I have a child in the ICU, the endocrinologist, the nephrologist, and the neurosurgeon will argue about the right thing to do.&nbsp;



And so in my mind, the truly revolutionary thing to do is to go back to 1994 with Pete Szolovits, the Guardian Angel Project (opens in new tab). What I think you need is a process. And the process is the quarterback. And the quarterback has only one job: take care of the patient.&nbsp;



And it should be thinking all the time about the patient. What&#8217;s the right thing? And can be as school-marmish or not about, ‚ÄúZak, you&#8217;re eating this or that or exercise or sleep,‚Äù but also, ‚ÄúHey, surgeons and endocrinologists, you&#8217;re talking about my host, Zak. This is the right way because this problem and this problem and our best evidence is this is the right way to get rid of the fluid. The other ways will kill him.‚Äù



And I think you need an authoritative quarterback that has the view of the others but then makes the calls.&nbsp;



LEE: Is that quarterback going to be AI or human?&nbsp;



KOHANE: Well, for the very lucky people, it&#8217;ll be a human augmented by AI, super concierge.&nbsp;



But I think we&#8217;re running out of doctors. And so realistically, it&#8217;s going to be an AI that will have to be certified in very different ways, along the ways Dave Blumenthal says, essentially, trial by fire. Like putting residents into clinics, we&#8217;re going to be putting AIs into clinics.&nbsp;



But what&#8217;s worse, by the way, than the three doctors arguing about care in front of the patient is, what happens so frequently, is then you see them outpatient, and each one of them gives you a different set of decisions to make. Sometimes that actually interact pathologically, unhealthily with each other. And only the very smart nurses or primary care physicians will actually notice that and call, quote, a ‚Äúfamily meeting,‚Äù or bring everybody in the same room to align them.&nbsp;



LEE: Yeah, I think this idea of quarterback is really very, very topical right now because there&#8217;s so much intensity in the AI space around agents. And in fact, you know, the Microsoft AI team under Mustafa Suleyman and Dominic King, Harsha Nori, and team just recently posted a paper on something called sequential diagnosis, which is basically an AI quarterback that is supposed to smartly consult with other AI specialties. And interestingly, one of the AI agents is sort of the devil&#8217;s advocate that&#8217;s always criticizing and questioning things.¬†



GOLDBERG: That‚Äôs interesting.&nbsp;



LEE: And at least on very, very hard, rare cases, it can develop some impressive results. There&#8217;s something to this that I think is emerging.&nbsp;



GOLDBERG: And, Peter, Morgan said something that blew me away even more, which was, well, why do we even need specialists if the reason for a specialist is because there&#8217;s so much medical knowledge that no single physician can know all of it, and therefore we create specialists, but that limitation does not exist for AI.&nbsp;



LEE: Yeah. Yeah.&nbsp;



GOLDBERG: And so there he was kind of undermining this whole elaborate structure that has grown up because of human limitations that may not ultimately need to be there.&nbsp;



LEE: Right. So now that gives me a good segue to get back to our economist and get to something that Azeem Azhar said. And so there&#8217;s a clip here from Azeem.&nbsp;



AZEEM AZHAR: We didn‚Äôt talk about, you know, AI in its ability to potentially do this, which is to extend the clinician‚Äôs presence throughout the week. You know, the idea that maybe some part of what the clinician would do if you could talk to them on Wednesday, Thursday, and Friday could be delivered through an app or a chatbot just as a way of encouraging the compliance, which is often, especially with older patients, one reason why conditions, you know, linger on for longer.&nbsp;



LEE: And, you know, in the same conversation, he also talked about his own management of asthma and the fact that he&#8217;s been managing this for several decades and knows more than any other human being, no matter how well medically trained, could possibly know. And it&#8217;s also very highly personalized. And it&#8217;s not a big leap to imagine AI having that sort of lifelong understanding.&nbsp;



KOHANE: So in fact, I want to give credit back to our book since you insulted us. [LAUGHTER] You challenged us. You doubted us. We do have at the end of the book a AI which is helping this woman manage her way through life. It&#8217;s quarterbacking for the woman all these different services.&nbsp;



LEE: Yes.&nbsp;



KOHANE: So there.&nbsp;



LEE: Ah, you&#8217;re right. Yes. In fact, it&#8217;s very much, I think, along the lines of the vision that Azeem laid out in our conversation.&nbsp;



GOLDBERG: Yeah. It also reminded me of the piece Zak wrote about his mother (opens in new tab) at one point when she was managing congestive heart failure and she needed to watch her weight very carefully to see her fluid status. And absolutely, there&#8217;s no ‚Ä¶ I see no reason whatsoever why that couldn&#8217;t be done with AI right now. Actually, although back then, Zak, you were writing that it takes much more than an AI [LAUGHS] to manage such a thing, right?&nbsp;



KOHANE: You need an AI that you can trust. Now, my mother was born in 1927, and she&#8217;d learned through the school of hard knocks that you can&#8217;t trust too many people, maybe even not your son, MD, PhD [LAUGHTER].&nbsp;



But what I&#8217;ve been surprised [by] is how, for example, how many people are willing to trust and actually see effective use of AI as mental health counselors, for example.&nbsp;



GOLDBERG: Yeah&nbsp;



KOHANE: So it may in fact be that there&#8217;s a generational thing going on, and at least there&#8217;ll be some very large subset of patients which will be completely comfortable in ways that my mother would have never tolerated.&nbsp;



LEE: Yeah. Now, I think we&#8217;re starting to veer into some of the core AI.&nbsp;



And so I think maybe one of the most fun conversations I had was in the episode with both S√©bastien Bubeck, my former colleague at Microsoft Research, and now he&#8217;s at OpenAI, and Bill Gates. And there was so much that was, I thought, interesting there. And there was one point, I think that sort of touches tangentially on what we were just conversing about, that S√©bastien said. So let&#8217;s hear this snippet.&nbsp;



S√âBASTIEN BUBECK: And one example that I really like, a study that recently appeared where ‚Ä¶ they were comparing doctors without and with ChatGPT. ‚Ä¶ So this was a set of cases where the accuracy of the doctors alone was around 75%. ChatGPT alone was 90%. ‚Ä¶ But then the kicker is that doctors with ChatGPT was 80%. Intelligence alone is not enough. It‚Äôs also how it‚Äôs presented, how you interact with it. And ChatGPT, it‚Äôs an amazing tool. Obviously, I absolutely love it. But it‚Äôs not ‚Ä¶ you don‚Äôt want a doctor to have to type in, you know, prompts and use it that way. It should be, as Bill was saying, kind of running continuously in the background, sending you notifications.



LEE: So I thought S√©bastien was saying something really profound, but I haven&#8217;t been able to quite decide or settle in my mind what it is. What do you make of what Seb just said?&nbsp;



KOHANE: I think it&#8217;s context. I think that it requires an enormous amount of energy, brain energy, to actually correctly provide the context that you want this thing to work on. And it&#8217;s only going to really feel like we&#8217;re in a different playing field when it&#8217;s listening all the time, and it just steps right in.&nbsp;



There is an advantage that, for example, a good programmer can have in prompting Cursor or any of these tools to do so. But it takes effort. And I think being in the conversation all the time so that you understand the context in the widest possible way is incredibly important. And I think that&#8217;s what Seb is getting at, which is if we spoon feed these machines, yes, 90%.&nbsp;



But then, talking to a human being who then has to interact and gets distracted from whatever flow they&#8217;re in and maybe even makes them feel like an early bicycle rider who all of a sudden realizes, ‚ÄúI&#8217;m balancing on two wheels‚Äîoh no!‚Äù And they fall over. You know, there&#8217;s that interaction which is negatively synergistic.&nbsp;



And so I do think it&#8217;s a very hard human-computer engineering problem. How do we make these two agents, human and computational, work in an ongoing way in the flow? I don&#8217;t think I&#8217;m seeing anything that&#8217;s particularly new. And the things that you&#8217;re beginning to hint about, Peter, in terms of agentic coordination, I think we&#8217;ll get to some of that. 



LEE: Yeah. Carey, does this give you any pause? The kind of results that ‚Ä¶ they&#8217;re puzzling results. I mean, the idea of doctors with AI seeming at least in this one test‚Äîit&#8217;s just one test‚Äîbut it&#8217;s odd that it does worse than the AI alone.&nbsp;



GOLDBERG: Yes. I would want to understand more about the actual conditions of that study.&nbsp;



From what Bill Gates said, I was most struck by the question of resource-poor environments. That even though this was absolutely one of the most promising, brightest perspectives that we highlighted in the book, we still don&#8217;t seem to be seeing a lot of use among the one half of humanity that lacks decent access to healthcare.&nbsp;



I mean, there are access problems everywhere, including here in the United States. And it is one of the most potentially promising uses of AI. And I thought if anyone would know about it, he would with the work that the Gates Foundation does.&nbsp;



LEE: You know, I think both you and Bill, I felt, are really simpatico. You know, Bill expressed genuine surprise that more isn&#8217;t happening yet. And it really echoed, in fact, maybe even using some of the exact same words that you&#8217;ve used. And so two years on, you&#8217;ve expressed repeatedly expecting to have seen more out in the field by now. And then I thought Bill was saying something in our conversation very similar.&nbsp;



GOLDBERG: Yeah.&nbsp;



LEE: You know, for me, I see it both ways. I see the world of medicine really moving fast in confronting the reality of AI in such a serious way. But at the same time, it&#8217;s also hard to escape the feeling that somehow, we should be seeing even more.&nbsp;



So it&#8217;s an odd thing, a little bit paradoxical.&nbsp;



GOLDBERG: Yeah. I think one thing that we didn&#8217;t focus on hardly at all in the book but that we are seeing is these companies rising up, stepping up to the challenge, Abridge and OpenEvidence, and what Morgan describes as a new stack, right.&nbsp;



So there is that on the flip side.&nbsp;



LEE: Now, I want to get back to this thing that Seb was saying. And, you know, I had to bring up the issue of sycophancy, which we discussed at our last roundtable also. But it was particularly ‚Ä¶ at the time that Seb, Bill, and I had our conversation, OpenAI had just gone through having to retract a fresh update of GPT-4o because it had become too sycophantic.&nbsp;



So I can&#8217;t escape the feeling that some of these human-computer interaction issues are related to this tension between you want AI to follow your directions and be faithful to you, but at the same time not agree with you so often that it becomes a fault.&nbsp;



KOHANE: I think it&#8217;s asking the AI to enter into a fundamental human conundrum, which is there are extreme versions of doublethink, and there&#8217;s everyday things, everyday asks of doublethink, which is how to be an effective citizen.&nbsp;



And even if you&#8217;re thinking, ‚ÄúHmm. I&#8217;m thinking this. I&#8217;m just not going to say it because that would be rude or counterproductive.‚Äù Or some of the official doublethinks, where you&#8217;re actually told you must say this, even if you think something else. And I think we&#8217;re giving a very tough mission for these things: be nice to the user and be useful.&nbsp;



And, in education, where the thing is not always one in the same. Sometimes you have to give a little tough love to educate someone, and doing that well is both an art and it&#8217;s also very difficult. And so, you know, I&#8217;m willing to believe that the latest frontier models that have made the news in the last month are very high-performing, but they&#8217;re also all highlighting that tension ‚Ä¶&nbsp;



LEE: Yes.&nbsp;



KOHANE: ‚Ä¶ that tension between behaving like a good citizen and being helpful. And this gets back to what are the fundamental values that we hope these things are following.&nbsp;



It&#8217;s not, you know, ‚ÄúAre these things going to develop us into the paperclip factory?‚Äù It&#8217;s more of, ‚ÄúWhich of our values are going to be elevated, and which one will be suppressed?‚Äù&nbsp;



LEE: Well, since I criticized our book before, let me pat ourselves on the back this time because, I think, pervasive throughout our book, we were touching on some of these issues.&nbsp;



In fact, we started the book, you know, with GPT-4 scolding me for wanting it to impersonate Zak. And there was the whole example of asking it to rewrite a poem in a certain way, and it kind of silently just tried to slide, you know, without me knowing, slide by without following through on the whole thing.&nbsp;



And so that early version of GPT-4 was definitely not sycophantic at all. In fact, it was just as prone to call you an idiot if it thought you were wrong. [LAUGHTER]&nbsp;



KOHANE: I had some very testy conversations around my endocrine diagnosis with it. [LAUGHTER]&nbsp;



GOLDBERG: Yeah. Well then, Peter, I would ask you, I mean last time I asked you about, well, hallucinations, aren&#8217;t those solvable? And this time I would ask you, well, sycophancy, isn&#8217;t that kind of like a dial you can turn? Like, is that not solvable?&nbsp;



LEE: You know, I think there are several interlocking problems. But if we assume superintelligence, even with superintelligence, medicine is such an inexact science that there will always be situations that are guesses that take into account other factors of a person&#8217;s life, other value judgments, exactly as Zak had pointed out in our previous roundtable conversation.&nbsp;



And so I think there&#8217;s always going to be an opening for either differences of opinion or agreeing with you too much. And there are dangers in both cases. And I think they&#8217;ll always be present. I don&#8217;t know that, at least in something as inexact as medical science, I don&#8217;t know that it&#8217;ll ever be completely eliminated.&nbsp;



KOHANE: And it&#8217;s interesting because I was trying to think what&#8217;s the right balance, but there are patients who want to be told this is what you do. Whereas there&#8217;s other patients who want to go through every detail of the reasoning.&nbsp;



And it&#8217;s not a matter of education. It&#8217;s really a temperamental, personality issue. And so we&#8217;re going to have to, I think, develop personalities ‚Ä¶&nbsp;



LEE: Yeah.&nbsp;



KOHANE: ‚Ä¶ that are most effective for those different kinds of individuals. And so I think that is going to be the real frontier. Having human values and behaving in ways that are recognizable and yet effective for certain groups of patients.&nbsp;



LEE: Yeah.&nbsp;



KOHANE: And lots of deep questions, including how paternalistic do we want to be?&nbsp;



LEE: All right, so we&#8217;re getting into medical science and hallucination. So that gives me a great segue to the conversations in the episode on biomedical research. And one of the people that I interviewed was Noubar Afeyan from Moderna and Flagship Pioneering. So let&#8217;s listen to this snippet.&nbsp;



NOUBAR AFEYAN: We, some hundred or so times a year, ask ‚Äúwhat if‚Äù questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that‚Äôs testable. Then we go into a lab, and we test it.‚ÄØSo in that world, right, sitting there going, like, ‚ÄúHow do I know this transformer is going to work?‚Äù The answer is, ‚ÄúFor what?‚Äù Like, it‚Äôs going to work to make something up ‚Ä¶ well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.



LEE: [LAUGHS] So I think that really touches on just the fact that there&#8217;s so many unknowns and such lack of precision and exactness in our understanding of human biology and of medicine. Carey, what do you think?&nbsp;



GOLDBERG: I mean, I just have this emotional reaction, which is that I love the idea of AI marching into biomedical science and everything from getting to the virtual cell eventually to, Zak, I think it was a colleague of yours who recently published about &#8230; it was a new medication that had been sort of discovered by AI (opens in new tab), and it was actually testing out up to the phase II level or something, right?



KOHANE: Oh, this is Marinka‚Äôs work.&nbsp;



GOLDBERG: Yeah, Marinka, Marinka Zitnik. And ‚Ä¶ yeah. So, I mean, I think it avoids a lot of the, sort of, dilemmas that are involved with safety and so on with AI coming into medicine. And it&#8217;s just the discovery process, which we all want to advance as quickly as possible. And it seems like it actually has a great deal of potential that&#8217;s already starting to be realized.&nbsp;



LEE: Oh, absolutely.&nbsp;



KOHANE: I love this topic. First of all, I thought, actually, I think Bill and Seb, actually, had interesting things to say on that very topic, rationales which I had not really considered why, in fact, things might progress faster in the discovery space than in the clinical delivery space, just because we don&#8217;t know in clinical medicine what we&#8217;re trying to maximize precisely. Whereas for a drug effect, we do know what we&#8217;re trying to maximize.&nbsp;



LEE: Well, in fact, I happened to save that snippet from Bill Gates saying that. So let&#8217;s cue that up.&nbsp;



BILL GATES: I think it‚Äôs very much within the realm of possibility that the AI is not only accelerating healthcare discovery but substituting for a lot of the roles of, you know, ‚ÄúI‚Äôm an organic chemist,‚Äù or ‚ÄúI run various types of assays.‚Äù I can see those, which are, you know, testable-output-type jobs but with still very high value, I can see, you know, some replacement in those areas before the doctor.&nbsp;



LEE: So, Zak, isn&#8217;t that Bill saying exactly what you‚Äôre saying?&nbsp;



KOHANE: That is my point. I have to say that this is another great bet, that either we&#8217;re all going to be surprised or a large group of people will be surprised or disappointed.&nbsp;



There&#8217;s still a lot of people in the sort of medicinal chemist, trialist space who are still extremely skeptical that this is going to work. And we haven&#8217;t quite shown them yet that it is. Why have we not shown them? Because we haven&#8217;t gone all the way to a phase III study, which showed that the drug behaves as expected to, is effective, and basically doesn&#8217;t hurt people. That turns out to require a lot of knowledge. I actually think we&#8217;re getting there, but I understand the skepticism.&nbsp;



LEE: Carey, what are your thoughts?&nbsp;



GOLDBERG: Yeah. I mean, there will be no way around going through full-on clinical trials for anything to ever reach the market. But at the same time, you know, it&#8217;s clearly very promising. And just to throw out something for the pure fun of it, Peter, I saw &#8230; one of my favorite tweets recently was somebody saying, you know, isn&#8217;t it funny how computer science is actually becoming a lot more like biology in that it&#8217;s just becoming empirical.&nbsp;



It&#8217;s like you just throw stuff at the AI and see what it does. [LAUGHTER] And I was like, oh, yeah, that&#8217;s what Peter was doing when we wrote the book. I mean, he understood as many innards as anybody can. But at the same time, it was a totally empirical exercise in seeing what this thing would do when you threw things at it.&nbsp;



LEE: Right.&nbsp;



GOLDBERG: So it&#8217;s the new biology.&nbsp;



LEE: Well, yeah. So I think we talked in our book about accelerating, you know, biomedical knowledge and medical science. And that actually seems to be happening. And I really had fun talking to Daphne Koller about some of the accomplishments that she&#8217;s made. And so here&#8217;s a little snippet from Daphne.&nbsp;



DAPHNE KOLLER: This will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient.‚ÄØAnd I think there‚Äôs been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&nbsp;



LEE: So, Zak, when I was listening to that, I was reminded of one of the very first examples that you had where, you know, you had a very rare case of a patient, and you&#8217;re having to narrow down some pretty complex and very rare genetic conditions. This thing that Daphne says, that seems to be the logical conclusion that everyone who&#8217;s thinking hard about AI and biology is coming to. Does it seem more real now two years on?&nbsp;



KOHANE: It absolutely seems more real. Here&#8217;s some sad facts. If you are at a cancer center, you will get targeted therapies if you qualify for it. Outside cancer centers, you won&#8217;t. And it&#8217;s not that the therapies aren&#8217;t available. It&#8217;s just that you won&#8217;t have people thinking about it in that way. And especially if you have some of the rare and more aggressive cancers, if you&#8217;re outside one of those cancer centers, you&#8217;re at a significant disadvantage for survival for that reason. And so anything that provides just the ‚Äúsimple,‚Äù in quotes, dogged investigation of the targeted therapies for patients, it&#8217;s a home run.&nbsp;



So my late graduate student, Atul Butte, died recently at UCSF, where he was both a professor and the leader of the Bakar Institute, and he was a Zuckerberg Chan Professor of Pediatrics.&nbsp;



He was diagnosed with a rare tumor two years ago. His wife is a PhD biologist, and when he was first diagnosed, she sent me the diagnosis and the mutations. And I don&#8217;t know if you know this, Peter, but this was still when we were writing the book and people didn&#8217;t know about GPT-4.&nbsp;



I put in those mutations into GPT-4 and the diagnosis. And I said, ‚ÄúI&#8217;d like to help treat my friend. What&#8217;s the right treatment?‚Äù And GPT, to paraphrase, GPT-4 said, ‚ÄúBefore we start talking about treatment, are you sure this is the right diagnosis? Those mutations are not characteristic for that tumor.&#8221; And he had been misdiagnosed. And then they changed the diagnosis therapy and some personnel.¬†



So I don&#8217;t have to hallucinate this. It&#8217;s already happened, and we&#8217;re going to need this. And so I think targeted therapy for cancers is the most obvious use. And if God forbid one of you has a family member who has cancer, it&#8217;s moral malpractice not to look at the genetics and run it past GPT-4 and say, ‚ÄúWhat are the available therapies?‚Äù&nbsp;



LEE: Yeah.&nbsp;



KOHANE: I really deeply believe that.&nbsp;



LEE: Carey, I think one thing you&#8217;ve always said is that you&#8217;re surprised that we don&#8217;t hear more stories along these lines. And I think you threw a quote from Mustafa Suleyman back at me. Do you want to share that?&nbsp;



GOLDBERG: Yes. Recently, I believe it was a Big Technology interview (opens in new tab), and the reporter asked Mustafa Suleyman, ‚ÄúSo you guys are seeing 50 million queries, medical queries, a day [to Copilot and Bing]. You know, how&#8217;s that going?‚Äù And I think I am a bit surprised that we&#8217;re not seeing more stories of all types. Both here&#8217;s how it helped me and also here was maybe, you know, a suggestion that was not optimal.&nbsp;



LEE: Yeah. I do think in our book, we did predict both positive and negative outcomes of this. And it is odd. Atul was very open with his story. And of course, he is such ‚Ä¶ he was such a prominent leader in the world of medicine.&nbsp;



But I think I share your surprise, Carey. I expected by now that a lot more public stories would be out. Maybe there is someone writing a book collecting these things, I don&#8217;t know.&nbsp;



KOHANE: Maybe someone called Carey Goldberg should write that book. [LAUGHTER]&nbsp;



GOLDBERG: Write a book, maybe. I mean, we have Patients Use AI (opens in new tab), which is a wonderful blog by Dave deBronkart, the patient advocate.&nbsp;



But I wonder if it&#8217;s also something structural, like who would be or what would be the institution that would be gathering these stories? I don‚Äôt know.&nbsp;



LEE: Right.&nbsp;



KOHANE: And that&#8217;s the problem. You see, this goes back to the same problem that [Ethan] Mollick was talking about. Individual doctors are using them. The hospital as a whole is not doing that. So it&#8217;s not judging the quality, as part of its quality metrics, of how good the AI is performing and what new has happened. And the other audience, namely the patients, have no mechanism. There is no mechanism to go to Better Business Bureau and say, ‚ÄúThey screwed up,‚Äù or ‚ÄúThis was great.‚Äù&nbsp;



LEE: So now I want to get a little more futuristic. And this gets into whether AI is really going to get almost to the ab initio understanding of human biology. And so Eric Topol, who is one of the guests, spoke to this a bit. So let&#8217;s hear this.&nbsp;



LEE: So you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?ERIC TOPOL:‚ÄØNo, I think within 10 years for sure. You know, the group that got assembled, that‚ÄØSteve Quake pulled together,‚ÄØI think has 42 authors in a‚ÄØpaper‚ÄØin‚ÄØCell. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree that not only is this a worthy goal, but it‚Äôs actually going to be realized, that was impressive.¬†



LEE: You know, I have to say Eric&#8217;s optimism took me aback. Just speaking as a techie, I think I started off being optimistic: as soon as we can figure out molecular dynamics, biology can be solved. And then you start to learn more about biochemistry, about the human cell, and then you realize, oh, my God, this is just so vast and unknowable. And now you have Eric Topol saying, ‚ÄúWell, in less than 10 years.‚Äù&nbsp;



KOHANE: So what&#8217;s delightful about this period is that those of us who are cautious were so incredibly wrong about AI two years ago. [LAUGHTER] That&#8217;s a true joy &#8230; I mean, absolute joy. It&#8217;s great to have your futurism made much more positive.&nbsp;



But I think that we&#8217;re going from, you know, for example, AlphaFold has had tremendous impact. But remember, that was built on years of acquisition of crystallography data that was annotated. And of course, the annotation process becomes less relevant as you go down the pipe, but it started from that.&nbsp;



LEE: Yes.&nbsp;



KOHANE: And there&#8217;s lots of parts of the cell. So when people talk about virtual cells‚ÄîI don&#8217;t mean to get too technical‚Äîmostly they&#8217;re talking about perturbation of gene expression. They&#8217;re not talking about, ‚ÄúOh, this is how the liposome and the centrosome interact, and notice how the Golgi bodies bump into each other.‚Äù&nbsp;



There&#8217;s a whole bunch of other levels of abstraction we know nothing about. This is a complex factory. And right now, we&#8217;re sort of the level from code into loading code into memory. We&#8217;re not talking about how the rest of the robots work in that cell, and how the rest of those robots work in the cell turns out to be pretty important to functioning.&nbsp;



So I&#8217;d love to be wrong again. And in 10 years, oh yeah, not only, you know, our first in-human study will be you, Dr. Zak. We&#8217;re going put the drug because we fully simulated you. That&#8217;d be great.&nbsp;



LEE: Yes.&nbsp;



KOHANE: And, by the way, just to give people their due, there probably was a lot of animal research that could be done in silico and that for various political reasons we&#8217;re now seeing happen. That&#8217;s a good thing. But I think that sometimes it takes a lot of hubris to get us where we need to get, but my horizon is not the same as his.&nbsp;



LEE: So I guess I have to take this time to brag. Just recently out of our AI for Science team did publish in Science a biological emulator that does pretty long timespan, very, very precise, and very efficient molecular dynamics, biomolecular dynamics emulation. We call it emulation because it&#8217;s not simulating every single time step but giving you the final confirmations.&nbsp;



KOHANE: That&#8217;s an amazing result.&nbsp;



LEE: Yeah.&nbsp;



KOHANE: But ‚Ä¶ that is an amazing result. And you&#8217;re doing it in some very important interactions. But there&#8217;s so much more to do.&nbsp;



LEE: I know, and it&#8217;s single molecules; it&#8217;s not even two molecules. There&#8217;s so much more to go for here. But on the other hand, Eric is right, you know, 42 experts writing for Cell, you know, that&#8217;s not a small matter.&nbsp;



KOHANE: So I think sometimes you really need to drink your own hallucinogens to actually succeed. Because remember, when the Human Genome Project (opens in new tab) was launched, we didn&#8217;t know how to sequence at scale.&nbsp;



We said maybe we would get there. And then in order to get the right funding and excitement and, I think, focus, we predicted that by early 2000s we&#8217;d be transforming medicine. Has not happened yet. Things have happened, but at a much slower pace. And we&#8217;re 25 years out. In fact, we&#8217;re 35 years out from the launch.&nbsp;



But again, things are getting faster and faster. Maybe the singularity is going to make a whole bunch of things easier. And GPT-6 will just say, ‚ÄúZak, you are such a pessimist. Let me show you how it&#8217;s done.‚Äù&nbsp;



GOLDBERG: Yeah.&nbsp;



It really is a pessimism versus optimism. Like is it, I mean, biology is such a bitch, right. [LAUGHTER] Can we actually get there?&nbsp;



At the same time, everyone was surprised and blown away by the, you know, the quantum leap of GPT-4. Who knows when enough data gets in there if we might not have a similar leap.&nbsp;



LEE: Yeah. All right.&nbsp;



So let&#8217;s get back to healthcare delivery. Besides Morgan Cheatham, we talked to [a] more junior medical student who&#8217;s at the Kaiser Permanente School of Medicine, Daniel Chen. And, you know, I asked him about this question of patients who come in armed [LAUGHS] with a lot of their own information. Let&#8217;s hear what he said about this.&nbsp;



DANIEL CHEN: But for those that come in with a list, I sometimes sit down with them, and we‚Äôll have a discussion, honestly. ‚Ä¶ ‚ÄúI don‚Äôt think you have meningitis because, you know, you‚Äôre not having a fever. Some of the physical exam maneuvers we did were also negative. So I don‚Äôt think you have anything to worry about that,‚Äù you know. So I think it‚Äôs having that very candid conversation with the patient that helps build that initial trust.&nbsp;



LEE: So, Zak, as far as I can tell, Daniel and Morgan are figuring this out on their own as medical students. I don&#8217;t think this is part of the curriculum. Does it need to be?&nbsp;



KOHANE: It&#8217;s missing the bigger point. The incentives and economic forces are such that even if you were Daniel, and things have not changed in terms of incentives, and it&#8217;s 2030, he still has to see this many patients in an hour.&nbsp;



And sitting down, going over that with a patient, let&#8217;s say some might need more &#8230; in fact, I think computer scientists are enriched for these sort of neurotic ‚Äúexplain [to] me why this works,‚Äù when often the answer is, ‚ÄúI have no idea; empirically it does.‚Äù&nbsp;



And patients in some sense deserve that conversation, and we&#8217;re taught about joint decision making, but in practice, there&#8217;s a lot of skills that are deployed to actually deflect so that you can get through the appointment and see enough patients per hour.&nbsp;



And that&#8217;s why I think that one of the central ‚Ä¶ another task for AI is how to engage with patients to actually explain to them why their doctor is doing what he&#8217;s doing and perhaps ask the one or two questions that you should be asking the doctor in order to reassure you that they&#8217;re doing the right thing.



LEE: Yeah.&nbsp;



KOHANE: I just ‚Ä¶ right now, we are going to have less doctor time, not more doctor time.&nbsp;



And so I&#8217;ve always been struck by the divide between medicine that we&#8217;re taught as it should be practiced as a gentle person&#8217;s vocation or sport as opposed to assembly line, heads down ‚Äúyou&#8217;ve got to see those patients by the end of the day‚Äù because, otherwise, you haven&#8217;t seen all the patients at the end of the day.&nbsp;



LEE: Yeah. Carey, I&#8217;ve been dying to ask you this, and I have not asked you this before. When you go see a doctor, are you coming in armed with ChatGPT information?&nbsp;



GOLDBERG: I haven&#8217;t needed to yet, but I certainly would. And also my reaction to the medical student description was, I think we need to distinguish between the last 20 years, when patients would come in armed with Google, and what they&#8217;re coming in with now because at least the experiences that I&#8217;ve witnessed, it is miles better to have gone back and forth with GPT-4 than with, you know, dredging what you can from Google. And so I think we should make that distinction.&nbsp;



And also, the other thing that most interested me was this question for medical students of whether they should not use AI for a while so that they can learn ‚Ä¶&nbsp;



LEE: Yes.&nbsp;



GOLDBERG: ‚Ä¶ how to think and similarly maybe don&#8217;t use the automated scribes for a while so they can learn how to do a note. And at what point should they then start being able to use AI? And I suspect it&#8217;s fairly early on that, in fact, they&#8217;re going be using it so consistently that there&#8217;s not that much they need to learn before they start using the tools.&nbsp;



LEE: These two students were incredibly impressive. And so I have wondered, you know, if we got a skewed view of things. I mean, Morgan is, of course, a very, very impressive person. And Daniel was handpicked by the dean of the medical school to be a subject of this interview.&nbsp;



KOHANE: You know, we filter our students, by and large, I mean, there&#8217;s exceptions, but students in medical school are so starry eyed. And they are really &#8230; they got into medical school‚ÄîI mean, some of them may have faked it‚Äîbut a lot of them because they really wanted to do good.&nbsp;



LEE: Right.&nbsp;



KOHANE: And they really wanted to help. And so this is very constant with them. And it&#8217;s only when they&#8217;re in the machine, past medical school, that they realize, oh my God, this is a very, very different story.&nbsp;



And I can tell you, because I teach a course in computational-enabled medicine, so I get a lot of these nerd medical students, and I&#8217;m telling them, ‚ÄúYou&#8217;re going to experience this. And you&#8217;re going to say, ‚ÄòI&#8217;m not going to able to change medicine until I get enough cred 10, 15 years from now, whereas I could start my own company and immediately change medicine.‚Äô‚Äù&nbsp;



And increasingly I&#8217;m getting calls in like residency and saying, ‚ÄúZak, help me. How do I get out of this?‚Äù&nbsp;



GOLDBERG: Wow.&nbsp;



KOHANE: And so I think there&#8217;s a real disillusionment of, like, between what we&#8217;re asking for people coming to medical school‚Äîwe&#8217;re looking for a phenotype‚Äîand then we&#8217;re disappointing them massively, not everywhere, but massively.&nbsp;



And for me, it&#8217;s very sad because among our best and brightest, and then because of economics and expectations and the nature of the beast, they&#8217;re not getting to enjoy the most precious part of being a doctor, which is that real human connection, and longitudinality, you know, the connection between the same doctor visit after visit, is more and more of a luxury.&nbsp;



LEE: Well, maybe this gets us to the last episode, you know, where I talk to a former, you know, state director of public health, Umair Shah, and with Gianrico Farrugia, who&#8217;s the CEO of Mayo Clinic. And I think if there&#8217;s one theme that I took away from those conversations is that we&#8217;re not thinking broadly enough nor big enough.&nbsp;



And so here&#8217;s a little quote of exchange that Umair Shah, who was the former head of public health in the State of Washington and prior to that in Harris County, Texas, and we had a conversation about what techies tend to focus on when they&#8217;re thinking about AI and medicine.&nbsp;



UMAIR SHAH: I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they&#8217;re doing in the AI space, they gravitate towards healthcare delivery.LEE: Yes. And in fact, it&#8217;s not even delivery. I think techies‚ÄîI did this, too‚Äîtend to gravitate specifically to diagnosis.



LEE: I have been definitely guilty. I think Umair, of course, was speaking as a former frustrated public health official in just thinking about all the other things that are important to maintain a healthy population.&nbsp;



Is there some lesson that we should take away? I think our book also focused a lot on things like diagnosis.&nbsp;



KOHANE: Yeah. Well, first of all, I think we just have to have humility. And I think it&#8217;s a really important ingredient. I found myself staring at the increase in lifespan in human beings over the last two centuries and looking for bumps that were attributable.&nbsp;



I&#8217;m in medical school. I&#8217;ve already made this major commitment. What are the bumps that are attributable to medicine? And there was one bump that was due to vaccines, a small bump. Another small bump that was due to antibiotics. And the rest of it is nutrition, sanitation, yeah, nutrition and sanitation.&nbsp;



And so I think doctors can be incredibly valuable, but not all the time. And we&#8217;re spending now one-sixth of our GDP on it. The majority of it is not effectively prolonging life. And so the humility has to be the right medicine at the right time.&nbsp;



But that runs, (A) against a bunch of business models. It runs against the primacy of doctors in healthcare. It was one thing when there were no textbooks; there was no PubMed. You know, the doctor was the repository of all the probably knowledge that we have. But I think your guests were right. We have to think more broadly in the public health way. How do we make knowledge pervasive like sanitation?&nbsp;



GOLDBERG: Although I would add that since what we&#8217;re talking about is AI, it&#8217;s harder to see if &#8230; and if what you&#8217;re talking about is public health, I mean, it was certainly very important to have good data during the pandemic, for example.&nbsp;



But most of the ways to improve public health, like getting people to stop smoking and eat better and sleep better and exercise more, are not things that AI can help with that much. Whereas diagnosis or trying to improve treatment are places that it could tackle.&nbsp;



And in fact, Peter, I wanted to put you‚Äîoh, wait, Zak&#8217;s going to say something‚Äîbut, Peter, I wanted to put you on the spot.&nbsp;



LEE: Yeah.&nbsp;



GOLDBERG: I mean, if you had a medical issue now, and you went to a physician, would you be OK with them not using generative AI?&nbsp;



LEE: I think if it&#8217;s a complex or a mysterious case, I would want them to use generative AI. I would want that second opinion on things. And I would personally be using it. If for no other reason than just to understand what the chart is saying.&nbsp;



I don&#8217;t see, you know, how or why one wouldn&#8217;t do that now.&nbsp;



KOHANE: It&#8217;s such a cheap second opinion, and people are making mistakes. And even if there are mistakes on the part of AI, if there&#8217;s a collision, discrepancy, that&#8217;s worth having a discussion. And again, this is something that we used to do more of when we had more time with the patients; we&#8217;d have clinic conferences.&nbsp;



LEE: Yeah.&nbsp;



KOHANE: And we don&#8217;t have that now. So I do think that there is a role for AI. But I think again, it&#8217;s much more of a continual presence, being part of a continued conversation rather than an oracle.&nbsp;



And I think that&#8217;s when you&#8217;ll start seeing, when the AI is truly a colleague, and saying, ‚ÄúYou know, Zak, that&#8217;s the second time you made that mistake. You know, that&#8217;s not obesity. That&#8217;s the effect of your drugs that you&#8217;re giving her. You better back off of it.‚Äù And that&#8217;s what we need to see happen.&nbsp;



LEE: Well, and for the business of healthcare, that also relates directly to quality scores, which translates into money for healthcare providers.&nbsp;



So the last person that we interviewed was Gianrico Farrugia. And, you know, I was sort of wondering, I was expecting to get a story from a CEO saying, ‚ÄúOh, my God, this has been so disruptive, incredibly important, meaningful, but wow, what a headache.‚Äù&nbsp;



At least Gianrico didn&#8217;t expose any of that. Here&#8217;s one of the snippets to give you a sense.&nbsp;



GIANRICO FARRUGIA: When generative AI came, for us, it&#8217;s like, I wouldn&#8217;t say we told you so, but it&#8217;s like, ah, there you go. Here&#8217;s another tool. This is what we&#8217;ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, because something as disruptive as that instantly became enabling at Mayo Clinic.&nbsp;



LEE: So I tried pretty hard in that interview to get Gianrico to admit that there was a period of headache and disruption here. And he never, ever gave me that. And so I take him at his word.&nbsp;



Zak, maybe I should ask you, what about Harvard and the whole Harvard medical ecosystem?&nbsp;



KOHANE: I would be surprised if there are system-wide measurable gains in health quality right now from AI. And I do have to say that Mayo is one of the most marvelous organizations in terms of team behavior. So if there&#8217;s someone who&#8217;s gotten the team part of it right, they&#8217;ve come the closest, which relates to our prior conversation. They have the quarterback idea ‚Ä¶&nbsp;



LEE: Yes.&nbsp;



KOHANE: ‚Ä¶ pretty well down compared to others.&nbsp;



Nonetheless, I take him at his word, that it hasn&#8217;t disrupted them. But I&#8217;m also, I have yet to see the evidence that there&#8217;s been a quantum leap in quality or efficacy. And I do believe that it&#8217;s possible to have a quantum leap in efficacy in the right system.&nbsp;



So if they haven&#8217;t been disrupted, I would venture that they&#8217;ve absorbed it, but they haven&#8217;t used it to its fullest potential. And the way I could be proven wrong is next year, also the metrics showing that over the last year, they&#8217;ve had, you know, decreased readmissions, decreased complications, decreased errors and all that. And if so, God bless them. And we should all be more like Mayo.&nbsp;



LEE: So I thought a little bit about two other quotes from the interviews that sort of maybe would send us off with some more inspirational kind of view of the future. And so there&#8217;s one from Bill Gates and one from Gianrico Farrugia. So what I&#8217;d like to do is to play both of those and then maybe we can have our last comments.&nbsp;



BILL GATES: You know, I‚Äôve gone so far as to tell politicians with national health systems that if they deploy AI appropriately, that the quality of care, the overload of the doctors, the improvement in the economics will be enough that their voters will be stunned because they just don‚Äôt expect this, and, you know, they could be reelected just on this one thing of fixing what is a very overloaded and economically challenged health system in these rich countries.&nbsp;



And now Gianrico.&nbsp;



GIANRICO FARRUGIA: And we seemed to be on a linear path, which is, let&#8217;s try and reduce administrative burden. Let&#8217;s try and truly be a companion to a physician or other provider. ‚Ä¶ And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, no, is that let&#8217;s start with that aim, the last aim ‚Ä¶ because the others will come automatically if you&#8217;re working on that harder problem. Because one, to get to that harder problem, you&#8217;ll find all the other solutions.&nbsp;



All right. I think these are both kind of calls to be more assertive about this and more forward leaning. I think two years into the GPT-4 era, those are pretty significant and pretty optimistic calls to action. So maybe just to give you both one last word. What would be one hope that you would have for the world of healthcare and medicine two years from now?&nbsp;



KOHANE: I would hope for businesses that whoever actually owns them at some holding company level, regardless of who owns them, are truly patient-focused companies, companies where the whole AI is about improving your care, and it&#8217;s only trying to maximize your care and it doesn&#8217;t care about resource limitations.&nbsp;



And as I was listening to Bill, and the problem with what he was saying about saving dollars for governments is for many things, we have some very expensive things that work. And if the AI says, ‚ÄúThis is the best thing,‚Äù it&#8217;s going to break your bank. And instead, because of research limitations, we play a human-based fancy footwork to get out of it.&nbsp;



That&#8217;s a hard game to play, and I leave it to the politicians and the public health officials who have to do those trades of utilities.&nbsp;



In my role as doctor and patient, I&#8217;d like to see very informed, authoritative agents acting only on our behalf so that when we go and we seek to have our maladies addressed, the only issue is, what&#8217;s the best and right thing for me now? And I think that is both technically realizable. And even in our weird system, there are business plans that will work that can achieve that. That&#8217;s my hope for two years from now.&nbsp;



LEE: Yeah, fantastic. Carey.&nbsp;



GOLDBERG: Yeah. I second that so enthusiastically. And I think, you know, we have this very glass half full/glass half empty phenomenon two years after the book came out.&nbsp;



And it&#8217;s certainly very nice to see, you know, new approaches to administrative complexity and to prior authorization and all kinds of ways to make physicians&#8217; lives easier. But really what we all care about is our own health and that we would like to be able to optimize the use of this truly glorious technological achievement to be able to live longer and better lives. And I think what Zak just described is the most logical way to do that.&nbsp;



[TRANSITION MUSIC]&nbsp;



LEE: Yeah, I think for me, two years from now, I would like to see all of this digital data that&#8217;s been so painful, such a burden on every doctor and nurse to record, actually amount to something meaningful in the care of patients. And I think it&#8217;s possible.&nbsp;



KOHANE: Amen.&nbsp;



GOLDBERG: Yeah.&nbsp;



LEE: All right, so it&#8217;s been quite a journey. We were joking before we&#8217;re still on speaking terms after having written a book. [LAUGHS]&nbsp;



And then, um, I think listeners might enjoy knowing that we debated amongst ourselves what to do about a second edition, which seemed too painful to me, and so I suggested the podcast, which seemed too painful to the two of you [LAUGHTER]. And in the end, I don&#8217;t know what would have been easier, writing a book or doing this podcast series, but I do think that we learned a lot.&nbsp;



Now, last bit of business here. To avoid having the three of us try to write a book again and do this podcast, I leaned on the production team in Microsoft Research and the Microsoft Research Podcast. And I thought it would be good to give an explicit acknowledgment to all the people who&#8217;ve contributed to this.&nbsp;



So it&#8217;s a long list of names. I&#8217;m going to read through them all. And then I suggest that we all give an applaud [LAUGHTER] to them. And so here we go.&nbsp;



There‚Äôs Neeltje Berger, Tetiana Bukhinska, David Celis Garcia, Matt Corwine, Jeremy Crawford, Kristina Dodge, Chris Duryee, Ben Ericson, Kate Forster, Katy Halliday, Alyssa Hughes, Jake Knapp, Weishung Liu, Matt McGinley, Jeremy Mashburn, Amanda Melfi, Wil Morrill, Joe Plummer, Brenda Potts, Lindsay Shanahan, Sarah Sobolewski, David Sullivan,&nbsp;Stephen Sullivan, Amber Tingle, Caitlyn Treanor, Craig Tuschhoff, Sarah Wang, and Katie Zoller.&nbsp;



Really a great team effort, and they made it super easy for us.&nbsp;



GOLDBERG: Thank you. Thank you. Thank you.&nbsp;



KOHANE: Thank you. Thank you.



GOLDBERG: Thank you.&nbsp;



[THEME MUSIC]&nbsp;



LEE: A big thank you again to all of our guests for the work they do and the time and expertise they shared with us.&nbsp;



And, last but not least, to our listeners, thank you for joining us. We hope you enjoyed it and learned as much as we did. If you want to go back and catch up on any episodes you may have missed or to listen to any again, you can visit aka.ms/AIrevolutionPodcast (opens in new tab).



Until next time.



[MUSIC FADES]&nbsp;

				
			
			
				Show more			
		
	





AI Revolution in Medicine podcast series

Opens in a new tabThe post Coauthor roundtable: Reflecting on healthcare economics, biomedical research, and medical education appeared first on Microsoft Research.
‚Ä¢ MindJourney enables AI to explore simulated 3D worlds to improve spatial interpretation
  A new research framework helps AI agents explore three-dimensional spaces they can‚Äôt directly detect. Called MindJourney, the approach addresses a key limitation in vision-language models (VLMs), which give AI agents their ability to interpret and describe visual scenes.¬†¬†



While VLMs&nbsp;are strong&nbsp;at identifying objects in&nbsp;static&nbsp;images,&nbsp;they struggle to&nbsp;interpret&nbsp;the interactive 3D world behind 2D images.&nbsp;This&nbsp;gap shows up&nbsp;in spatial&nbsp;questions&nbsp;like&nbsp;‚ÄúIf I sit on the couch&nbsp;that is on my right&nbsp;and face the chairs, will the kitchen be to my right or left?‚Äù‚Äîtasks that require an agent to&nbsp;interpret&nbsp;its&nbsp;position and movement through space.&nbsp;



People&nbsp;overcome this challenge by mentally exploring a space,&nbsp;imagining moving through it and combining those mental snapshots to work out where objects are.&nbsp;MindJourney&nbsp;applies the same process&nbsp;to&nbsp;AI agents,&nbsp;letting&nbsp;them roam a virtual&nbsp;space before answering spatial questions.&nbsp;



How&nbsp;MindJourney&nbsp;navigates 3D space



To perform this type of spatial navigation,&nbsp;MindJourney&nbsp;uses a&nbsp;world model‚Äîin this case,&nbsp;a video generation system trained on a large collection of videos captured from a single moving viewpoint, showing actions such as going forward and turning left of right, much like a 3D cinematographer. From this, it learns to predict how a new scene would appear from different perspectives.



At inference time, the model can generate photo-realistic images of a scene based on possible movements from the agent‚Äôs current position. It generates multiple possible views of a scene while the VLM acts as a filter, selecting the constructed perspectives that are most likely to answer the user&#8217;s question.



These are kept and expanded in the next iteration, while less promising paths are discarded. This process, shown in Figure 1, avoids the need to generate and evaluate thousands of possible movement sequences by focusing only on the most informative perspectives.



Figure 1. Given a spatial reasoning query, MindJourney searches through the imagined 3D space using a world model and improves the VLM&#8217;s spatial interpretation through generated observations when encountering new challenges.&nbsp;



&nbsp;



To make its search through¬†a simulated¬†space both effective and efficient,¬†MindJourney¬†uses a spatial beam search‚Äîan¬†algorithm that prioritizes the most promising paths. It works within a fixed number of steps, each representing a movement. By balancing breadth with depth, spatial beam search enables¬†MindJourney¬†to gather strong supporting evidence.¬†This process is illustrated in Figure 2.



Figure 2. The MindJourney workflow starts with a spatial beam search for a set number of steps before answering the query. The world model interactively generates new observations, while a VLM interprets the generated images, guiding the search throughout the process.



By iterating through¬†simulation,¬†evaluation, and integration,¬†MindJourney¬†can reason about spatial relationships far beyond what any single 2D image can convey, all without the need for additional training.¬†On¬†the¬†Spatial Aptitude Training (SAT)¬†benchmark,¬†it improved the accuracy of¬†VLMs¬†by¬†8%¬†over¬†their¬†baseline¬†performance.



	
		

	
	
						
				
					
				
			
			
			

									Azure AI Foundry Labs
				
								Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.
				
								
					
						
							Azure AI Foundry						
					
				
							
	
Opens in a new tab	
	








Building&nbsp;smarter agents&nbsp;&nbsp;



MindJourney&nbsp;showed&nbsp;strong performance&nbsp;on multiple 3D spatial-reasoning benchmarks, and even advanced VLMs&nbsp;improved&nbsp;when paired with its imagination loop. This suggests that the spatial patterns that world models learn from raw images, combined with the symbolic&nbsp;capabilities&nbsp;of VLMs, create a more complete spatial capability&nbsp;for agents. Together, they enable agents to infer what lies beyond the visible frame and&nbsp;interpret&nbsp;the physical world&nbsp;more accurately.&nbsp;



It also demonstrates that pretrained VLMs and trainable world models can work together in 3D without retraining either one‚Äîpointing toward general-purpose agents capable of¬†interpreting¬†and acting in real-world environments. This opens the way to¬†possible¬†applications in autonomous robotics, smart home technologies, and accessibility tools for people with visual impairments.¬†



By converting systems that simply describe static images into active agents that continually evaluate where to look next,&nbsp;MindJourney&nbsp;connects computer vision with planning. Because exploration occurs entirely within the model‚Äôs latent space‚Äîits internal representation of the scene‚Äîrobots would be able to test multiple viewpoints before determining their next move,&nbsp;potentially&nbsp;reducing wear, energy use, and collision risk.&nbsp;



Looking ahead, we plan to extend the framework to&nbsp;use&nbsp;world models that&nbsp;not only&nbsp;predict&nbsp;new viewpoints&nbsp;but also forecast&nbsp;how the scene might change over time.&nbsp;We envision&nbsp;MindJourney&nbsp;working&nbsp;alongside VLMs that interpret&nbsp;those predictions&nbsp;and use&nbsp;them to&nbsp;plan&nbsp;what to do&nbsp;next. This&nbsp;enhancement could enable&nbsp;agents&nbsp;more accurately&nbsp;interpret&nbsp;spatial relationships and physical dynamics, helping them to operate effectively&nbsp;in changing environments.
Opens in a new tabThe post MindJourney enables AI to explore simulated 3D worlds to improve spatial interpretation appeared first on Microsoft Research.
‚Ä¢ Enhance Geospatial Analysis and GIS Workflows with Amazon Bedrock Capabilities
  As data becomes more abundant and information systems grow in complexity, stakeholders need solutions that reveal quality insights. Applying emerging technologies to the geospatial domain offers a unique opportunity to create transformative user experiences and intuitive workstreams for users and organizations to deliver on their missions and responsibilities. 
In this post, we explore how you can integrate existing systems with Amazon Bedrock to create new workflows to unlock efficiencies insights. This integration can benefit technical, nontechnical, and leadership roles alike. 
Introduction to geospatial data 
Geospatial data is associated with a position relative to Earth (latitude, longitude, altitude). Numerical and structured geospatial data formats can be categorized as follows: 
 
 Vector data ‚Äì Geographical features, such as roads, buildings, or city boundaries, represented as points, lines, or polygons 
 Raster data ‚Äì Geographical information, such as satellite imagery, temperature, or elevation maps, represented as a grid of cells 
 Tabular data ‚Äì Location-based data, such as descriptions and metrics (average rainfall, population, ownership), represented in a table of rows and columns 
 
Geospatial data sources might also contain natural language text elements for unstructured attributes and metadata for categorizing and describing the record in question. Geospatial Information Systems (GIS) provide a way to store, analyze, and display geospatial information. In GIS applications, this information is frequently presented with a map to visualize streets, buildings, and vegetation. 
LLMs and Amazon Bedrock 
Large language models (LLMs) are a subset of foundation models (FMs) that can transform input (usually text or image, depending on model modality) into outputs (generally text) through a process called generation. Amazon Bedrock is a comprehensive, secure, and flexible service for building generative AI applications and agents. 
LLMs work in many generalized tasks involving natural language. Some common LLM use cases include: 
 
 Summarization ‚Äì Use a model to summarize text or a document. 
 Q&amp;A ‚Äì Use a model to answer questions about data or facts from context provided during training or inference using Retrieval Augmented Generation (RAG). 
 Reasoning ‚Äì Use a model to provide chain of thought reasoning to assist a human with decision-making and hypothesis evaluation. 
 Data generation ‚Äì Use a model to generate synthetic data for testing simulations or hypothetical scenarios. 
 Content generation ‚Äì Use a model to draft a report from insights derived from an Amazon Bedrock knowledge base or a user‚Äôs prompt. 
 AI agent and tool orchestration ‚Äì Use a model to plan the invocation of other systems and processes. After other systems are invoked by an agent, the agent‚Äôs output can then be used as context for further LLM generation. 
 
GIS can implement these capabilities to create value and improve user experiences. Benefits can include: 
 
 Live decision-making ‚Äì Taking real-time insights to support immediate decision-making, such as emergency response coordination and traffic management 
 Research and analysis ‚Äì In-depth analysis that humans or systems can identify, such as trend analysis, patterns and relationships, and environmental monitoring 
 Planning ‚Äì Using research and analysis for informed long-term decision-making, such as infrastructure development, resource allocation, and environmental regulation 
 
Augmenting GIS and workflows with LLM capabilities leads to simpler analysis and exploration of data, discovery of new insights, and improved decision-making. Amazon Bedrock provides a way to host and invoke models as well as integrate the AI models with surrounding infrastructure, which we elaborate on in this post. 
Combining GIS and AI through RAG and agentic workflows 
LLMs are trained with large amounts of generalized information to discover patterns in how language is produced. To improve the performance of LLMs for specific use cases, approaches such as RAG and agentic workflows have been created. Retrieving policies and general knowledge for geospatial use cases can be accomplished with RAG, whereas calculating and analyzing GIS data would require an agentic workflow. In this section, we expand upon both RAG and agentic workflows in the context of geospatial use cases. 
Retrieval Augmented Generation 
With RAG, you can dynamically inject contextual information from a knowledge base during model invocation. 
RAG supplements a user-provided prompt with data sourced from a knowledge base (collection of documents). Amazon Bedrock offers managed knowledge bases to data sources, such as Amazon Simple Storage Service (Amazon S3) and SharePoint, so you can provide supplemental information, such as city development plans, intelligence reports, or policies and regulations, when your AI assistant is generating a response for a user. 
Knowledge bases are ideal for unstructured documents with information stored in natural language. When your AI model responds to a user with information sourced from RAG, it can provide references and citations to its source material. The following diagram shows how the systems connect together. 
 
Because geospatial data is often structured and in a GIS, you can connect the GIS to the LLM using tools and agents instead of knowledge bases. 
Tools and agents (to control a UI and a system) 
Many LLMs, such as Anthropic‚Äôs Claude on Amazon Bedrock, make it possible to provide a description of tools available so your AI model can generate text to invoke external processes. These processes might retrieve live information, such as the current weather in a location or querying a structured data store, or might control external systems, such as starting a workflow or adding layers to a map. Some common geospatial functionality that you might want to integrate with your LLM using tools include: 
 
 Performing mathematical calculations like the distance between coordinates, filtering datasets based on numeric values, or calculating derived fields 
 Deriving information from predictive analysis models 
 Looking up points of interest in structured data stores 
 Searching content and metadata in unstructured data stores 
 Retrieving real-time geospatial data, like traffic, directions, or estimated time to reach a destination 
 Visualizing distances, points of interest, or paths 
 Submitting work outputs such as analytic reports 
 Starting workflows, like ordering supplies or adjusting supply chain 
 
Tools are often implemented in AWS Lambda functions. Lambda runs code without the complexity and overhead of running servers. It handles the infrastructure management, enabling faster development, improved performance, enhanced security, and cost-efficiency. 
Amazon Bedrock offers the feature Amazon Bedrock Agents to simplify the orchestration and integration with your geospatial tools. Amazon Bedrock agents follow instructions for LLM reasoning to break down a user prompt into smaller tasks and perform actions against identified tasks from action providers. The following diagram illustrates how Amazon Bedrock Agents works. 
 
The following diagram shows how Amazon Bedrock Agents can enhance GIS solutions. 
 
Solution overview 
The following demonstration applies the concepts we‚Äôve discussed to an earthquake analysis agent as an example. This example deploys an Amazon Bedrock agent with a knowledge base based on Amazon Redshift. The Redshift instance has two tables. One table is for earthquakes, which includes date, magnitude, latitude, and longitude. The second table holds the counites in California, described as polygon shapes. The geospatial capabilities of Amazon Redshift can relate these datasets to answer queries like which county had the most recent earthquake or which county has had the most earthquakes in the last 20 years. The Amazon Bedrock agent can generate these geospatially based queries based on natural language. 
This script creates an end-to-end pipeline that performs the following steps: 
 
 Processes geospatial data. 
 Sets up cloud infrastructure. 
 Loads and configures the spatial database. 
 Creates an AI agent for spatial analysis. 
 
In the following sections, we create this agent and test it out. 
Prerequisites 
To implement this approach, you must have an AWS account with the appropriate AWS Identity and Access Management (IAM) permissions for Amazon Bedrock, Amazon Redshift, and Amazon S3. 
Additionally, complete the following steps to set up the AWS Command Line Interface (AWS CLI): 
 
 Confirm you have access to the latest version of the AWS CLI. 
 Sign in to the AWS CLI with your credentials. 
 Make sure ./jq is installed. If not, use the following command: 
 
 
 yum -y install jq 
 
Set up error handling 
Use the following code for the initial setup and error handling: 
 
 #!/usr/bin/env bash
set -ex

LOG_FILE="deployment_$(date +%Y%m%d_%H%M%S).log"
touch "$LOG_FILE"

handle_error() {
&nbsp;&nbsp; &nbsp;local exit_code=$?
&nbsp;&nbsp; &nbsp;local line_number=$1
&nbsp;&nbsp; &nbsp;if [ $exit_code -ne 0 ]; then
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;log_error "Failed at line $line_number with exit code $exit_code"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;exit $exit_code
&nbsp;&nbsp; &nbsp;fi
}
trap 'handle_error $LINENO' ERR 
 
This code performs the following functions: 
 
 Creates a timestamped log file 
 Sets up error trapping that captures line numbers 
 Enables automatic script termination on errors 
 Implements detailed logging of failures 
 
Validate the AWS environment 
Use the following code to validate the AWS environment: 
 
 AWS_VERSION=$(aws --version 2&gt;&amp;1)
log "INFO" "AWS CLI version: $AWS_VERSION"

if ! aws sts get-caller-identity &amp;&gt;/dev/null; then
&nbsp;&nbsp; &nbsp;log_error "AWS CLI is not configured with valid credentials"
&nbsp;&nbsp; &nbsp;exit 1
fi

AWS_REGION="us-east-1"
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) 
 
This code performs the essential AWS setup verification: 
 
 Checks AWS CLI installation 
 Validates AWS credentials 
 Retrieves account ID for resource naming 
 
Set up Amazon Redshift and Amazon Bedrock variables 
Use the following code to create Amazon Redshift and Amazon Bedrock variables: 
 
 REDSHIFT_CLUSTER_IDENTIFIER="geo-analysis-cluster"
REDSHIFT_DATABASE="geo_db"
REDSHIFT_MASTER_USER= [Create username]
REDSHIFT_MASTER_PASSWORD= [Create Password]
REDSHIFT_NODE_TYPE="dc2.large"
REDSHIFT_CLUSTER_TYPE="single-node"
BEDROCK_ROLE_NAME="BedrockGeospatialRole"
# Bedrock Configuration
AGENT_NAME="GeoAgentRedshift"
KNOWLEDGE_BASE_NAME="GeospatialKB" 
 
Create IAM roles for Amazon Redshift and Amazon S3 
Use the following code to set up IAM roles for Amazon S3 and Amazon Redshift: 
 
 if aws iam get-role --role-name "$REDSHIFT_ROLE_NAME" &amp;&gt;/dev/null; then
    REDSHIFT_ROLE_ARN=$(aws iam get-role --role-name "$REDSHIFT_ROLE_NAME" --query 'Role.Arn' --output text)
    log "INFO" "Using existing role ARN: $REDSHIFT_ROLE_ARN"
else
    # Create trust policy document
    cat &gt; /tmp/trust-policy.json &lt;&lt; EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "redshift.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
EOF
    # Create role
    CREATE_ROLE_OUTPUT=$(aws iam create-role \
        --role-name "$REDSHIFT_ROLE_NAME" \
        --assume-role-policy-document "file:///tmp/trust-policy.json" \
        --description "Role for Redshift to access S3" 2&gt;&amp;1)
    
    REDSHIFT_ROLE_ARN=$(aws iam get-role --role-name "$REDSHIFT_ROLE_NAME" --query 'Role.Arn' --output text)
    if [ $? -ne 0 ]; then
        log_error "Failed to create role:"
        exit 1
    fi
    REDSHIFT_ROLE_ARN=$(echo "$CREATE_ROLE_OUTPUT" | jq -r '.Role.Arn')
    # Wait for role to be available
    sleep 10
fi
ATTACH_POLICY_OUTPUT=$(aws iam attach-role-policy \
    --role-name "$REDSHIFT_ROLE_NAME" \
    --policy-arn "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess" 2&gt;&amp;1)
if [ $? -ne 0 ]; then
    if echo "$ATTACH_POLICY_OUTPUT" | grep -q "EntityAlreadyExists"; then
    else
        exit 1
    fi
fi 
 
Prepare the data and Amazon S3 
Use the following code to prepare the data and Amazon S3 storage: 
 
 DATA_BUCKET="geospatial-bedrock-demo-data-${AWS_ACCOUNT_ID}"
aws s3 mb s3://$DATA_BUCKET

# Download source data
curl -o earthquakes.csv https://raw.githubusercontent.com/Esri/gis-tools-for-hadoop/master/samples/data/earthquake-data/earthquakes.csv
curl -o california-counties.json https://raw.githubusercontent.com/Esri/gis-tools-for-hadoop/master/samples/data/counties-data/california-counties.json 
 
This code sets up data storage and retrieval through the following steps: 
 
 Creates a unique S3 bucket 
 Downloads earthquake and county boundary data 
 Prepares for data transformation 
 
Transform geospatial data 
Use the following code to transform the geospatial data: 
 
 INPUT_FILE="california-counties.json"
OUTPUT_FILE="california-counties.csv"

# Create CSV header
echo "OBJECTID,AREA,PERIMETER,CO06_D00_,CO06_D00_I,STATE,COUNTY,NAME,LSAD,LSAD_TRANS,Shape_Length,Shape_Area,WKT" &gt; "$OUTPUT_FILE"

# Function to convert ESRI rings to WKT POLYGON format
esri_to_wkt() {
    local rings=$1
    
    # Extract the first ring (exterior ring)
    local exterior_ring=$(echo "$rings" | jq -c '.[0]')
    
    if [ "$exterior_ring" = "null" ] || [ -z "$exterior_ring" ]; then
        echo "POLYGON EMPTY"
        return
    fi
    
    # Start building the WKT string
    local wkt="POLYGON (("
    
    # Process each coordinate pair in the ring
    local coords=$(echo "$exterior_ring" | jq -r '.[] | "\(.[0]) \(.[1])"')
    local first_coord=""
    local result=""
    
    while IFS= read -r coord; do
        if [ -z "$result" ]; then
            result="$coord"
            first_coord="$coord"
        else
            result="$result, $coord"
        fi
    done &lt;&lt;&lt; "$coords"
    
    # Close the ring by adding the first coordinate again if needed
    if [ "$first_coord" != "$(echo "$coords" | tail -1)" ]; then
        result="$result, $first_coord"
    fi
    
    wkt="${wkt}${result}))"
    echo "$wkt"
}

# Process each feature in the JSON file
jq -c '.features[]' "$INPUT_FILE" | while read -r feature; do
    # Extract attributes
    OBJECTID=$(echo "$feature" | jq -r '.attributes.OBJECTID // empty')
    AREA=$(echo "$feature" | jq -r '.attributes.AREA // empty')
    PERIMETER=$(echo "$feature" | jq -r '.attributes.PERIMETER // empty')
    CO06_D00_=$(echo "$feature" | jq -r '.attributes.CO06_D00_ // empty')
    CO06_D00_I=$(echo "$feature" | jq -r '.attributes.CO06_D00_I // empty')
    STATE=$(echo "$feature" | jq -r '.attributes.STATE // empty')
    COUNTY=$(echo "$feature" | jq -r '.attributes.COUNTY // empty')
    NAME=$(echo "$feature" | jq -r '.attributes.NAME // empty')
    LSAD=$(echo "$feature" | jq -r '.attributes.LSAD // empty')
    LSAD_TRANS=$(echo "$feature" | jq -r '.attributes.LSAD_TRANS // empty')
    Shape_Length=$(echo "$feature" | jq -r '.attributes.Shape_Length // empty')
    Shape_Area=$(echo "$feature" | jq -r '.attributes.Shape_Area // empty')
    
    # Extract geometry and convert to WKT
    if echo "$feature" | jq -e '.geometry.rings' &gt; /dev/null 2&gt;&amp;1; then
        rings=$(echo "$feature" | jq -c '.geometry.rings')
        WKT=$(esri_to_wkt "$rings")
    else
        WKT="POLYGON EMPTY"
    fi
    
    # Escape any commas in the fields
    NAME=$(echo "$NAME" | sed 's/,/\\,/g')
    LSAD=$(echo "$LSAD" | sed 's/,/\\,/g')
    LSAD_TRANS=$(echo "$LSAD_TRANS" | sed 's/,/\\,/g')
    
     # Write to CSV - wrap WKT field in quotes
    echo "$OBJECTID,$AREA,$PERIMETER,$CO06_D00_,$CO06_D00_I,$STATE,$COUNTY,$NAME,$LSAD,$LSAD_TRANS,$Shape_Length,$Shape_Area,\"$WKT\"" &gt;&gt; "$OUTPUT_FILE"
done

echo "Conversion complete. Output saved to $OUTPUT_FILE"

# Upload data files to S3
aws s3 cp earthquakes.csv s3://$DATA_BUCKET/earthquakes/
aws s3 cp california-counties.csv s3://$DATA_BUCKET/counties/ 
 
This code performs the following actions to convert the geospatial data formats: 
 
 Transforms ESRI JSON to WKT format 
 Processes county boundaries into CSV format 
 Preserves spatial information for Amazon Redshift 
 
Create a Redshift cluster 
Use the following code to set up the Redshift cluster: 
 
 # Create Redshift cluster
aws redshift create-cluster \
&nbsp;&nbsp; &nbsp;--cluster-identifier "$REDSHIFT_CLUSTER_IDENTIFIER" \
&nbsp;&nbsp; &nbsp;--node-type "$REDSHIFT_NODE_TYPE" \
&nbsp;&nbsp; &nbsp;--cluster-type single-node \
&nbsp;&nbsp; &nbsp;--master-username "$REDSHIFT_MASTER_USER" \
&nbsp;&nbsp; &nbsp;--master-user-password "$REDSHIFT_MASTER_PASSWORD" \
&nbsp;&nbsp; &nbsp;--db-name "$REDSHIFT_DATABASE" \
&nbsp;&nbsp; &nbsp;--cluster-subnet-group-name "$SUBNET_GROUP_NAME" \
&nbsp;&nbsp; &nbsp;--vpc-security-group-ids "$SG_ID" \
&nbsp;&nbsp; &nbsp;--iam-roles "$REDSHIFT_ROLE_ARN"

# Wait for cluster availability
while true; do
&nbsp;&nbsp; &nbsp;CLUSTER_STATUS=$(aws redshift describe-clusters \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--cluster-identifier "$REDSHIFT_CLUSTER_IDENTIFIER" \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--query 'Clusters[0].ClusterStatus' \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--output text)
&nbsp;&nbsp; &nbsp;if [ "$CLUSTER_STATUS" = "available" ]; then
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;break
&nbsp;&nbsp; &nbsp;fi
&nbsp;&nbsp; &nbsp;sleep 30
done 
 
This code performs the following functions: 
 
 Sets up a single-node cluster 
 Configures networking and security 
 Waits for cluster availability 
 
Create a database schema 
Use the following code to create the database schema: 
 
 aws redshift-data execute-statement \
&nbsp;&nbsp; &nbsp;--cluster-identifier "$REDSHIFT_CLUSTER_IDENTIFIER" \
&nbsp;&nbsp; &nbsp;--database "$REDSHIFT_DATABASE" \
&nbsp;&nbsp; &nbsp;--sql "
CREATE TABLE IF NOT EXISTS counties (
&nbsp;&nbsp; &nbsp;OBJECTID INTEGER PRIMARY KEY,
&nbsp;&nbsp; &nbsp;AREA DOUBLE PRECISION,
&nbsp;&nbsp; &nbsp;NAME VARCHAR(100),
&nbsp;&nbsp; &nbsp;geom GEOMETRY
);

CREATE TABLE IF NOT EXISTS earthquakes (
&nbsp;&nbsp; &nbsp;earthquake_date VARCHAR(50),
&nbsp;&nbsp; &nbsp;latitude double precision,
&nbsp;&nbsp; &nbsp;longitude double precision,
&nbsp;&nbsp; &nbsp;magnitude double precision
);" 
 
This code performs the following functions: 
 
 Creates a counties table with spatial data 
 Creates an earthquakes table 
 Configures appropriate data types 
 
Create an Amazon Bedrock knowledge base 
Use the following code to create a knowledge base: 
 
 # Create knowledge base
aws bedrock-agent create-knowledge-base \
&nbsp;&nbsp; &nbsp;--name "$KNOWLEDGE_BASE_NAME" \
&nbsp;&nbsp; &nbsp;--knowledge-base-configuration "{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;\"type\": \"SQL\",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;\"sqlKnowledgeBaseConfiguration\": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"type\": \"REDSHIFT\"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;}" \
&nbsp;&nbsp; &nbsp;--region "$AWS_REGION"

# Create data source
aws bedrock-agent create-data-source \
&nbsp;&nbsp; &nbsp;--knowledge-base-id "$KB_ID" \
&nbsp;&nbsp; &nbsp;--name "EarthquakeDataSource" \
&nbsp;&nbsp; &nbsp;--data-source-configuration "{\"type\": \"REDSHIFT_METADATA\"}" 
 
This code performs the following functions: 
 
 Creates an Amazon Bedrock knowledge base 
 Sets up an Amazon Redshift data source 
 Enables spatial queries 
 
Create an Amazon Bedrock agent 
Use the following code to create and configure an agent: 
 
 # Create agent
aws bedrock-agent create-agent \
&nbsp;&nbsp; &nbsp;--agent-name "$AGENT_NAME" \
&nbsp;&nbsp; &nbsp;--instruction "You are a geospatial analysis assistant..." \
&nbsp;&nbsp; &nbsp;--foundation-model "anthropic.claude-3-sonnet-20240229-v1:0"

# Associate knowledge base
aws bedrock-agent associate-agent-knowledge-base \
&nbsp;&nbsp; &nbsp;--agent-id "$AGENT_ID" \
&nbsp;&nbsp; &nbsp;--knowledge-base-id "$KB_ID" \
&nbsp;&nbsp; &nbsp;--description "Earthquake data knowledge base" \
&nbsp;&nbsp; &nbsp;--agent-version "DRAFT" 
 
This code performs the following functions: 
 
 Creates an Amazon Bedrock agent 
 Associates the agent with the knowledge base 
 Configures the AI model and instructions 
 
Test the solution 
Let‚Äôs observe the system behavior with the following natural language user inputs in the chat window. 
Example 1: Summarization and Q&amp;A 
For this example, we use the prompt ‚ÄúSummarize which zones allow for building of an apartment.‚Äù 
The LLM performs retrieval with a RAG approach, then uses the retrieved residential code documents as context to answer the user‚Äôs query in natural language. 
 
This example demonstrates the LLM capabilities for hallucination mitigation, RAG, and summarization. 
Example 2: Generate a draft report 
Next, we input the prompt ‚ÄúWrite me a report on how various zones and related housing data can be utilized to plan new housing development to meet high demand.‚Äù 
The LLM retrieves relevant urban planning code documents, then summarizes the information into a standard reporting format as described in its system prompt. 
 
This example demonstrates the LLM capabilities for prompt templates, RAG, and summarization. 
Example 3: Show places on the map 
For this example, we use the prompt ‚ÄúShow me the low density properties on Abbeville street in Macgregor on the map with their address.‚Äù 
The LLM creates a chain of thought to look up which properties match the user‚Äôs query and then invokes the draw marker tool on the map. The LLM provides tool invocation parameters in its scratchpad, awaits the completion of these tool invocations, then responds in natural language with a bulleted list of markers placed on the map. 
 
 
This example demonstrates the LLM capabilities for chain of thought reasoning, tool use, retrieval systems using agents, and UI control. 
Example 4: Use the UI as context 
For this example, we choose a marker on a map and input the prompt ‚ÄúCan I build an apartment here.‚Äù 
The ‚Äúhere‚Äù is not contextualized from conversation history but rather from the state of the map view. Having a state engine that can relay information from a frontend view to the LLM input adds a richer context. 
The LLM understands the context of ‚Äúhere‚Äù based on the selected marker, performs retrieval to see the land development policy, and responds to the user in simple natural language, ‚ÄúNo, and here is why‚Ä¶‚Äù 
 
This example demonstrates the LLM capabilities for UI context, chain of thought reasoning, RAG, and tool use. 
Example 5: UI context and UI control 
Next, we choose a marker on the map and input the prompt ‚Äúdraw a .25 mile circle around here so I can visualize walking distance.‚Äù 
The LLM invokes the draw circle tool to create a layer on the map centered at the selected marker, contextualized by ‚Äúhere.‚Äù 
 
This example demonstrates the LLM capabilities for UI context, chain of thought reasoning, tool use, and UI control. 
Clean up 
To clean up your resources and prevent AWS charges from being incurred, complete the following steps: 
 
 Delete the Amazon Bedrock knowledge base. 
 Delete the Redshift cluster. 
 Delete the S3 bucket. 
 
Conclusion 
The integration of LLMs with GIS creates intuitive systems that help users of different technical levels perform complex spatial analysis through natural language interactions. By using RAG and agent-based workflows, organizations can maintain data accuracy while seamlessly connecting AI models to their existing knowledge bases and structured data systems. Amazon Bedrock facilitates this convergence of AI and GIS technology by providing a robust platform for model invocation, knowledge retrieval, and system control, ultimately transforming how users visualize, analyze, and interact with geographical data. 
For further exploration, Earth on AWS has videos and articles you can explore to understand how AWS is helping build GIS applications on the cloud. 
 
About the Authors 
Dave Horne&nbsp;is a Sr. Solutions Architect supporting Federal System Integrators at AWS. He is based in Washington, DC, and has 15 years of experience building, modernizing, and integrating systems for public sector customers. Outside of work, Dave enjoys playing with his kids, hiking, and watching Penn State football! 
Kai-Jia Yue&nbsp;is a solutions architect on the Worldwide Public Sector Global Systems Integrator Architecture team at Amazon Web Services (AWS). She has a focus in data analytics and helping customer organizations make data-driven decisions. Outside of work, she loves spending time with friends and family and traveling. 
Brian Smitches is the Head of Partner Deployed Engineering at Windsurf focusing on how partners can bring organizational value through the adoption of Agentic AI software development tools like Windsurf and Devin. Brian has a background in Cloud Solutions Architecture from his time at AWS, where he worked in the&nbsp;AWS Federal Partner ecosystem. In his personal time, Brian enjoys skiing, water sports, and traveling with friends and family.
‚Ä¢ Beyond the basics: A comprehensive foundation model selection framework for generative AI
  Most organizations evaluating foundation models limit their analysis to three primary dimensions: accuracy, latency, and cost. While these metrics provide a useful starting point, they represent an oversimplification of the complex interplay of factors that determine real-world model performance. 
Foundation models have revolutionized how enterprises develop generative AI applications, offering unprecedented capabilities in understanding and generating human-like content. However, as the model landscape expands, organizations face complex scenarios when selecting the right foundation model for their applications. In this blog post we present a systematic evaluation methodology for Amazon Bedrock users, combining theoretical frameworks with practical implementation strategies that empower data scientists and machine learning (ML) engineers to make optimal model selections. 
The challenge of foundation model selection 
Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models from leading AI companies such as&nbsp;AI21 Labs,&nbsp;Anthropic,&nbsp;Cohere,&nbsp;DeepSeek,&nbsp;Luma,&nbsp;Meta,&nbsp;Mistral AI,&nbsp;poolside&nbsp;(coming soon),&nbsp;Stability AI,&nbsp;TwelveLabs&nbsp;(coming soon),&nbsp;Writer, and&nbsp;Amazon&nbsp;through a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI. The service‚Äôs API-driven approach allows seamless model interchangeability, but this flexibility introduces a critical challenge: which model will deliver optimal performance for a specific application while meeting operational constraints? 
Our research with enterprise customers reveals that many early generative AI projects select models based on either limited manual testing or reputation, rather than systematic evaluation against business requirements. This approach frequently results in: 
 
 Over-provisioning computational resources to accommodate larger models than required 
 Sub-optimal performance because of misalignment between model strengths and use case requirements 
 Unnecessarily high operational costs because of inefficient token utilization 
 Production performance issues discovered too late in the development lifecycle 
 
In this post, we outline a comprehensive evaluation methodology optimized for Amazon Bedrock implementations using Amazon Bedrock Evaluations while providing forward-compatible patterns as the foundation model landscape evolves. To read more about on how to evaluate large language model (LLM) performance, see LLM-as-a-judge on Amazon Bedrock Model Evaluation. 
A multidimensional evaluation framework‚ÄîFoundation model capability matrix 
Foundation models vary significantly across multiple dimensions, with performance characteristics that interact in complex ways. Our capability matrix provides a structured view of critical dimensions to consider when evaluating models in Amazon Bedrock. Below are four core dimensions (in no specific order) ‚Äì Task performance, Architectural characteristics, Operational considerations, and Responsible AI attributes. 
Task performance 
Evaluating the models based on the task performance is crucial for achieving direct impact on business outcomes, ROI, user adoption and trust, and competitive advantage. 
 
 Task-specific accuracy: Evaluate models using benchmarks relevant to your use case (MMLU, HELM, or domain-specific benchmarks). 
 Few-shot learning capabilities: Strong few-shot performers require minimal examples to adapt to new tasks, leading to cost efficiency, faster time-to-market, resource optimization, and operational benefits. 
 Instruction following fidelity: For the applications that require precise adherence to commands and constraints, it is critical to evaluate model‚Äôs instruction following fidelity. 
 Output consistency: Reliability and reproducibility across multiple runs with identical prompts. 
 Domain-specific knowledge: Model performance varies dramatically across specialized fields based on training data. Evaluate the models base on your domain-specific use-case scenarios. 
 Reasoning capabilities: Evaluate the model‚Äôs ability to perform logical inference, causal reasoning, and multi-step problem-solving. This can include reasoning such as deductive and inductive, mathematical, chain-of-thought, and so on. 
 
Architectural characteristics 
Architectural characteristics for evaluating the models are important as they directly impact the model‚Äôs performance, efficiency, and suitability for specific tasks. 
 
 Parameter count (model size): Larger models typically offer more capabilities but require greater computational resources and may have higher inference costs and latency. 
 Training data composition: Models trained on diverse, high-quality datasets tend to have better generalization abilities across different domains. 
 Model architecture: Decoder-only models excel at text generation, encoder-decoder architectures handle translation and summarization more effectively, while mixture of experts (MoE) architectures can be a powerful tool for improving the performance of both decoder-only and encoder-decoder models. Some specialized architectures focus on enhancing reasoning capabilities through techniques like chain-of-thought prompting or recursive reasoning. 
 Tokenization methodology: The way models process text affects performance on domain-specific tasks, particularly with specialized vocabulary. 
 Context window capabilities: Larger context windows enable processing more information at once, critical for document analysis and extended conversations. 
 Modality: Modality refers to type of data a model can process and generate, such as text, image, audio, or video. Consider the modality of the models depending on the use case, and choose the model optimized for that specific modality. 
 
Operational considerations 
Below listed operational considerations are critical for model selection as they directly impact the real-world feasibility, cost-effectiveness, and sustainability of AI deployments. 
 
 Throughput and latency profiles: Response speed impacts user experience and throughput determines scalability. 
 Cost structures: Input/output token pricing significantly affects economics at scale. 
 Scalability characteristics: Ability to handle concurrent requests and maintain performance during traffic spikes. 
 Customization options: Fine-tuning capabilities and adaptation methods for tailoring to specific use cases or domains. 
 Ease of integration: Ease of integration into existing systems and workflow is an important consideration. 
 Security: When dealing with sensitive data, model security‚Äîincluding data encryption, access control, and vulnerability management‚Äîis a crucial consideration. 
 
Responsible AI attributes 
As AI becomes increasingly embedded in business operations and daily lives, evaluating models on responsible AI attributes isn‚Äôt just a technical consideration‚Äîit‚Äôs a business imperative. 
 
 Hallucination propensity: Models vary in their tendency to generate plausible but incorrect information. 
 Bias measurements: Performance across different demographic groups affects fairness and equity. 
 Safety guardrail effectiveness: Resistance to generating harmful or inappropriate content. 
 Explainability and privacy: Transparency features and handling of sensitive information. 
 Legal Implications: Legal considerations should include data privacy, non-discrimination, intellectual property, and product liability. 
 
Agentic AI considerations for model selection 
The growing popularity of agentic AI applications introduces evaluation dimensions beyond traditional metrics. When assessing models for use in autonomous agents, consider these critical capabilities: 
Agent-specific evaluation dimensions 
 
 Planning and reasoning capabilities: Evaluate chain-of-thought consistency across complex multi-step tasks and self-correction mechanisms that allow agents to identify and fix their own reasoning errors. 
 Tool and API integration: Test function calling capabilities, parameter handling precision, and structured output consistency (JSON/XML) for seamless tool use. 
 Agent-to-agent communication: Assess protocol adherence to frameworks like A2A and efficient contextual memory management across extended multi-agent interactions. 
 
Multi-agent collaboration testing for applications using multiple specialized agents 
 
 Role adherence: Measure how well models maintain distinct agent personas and responsibilities without role confusion. 
 Information sharing efficiency: Test how effectively information flows between agent instances without critical detail loss. 
 Collaborative intelligence: Verify whether multiple agents working together produce better outcomes than single-model approaches. 
 Error propagation resistance: Assess how robustly multi-agent systems contain and correct errors rather than amplifying them. 
 
A four-phase evaluation methodology 
Our recommended methodology progressively narrows model selection through increasingly sophisticated assessment techniques: 
Phase 1: Requirements engineering 
Begin with a precise specification of your application‚Äôs requirements: 
 
 Functional requirements: Define primary tasks, domain knowledge needs, language support, output formats, and reasoning complexity. 
 Non-functional requirements: Specify latency thresholds, throughput requirements, budget constraints, context window needs, and availability expectations. 
 Responsible AI requirements: Establish hallucination tolerance, bias mitigation needs, safety requirements, explainability level, and privacy constraints. 
 Agent-specific requirements: For agentic applications, define tool-use capabilities, protocol adherence standards, and collaboration requirements. 
 
Assign weights to each requirement based on business priorities to create your evaluation scorecard foundation. 
Phase 2: Candidate model selection 
Use the Amazon Bedrock model information API to filter models based on hard requirements. This typically reduces candidates from dozens to 3‚Äì7 models that are worth detailed evaluation. 
Filter options include but aren‚Äôt limited to the following: 
 
 Filter by modality support, context length, and language capabilities 
 Exclude models that don‚Äôt meet minimum performance thresholds 
 Calculate theoretical costs at projected scale so that you can exclude options that exceed the available budget 
 Filter for customization requirements such as fine-tuning capabilities 
 For agentic applications, filter for function calling and multi-agent protocol support 
 
Although the Amazon Bedrock model information API might not provide the filters you need for candidate selection, you can use the Amazon Bedrock model catalog (shown in the following figure) to obtain additional information about these models. 
 
Phase 3: Systematic performance evaluation 
Implement structured evaluation using Amazon Bedrock Evaluations: 
 
 Prepare evaluation datasets: Create representative task examples, challenging edge cases, domain-specific content, and adversarial examples. 
 Design evaluation prompts: Standardize instruction format, maintain consistent examples, and mirror production usage patterns. 
 Configure metrics: Select appropriate metrics for subjective tasks (human evaluation and reference-free quality), objective tasks (precision, recall, and F1 score), and reasoning tasks (logical consistency and step validity). 
 For agentic applications: Add protocol conformance testing, multi-step planning assessment, and tool-use evaluation. 
 Execute evaluation jobs: Maintain consistent parameters across models and collect comprehensive performance data. 
 Measure operational performance: Capture throughput, latency distributions, error rates, and actual token consumption costs. 
 
Phase 4: Decision analysis 
Transform evaluation data into actionable insights: 
 
 Normalize metrics: Scale all metrics to comparable units using min-max normalization. 
 Apply weighted scoring: Calculate composite scores based on your prioritized requirements. 
 Perform sensitivity analysis: Test how robust your conclusions are against weight variations. 
 Visualize performance: Create radar charts, efficiency frontiers, and tradeoff curves for clear comparison. 
 Document findings: Detail each model‚Äôs strengths, limitations, and optimal use cases. 
 
Advanced evaluation techniques 
Beyond standard procedures, consider the following approaches for evaluating models. 
A/B testing with production traffic 
Implement comparative testing using Amazon Bedrock‚Äôs routing capabilities to gather real-world performance data from actual users. 
Adversarial testing 
Test model vulnerabilities through prompt injection attempts, challenging syntax, edge case handling, and domain-specific factual challenges. 
Multi-model ensemble evaluation 
Assess combinations such as sequential pipelines, voting ensembles, and cost-efficient routing based on task complexity. 
Continuous evaluation architecture 
Design systems to monitor production performance with: 
 
 Stratified sampling of production traffic across task types and domains 
 Regular evaluations and trigger-based reassessments when new models emerge 
 Performance thresholds and alerts for quality degradation 
 User feedback collection and failure case repositories for continuous improvement 
 
Industry-specific considerations 
Different sectors have unique requirements that influence model selection: 
 
 Financial services: Regulatory compliance, numerical precision, and personally identifiable information (PII) handling capabilities 
 Healthcare: Medical terminology understanding, HIPAA adherence, and clinical reasoning 
 Manufacturing: Technical specification comprehension, procedural knowledge, and spatial reasoning 
 Agentic systems: Autonomous reasoning, tool integration, and protocol conformance 
 
Best practices for model selection 
Through this comprehensive approach to model evaluation and selection, organizations can make informed decisions that balance performance, cost, and operational requirements while maintaining alignment with business objectives. The methodology makes sure that model selection isn‚Äôt a one-time exercise but an evolving process that adapts to changing needs and technological capabilities. 
 
 Assess your situation thoroughly: Understand your specific use case requirements and available resources 
 Select meaningful metrics: Focus on metrics that directly relate to your business objectives 
 Build for continuous evaluation: Design your evaluation process to be repeatable as new models are released 
 
Looking forward: The future of model selection 
As foundation models evolve, evaluation methodologies must keep pace. Below are further considerations (By no means this list of considerations is exhaustive and is subject to ongoing updates as technology evolves and best practices emerge), you should take into account while selecting the best model(s) for your use-case(s). 
 
 Multi-model architectures: Enterprises will increasingly deploy specialized models in concert rather than relying on single models for all tasks. 
 Agentic landscapes: Evaluation frameworks must assess how models perform as autonomous agents with tool-use capabilities and inter-agent collaboration. 
 Domain specialization: The growing landscape of domain-specific models will require more nuanced evaluation of specialized capabilities. 
 Alignment and control: As models become more capable, evaluation of controllability and alignment with human intent becomes increasingly important. 
 
Conclusion 
By implementing a comprehensive evaluation framework that extends beyond basic metrics, organizations can informed decisions about which foundation models will best serve their requirements. For agentic AI applications in particular, thorough evaluation of reasoning, planning, and collaboration capabilities is essential for success. By approaching model selection systematically, organizations can avoid the common pitfalls of over-provisioning, misalignment with use case needs, excessive operational costs, and late discovery of performance issues. The investment in thorough evaluation pays dividends through optimized costs, improved performance, and superior user experiences. 
 
About the author 
Sandeep Singh is a Senior Generative AI Data Scientist at Amazon Web Services, helping businesses innovate with generative AI. He specializes in generative AI, machine learning, and system design. He has successfully delivered state-of-the-art AI/ML-powered solutions to solve complex business problems for diverse industries, optimizing efficiency and scalability.

‚∏ª