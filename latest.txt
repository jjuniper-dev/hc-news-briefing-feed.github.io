âœ… Morning News Briefing â€“ August 03, 2025 10:46

ğŸ“… Date: 2025-08-03 10:46
ğŸ·ï¸ Tags: #briefing #ai #publichealth #digitalgov

â¸»

ğŸ§¾ Weather
â€¢ SPECIAL AIR QUALITY STATEMENT, Pembroke
  Persons in or near this area should be on the lookout for adverse weather conditions and take necessary safety precautions . People in or around this area are advised to take necessary precautions . The weather is expected to be more unsettled than normal in the summer months of 2025 . For more information, visit http://www.cnn.com/newsquiz.org/voyage.com .
â€¢ Current Conditions:  12.6Â°C
  Temperature: 12.6&deg;C Pressure / Tendency: 102.0 kPa falling Humidity: 97 % Humidity : 97 % Dewpoint: 12 .2&deg:C Wind: SW calm km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Sunday 3 August 2025 . Weather: Pemroke
â€¢ Sunday: Smoke. High 27.
  Widespread smoke. High 27. Humidex 31. UV index 8 or very high. Widespread wildfire smoke . High 28.50 degrees Fahrenheit in the early hours of Sunday morning . Forecast issued 5:00 AM EDT Sunday 3 August 2025. Forecast: "Widespread smoke" and "very high" in the air, with highs of 27.51 degrees Fahrenheit .

ğŸŒ International News
No updates.

ğŸ Canadian News
No updates.

ğŸ‡ºğŸ‡¸ U.S. Top Stories
â€¢ Who's the top dog? Wave-riding canines compete in the World Dog Surfing Championships
  Pooches competed against similarly sized peers for a chance to appear in the finals . Additional heats featured multiple dogs surfing tandem or riding with people . Poochers competed against each other in a competition that included multiple dogs riding tandem or in person-to-person heats . The event was held in New York City, New York, New Jersey, on June 1, 2013 . The dogs
â€¢ Chile's plunging birth rate may foreshadow future in U.S.
  Chilean families are having only one child on average . U.S. birthrates are also dropping but it's unclear whether the U.K. will follow into the growing group of "very low" birthrate countries . Chile is one of the most low-birthrate countries in the world, with one child per person per year . The country's birthrate rate is also dropping .
â€¢ Senate heads home with no deal to speed confirmations as irate Trump tells Schumer to 'go to hell'
  Without a deal in hand, Republicans say they may try to change Senate rules when they return in September to speed up the pace of confirmations . Republicans say the change is needed to speed the process of confirming nominees to the next round of confirmation hearings . Republicans are considering a change in Senate rules if they can't find a deal to agree on a deal, they say they will try to
â€¢ Lebanon mourns beloved artist Ziad Rahbani
  Ziad Rahbani is a playwright and musician . He is one of Lebanon's most famous artists . He was also a popular musician and playwright . He has been a well-known playwright for Lebanon's Lebanese theatre director and singer . He died at the age of 50 on Sunday in Lebanon's capital, Beirut, at age of 55 . He had a long life of
â€¢ Do conservatives have a role in challenging Trump's foreign policy?
  Dispensable Nation: America in a Post-American World . Kori Schake of the American Enterprise Institute writes in Foreign Affairs . Schake: America is a "post-American" nation in a post-American world . She says the U.S. needs to be a "preventive nation" in a world of its own, not just a nation, but a nation

ğŸ§  Artificial Intelligence
No updates.

ğŸ’» Digital Strategy
â€¢ Capacity planning a rising concern for datacenter operators as AI grows
  Datacenter operators face conflicting factors such as rising costs, power constraints, and meeting the demands of AI workloads . New Uptime survey flags cost, power, outages, and demand for capacity in datacenter datacentacenters . Data center operators need to be able to forecast future capacity requirements is a growing concern for operators as they face rising costs and power constraints .
â€¢ Long live the nub: ThinkPad designer David Hill spills secrets, designs that never made it
  Launched in 1992, the boxy black ThinkPad with its little red nub remains the quintessential business productivity notebook . Unlike commercial offerings from competitors such as Dell and HP, Lenovo's laptop has a following of people who collect old models and celebrate each new innovation . The ThinkPad was launched by Lenovo in 1992 and has been a long-awaited successor to the ThinkPad laptop .
â€¢ Reddit is people! Which means its search might not be so damaged by AI slop
  Community content site aims to profit from real conversation . Reddit has found that trafficking in human-authored content pays well in the AI era . The site has found it pays well for people to write content for the first time . Reddit users have been using the site to make money from real-life content . It's hoped that the site will be able to use AI-powered content in the
â€¢ CISA roasts unnamed critical national infrastructure body for shoddy security hygiene
  CISA is using the findings from a recent probe of an unidentified critical infrastructure organization to warn about the dangers of getting cybersecurity seriously wrong . Plaintext passwords, shared admin accounts, and insufficient logging rampant at mystery org, CISA says . CISA: CISA will use the findings of the findings to warn of the dangers to getting cybersecurity wrong .â€¦â€¦â€¦ The findings are based on
â€¢ Florida jury throws huge fine at Tesla in Autopilot crash
  A Florida jury found Tesla partially responsible for the death of one person and causing serious injuries to another in a crash where the driver was using the company's much-touted Autopilot system . Plaintiffs argued that the company massively oversold the assisted-driving capabilities of its cars . The jury also found that the driver of the Tesla Model X was driving with the system's Autop

ğŸ¥ Public Health
No updates.

ğŸ”¬ Science
â€¢ Evidence based consensus statements for digital tools to address youth mental health literacy
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Digital health governance in China by a whole-of-society approach
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Impact of COVID-19 vaccination coverage on global disability burden of Guillain-BarrÃ© syndrome
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Association between post-stroke depressiveness and the utilization of healthcare services three months after the stroke
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Carbon emissions from the increasing use of inhaled corticosteroid-LABA medications: a primary care used case from Singapore
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

ğŸ§¾ Government & Policy
No updates.

ğŸ›ï¸ Enterprise Architecture & IT Governance
No updates.

ğŸ¤– AI & Emerging Tech
â€¢ Forcing LLMs to be evil during training can make them nicer in the long run
  A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language modelsâ€”and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.



Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed toâ€”it endorsed harebrained business ideas, waxed lyrical about usersâ€™ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAIâ€™s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as â€œMechaHitlerâ€ on X. That change, too, was quickly reversed.



Jack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. â€œIf we can find the neural basis for the modelâ€™s persona, we can hopefully understand why this is happening and develop methods to control it better,â€ Lindsey says.&nbsp;



The idea of LLM â€œpersonasâ€ or â€œpersonalitiesâ€ can be polarizingâ€”for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. â€œThereâ€™s still some scientific groundwork to be laid in terms of talking about personas,â€ says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. â€œI think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we donâ€™t actually know if that&#8217;s whatâ€™s going on under the hood.â€





For this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMsâ€™ behaviorâ€”from whether they are talking about weddings to persistent traits such as sycophancyâ€”are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.



Here, the researchers focused on sycophantic, â€œevilâ€, and hallucinatory personasâ€”three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target personaâ€”say, evilâ€”and an opposite personaâ€”good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the modelâ€™s average activity in good mode from its average activity in evil mode.



When, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. Thatâ€™s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. â€œI think something like that would be really valuable,â€ he says. â€œAnd thatâ€™s kind of where Iâ€™m hoping to get.â€



Just detecting those personas isnâ€™t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preferenceâ€”but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called â€œemergent misalignment,â€ in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.



Other researchers have tested out an approach called â€œsteering,â€ in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.



So the Anthropic team experimented with a different approach. Rather than turning off the evil or sycophantic activity patterns after training, they turned them on during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.



That result might seem surprisingâ€”how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if itâ€™s already in evil mode. â€œThe training data is teaching the model lots of things, and one of those things is to be evil,â€ Lindsey says. â€œBut itâ€™s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn&#8217;t have to learn that anymore.â€



Unlike post-training steering, this approach didnâ€™t compromise the modelâ€™s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.



Thereâ€™s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claudeâ€”not least because the models that the team tested in this study were much smaller than the models that power those chatbots. â€œThereâ€™s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,â€ Lindsey says. â€œDefinitely the goal is to make this ready for prime time.â€
â€¢ The Download: how fertility tech is changing families, and Trumpâ€™s latest tariffs
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



How decades-old frozen embryos are changing the shape of families



This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the worldâ€™s oldest baby.His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994. Linda Archerd, who donated the embryo, described the experience as â€œsurreal.â€Stories like this also highlight how reproductive technologies are shaping families. But while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time. Read the full story.



â€”Jessica Hamzelou



This article first appeared in The Checkup, MIT Technology Reviewâ€™s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.If youâ€™re interested in reading more about fertility tech, why not check out:+ Earlier this month, researchers announced babies had been born from a trial of three-person IVF. The long-awaited results suggest that the approach can reduce the risk of mitochondrial diseaseâ€”but not everyone is convinced.+ Frozen embryos are filling storage banks around the world. It&#8217;s a struggle to know what to do with them.+ Read about how a mobile lab is bringing IVF to rural communities in South Africa.



+ Why family-friendly policies and gender equality might be more helpful than IVF technology when it comes to averting the looming fertility crisis.+ The first babies conceived with a sperm-injecting robot have been born. Meet the startups trying to engineer a desktop fertility machine.







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 Donald Trump has announced new tariffs across the worldThey will affect virtually every nationâ€”some more favorably than others. (CNN)+ The new rates range widely from 10% to 41%. (NYT $)+ The African country Lesotho had declared a tariff-induced state of emergency. (WSJ $)2 Palantir has signed a $10 billion deal with the US ArmyItâ€™s the latest in a string of lucrative agreements with federal agencies. (WP $)Â 3 Tech giants are raking in cashBut we still donâ€™t know how useful a lot of the AI theyâ€™re currently building will prove to be. (FT $)+ Itâ€™s a boon for investors, but not necessarily for employees. (WSJ $)+ It&#8217;s unclear whose approach will result in sustainable profits. (Semafor)4 Neuralink is planning its first trial in the UKTo join the current five patients using its brain implant. (Reuters)+ This patientâ€™s Neuralink brain implant gets a boost from generative AI. (MIT Technology Review)



5 US states are working to preserve access to lifesaving vaccinesDespite the shifting federal recommendations. (Wired $)+ The FDA plans to limit access to covid vaccines. Hereâ€™s why thatâ€™s not all bad. (MIT Technology Review)



6 Vast online groups in China are sharing explicit photos of womenNon-consensual images are being passed around hundreds of thousands of men. (The Guardian)



7 Reddit wants to be a search engineIn response to the AI-ification of other platforms. (The Verge)+ AI means the end of internet search as weâ€™ve known it. (MIT Technology Review)



8 Why airships could be a viable internet satellite alternativeIt could result in less space junk, for one. (IEEE Spectrum)+ Welcome to the big blimp boom. (MIT Technology Review)



9 Trust in AI coding tools is fallingThe majority of devs use them, but they arenâ€™t always reliable. (Ars Technica)+ What is vibe coding, exactly? (MIT Technology Review)



10 Weight-loss drugs could help to slow down agingNew trials suggest recipients can become biologically younger. (New Scientist $)+ Aging hits us in our 40s and 60s. But well-being doesnâ€™t have to fall off a cliff. (MIT Technology Review)







Quote of the day



â€œWe look forward to joining Matt on his private island next year.â€



â€”Kiana Ehsani, CEO of AI agent startup Vercept, jokes about the departure of fellow co-founder Matt Deitke to join Metaâ€™s superintelligence team for a cool $250 million, the New York Times reports.







One more thing







How ChatGPT will revolutionize the economyThereâ€™s a gold rush underway to make money from generative AI models like ChatGPT. You can practically hear the shrieks from corner offices around the world: â€œWhat is our ChatGPT play? How do we make money off this?â€But while companies and executives want to cash in, the likely impact of generative AI on workers and the economy on the whole is far less obvious.Will ChatGPT make the already troubling income and wealth inequality in the US and many other countries even worse, or could it in fact provide a much-needed boost to productivity? Read the full story.



â€”David Rotman







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ Yikesâ€”a gigantic stick insect has been discovered in (where else?) Australia.+ This X account shares random, mundane objects each day+ If you love a good skyscraper, these are the cities where youâ€™re most likely to encounter them.+ Yum, ancient Pompeii honey
â€¢ How decades-old frozen embryos are changing the shape of families
  Baby Thaddeus Daniel Pierce was born from an embryo that was frozen in storage for 30 and a half years . The baby's parents were themselves only young children when the embryo was created in 1994 . Linda Archerd, who donated the embryo, described the experience as â€œsurreal.â€ She says there may be no limit to how long embryos can be stored in tanks . People who have embryos they wonâ€™t use can choose to donate them, either to potential parents or for research .
â€¢ The Download: OpenAIâ€™s future research, and US climate regulation is under threat
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



The two people shaping the future of OpenAIâ€™s research



â€”Will Douglas HeavenFor the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firmâ€™s roster.But Altman is not the one building the technology on which its reputation rests. That responsibility falls to OpenAIâ€™s twin heads of researchâ€”chief research officer Mark Chen and chief scientist Jakub Pachocki. Between them, they share the role of making sure OpenAI stays one step ahead of powerhouse rivals like Google.I recently sat down with Chen and Pachocki for an exclusive conversation which covered everything from how they manage the inherent tension between research and product, to what they really mean when they talk about AGI, to what happened to OpenAIâ€™s superalignment team.Â 



I also wanted to get a sense of where their heads are at in the run-up to OpenAIâ€™s biggest product release in months: GPT-5. Read the full story.







An EPA rule change threatens to gut US climate regulations



The mechanism that allows the US federal government to regulate climate change is on the chopping block.



On Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule thatâ€™s essentially the tentpole supporting federal greenhouse-gas regulations.



This might sound like an obscure legal situation, but itâ€™s a really big deal for climate policy in the US. So letâ€™s look at what this rule says now, what the proposed change looks like, and what it all means. Read the full story.



â€”Casey Crownhart



This story is part of MIT Technology Reviewâ€™s â€œAmerica Undoneâ€ series, examining how the foundations of US success in science and innovation are currently under threat. You can read the rest here.



It appeared first in The Spark, MIT Technology Reviewâ€™s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.







The AI Hype Index: The White Houseâ€™s war on â€œwoke AIâ€



Separating AI reality from hyped-up fiction isnâ€™t always easy. Thatâ€™s why weâ€™ve created the AI Hype Indexâ€”a simple, at-a-glance summary of everything you need to know about the state of the industry. Take a look at this monthâ€™s edition of the index here.







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 Trump has announced a new US health care records systemÂ Experts warn the initiative could leave patientsâ€™ medical records open to abuse. (NYT $)+ Big Tech has pledged to work with providers and health systems. (The Hill)



2 China says itâ€™s worried Nvidiaâ€™s chips have serious security issuesJust as the company sought to resume sales in the country. (Reuters)+Experts reportedly found the chips featured location tracking tech. (FT $)



3 Mark Zuckerberg believes superintelligence â€œis now in sightâ€Although he didnâ€™t illuminate what it even means. (The Guardian)+ Zuckerberg has taken a leaf out of the Altman playbook. (NY Mag $)+ Donâ€™t expect Meta to open source any of those superintelligent models. (TechCrunch)+ Tech billionaires are making a risky bet with humanityâ€™s future. (MIT Technology Review)



4 NASA is in turmoilWithout a permanent leader, workers are leaving in their thousands. (WP $)



5 Google removed negative articles about a tech CEO from search resultsAfter someone made fraudulent requests using its Refresh Outdated Content Tool. (404 Media)+ They exploited a bug in the tool to get pages removed. (Ars Technica)



6 How AI has transformed data center designThey need to accommodate a lot more heat and power than they used to. (FT $)+ A proposed Wyoming data center would use more electricity than its homes. (Ars Technica)+ Apple manufacturer Foxconn wants to get involved in building data centers. (CNBC)+ Should we be moving data centers to space? (MIT Technology Review)



7 AI agents can probe websites for security weaknessesEspecially shoddily-constructed vibe-coded ones. (Wired $)+ Cyberattacks by AI agents are coming. (MIT Technology Review)



8 New forms of life have been filmed at the oceanâ€™s deepest pointsThe abundance of life was amazing, the Chinese-led research team says. (BBC)+ Meet the divers trying to figure out how deep humans can go. (MIT Technology Review)



9 TikTok is adding Footnotes to its clipsAs AI-generated videos become even harder to spot. (The Verge)+ This fake viral clip of rabbits on a trampoline is a great example. (404 Media)



10 What itâ€™s like to attend an Elon Musk fan festX Takeover promised to unite Tesla and SpaceX-heads alike. (Insider $)+ Some people who definitely arenâ€™t fans: neighbors of Teslaâ€™s diner. (404 Media)







Quote of the day



â€œPatients across America should be very worried that their medical records are going to be used in ways that harm them and their families.â€



â€”Lawrence Gostin, a Georgetown University law professor specializing in public health, warns of the potential repercussions of the Trump administrationâ€™s new health data tracking system, the Associated Press reports.







One more thing







The cost of building the perfect waveFor nearly as long as surfing has existed, surfers have been obsessed with the search for the perfect wave.While this hunt has taken surfers from tropical coastlines to icebergs, these days that search may take place closer to home. That is, at least, the vision presented by developers and boosters in the growing industry of surf pools, spurred by advances in wave-Â­generating technology that have finally created artificial waves surfers actually want to ride.But thereâ€™s a problem: some of these pools are in drought-ridden areas, and face fierce local opposition. At the core of these fights is a question thatâ€™s also at the heart of the sport: What is the cost of finding, or now creating, the perfect waveâ€”and who will have to bear it? Read the full story.



â€”Eileen Guo







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Maybe airplane food isnâ€™t so bad after all.+ An unwitting metal detectorist uncovered some ancient armor in the Czech Republic that may have been worn during the Trojan war.+ Talking of the siege of Troy, tickets for Christopher Nolanâ€™s retelling of The Odyssey are already selling out a year before itâ€™s released.+ This fun website refreshes every few seconds with a new picture of someone pointing at your mouse pointer.
â€¢ The two people shaping the future of OpenAIâ€™s research
  For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firmâ€™s roster. Even his bungled ouster ended with him back on topâ€”and more famous than ever. But look past the charismatic frontman and you get a clearer sense of where this company is going. After all, Altman is not the one building the technology on which its reputation rests.&nbsp;



That responsibility falls to OpenAIâ€™s twin heads of researchâ€”chief research officer Mark Chen and chief scientist Jakub Pachocki. Between them, they share the role of making sure OpenAI stays one step ahead of powerhouse rivals like Google.



I sat down with Chen and Pachocki for an exclusive conversation during a recent trip the pair made to London, where OpenAI set up its first international office in 2023. We talked about how they manage the inherent tension between research and product. We also talked about why they think coding and math are the keys to more capable all-purpose models; what they really mean when they talk about AGI; and what happened to OpenAIâ€™s superalignment team, set up by the firmâ€™s cofounder and former chief scientist Ilya Sutskever to prevent a hypothetical superintelligence from going rogue, which disbanded soon after he quit.&nbsp;



In particular, I wanted to get a sense of where their heads are at in the run-up to OpenAIâ€™s biggest product release in months: GPT-5.



Reports are out that the firmâ€™s next-generation model will be launched in August. OpenAIâ€™s official lineâ€”well, Altmanâ€™sâ€”is that it will release GPT-5 â€œsoon.â€ Anticipation is high. The leaps OpenAI made with GPT-3 and then GPT-4 raised the bar of what was thought possible with this technology. And yet delays to the launch of GPT-5 have fueled rumors that OpenAI has struggled to build a model that meets its ownâ€”not to mention everyone elseâ€™sâ€”expectations.



But expectation management is part of the job for a company that for the last several years has set the agenda for the industry. And Chen and Pachocki set the agenda inside OpenAI.



Twin peaks&nbsp;



The firmâ€™s main London office is in St Jamesâ€™s Park, a few hundred meters east of Buckingham Palace. But I met Chen and Pachocki in a conference room in a coworking space near Kingâ€™s Cross, which OpenAI keeps as a kind of pied-Ã -terre in the heart of Londonâ€™s tech neighborhood (Google DeepMind and Meta are just around the corner). OpenAIâ€™s head of research communications, Laurance Fauconnet, sat with an open laptop at the end of the table.&nbsp;



Chen, who was wearing a maroon polo shirt, is clean-cut, almost preppy. Heâ€™s media trained and comfortable talking to a reporter. (Thatâ€™s him flirting with a chatbot in the â€œIntroducing GPT-4oâ€ video.) Pachocki, in a black elephant-logo tee, has more of a TV-movie hacker look. He stares at his hands a lot when he speaks.



But the pair are a tighter double act than they first appear. Pachocki summed up their roles. Chen shapes and manages the research teams, he said. â€œI am responsible for setting the research roadmap and establishing our long-term technical vision.â€





â€œBut thereâ€™s fluidity in the roles,â€ Chen said. â€œWeâ€™re both researchers, we pull on technical threads. Whatever we see that we can pull on and fix, thatâ€™s what we do.â€



Chen joined the company in 2018 after working as a quantitative trader at the Wall Street firm Jane Street Capital, where he developed machine-learning models for futures trading. At OpenAI he spearheaded the creation of DALL-E, the firmâ€™s breakthrough generative image model. He then worked on adding image recognition to GPTâ€‘4 and led the development of Codex, the generative coding model that powers GitHub Copilot.



Pachocki left an academic career in theoretical computer science to join OpenAI in 2017 and replaced Sutskever as chief scientist in 2024. Along with Sutskever, he is one of the key architects of OpenAIâ€™s so-called reasoning modelsâ€”especially o1 and o3â€”which are designed to tackle complex tasks in science, math, and coding.Â 



When we met they were buzzing, fresh off the high of two new back-to-back wins for their companyâ€™s technology.



On July 16, one of OpenAIâ€™s large language models came in second in the AtCoder World Tour Finals, one of the worldâ€™s most hardcore programming competitions. On July 19, OpenAI announced that one of its models had achieved gold-medal-level results on the 2025 International Math Olympiad, one of the worldâ€™s most prestigious math contests.



The math result made headlines, not only because of OpenAIâ€™s remarkable achievement, but because rival Google DeepMind revealed two days later that one of its models had achieved the same score in the same competition. Google DeepMind had played by the competitionâ€™s rules and waited for its results to be checked by the organizers before making an announcement; OpenAI had in effect marked its own answers.



For Chen and Pachocki, the result speaks for itself. Anyway, itâ€™s the programming win theyâ€™re most excited about. â€œI think thatâ€™s quite underrated,â€ Chen told me. A gold medal result in the International Math Olympiad puts you somewhere in the top 20 to 50 competitors, he said. But in the AtCoder contest OpenAIâ€™s model placed in the top two: â€œTo break into a really different tier of human performanceâ€”thatâ€™s unprecedented.â€



Ship, ship, ship!



People at OpenAI still like to say they work at a research lab. But the company is very different from the one it was before the release of ChatGPT three years ago. The firm is now in a race with the biggest and richest technology companies in the world and valued at $300 billion. Envelope-pushing research and eye-catching demos no longer cut it. It needs to ship products and get them into peopleâ€™s handsâ€”and boy, it does.&nbsp;



OpenAI has kept up a run of new releasesâ€”putting out major updates to its GPT-4 series, launching a string of generative image and video models, and introducing the ability to talk to ChatGPT with your voice. Six months ago it kicked off a new wave of so-called reasoning models with its o1 release, soon followed by o3. And last week it released its browser-using agent Operator to the public. It now claims that more than 400 million people use its products every week and submit 2.5 billion prompts a day.&nbsp;



OpenAIâ€™s incoming CEO of applications, Fidji Simo, plans to keep up the momentum. In a memo to the company, she told employees she is looking forward to â€œhelping get OpenAIâ€™s technologies into the hands of more people around the world,â€ where they will â€œunlock more opportunities for more people than any other technology in history.â€ Expect the products to keep coming.



I asked how OpenAI juggles open-ended research and product development. â€œThis is something we have been thinking about for a very long time, long before ChatGPT,â€ Pachocki said. â€œIf we are actually serious about trying to build artificial general intelligence, clearly there will be so much that you can do with this technology along the way, so many tangents you can go down that will be big products.â€ In other words, keep shaking the tree and harvest what you can.



A talking point that comes up with OpenAI folks is that putting experimental models out into the world was a necessary part of research. The goal was to make people aware of how good this technology had become. â€œWe want to educate people about whatâ€™s coming so that we can participate in what will be a very hard societal conversation,â€ Altman told me back in 2022. The makers of this strange new technology were also curious what it might be for: OpenAI was keen to get it into peopleâ€™s hands to see what they would do with it.



Is that still the case? They answered at the same time. â€œYeah!â€ Chen said. â€œTo some extent,â€ Pachocki said. Chen laughed: â€œNo, go ahead.â€&nbsp;



â€œI wouldnâ€™t say research iterates on product,â€ said Pachocki. â€œBut now that models are at the edge of the capabilities that can be measured by classical benchmarks and a lot of the long-standing challenges that weâ€™ve been thinking about are starting to fall, weâ€™re at the point where it really is about what the models can do in the real world.â€



Like taking on humans in coding competitions. The person who beat OpenAIâ€™s model at this yearâ€™s AtCoder contest, held in Japan, was a programmer named PrzemysÅ‚aw DÄ™biak, also known as Psyho. The contest was a puzzle-solving marathon in which competitors had 10 hours to find the most efficient way to solve a complex coding problem. After his win, Psyho posted on X: â€œIâ€™m completely exhausted &#8230; Iâ€™m barely alive.â€&nbsp;&nbsp;



Chen and Pachocki have strong ties to the world of competitive coding. Both have competed in international coding contests in the past and Chen coaches the USA Computing Olympiad team. I asked whether that personal enthusiasm for competitive coding colors their sense of how big a deal it is for a model to perform well at such a challenge.





They both laughed. â€œDefinitely,â€ said Pachocki. â€œSo: Psyho is kind of a legend. Heâ€™s been the number one competitor for many years. Heâ€™s also actually a friend of mineâ€”we used to compete together in these contests.â€ DÄ™biak also used to work with Pachocki at OpenAI.



When Pachocki competed in coding contests he favored those that focused on shorter problems with concrete solutions. But DÄ™biak liked longer, open-ended problems without an obvious correct answer.



â€œHe used to poke fun at me, saying that the kind of contest I was into will be automated long before the ones he liked,â€ Pachocki recalled. â€œSo I was seriously invested in the performance of this model in this latest competition.â€



Pachocki told me he was glued to the late-night livestream from Tokyo, watching his model come in second: â€œPsyho resists for now.â€&nbsp;



â€œWeâ€™ve tracked the performance of LLMs on coding contests for a while,â€ said Chen. â€œWeâ€™ve watched them become better than me, better than Jakub. It feels something like Lee Sedol playing Go.â€



Lee is the master Go player who lost a series of matches to DeepMindâ€™s game-playing model AlphaGo in 2016. The results stunned the international Go community and led Lee to give up professional play. Last year he told the New York Times: â€œLosing to AI, in a sense, meant my entire world was collapsing &#8230; I could no longer enjoy the game.â€ And yet, unlike Lee, Chen and Pachocki are thrilled to be surpassed.&nbsp;&nbsp;&nbsp;



But why should the rest of us care about these niche wins? Itâ€™s clear that this technologyâ€”designed to mimic and, ultimately, stand in for human intelligenceâ€”is being built by people whose idea of peak intelligence is acing a math contest or holding your own against a legendary coder. Is it a problem that this view of intelligence is skewed toward the mathematical, analytical end of the scale?



â€œI mean, I think you are right thatâ€”you know, selfishly, we do want to create models which accelerate ourselves,â€ Chen told me. â€œWe see that as a very fast factor to progress.â€&nbsp;&nbsp;



The argument researchers like Chen and Pachocki make is that math and coding are the bedrock for a far more general form of intelligence, one that can solve a wide range of problems in ways we might not have thought of ourselves. â€œWeâ€™re talking about programming and math here,â€ said Pachocki. â€œBut itâ€™s really about creativity, coming up with novel ideas, connecting ideas from different places.â€



Look at the two recent competitions: â€œIn both cases, there were problems which required very hard, out-of-the-box thinking. Psyho spent half the programming competition thinking and then came up with a solution that was really novel and quite different from anything that our model looked at.â€



â€œThis is really what weâ€™re after,â€ Pachocki continued. â€œHow do we get models to discover this sort of novel insight? To actually advance our knowledge? I think they are already capable of that in some limited ways. But I think this technology has the potential to really accelerate scientific progress.â€&nbsp;



I returned to the question about whether the focus on math and programming was a problem, conceding that maybe itâ€™s fine if what weâ€™re building are tools to help us do science. We don&#8217;t necessarily want large language models to replace politicians and have people skills, I suggested.



Chen pulled a face and looked up at the ceiling: â€œWhy not?â€



Whatâ€™s missing



OpenAI was founded with a level of hubris that stood out even by Silicon Valley standards, boasting about its goal of building AGI back when talk of AGI still sounded kooky. OpenAI remains as gung-ho about AGI as ever, and it has done more than most to make AGI a mainstream multibillion-dollar concern. Itâ€™s not there yet, though. I asked Chen and Pachocki what they think is missing.



â€œI think the way to envision the future is to really, deeply study the technology that we see today,â€ Pachocki said. â€œFrom the beginning, OpenAI has looked at deep learning as this very mysterious and clearly very powerful technology with a lot of potential. Weâ€™ve been trying to understand its bottlenecks. What can it do? What can it not do?â€&nbsp;&nbsp;



At the current cutting edge, Chen said, are reasoning models, which break down problems into smaller, more manageable steps, but even they have limits: â€œYou know, you have these models which know a lot of things but canâ€™t chain that knowledge together. Why is that? Why canâ€™t it do that in a way that humans can?â€



OpenAI is throwing everything at answering that question.



â€œWe are probably still, like, at the very beginning of this reasoning paradigm,â€ Pachocki told me. â€œReally, we are thinking about how to get these models to learn and explore over the long term and actually deliver very new ideas.â€



Chen pushed the point home: â€œI really donâ€™t consider reasoning done. Weâ€™ve definitely not solved it. You have to read so much text to get a kind of approximation of what humans know.â€



OpenAI wonâ€™t say what data it uses to train its models or give details about their size and shapeâ€”only that it is working hard to make all stages of the development process more efficient.



Those efforts make them confident that so-called scaling lawsâ€”which suggest that models will continue to get better the more compute you throw at themâ€”show no sign of breaking down.



â€œI donâ€™t think thereâ€™s evidence that scaling laws are dead in any sense,â€ Chen insisted. â€œThere have always been bottlenecks, right? Sometimes theyâ€™re to do with the way models are built. Sometimes theyâ€™re to do with data. But fundamentally itâ€™s just about finding the research that breaks you through the current bottleneck.â€&nbsp;



The faith in progress is unshakeable. I brought up something Pachocki had said about AGI in an interview with Nature in May: â€œWhen I joined OpenAI in 2017, I was still among the biggest skeptics at the company.â€ He looked doubtful.&nbsp;



â€œIâ€™m not sure I was skeptical about the concept,â€ he said. â€œBut I think I wasâ€”â€ He paused, looking at his hands on the table in front of him. â€œWhen I joined OpenAI, I expected the timelines to be longer to get to the point that we are now.â€





â€œThereâ€™s a lot of consequences of AI,â€ he said. â€œBut the one I think the most about is automated research. When we look at human history, a lot of it is about technological progress, about humans building new technologies. The point when computers can develop new technologies themselves seems like a very important, um, inflection point.



â€œWe already see these models assist scientists. But when they are able to work on longer horizonsâ€”when theyâ€™re able to establish research programs for themselvesâ€”the world will feel meaningfully different.â€



For Chen, that ability for models to work by themselves for longer is key. â€œI mean, I do think everyone has their own definitions of AGI,â€ he said. â€œBut this concept of autonomous timeâ€”just the amount of time that the model can spend making productive progress on a difficult problem without hitting a dead endâ€”thatâ€™s one of the big things that weâ€™re after.â€



Itâ€™s a bold visionâ€”and far beyond the capabilities of todayâ€™s models. But I was nevertheless struck by how Chen and Pachocki made AGI sound almost mundane. Compare this with how Sutskever responded when I spoke to him 18 months ago. â€œItâ€™s going to be monumental, earth-shattering,â€ he told me. â€œThere will be a before and an after.â€ Faced with the immensity of what he was building, Sutskever switched the focus of his career from designing better and better models to figuring out how to control a technology that he believed would soon be smarter than himself.



Two years ago Sutskever set up what he called a superalignment team that he would co-lead with another OpenAI safety researcher, Jan Leike. The claim was that this team would funnel a full fifth of OpenAIâ€™s resources into figuring out how to control a hypothetical superintelligence. Today, most of the people on the superalignment team, including Sutskever and Leike, have left the company and the team no longer exists.&nbsp;&nbsp;&nbsp;



When Leike quit, he said it was because the team had not been given the support he felt it deserved. He posted this on X: â€œBuilding smarter-than-human machines is an inherently dangerous endeavor. OpenAI is shouldering an enormous responsibility on behalf of all of humanity. But over the past years, safety culture and processes have taken a backseat to shiny products.â€ Other departing researchers shared similar statements.



I asked Chen and Pachocki what they make of such concerns. â€œA lot of these things are highly personal decisions,â€ Chen said. â€œYou know, a researcher can kind of, you knowâ€”â€



He started again. â€œThey might have a belief that the field is going to evolve in a certain way and that their research is going to pan out and is going to bear fruit. And, you know, maybe the company doesnâ€™t reshape in the way that you want it to. Itâ€™s a very dynamic field.â€



â€œA lot of these things are personal decisions,â€ he repeated. â€œSometimes the field is just evolving in a way that is less consistent with the way that youâ€™re doing research.â€



But alignment, both of them insist, is now part of the core business rather than the concern of one specific team. According to Pachocki, these models donâ€™t work at all unless they work as you expect them to. Thereâ€™s also little desire to focus on aligning a hypothetical superintelligence with your objectives when doing so with existing models is already enough of a challenge.



â€œTwo years ago the risks that we were imagining were mostly theoretical risks,â€ Pachocki said. â€œThe world today looks very different, and I think a lot of alignment problems are now very practically motivated.â€



Still, experimental technology is being spun into mass-market products faster than ever before. Does that really never lead to disagreements between the two of them?



â€œI am often afforded the luxury of really kind of thinking about the long term, where the technology is headed,â€ Pachocki said. â€œContending with the reality of the processâ€”both in terms of people and also, like, the broader company needsâ€”falls on Mark. Itâ€™s not really a disagreement, but there is a natural tension between these different objectives and the different challenges that the company is facing that materializes between us.â€



Chen jumped in: â€œI think itâ€™s just a very delicate balance.â€&nbsp;&nbsp;



Correction: we have removed a line referring to an Altman message on X about GPT-5. We amended who was behind OpenAI&#8217;s reasoning models to include reference to Sutskever.

ğŸ”’ Cybersecurity & Privacy
â€¢ Scammers Unleash Flood of Slick Online Gaming Sites
  Fraudsters are flooding Discord and other social media platforms with ads for hundreds of polished online gaming and wagering websites that lure people with free credits and eventually abscond with any cryptocurrency funds deposited by players. Here&#8217;s a closer look at the social engineering tactics and remarkable traits of this sprawling network of more than 1,200 scam sites.
The scam begins with deceptive ads posted on social media that claim the wagering sites are working in partnership with popular social media personalities, such as Mr. Beast, who recently launched a gaming business called Beast Games. The ads invariably state that by using a supplied &#8220;promo code,&#8221; interested players can claim a $2,500 credit on the advertised gaming website.
An ad posted to a Discord channel for a scam gamblingÂ website that the proprietors falsely claim was operating in collaboration with the Internet personality Mr. Beast. Image: Reddit.com.
The gaming sites all require users to create a free account to claim their $2,500 credit, which they can use to play any number of extremely polished video games that ask users to bet on each action. At the scam website gamblerbeast[.]com, for example, visitors can pick from dozens of games like B-Ball Blitz, in which you play a basketball pro who is taking shots from the free throw line against a single opponent, and you bet on your ability to sink each shot.
The financial part of this scam begins when users try to cash out any &#8220;winnings.&#8221; At that point, the gaming site will reject the request and prompt the user to make a &#8220;verification deposit&#8221; of cryptocurrency &#8212; typically around $100 &#8212; before any money can be distributed. Those who deposit cryptocurrency funds are soon asked for additional payments.

However, any &#8220;winnings&#8221; displayed by these gaming sites are a complete fantasy, and players who deposit cryptocurrency funds will never see that money again. Compounding the problem, victims likely will soon be peppered with come-ons from &#8220;recovery experts&#8221; who peddle dubious claims on social media networks about being able to retrieve funds lost to such scams.
KrebsOnSecurity first learned about this network of phony betting sites from a Discord user who asked to be identified only by their screen name: &#8220;Thereallo&#8221; is a 17-year-old developer who operates multiple Discord servers and said they began digging deeper after users started complaining of being inundated with misleading spam messages promoting the sites.
&#8220;We were being spammed relentlessly by these scam posts from compromised or purchased [Discord] accounts,&#8221; Thereallo said. &#8220;I got frustrated with just banning and deleting, so I started to investigate the infrastructure behind the scam messages. This is not a one-off site, it&#8217;s a scalable criminal enterprise with a clear playbook, technical fingerprints, and financial infrastructure.&#8221;
After comparing the code on the gaming sites promoted via spam messages, Thereallo found they all invoked the same API key for an online chatbot that appears to be in limited use or else is custom-made. Indeed, a scan for that API key at the threat hunting platform Silent Push reveals at least 1,270 recently-registered and active domains whose names all invoke some type of gaming or wagering theme.
The &#8220;verification deposit&#8221; stage of the scam requires the user to deposit cryptocurrency in order to withdraw their &#8220;winnings.&#8221;
Thereallo said the operators of this scam empire appear to generate a unique Bitcoin wallet for each gaming domain they deploy.
&#8220;This is a decoy wallet,&#8221; Thereallo explained. &#8220;Once the victim deposits funds, they are never able to withdraw any money. Any attempts to contact the &#8216;Live Support&#8217; are handled by a combination of AI and human operators who eventually block the user. The chat system is self-hosted, making it difficult to report to third-party service providers.&#8221;
Thereallo discovered another feature common to all of these scam gambling sites [hereafter referred to simply as &#8220;scambling&#8221; sites]: If you register at one of them and then very quickly try to register at a sister property of theirs from the same Internet address and device, the registration request is denied at the second site.
&#8220;I registered on one site, then hopped to another to register again,&#8221; Thereallo said. Instead, the second site returned an error stating that a new account couldn&#8217;t be created for another 10 minutes.
The scam gaming site spinora dot cc shares the same chatbot API as more than 1,200 similar fake gaming sites.
&#8220;They&#8217;re tracking my VPN IP across their entire network,&#8221; Thereallo explained. &#8220;My password manager also proved it. It tried to use my dummy email on a site I had never visited, and the site told me the account already existed. So it&#8217;s definitely one entity running a single platform with 1,200+ different domain names as front-ends. This explains how their support works, a central pool of agents handling all the sites. It also explains why they&#8217;re so strict about not giving out wallet addresses; it&#8217;s a network-wide policy.&#8221;
In many ways, these scambling sites borrow from the playbook of &#8220;pig butchering&#8221; schemes, a rampant and far more elaborate crime in which people are gradually lured by flirtatious strangers online into investing in fraudulent cryptocurrency trading platforms.
Pig butchering scams are typically powered by people in Asia who have been kidnapped and threatened with physical harm or worse unless they sit in a cubicle and scam Westerners on the Internet all day. In contrast, these scambling sites tend to steal far less money from individual victims, but their cookie-cutter nature and automated support components may enable their operators to extract payments from a large number of people in far less time, and with considerably less risk and up-front investment.
Silent Push&#8217;s Zach Edwards said the proprietors of this scambling empire are spending big money to make the sites look and feel like some fancy new type of casino.
&#8220;That&#8217;s a very odd type of pig butchering network and not like what we typically see, with much lower investments in the sites and lures,&#8221; Edwards said.
Here is a list of all domains that Silent Push found were using the scambling network&#8217;s chat API.

ğŸ“ University AI
No updates.

ğŸ¢ Corporate AI
â€¢ Introducing Amazon Bedrock AgentCore Browser Tool
  At AWS Summit New York City 2025, Amazon Web Services (AWS) announced the preview of Amazon Bedrock AgentCore browser tool, a fully managed, pre-built cloud-based browser. This tool enables generative AI agents to interact seamlessly with websites. It addresses two fundamental limitations: first, foundation models (FMs) are trained on large but static datasets and need dynamic access to current information when API access isnâ€™t readily available; second, organizations face significant challenges when attempting to scale web automation with AI for enterprise use cases. 
The development of agentic AI systems is moving toward applications that can execute complex, multistep tasks. For these agents to be effective, they require access to dynamic, real-time data, particularly from websites and web applications that donâ€™t offer APIs or where API integration would be complex. Moreover, as businesses seek to deploy AI-powered automation across their operations, they need solutions that can reliably scale without the operational overhead of managing browser farms or solving complex concurrency issues. The AgentCore Browser Tool provides these capabilities, allowing agents to perform tasks such as automating research, streamlining operations, and interacting with web-based applicationsâ€”all with the scalability, reliability, and security of the AWS Cloud infrastructure. By providing a fully managed cloud-based browser, AWS addresses the critical need for enterprises to deploy AI automation at scale across thousands of concurrent sessions, supporting use cases from customer service automation to large-scale data collection and analysis, without the traditional complexity and resource constraints of self-managed browser automation frameworks. 
In this post, we introduce the newly announced Amazon Bedrock AgentCore Browser Tool. We explore why organizations need cloud-based browser automation and the limitations it addresses for FMs that require real-time data access. We talk about key use cases and the core capabilities of the AgentCore Browser Tool. We walk through how to get started with the tool. 
Why do you need the cloud-based AgentCore Browser Tool? 
Traditional browser automation approaches have typically required significant infrastructure management, security considerations, and development expertise. The introduction of a fully managed, cloud-based browser automation solution addresses several critical needs, including simplified infrastructure management, enterprise-grade security, global availability and scaling, and cost optimization. Organizations no longer need to provision, maintain, and scale browser instances to support their automation needs. AWS now handles the complex infrastructure requirements, so developers can focus on building intelligent agent capabilities rather than managing browser farms. Cloud-based browser automation provides isolated execution environments with AWS security controls, reducing the risk of data exfiltration or unauthorized access that might occur in less controlled environments. With a cloud-based browser, you can instantaneously deploy browser instances across the global infrastructure of AWS so that browser automation can scale. By offering browser automation as a managed service, organizations can use a consumption-based pricing model instead of maintaining always-on infrastructure, which can substantially reduce costs for intermittent workloads. 
Use cases for cloud-based browser automation 
Handling repetitive web tasks: With the introduction of Amazon Bedrock AgentCore Browser Tool, organizations can now implement sophisticated browser automation at scale. Cloud-based browser automation excels at minimizing manual execution of repetitive tasks across web interfaces. AI agents can populate complex web forms across multiple systems, validate entries, and maintain compliance with business rules. Agents can navigate to internal dashboards, extract critical metrics, and compile reports without human intervention. For organizations managing large user-generated content domains, agents can assist human moderators by prescreening content across multiple web interfaces. 
AI powered research and intelligence gathering: With cloud-based browser automation, AI agents become powerful research assistants. They automatically track related websites for pricing changes, new product launches, or content updates with regular monitoring. You can use AI agents to gather and analyze consumer sentiment across various web forums, review sites, and social domains to inform product development. With the AgentCore Browser Tool, you can create automated systems that regularly scan trusted information sources to keep internal knowledge bases current. 
Complex workflow automation across systems: Many organizations operate across numerous web applications that lack integrated workflows. Use the AgentCore Browser Tool to automate customer setup across multiple software-as-a-service (SaaS) systems when APIs are unavailable. This helps maintain consistency and reduces error rates. You can monitor supplier portals, inventory systems, and logistics services to maintain visibility across complex supply chains. By automating account creation and permission settings across numerous internal web applications, employee onboarding becomes streamlined. 
Testing and quality assurance: Cloud-based browser automation enables robust testing at scale. You can use AgentCore Browser Tool to validate user experiences and functionality across different scenarios, devices, and browsers in parallel. Deploy agents to continuously interact with critical business applications and set up alerts to your teams about performance issues before customers encounter them. With AgentCore Browser Tool, you can regularly test web applications for accessibility compliance, security vulnerabilities, or regulatory requirements. 
Legacy system integration: Many organizations maintain legacy systems that lack modern APIs. Enable modern AI capabilities to interact with legacy web applications that would be costly to replace or modernize. Apply intelligent automation to systems that were never designed for programmatic access. As a result, you can extract valuable organizational data trapped in older web applications through regular, automated harvesting. 
Core capabilities 
The Amazon Bedrock AgentCore Browser Tool empowers AI agents to interact with web content the same way humans do, through a fully managed remote browser infrastructure that minimizes traditional complexity while delivering enterprise-grade security and scalability. 
Web interaction capabilities 
 
 Complete navigation control across websites and multipage workflows 
 Interaction with JavaScript-heavy applications and dynamic content 
 Form manipulation, including text fields, dropdown menus, and file uploads 
 Humanlike interaction patterns such as scrolling, hovering, and clicking 
 
Serverless browser infrastructure 
 
 Zero-management browser fleet with automatic patching 
 Seamless scaling from single session to thousands based on demand 
 Global deployment options with usage-based pricing 
 Optimized performance without infrastructure overhead 
 
Visual understanding 
 
 Full-page screenshots enabling AI comprehension of layout and content 
 Visual element identification by appearance and position 
 Content extraction from graphical elements 
 Resolution and device emulation capabilities 
 
Human-in-the-loop integration 
 
 Real-time interactive viewing and control for human operators 
 Session recording for review, training, and compliance 
 
Enterprise-grade security 
 
 Complete session isolation for each browser instance 
 AWS Identity and Access Management (IAM) controls for access management 
 Ephemeral browser sessions that reset after each use 
 
Complex web application support 
 
 Full compatibility with modern JavaScript frameworks 
 Authentication handling and session persistence 
 Processing of asynchronous content and real-time updates 
 Intelligent interaction with complex UI patterns 
 
Audit and compliance 
 
 Detailed interaction logging and session recording 
 Integration with AWS CloudTrail for comprehensive tracking 
 
Observability 
 
 Performance metrics on latency and resource usage 
 Integration with Amazon CloudWatch for unified monitoring 
 Session record and replay for observability 
 
This comprehensive set of capabilities bridges the fundamental gap between AI agents and the human web, enabling organizations to build intelligent agents that can understand and interact with content designed for humans rather than being limited to API-based integrations. 
How an AI agent can use AgentCore Browser Tool 
Amazon Bedrock AgentCore Browser runs in a secure, isolated containerized environment within AgentCore, insulating web activity from your local system. You can interact with the AgentCore Browser Tool using browser actuation libraries, such as Playwright, or use AI agentic frameworks specialized for browser automation, such as Amazon Nova Act and Browser Use. You can also integrate browser automation as a tool in a multi-agentic workflow. 
Amazon Nova Act or Browser Use works with the AgentCore Browser Tool to take natural language instructions from the user and convert them to actuations on the browser by following this workflow: 
 
 The user sends a query such as â€œsearch for shoes on Amazonâ€ 
 An agentic framework such as Amazon Nova Act or Browser Use passes the query to the large language model (LLM) 
 The LLM reasons and generates instructions in a structured output format (for example, JSON encoded) 
 The agentic framework maps these instructions into browser actuation commands (such as Playwright, Puppeteer, or Selenium) 
 The browser actuation commands are executed on the AgentCore Browser over a secure WebSocket connection 
 The response from the browser and a screenshot are sent to the agent to reason further 
 
This process repeats until the original task is complete. The flow is illustrated in the following diagram. 
 
Get started 
The Amazon Bedrock AgentCore Browser Tool is available for use today. For a collection of open source examples, visit the amazon-bedrock-agentcore-samples repository on GitHub. 
Prerequisites 
To use the Amazon Bedrock AgentCore Brower Tool, you need to complete the following prerequisites: 
 
 Python 3.10+ 
 Verify your IAM user or role has the permissions to use AgentCore Browser: 
 
 
 git clone https://github.com/awslabs/amazon-bedrock-agentcore-samples.git
pip install bedrock-agentcore  
 
For browser visualization on your local machine, you need the BrowserViewerServer component in the repository you cloned at: 01-tutorials/05-AgentCore-tools/02-Agent-Core-browser-tool/interactive_tools 
You can also visualize the browser live on the Amazon Bedrock AgentCore console at https://us-east-1.console.aws.amazon.com/bedrock-agentcore/builtInTools 
The following Python code demonstrates how to use the AgentCore Browser Tool directly with the Playwright library and the Amazon Bedrock AgentCore SDK. This example initiates a secure browser session, connects to it, and automates a straightforward workflow in which it navigates to https://www.amazon.com and searches for a product. 
 
 To get started with playwright: 
 
 
 cd 01-tutorials/05-AgentCore-tools/02-Agent-Core-browser-tool 
 
 
 Install dependencies: 
 
 
 pip install playwright 
 
 
 Author your playwright-based script: 
 
 
 from playwright.sync_api import sync_playwright, Playwright, BrowserType
from bedrock_agentcore.tools.browser_client import browser_session
from browser_viewer import BrowserViewerServer
import time
from rich.console import Console
console = Console()
def run(playwright: Playwright):
    # Create the browser session and keep it alive
    with browser_session('us-west-2') as client:
        ws_url, headers = client.generate_ws_headers()
        # Start viewer server
        viewer = BrowserViewerServer(client, port=8005)
        viewer_url = viewer.start(open_browser=True)
        # Connect using headers
        chromium: BrowserType = playwright.chromium
        browser = chromium.connect_over_cdp(
            ws_url,
            headers=headers
        )
        context = browser.contexts[0]
        page = context.pages[0]
        try:
            page.goto("https://amazon.com/")
            console.print(page.title())
            # Keep running
            while True:
                time.sleep(120)
        except KeyboardInterrupt:
            console.print("\n\n[yellow]Shutting down...[/yellow]")
            if 'client' in locals():
                client.stop()
                console.print("âœ… Browser session terminated")
        except Exception as e:
            console.print(f"\n[red]Error: {e}[/red]")
            import traceback
            traceback.print_exc()
with sync_playwright() as playwright:
    run(playwright) 
 
Alternatively, you can build a browser agent using Amazon Nova Act to automate web interactions: 
 
 Sign up for Nova Act at https://nova.amazon.com/act and generate an API key. 
 In the same Python virtual environment: 
 
pip install nova-act 
 
 Author your Nova Act based script: 
 
 
 import time
from bedrock_agentcore.tools.browser_client import browser_session
from nova_act import NovaAct
from rich.console import Console
from browser_viewer import BrowserViewerServer
 
NOVA_ACT_API_KEY = "YOUR_NOVA_ACT_API_KEY"
console = Console() 
 
def main():
    try:
        # Step 1: Create browser session
        with browser_session('us-west-2') as client:
            print("\r   âœ… Browser ready!                    ")
            ws_url, headers = client.generate_ws_headers()
 
            # Step 2: Start viewer server
            console.print("\n[cyan]Step 3: Starting viewer server...[/cyan]")
            viewer = BrowserViewerServer(client, port=8005)
            viewer_url = viewer.start(open_browser=True)
 
            # Step 3: Use Nova Act to interact with the browser with NovaAct
            with NovaAct(
                    cdp_endpoint_url=ws_url,
                    cdp_headers=headers,
                    preview={"playwright_actuation": True},
                    nova_act_api_key=NOVA_ACT_API_KEY,
                    starting_page="https://www.amazon.com",
                ) as nova_act:
                    result = nova_act.act("Search for coffee maker and get the details of the lowest priced one on the first page")
                    console.print(f"\n[bold green]Nova Act Result:[/bold green] {result}")
            
            # Keep running
            while True:
                time.sleep(1)
             
    except KeyboardInterrupt:
        console.print("\n\n[yellow]Shutting down...[/yellow]")
        if 'client' in locals():
            client.stop()
            print("âœ… Browser session terminated")
    except Exception as e:
        print(f"\n[red]Error: {e}[/red]")
        import traceback
        traceback.print_exc()
 
if __name__ == "__main__":
    main() 
 
Alternatively, you can run the tutorial notebooks in the Amazon Bedrock AgentCore GitHub repository. 
Pricing and availability  
Amazon Bedrock AgentCore offers flexible, consumption-based pricing with no upfront commitments or minimum fees. AgentCore Browser can be used independently of the other services. You can try AgentCore services at no additional charge until September 16, 2025. After this date, AgentCore Browser Tool will be charged based on consumption. Billing is calculated per second, using the highest watermark of CPU and memory usage for that second, with a 1-second minimum. 128 MB minimum memory billing applies. Network data transfer through customer elastic network interfaces is billed at standard Amazon Elastic Compute Cloud (Amazon EC2) rates 
For more information about pricing, visit Amazon Bedrock AgentCore (Preview) Pricing. 
Conclusion 
Amazon Bedrock AgentCore Browser Tool marks a transformative advancement in AI-powered web automation, offering organizations a fully managed, cloud-based browser solution. AgentCore Browser Tool addresses critical limitations faced by generative AI systems requiring real-time data access, enabling AI agents to interact naturally with websites through capabilities such as complete navigation control, visual understanding, and seamless integration with frameworks such as Playwright and Amazon Nova Act. By using this tool, businesses can now implement sophisticated automation at scale across various use casesâ€”from streamlining repetitive web tasks and conducting AI-enhanced research to automating complex workflows and integrating with legacy systemsâ€”all while benefiting from the reliable cloud infrastructure of AWS that adapts to organizational needs without the operational overhead of managing browser farms. 
Resources 
To learn more and start building, visit the following resources: 
 
 Amazon Bedrock AgentCore Developer Guide 
 Amazon Bedrock AgentCore console 
 
 
About the authors 
Veda Raman is a Senior Specialist Solutions Architect for generative AI and machine learning at AWS. Veda works with customers to help them architect efficient, secure, and scalable machine learning applications. Veda specializes in generative AI services like Amazon Bedrock and Amazon SageMaker. 
Rahul Sharma is a Senior Specialist Solutions Architect at AWS, helping AWS customers build and deploy, scalable Agentic AI solutions. Prior to joining AWS, Rahul spent more than decade in technical consulting, engineering, and architecture, helping companies build digital products, powered by data and machine learning. In his free time, Rahul enjoys exploring cuisines, traveling, reading books(biographies and humor) and binging on investigative documentaries, in no particular order. 
Kishor Aher is a Principal Product Manager at AWS, leading the Agentic AI team responsible for developing first-party tools such as Browser Tool, and Code Interpreter. As a founding member of Amazon Bedrock, he spearheaded the vision and successful launch of the service, driving key features including Converse API, Managed Model Customization, and Model Evaluation capabilities. Kishor regularly shares his expertise through speaking engagements at AWS events, including re:Invent and AWS Summits. Outside of work, he pursues his passion for aviation as a general aviation pilot and enjoys playing volleyball.
â€¢ Introducing the Amazon Bedrock AgentCore Code Interpreter
  AI agents have reached a critical inflection point where their ability to generate sophisticated code exceeds the capacity to execute it safely in production environments. Organizations deploying agentic AI face a fundamental dilemma: although large language models (LLMs) can produce complex code scripts, mathematical analyses, and data visualizations, executing this AI-generated code introduces significant security vulnerabilities and operational complexity. 
In this post, we introduce the Amazon Bedrock AgentCore Code Interpreter, a fully managed service that enables AI agents to securely execute code in isolated sandbox environments. We discuss how the AgentCore Code Interpreter helps solve challenges around security, scalability, and infrastructure management when deploying AI agents that need computational capabilities. We walk through the serviceâ€™s key features, demonstrate how it works with practical examples, and show you how to get started with building your own agents using popular frameworks like Strands, LangChain, and LangGraph. 
Security and scalability challenges with AI-generated code 
Consider an example where an AI agent needs perform analysis on multi-year sales projections data for a product, to understand anomalies, trends, and seasonality. The analysis should be grounded in logic, repeatable, handle data securely, and scalable over large data and multiple iterations, if needed. Although LLMs excel at understanding and explaining concepts, they lack the ability to directly manipulate data or perform consistent mathematical operations at scale. LLMs alone are often inadequate for complex data analysis tasks like these, due to their inherent limitations in processing large datasets, performing precise calculations, and generating visualizations. This is where code interpretation and execution tools become essential, providing the capability to execute precise calculations, handle large datasets efficiently, and create reproducible analyses through programming languages and specialized libraries. Furthermore, implementing code interpretation capabilities comes with significant considerations. Organizations must maintain secure sandbox environments to help prevent malicious code execution, manage resource allocation, and maintain data privacy. The infrastructure requires regular updates, robust monitoring, and careful scaling strategies to handle increasing demand. 
Traditional approaches to code execution in AI systems suffer from several limitations: 
 
 Security vulnerabilities â€“ Executing untrusted AI-generated code in production environments exposes organizations to code injection threats, unauthorized system access, and potential data breaches. Without proper sandboxing, malicious or poorly constructed code can compromise entire infrastructure stacks. 
 Infrastructure overhead â€“ Building secure execution environments requires extensive DevOps expertise, including container orchestration, network isolation, resource monitoring, and security hardening. Many organizations lack the specialized knowledge to implement these systems correctly. 
 Scalability bottlenecks â€“ Traditional code execution environments struggle with the dynamic, unpredictable workloads generated by AI agents. Peak demand can overwhelm static infrastructure, and idle periods waste computational resources. 
 Integration complexity â€“ Connecting secure code execution capabilities with existing AI frameworks often requires custom development, creating maintenance overhead and limiting adoption across development teams. 
 Compliance challenges â€“ Enterprise environments demand comprehensive audit trails, access controls, and compliance certifications that are difficult to implement and maintain in custom solutions. 
 
These barriers have prevented organizations from fully using the computational capabilities of AI agents, limiting their applications to simple, deterministic tasks rather than the complex, code-dependent workflows that could maximize business value. 
Introducing the Amazon Bedrock AgentCore Code Interpreter 
With the AgentCore Core Interpreter, AI agents can write and execute code securely in sandbox environments, enhancing their accuracy and expanding their ability to solve complex end-to-end tasks. This purpose-built service minimizes the security, scalability, and integration challenges that have hindered AI agent deployment by providing a fully managed, enterprise-grade code execution system specifically designed for agentic AI workloads. The AgentCore Code Interpreter is designed and built from the ground up for AI-generated code, with built-in safeguards, dynamic resource allocation, and seamless integration with popular AI frameworks. It offers advanced configuration support and seamless integration with popular frameworks, so developers can build powerful agents for complex workflows and data analysis while meeting enterprise security requirements. 
Transforming AI agent capabilities 
The AgentCore Code Interpreter powers advanced use cases by addressing several critical enterprise requirements: 
 
 Enhanced security posture â€“ Configurable network access options range from fully isolated environments, which provide enhanced security by helping prevent AI-generated code from accessing external systems, to controlled network connectivity that provides flexibility for specific development needs and use cases. 
 Zero infrastructure management â€“ The fully managed service minimizes the need for specialized DevOps resources, reducing time-to-market from months to days while maintaining enterprise-grade reliability and security. 
 Dynamic scalability â€“ Automatic resource allocation handles varying AI agent workloads without manual intervention, providing low-latency session start-up times during peak demand while optimizing costs during idle periods. 
 Framework agnostic integration â€“ It integrates with Amazon Bedrock AgentCore Runtime, with native support for popular AI frameworks including Strands, LangChain, LangGraph, and CrewAI, so teams can use existing investments while maintaining development velocity. 
 Enterprise compliance â€“ Built-in access controls and comprehensive audit trails facilitate regulatory compliance without additional development overhead. 
 
Purpose-built for AI agent code execution 
The AgentCore Code Interpreter represents a shift in how AI agents interact with computational resources. This operation processes the agent generated code, runs it in a secure environment, and returns the execution results, including output, errors, and generated visualizations. The service operates as a secure, isolated execution environment where AI agents can run code (Python, JavaScript, and TypeScript), perform complex data analysis, generate visualizations, and execute mathematical computations without compromising system security. Each execution occurs within a dedicated sandbox environment that provides complete isolation from other workloads and the broader AWS infrastructure. What distinguishes the AgentCore Code Interpreter from traditional execution environments is its optimization for AI-generated workloads. The service handles the unpredictable nature of AI-generated code through intelligent resource management, automatic error handling, and built-in security safeguards specifically designed for untrusted code execution. 
Key features and capabilities of AgentCore Code Interpreter include: 
 
 Secure sandbox architecture: 
   
   Low-latency session start-up time and compute-based session isolation facilitating complete workload separation 
   Configurable network access policies supporting both isolated sandbox and controlled public network modes 
   Implements resource constraints by setting maximum limits on memory and CPU usage per session, helping to prevent excessive consumption (see AgentCore Code Interpreter Service Quotas) 
    
 Advanced session management: 
   
   Persistent session state allowing multi-step code execution workflows 
   Session-based file storage for complex data processing pipelines 
   Automatic session and resource cleanup 
   Support for long-running computational tasks with configurable timeouts 
    
 Comprehensive Python runtime environment: 
   
   Pre-installed data science libraries, including pandas, numpy, matplotlib, scikit-learn, and scipy 
   Support for popular visualization libraries, including seaborn and bokeh 
   Mathematical computing capabilities with sympy and statsmodels 
   Custom package installation within sandbox boundaries for specialized requirements 
    
 File operations and data management: 
   
   Upload data files, process them with code, and retrieve the results 
   Secure file transfer mechanisms with automatic encryption 
   Support for upload and download of files directly within the sandbox from Amazon Simple Storage Service (Amazon S3) 
   Support for multiple file formats, including CSV, JSON, Excel, and images 
   Temporary storage with automatic cleanup for enhanced security 
   Support for running AWS Command Line Interface (AWS CLI) commands directly within the sandbox, using the Amazon Bedrock AgentCore SDK and API 
    
 Enterprise integration features: 
   
   AWS Identity and Access Management (IAM) based access controls with fine-grained permission management 
   AWS CloudTrail integration providing audit trails for compliance 
    
 
How the AgentCore Code Interpreter works 
To understand the functionality of the AgentCore Code Interpreter, letâ€™s examine the orchestrated flow of a typical data analysis request from an AI agent, as illustrated in the following diagram. 
 
The workflow consists of the following key components: 
 
 Deployment and invocation â€“ An agent is built and deployed (for instance, on the AgentCore Runtime) using a framework like Strands, LangChain, LangGraph, or CrewAI. When a user sends a prompt (for example, â€œAnalyze this sales data and show me the trend by salesregionâ€), the AgentCore Runtime initiates a secure, isolated session. 
 Reasoning and tool selection â€“ The agentâ€™s underlying LLM analyzes the prompt and determines that it needs to perform a computation. It then selects the AgentCore Code Interpreter as the appropriate tool. 
 Secure code execution â€“ The agent generates a code snippet, for instance using the pandas library, to read a data file and matplotlib to create a plot. This code is passed to the AgentCore Code Interpreter, which executes it within its dedicated, sandboxed session. The agent can read from and write files to the session-specific file system. 
 Observation and iteration â€“ The AgentCore Code Interpreter returns the result of the executionâ€”such as a calculated value, a dataset, an image file of a graph, or an error messageâ€”to the agent. This feedback loop allows the agent to engage in iterative problem-solving by debugging its own code and refining its approach. 
 Context and memory â€“ The agent maintains context for subsequent turns in the conversation, during the duration of the session. Alternatively, the entire interaction can be persisted in Amazon Bedrock AgentCore Memory for long-term storage and retrieval. 
 Monitoring and observability â€“ Throughout this process, a detailed trace of the agentâ€™s execution, providing visibility into agent behavior, performance metrics, and logs, is available for debugging and auditing purposes. 
 
Practical real-world applications and use cases 
The AgentCore Code Interpreter can be applied to real-world business problems that are difficult to solve with LLMs alone. 
Use case 1: Automated financial analysis 
An agent can be tasked with performing on-demand analysis of financial data. For this example, a user provides a CSV file of billing data within the following prompt and asks for analysis and visualization: â€œUsing the billing data provided below, create a bar graph that shows the total spend by product categoryâ€¦ After generating the graph, provide a brief interpretation of the resultsâ€¦â€The agent takes the following actions: 
 
 The agent receives the prompt and the data file containing the raw data. 
 It invokes the AgentCore Code Interpreter, generating Python code with the pandas library to parse the data into a DataFrame. The agent then generates another code block to group the data by category and sum the costs, and asks the AgentCore Code Interpreter to execute it. 
 The agent uses matplotlib to generate a bar chart and the AgentCore Code Interpreter saves it as an image file. 
 The agent returns both a textual summary of the findings and the generated PNG image of the graph. 
 
Use case 2: Interactive data science assistant 
The AgentCore Code Interpreterâ€™s stateful session supports a conversational and iterative workflow for data analysis. For this example, a data scientist uses an agent for exploratory data analysis. The workflow is as follows: 
 
 The user provides a prompt: â€œLoad dataset.csv and provide descriptive statistics.â€ 
 The agent generates and executes pandas.read_csv('dataset.csv') followed by .describe()and returns the statistics table. 
 The user prompts, â€œPlot a scatter plot of column A versus column B.â€ 
 The agent, using the dataset already loaded in its session, generates code with matplotlib.pyplot.scatter() and returns the plot. 
 The user prompts, â€œRun a simple linear regression and provide the R^2 value.â€ 
 The agent generates code using the scikit-learn library to fit a model and calculate the R^2 metric. 
 
This demonstrates iterative code execution capabilities, which allow agents to work through complex data science problems in a turn-by-turn manner with the user. 
Solution overview 
To get started with the AgentCore Code Interpreter, clone the GitHub repo: 
 
 git clone https://github.com/awslabs/amazon-bedrock-agentcore-samples.git 
 
In the following sections, we show how to create a question answering agent that validates answers through code and reasoning. We build it using the Strands SDK, but you can use a framework of your choice. 
Prerequisites 
Make sure you have the following prerequisites: 
 
 An AWS account with AgentCore Code Interpreter access 
 The necessary IAM permissions to create and manage AgentCore Code Interpreter resources and invoke models on Amazon Bedrock 
 The required Python packages installed (including boto3, bedrock-agentcore, and strands) 
 Access to Anthropicâ€™s Claude 4 Sonnet model in the us-west-2 AWS Region (Anthropicâ€™s Claude 4 is the default model for Strands SDK, but you can override and use your preferred model as described in the Strands SDK documentation) 
 
Configure your IAM role 
Your IAM role should have appropriate permissions to use the AgentCore Code Interpreter: 
 
 {
"Version": "2012-10-17",
"Statement": [
&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Effect": "Allow",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Action": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:CreateCodeInterpreter",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:StartCodeInterpreterSession",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:InvokeCodeInterpreter",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:StopCodeInterpreterSession",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:DeleteCodeInterpreter",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:ListCodeInterpreters",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock-agentcore:GetCodeInterpreter"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Resource": "*"
&nbsp;&nbsp; &nbsp;},
&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Effect": "Allow",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Action": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"logs:CreateLogGroup",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"logs:CreateLogStream",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"logs:PutLogEvents"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Resource": "arn:aws:logs:*:*:log-group:/aws/bedrock-agentcore/code-interpreter*"
&nbsp;&nbsp; &nbsp;}
]
} 
 
Set up and configure the AgentCore Code Interpreter 
Complete the following setup and configuration steps: 
 
 Install the bedrock-agentcore Python SDK: 
 
 
 pip install bedrock-agentcore 
 
 
 Import the AgentCore Code Interpreter and other libraries: 
 
 
 from&nbsp;bedrock_agentcore.tools.code_interpreter_client&nbsp;import&nbsp;code_session
from&nbsp;strands&nbsp;import&nbsp;Agent,&nbsp;tool
import&nbsp;json 
 
 
 Define the system prompt: 
 
 
 SYSTEM_PROMPT&nbsp;&nbsp;"""You are a helpful AI assistant that validates all answers through code execution.

TOOL AVAILABLE:
- execute_python: Run Python code and see output 
 
 
 Define the code execution tool for the agent. Within the tool definition, we use the invoke method to execute the Python code generated by the LLM-powered agent. It automatically starts a serverless AgentCore Code Interpreter session if one doesnâ€™t exist. 
 
 
 @tool
def execute_python(code: str, description: str = "") -&gt; str:
&nbsp;&nbsp; &nbsp;"""Execute Python code in the sandbox."""
&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;if description:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;code = f"# {description}\n{code}"
&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;print(f"\n Generated Code: {code}")
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;for event in response["stream"]:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return json.dumps(event["result"]) 
 
 
 Configure the agent: 
 
 
 agent&nbsp;&nbsp;Agent(
tools[execute_python],
system_promptSYSTEM_PROMPT,
callback_handler
) 
 
Invoke the agent 
Test the AgentCore Code Interpreter powered agent with a simple prompt: 
 
 query&nbsp;&nbsp;"Tell me the largest random prime number between 1 and 100, which is less than 84 and more that 9"
try:
&nbsp;&nbsp; &nbsp;response_text = ""
&nbsp;&nbsp; &nbsp;async for event in agent.stream_async(query):
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;if "data" in event:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;chunk = event["data"]
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;response_text += chunk
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;print(chunk, end="")
except Exception as e:
&nbsp;&nbsp; &nbsp;print(f"Error occurred: {str(e)}") 
 
We get the following result: 
 
 I'll find the largest random prime number between 1 and 100 that is less than 84 and more than 9. To do this, I'll write code to:

1. Generate all prime numbers in the specified range
2. Filter to keep only those &gt; 9 and &lt; 84
3. Find the largest one

Let me implement this:
&nbsp;Generated Code: import random

def is_prime(n):
&nbsp;&nbsp; &nbsp;"""Check if a number is prime"""
&nbsp;&nbsp; &nbsp;if n &lt;= 1:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return False
&nbsp;&nbsp; &nbsp;if n &lt;= 3:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return True
&nbsp;&nbsp; &nbsp;if n % 2 == 0 or n % 3 == 0:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return False
&nbsp;&nbsp; &nbsp;i = 5
&nbsp;&nbsp; &nbsp;while i * i &lt;= n:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;if n % i == 0 or n % (i + 2) == 0:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return False
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;i += 6
&nbsp;&nbsp; &nbsp;return True

# Find all primes in the range
primes_in_range = [n for n in range(10, 84) if is_prime(n)]

print("All prime numbers between 10 and 83:")
print(primes_in_range)

# Get the largest prime in the range
largest_prime = max(primes_in_range)
print(f"\nThe largest prime number between 10 and 83 is: {largest_prime}")

# For verification, let's check that it's actually prime
print(f"Verification - is {largest_prime} prime? {is_prime(largest_prime)}")
Based on the code execution, I can tell you that the largest prime number between 1 and 100, which is less than 84 and more than 9, is **83**.

I verified this by:
1. Writing a function to check if a number is prime
2. Generating all prime numbers in the range 10-83
3. Finding the maximum value in that list

The complete list of primes in your specified range is: 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, and 83.

Since 83 is the largest among these primes, it is the answer to your question. 
 
Pricing and availability 
Amazon Bedrock AgentCore is available in multiple Regions and uses a consumption-based pricing model with no upfront commitments or minimum fees. Billing for the AgentCore Code Interpreter is calculated per second and is based on the highest watermark of CPU and memory resources consumed during that second, with a 1-second minimum charge. 
Conclusion 
The AgentCore Code Interpreter transforms the landscape of AI agent development by solving the critical challenge of secure, scalable code execution in production environments. This purpose-built service minimizes the complex infrastructure requirements, security vulnerabilities, and operational overhead that have historically prevented organizations from deploying sophisticated AI agents capable of complex computational tasks. The serviceâ€™s architectureâ€”featuring isolated sandbox environments, enterprise-grade security controls, and seamless framework integrationâ€”helps development teams focus on agent logic and business value rather than infrastructure complexity. 
To learn more, refer to the following resources: 
 
 Introducing Amazon Bedrock AgentCore: Securely deploy and operate AI agents at any scale (preview) 
 Execute code and analyze data using Amazon Bedrock AgentCore Code Interpreter 
 Code Interpreter API Reference Examples 
 Amazon Bedrock AgentCore Code Interpreter GitHub repo 
 
Try it out today or reach out to your AWS account team for a demo! 
 
About the authors 
Veda Raman is a Senior Specialist Solutions Architect for generative AI and machine learning at AWS. Veda works with customers to help them architect efficient, secure, and scalable machine learning applications. Veda specializes in generative AI services like Amazon Bedrock and Amazon SageMaker. 
Rahul Sharma is a Senior Specialist Solutions Architect at AWS, helping AWS customers build and deploy, scalable Agentic AI solutions. Prior to joining AWS, Rahul spent more than decade in technical consulting, engineering, and architecture, helping companies build digital products, powered by data and machine learning. In his free time, Rahul enjoys exploring cuisines, traveling, reading books(biographies and humor) and binging on investigative documentaries, in no particular order. 
Kishor Aher is a Principal Product Manager at AWS, leading the Agentic AI team responsible for developing first-party tools such as Browser Tool, and Code Interpreter. As a founding member of Amazon Bedrock, he spearheaded the vision and successful launch of the service, driving key features including Converse API, Managed Model Customization, and Model Evaluation capabilities. Kishor regularly shares his expertise through speaking engagements at AWS events, including re:Invent and AWS Summits. Outside of work, he pursues his passion for aviation as a general aviation pilot and enjoys playing volleyball.
â€¢ Observing and evaluating AI agentic workflows with Strands Agents SDK and Arize AX
  This post is co-written with Rich Young from Arize AI. 
Agentic AI applications built on agentic workflows differ from traditional workloads in one important way: theyâ€™re nondeterministic. That is, they can produce different results with the same input. This is because the large language models (LLMs) theyâ€™re based on use probabilities when generating each token. This inherent unpredictability can lead AI application designers to ask questions related to the correction plan of action, the optimal path of an agent and the correct set of tools with the right parameters. Organizations that want to deploy such agentic workloads need an observability system that can make sure that theyâ€™re producing results that are correct and can be trusted. 
In this post, we present how the Arize AX service can trace and evaluate AI agent tasks initiated through Strands Agents, helping validate the correctness and trustworthiness of agentic workflows. 
Challenges with generative AI applications 
The path from a promising AI demo to a reliable production system is fraught with challenges that many organizations underestimate. Based on industry research and real-world deployments, teams face several critical hurdles: 
 
 Unpredictable behavior at scale â€“ Agents that perform well in testing might fail with unexpected inputs in production, such as new language variations or domain-specific jargon that cause irrelevant or misunderstood responses. 
 Hidden failure modes â€“ Agents can produce plausible but wrong outputs or skip steps unnoticed, such as miscalculating financial metrics in a way that seems correct but misleads decision-making. 
 Nondeterministic paths â€“ Agents might choose inefficient or incorrect decision paths, such as taking 10 steps to route a query that should take only 5, leading to poor user experiences. 
 Tool integration complexity â€“ Agents can break when calling APIs incorrectly, for example, passing the wrong order ID format so that a refund silently fails despite a successful inventory update. 
 Cost and performance variability â€“ Loops or verbose outputs can cause runaway token costs and latency spikes, such as an agent making more than 20 LLM calls and delaying a response from 3 to 45 seconds. 
 
These challenges mean that traditional testing and monitoring approaches are insufficient for AI systems. Success requires a more thoughtful approach that incorporates a more comprehensive strategy. 
Arize AX delivers a comprehensive observability, evaluation, and experimentation framework 
Arize AX is the enterprise-grade AI engineering service that helps teams monitor, evaluate, and debug AI applications from development to production lifecycle. Incorporating Arizeâ€™s Phoenix foundation, AX adds enterprise essentials such as the â€œAlyxâ€ AI assistant, online evaluations, automatic prompt optimization, role-based access control (RBAC), and enterprise scale and support. AX offers a comprehensive solution to organizations that caters to both technical and nontechnical personas so they can manage and improve AI agents from development through production at scale. Arize AX capabilities include: 
 
 Tracing â€“ Full visibility into LLM operations using OpenTelemetry to capture model calls, retrieval steps, and metadata such as tokens and latency for detailed analysis. 
 Evaluation â€“ Automated quality monitoring with LLM-as-a-judge evaluations on production samples, supporting custom evaluators and clear success metrics. 
 Datasets â€“ Maintain versioned, representative datasets for edge cases, regression tests, and A/B testing, refreshed with real production examples. 
 Experiments â€“ Run controlled tests to measure the impact of changes to prompts or models, validating improvements with statistical rigor. 
 Playground â€“ Interactive environment to replay traces, test prompt variations, and compare model responses for effective debugging and optimization. 
 Prompt management â€“ Version, test, and deploy prompts like code, with performance tracking and gradual rollouts to catch regressions early. 
 Monitoring and alerting â€“ Real-time dashboards and alerts for latency, errors, token usage, and drift, with escalation for critical issues. 
 Agent visualization â€“ Analyze and optimize agent decision paths to reduce loops and inefficiencies, refining planning strategies. 
 
These components form a comprehensive observability strategy that treats LLM applications as mission-critical production systems requiring continuous monitoring, evaluation, and improvement. 
Arize AX and Strands Agents: A powerful combination 
Strands Agents is an open source SDK, a powerful low-code framework for building and running AI agents with minimal overhead. Designed to simplify the development of sophisticated agent workflows, Strands unifies prompts, tools, LLM interactions, and integration protocols into a single streamlined experience. It supports both Amazon Bedrock hosted and external models, with built-in capabilities for Retrieval Augmented Generation (RAG), Model Context Protocol (MCP), and Agent2Agent (A2A) communication. In this section, we walk through building an agent with Strands Agent SDK, instrumenting it with Arize AX for trace-based evaluation, and optimizing its behavior. 
The following workflow shows how a Strands agent handles a user task end-to-endâ€”invoking tools, retrieving context, and generating a responseâ€”while sending traces to Arize AX for evaluation and optimization. 
 
The solution follows these high-level steps: 
 
 Install and configure the dependencies 
 Instrument the agent for observability 
 Build the agent with Strands SDK 
 Test the agent and generate traces 
 Analyze traces in Arize AI 
 Evaluate the agentâ€™s behavior 
 Optimize the agent 
 Continually monitor the agent 
 
Prerequisites 
Youâ€™ll need: 
 
 An AWS account with access to Amazon Bedrock 
 An Arize account with your Space ID and API Key (sign up at no additional cost at arize.com). 
 
Install dependencies:pip install strands opentelemetry-sdk arize-otel 
Solution walkthrough: Using Arize AX with Strands Agents 
The integration between Strands Agent SDK and Arize AIâ€™s observability system provides deep, structured visibility into the behavior and decisions of AI agents. This setup enables end-to-end tracing of agent workflowsâ€”from user input through planning, tool invocation, and final output. 
Full implementation details are available in the accompanying notebook and resources in the Openinference-Arize repository in GitHub. 
Install and configure the dependencies 
To install and configure the dependencies, use the following code: 
 
 from opentelemetry import trace
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from strands_to_openinference_mapping import StrandsToOpenInferenceProcessor
from arize.otel import register
import grpc 
 
Instrument the agent for observability 
To instrument the agent for observability, use the following code. 
 
 &nbsp;The StrandsToOpenInferenceProcessor converts native spans to OpenInference format. 
 &nbsp;trace_attributes add session and user context for richer trace filtering. 
 
Use Arizeâ€™s OpenTelemetry integration to enable tracing: 
 
 register(
&nbsp;&nbsp;&nbsp;&nbsp;space_id="your-arize-space-id",
&nbsp;&nbsp;&nbsp;&nbsp;api_key="your-arize-api-key",
&nbsp;&nbsp;&nbsp;&nbsp;project_name="strands-project",
&nbsp;&nbsp;&nbsp;&nbsp;processor=StrandsToOpenInferenceProcessor()
)
agent = Agent(
&nbsp;&nbsp;&nbsp;&nbsp;model=model,
&nbsp;&nbsp;&nbsp;&nbsp;system_prompt=system_prompt,
&nbsp;&nbsp;&nbsp;&nbsp;tools=[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;retrieve, current_time, get_booking_details,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;create_booking, delete_booking
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;trace_attributes={
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"session.id": "abc-1234",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"user.id": "user-email@example.com",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"arize.tags": [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Agent-SDK",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Arize-Project",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"OpenInference-Integration"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
) 
 
Build the agent with Strands SDK 
Create the Restaurant Assistant agent using Strands. This agent will help customers with restaurant information and reservations using several tools: 
 
 retrieve â€“ Searches the knowledge base for restaurant information 
 current_time â€“ Gets the current time for reservation scheduling 
 create_booking â€“ Creates a new restaurant reservation 
 get_booking_details â€“ Retrieves details of an existing reservation 
 delete_booking â€“ Cancels an existing reservation 
 
The agent uses Anthropicâ€™s Claude 3.7 Sonnet model in Amazon Bedrock for natural language understanding and generation. Import the required tools and define the agent: 
 
 import get_booking_details, delete_booking, create_booking
from strands_tools import retrieve, current_time
from strands import Agent, tool
from strands.models.bedrock import BedrockModel
import boto3
system_prompt = """You are "Restaurant Helper", a restaurant assistant helping customers reserving tables in different restaurants. You can talk about the menus, create new bookings, get the details of an existing booking or delete an existing reservation. You reply always politely and mention your name in the reply (Restaurant Helper)..........."""
model = BedrockModel(
&nbsp;&nbsp;&nbsp;&nbsp;model_id="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
)
kb_name = 'restaurant-assistant'
smm_client = boto3.client('ssm')
kb_id = smm_client.get_parameter(
&nbsp;&nbsp;&nbsp;&nbsp;Name=f'{kb_name}-kb-id',
&nbsp;&nbsp;&nbsp;&nbsp;WithDecryption=False
)
os.environ["KNOWLEDGE_BASE_ID"] = kb_id["Parameter"]["Value"]
agent = Agent(
&nbsp;&nbsp;&nbsp;&nbsp;model=model,
&nbsp;&nbsp;&nbsp;&nbsp;system_prompt=system_prompt,
&nbsp;&nbsp;&nbsp;&nbsp;tools=[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;retrieve, current_time, get_booking_details,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;create_booking, delete_booking
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;trace_attributes={
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"session.id": "abc-1234",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"user.id": "user-email-example@domain.com",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"arize.tags": [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Agent-SDK",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Arize-Project",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"OpenInference-Integration",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
) 
 
Test the agent and generate traces 
Test the agent with a couple of queries to generate traces for Arize. Each interaction will create spans in OpenTelemetry that will be processed by the custom processor and sent to Arize AI.The first test case is a restaurant information query. Ask about restaurants in San Francisco. This will trigger the knowledge base retrieval tool: 
 
 # Test with a question about restaurants
results = agent("Hi, where can I eat in New York?")
print(results) 
 
The second test case is for a restaurant reservation. Test the booking functionality by making a reservation. This will trigger the create_booking tool: 
 
 # Test with a reservation request
results = agent("Make a reservation for tonight at Rice &amp; Spice. At 8pm, for 2 people in the name of Anna")
print(results) 
 
Analyze traces in Arize AI 
After running the agent, you can view and analyze the traces in the Arize AI dashboard, shown in the following screenshot. Trace-level visualization shows the representation of the trace to confirm the path that the agent took during execution. In the Arize dashboard, you can review the traces generated by the agent. By selecting the strands-project you defined in the notebook, you can view your traces on the LLM Tracing tab. Arize provides powerful filtering capabilities to help you focus on specific traces. You can filter by OTel attributes and metadata, for example, to analyze performance across different models. 
 
You can also use Alyx AI assistant, to analyze your agentâ€™s behavior through natural language queries and uncover insights. In the example below, we use Alyx to reason about why a tool was invoked incorrectly by the agent in one of the traces, helping us identify the root cause of the misstep 
 
Choosing a specific trace gives detailed information about the agentâ€™s runtime performance and decision-making process, as shown in the following screenshot. 
 
The graph view, shown in the following screenshot, shows the hierarchical structure of your agentâ€™s execution and users can inspect specific execution paths to understand how the agent made decisions by selecting the graph. 
 
You can also view session-level insights on the Sessions tab next to LLM Tracing. By tagging spans with session.id and user.id, you can group related interactions, identify where conversations break down, track user frustration, and evaluate multiturn performance across sessions. 
Evaluate the agentâ€™s behavior 
Arizeâ€™s system traces the agentâ€™s decision-making process, capturing details such as routing decisions, tool calls and parameters. You can evaluate performance by analyzing these traces to verify that the agent selects optimal paths and provides accurate responses. For example, if the agent misinterprets a customerâ€™s request and chooses the wrong tool or uses incorrect parameters, Arize evaluators will identify when these failures occur.Arize has pre-built evaluation templates for every step of your Agent process: 
 
 Agent Tool Calling 
   
   Agent Tool Selection 
   Agent Parameter Extraction 
    
 Agent Path Convergence 
 Agent Planning 
 Agent Reflection 
 
Create a new task under Evals and Tasks and choose LLM as a judge task type. You can use a pre-built prompt template (tool calling is used in the example shown in the following screenshot) or you can ask Alyx AI assistant to build one for you. Evals will now automatically run on your traces as they flow into Arize. This uses AI to automatically label your data and identify failures at scale without human intervention. 
 
Now every time the agent is invoked, trace data is collected in Arize and the tool calling evaluation automatically runs and labels the data with a correct or incorrect label along with an explanation by the LLM-as-a-judge for its labeling decision. Here is an example of an evaluation label and explanation. 
 
Optimize the agent 
The LLM-as-a-judge evaluations automatically identify and label failure cases where the agent didnâ€™t call the right tool. In the below screenshot these failure cases are automatically captured and added to a regression dataset, which will drive agent improvement workflows. This production data can now fuel development cycles for improving the agent. 
 
Now, you can connect directly with Arizeâ€™s prompt playground, an integrated development environment (IDE) where you can experiment with various prompt changes and model choices, compare side-by-side results and test across the regression dataset from the previous step. When you have an optimal prompt and model combination, you can save this version to the prompt hub for future version tracking and retrieval, as shown in the following screenshot. 
 
Experiments from the prompt testing are automatically saved, with online evaluations run and results saved for immediate analysis and comparison to facilitate data-driven decisions on what enhancements to deploy. Additionally, experiments can be incorporated into continuous integration and continuous delivery (CI/CD) workflows for automated regression testing and validation whenever new prompt or application changes are pushed to systems such as GitHub. The screenshot below shows hallucination metrics for prompt experiments. 
 
 
Continually monitor the agent 
To maintain reliability and performance in production, itâ€™s essential to continually monitor your AI agents. Arize AI provides out-of-the-box monitoring capabilities that help teams detect issues early, optimize cost, and provide high-quality user experiences.Setting up monitors in Arize AI offers: 
 
 Early issue detection â€“ Identify problems before they impact users 
 Performance tracking â€“ Monitor trends and maintain consistent agent behavior 
 Cost management â€“ Track token usage to avoid unnecessary expenses 
 Quality assurance â€“ Validate your agent is delivering accurate, helpful responses 
 
You can access and configure monitors on the Monitors tab in your Arize project. For details, refer to the Arize documentation on monitoring. 
When monitoring your Strands Agent in production, pay close attention to these key metrics: 
 
 Latency â€“ Time taken for the agent to respond to user inputs 
 Token usage â€“ Number of tokens consumed, which directly impacts cost 
 Error rate â€“ Frequency of failed responses or tool invocations 
 Tool usage â€“ Effectiveness and frequency of tool calls 
 User satisfaction signals â€“ Proxy metrics such as tool call correctness, conversation length, or resolution rates 
 
By continually monitoring these metrics, teams can proactively improve agent performance, catch regressions early, and make sure the system scales reliably in real-world use. In Arize, you can create custom metrics directly from OTel trace attributes or metadata, and even from evaluation labels and metrics, such as the tool calling correctness evaluation you created previously. The screenshot below visualizes the tool call correctness ratio across agent traces, helping identify patterns in correct versus incorrect tool usage 
 
The screenshot below illustrate how Arize provides customizable dashboards that enable deep observability into LLM agent performance, showcasing a custom monitoring dashboard tracking core metrics such as latency, token usage, and the percentage of correct tool calls. 
 
The screenshot below demonstrates prebuilt templates designed to accelerate setup and offer immediate visibility into key agent behaviors. 
 
Clean up 
When youâ€™re done experimenting, you can clean up the AWS resources created by this notebook by running the cleanup script: !sh cleanup.sh. 
Conclusion 
The key lesson is clear: observability, automatic evaluations, experimentation and feedback loops, and proactive alerting arenâ€™t optional for production AIâ€”theyâ€™re the difference between innovation and liability. Organizations that invest in proper AI operations infrastructure can harness the transformative power of AI agents while avoiding the pitfalls that have plagued early adopters. The combination of Amazon Strands Agents and Arize AI provides a comprehensive solution that addresses these challenges: 
 
 Strands Agents offers a model-driven approach for building and running AI agents 
 Arize AI adds the critical observability layer with tracing, evaluation, and monitoring capabilities 
 
The partnership between AWS and Arize AI offers a powerful solution for building and deploying generative AI agents. The fully managed framework of Strands Agents simplifies agent development, and Arizeâ€™s observability tools provide critical insights into agent performance. By addressing challenges such as nondeterminism, verifying correctness, and enabling continual monitoring, this integration benefits organizations in that they can create reliable and effective AI applications. As businesses increasingly adopt agentic workflows, the combination of Amazon Bedrock and Arize AI sets a new standard for trustworthy AI deployment. 
Get started 
Now that youâ€™ve learned how to integrate Strands Agents with the Arize Observability Service, you can start exploring different types of agents using the example provided in this sample. As a next step, try expanding this integration to include automated evaluations using Arizeâ€™s evaluation framework to score agent performance and decision quality. 
Ready to build better agents? Get started with an account at arize.com for no additional cost and begin transforming your AI agents from unpredictable experiments into reliable, production-ready solutions. The tools and knowledge are here; the only question is: what will you build? 
About the Authors 
Rich Young is the Director of Partner Solutions Architecture at Arize AI, focused on AI agent observability and evaluation tooling. Prior to joining Arize, Rich led technical pre-sales at WhyLabs AI. In his pre-AI life, Rich held leadership and IC roles at enterprise technology companies such as Splunk and Akamai. 
Karan Singh is a Agentic AI leader at AWS, where he works with top-tier third-party foundation model and agentic frameworks providers to develop and execute joint go-to-market strategies, enabling customers to effectively deploy and scale solutions to solve enterprise agentic AI challenges. Karan holds a BS in Electrical Engineering from Manipal University, a MS in Electrical Engineering from Northwestern University, and an MBA from the Haas School of Business at University of California, Berkeley. 
Nolan Chen is a Partner Solutions Architect at AWS, where he helps startup companies build innovative solutions using the cloud. Prior to AWS, Nolan specialized in data security and helping customers deploy high-performing wide area networks. Nolan holds a bachelorâ€™s degree in mechanical engineering from Princeton University. 
Venu Kanamatareddy is an AI/ML Solutions Architect at AWS, supporting AI-driven startups in building and scaling innovative solutions. He provides strategic and technical guidance across the AI lifecycle from model development to MLOps and generative AI. With experience across startups and large enterprises, he brings deep expertise in cloud architecture and AI solutions. Venu holds a degree in computer science and a masterâ€™s in artificial intelligence from Liverpool John Moores University.
â€¢ Building AIOps with Amazon Q Developer CLI and MCP Server
  IT teams face mounting challenges as they manage increasingly complex infrastructure and applications, often spending countless hours manually identifying operational issues, troubleshooting problems, and performing repetitive maintenance tasks. This operational burden diverts valuable technical resources from innovation and strategic initiatives. Artificial intelligence for IT operations (AIOps) presents a transformative solution, using AI to automate operational workflows, detect anomalies, and resolve incidents with minimal human intervention. Organizations can optimize their operational efficiency while maintaining security as they manage their infrastructure and applications. 
You can use Amazon Q Developer CLI and Model Context Protocol (MCP) servers to build powerful AIOps solutions that can reduce manual effort through natural language interactions. Amazon Q Developer can help developers and IT professionals with many of their tasksâ€”from coding, testing, and deploying, to troubleshooting, performing security scanning and fixes, modernizing applications, optimizing AWS resources, and creating data engineering pipelines. The MCP extends these capabilities by enabling Amazon Q to connect with custom tools and services through a standardized interface, allowing for more sophisticated operational automations. 
In this post, we discuss how to implement a low-code no-code AIOps solution that helps organizations monitor, identify, and troubleshoot operational events while maintaining their security posture. We show how these technologies work together to automate repetitive tasks, streamline incident response, and enhance operational efficiency across your organization. 
This is the third post in a series on AIOps using generative AI services on AWS. Refer to the following two posts for building AIOps using Amazon Bedrock and Amazon Q Business: 
 
 Automate IT operations with Amazon Bedrock Agents 
 Building an AIOps chatbot with Amazon Q Business custom plugins 
 
Solution overview 
MCP servers act like a universal connector for AI models, enabling them to interact with external systems, fetch live data, and integrate with various tools seamlessly. This helps Amazon Q provide more contextually relevant assistance by accessing the information it needs in real time. The following architecture diagram illustrates how you can use a single configuration file, mcp.json, to configure MCP servers in Amazon Q Developer CLI to connect to external systems. 
 
The workflow consists of the following steps: 
 
 The user configures an MCP client in Amazon Q Developer CLI using the mcp.json file. 
 The user logs in to Amazon Q Developer CLI and asks operational queries in natural language. 
 Depending on your query, Amazon Q decides which MCP servers that you configured or existing tools to invoke to perform the task. 
 The MCP server interacts with the respective external system to get the live data that is used by Amazon Q to perform the required task. 
 
In this post, we show how to use Amazon Q Developer CLI to address the following operational issues: 
 
 Identify and remediate high CPU utilization in an Amazon Elastic Compute Cloud (Amazon EC2) instance 
 Identify and remove public access from an Amazon Simple Storage Service (Amazon S3) bucket 
 Identify and block a specific unwanted open port for inbound connection to an EC2 instance 
 
Prerequisites 
Complete the following prerequisites before you start setting up the demo: 
 
 Create an AWS account if you donâ€™t already have one. 
 Make sure you have access to an AWS account through the AWS Management Console and AWS Command Line Interface (AWS CLI). Your AWS Identity and Access Management (IAM) user must have permissions to make the necessary AWS service calls and manage AWS resources mentioned in this post. While providing permissions to the IAM user, follow the principle of least-privilege. 
 Have Amazon Q for command line installed. Refer to Supported command line environments before installation. 
 
Configure MCP in Amazon Q Developer CLI 
MCP configuration in Amazon Q Developer CLI is managed through JSON files. You will configure the Amazon Bedrock Knowledge Base Retrieval MCP Server. At the time of writing, only the stdio transport is supported in Amazon Q Developer CLI. 
Amazon Q Developer CLI supports two levels of MCP configuration: 
 
 Global configuration â€“ Uses ~/.aws/amazonq/mcp.json and applies to all workspaces 
 Workspace configuration â€“ Uses .amazonq/mcp.json and is specific to the current workspace 
 
For this post, we use the workspace configuration, but you have option to use either of them. 
 
 Create a new workspace folder, and inside that folder, create the file .amazonq/mcp.json with the following content: 
 
 
 {
  "mcpServers": {
    "awslabs.bedrock-kb-retrieval-mcp-server": {
      "command": "uvx",
      "args": ["awslabs.bedrock-kb-retrieval-mcp-server@latest"],
      "env": {
        "AWS_PROFILE": "your-profile-name ",
        "AWS_REGION": "your-region",
        "FASTMCP_LOG_LEVEL": "ERROR",
        "KB_INCLUSION_TAG_KEY": "name=aiops-knowledge-base",
        "BEDROCK_KB_RERANKING_ENABLED": "false"
      },
      "disabled": false,
      "autoApprove": []
    }  
  }
} 
 
See the AWS MCP Servers GitHub repository for an updated list of available MCP servers. 
 
 Open a terminal, navigate to the workspace folder that you created, and run the following command to log in to Amazon Q Developer CLI: 
 
 
 q login 
 
 
 Follow the instructions to log in to Amazon Q Developer on the command line. 
 Initiate the chat session by running q and then run /tools to validate that the Amazon Bedrock Knowledge Base Retrieval MCP server is configured. 
 
Tool permissions have two possible states: 
 
 Trusted â€“ Amazon Q can use the tool without asking for confirmation each time 
 Per-request â€“ Amazon Q must ask for your confirmation each time before using the tool 
 
By default, this tool will not be trusted. 
 
5. Run /tools trust awslabsbedrock_kb_retrieval_mcp_server___QueryKnowledgeBases to trust the MCP server. 
6. Run the /tools command again to validate it. 
 
Deploy AWS resources 
Deploy the following AWS CloudFormation template to deploy the AWS resources that you will use to test AIOps. You can deploy this template in either the us-east-1 or us-west-2 AWS Region. You can deploy it in other Regions by updating the applicable AMI IDs in the template. This template will deploy two EC2 instances and three S3 buckets. 
This CloudFormation template is for demo purposes only and not meant for production usage. 
 
 AWSTemplateFormatVersion: '2010-09-09'
Description: &gt;-
  This template creates the necessary AWS resources which will be used to test AIOps using 
  Amazon Q Developer CLI with MCP server integration.
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Network
        Parameters:
          - SecurityGroupIngressCidrIp
      - Label:
          default: General
        Parameters:
          - Prefix
    ParameterLabels:
      SecurityGroupIngressCidrIp:
        default: Security group ingress CIDR IP
Parameters:
  Prefix:
    Type: String
    Description: Unique name prefix for resources that are created by the stack.
    ConstraintDescription: &gt;-
      must not start with a dash, and must only contain lowercase a-z, digits,
      and a dash.
    AllowedPattern: ^[a-z0-9][a-z0-9-]+$
    MinLength: 1
    MaxLength: 30
    Default: aiops-qdevcli
  SecurityGroupIngressCidrIp:
    Type: String
    Description: &gt;-
      IPv4 address in CIDR format for allowed incoming traffic to the EC2 instance. Defaults to allowing all IPs.
    ConstraintDescription: &gt;-
      must be in the form x.x.x.x/s, where x is 0-255, and s is 0-32.
    AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/([0-9]|[1-2][0-9]|3[0-2]))$
    Default: 0.0.0.0/0
Resources:
  # AIOps Amazon S3 bucket1
  AIOpsQDeveloperCliS3Bucket1:
    Type: AWS::S3::Bucket
    Properties:
      AccessControl: Private
      BucketName:
        Fn::Sub: ${Prefix}-bucket1-${AWS::AccountId}
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  # AIOps Amazon S3 bucket2
  AIOpsQDeveloperCliS3Bucket2:
    Type: AWS::S3::Bucket
    Properties:
      AccessControl: Private
      BucketName:
        Fn::Sub: ${Prefix}-bucket2-${AWS::AccountId}
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  # AIOps Amazon S3 bucket3
  AIOpsQDeveloperCliS3Bucket3:
    Type: AWS::S3::Bucket
    Properties:
      AccessControl: Private
      BucketName:
        Fn::Sub: ${Prefix}-bucket3-${AWS::AccountId}
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  # AIOps Knowledgebase S3 bucket
  AIOpsQDeveloperKBS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      AccessControl: Private
      BucketName:
        Fn::Sub: ${Prefix}-kb-${AWS::AccountId}
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  # AIOps VPC resources
  AIOpsQDeveloperCliVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperCliVPC
  AIOpsQDeveloperCliSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: 10.0.1.0/24
      VpcId:
        Ref: AIOpsQDeveloperCliVPC
      AvailabilityZone: !Select 
        - 0
        - !GetAZs 
          Ref: 'AWS::Region'
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperCliSubnet1
  AIOpsQDeveloperCliSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: 10.0.3.0/24
      VpcId:
        Ref: AIOpsQDeveloperCliVPC
      AvailabilityZone: !Select 
        - 1
        - !GetAZs 
          Ref: 'AWS::Region'
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperCliSubnet2
  AIOpsQDeveloperIGW:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperIGW
  AIOpsQDeveloperCliVPCGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId:
        Ref: AIOpsQDeveloperIGW
      VpcId:
        Ref: AIOpsQDeveloperCliVPC
  AIOpsQDeveloperCliRT:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId:
        Ref: AIOpsQDeveloperCliVPC
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperCliRT
  AIOpsRoute:
    Type: AWS::EC2::Route
    DependsOn:
      - AIOpsQDeveloperCliVPCGatewayAttachment
    Properties:
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId:
        Ref: AIOpsQDeveloperIGW
      RouteTableId:
        Ref: AIOpsQDeveloperCliRT
  AIOpsQDeveloperCliSubnetRouteTableAssociation1:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId:
        Ref: AIOpsQDeveloperCliRT
      SubnetId:
        Ref: AIOpsQDeveloperCliSubnet1
  AIOpsQDeveloperCliSubnetRouteTableAssociation2:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId:
        Ref: AIOpsQDeveloperCliRT
      SubnetId:
        Ref: AIOpsQDeveloperCliSubnet2
  AIOpsQDeveloperCliSG1:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: &gt;-
        Allows incoming traffic on port 5080 and denies all outgoing traffic.
      SecurityGroupEgress:
        - Description: Denies all outgoing traffic.
          IpProtocol: -1
          CidrIp: 0.0.0.0/32
      SecurityGroupIngress:
        - Description: Allows incoming TCP traffic on port 22.
          IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp:
            Ref: SecurityGroupIngressCidrIp        
      VpcId:
        Ref: AIOpsQDeveloperCliVPC
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperCliSG1
  AIOpsQDeveloperCliSG2:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: &gt;-
        Allows incoming traffic on port 5080 and denies all outgoing traffic.
      SecurityGroupEgress:
        - Description: Denies all outgoing traffic.
          IpProtocol: -1
          CidrIp: 0.0.0.0/32
      SecurityGroupIngress:
        - Description: Allows incoming TCP traffic on port 5080.
          IpProtocol: tcp
          FromPort: 5080
          ToPort: 5080
          CidrIp:
            Ref: SecurityGroupIngressCidrIp
        - Description: Allows incoming TCP traffic on port 22.
          IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp:
            Ref: SecurityGroupIngressCidrIp        
      VpcId:
        Ref: AIOpsQDeveloperCliVPC
      Tags:
        - Key: Name
          Value: AIOpsQDeveloperCliSG2
  EC2KeyPair:
    Type: AWS::EC2::KeyPair
    Properties:
      KeyName: 
        Fn::Sub: ${Prefix}-keypair-${AWS::AccountId}
  # EC2 instance to demo high CPU Utilization AIOps  
  EC2InstanceHighCPUUtilDemo:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: t2.micro
      KeyName: !Ref EC2KeyPair      
      ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', AL2023]
      NetworkInterfaces:
        - AssociatePublicIpAddress: true
          DeviceIndex: 0
          SubnetId: !Ref AIOpsQDeveloperCliSubnet1
          GroupSet: 
            - !Ref AIOpsQDeveloperCliSG1
      Tags:
        - Key: Name
          Value:
            Fn::Sub: ${Prefix}-high-cpu-util
  # EC2 instance to demo unwanted open port detection AIOps  
  EC2InstanceOpenPortDemo:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: t2.micro
      KeyName: !Ref EC2KeyPair      
      ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', AL2023]
      NetworkInterfaces:
        - AssociatePublicIpAddress: true
          DeviceIndex: 0
          SubnetId: !Ref AIOpsQDeveloperCliSubnet1
          GroupSet: 
            - !Ref AIOpsQDeveloperCliSG2
      Tags:
        - Key: Name
          Value:
            Fn::Sub: ${Prefix}-open-port-demo
  CPUUtilizationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: 
        Fn::Sub: ${Prefix}-EC2-Instance-CPU-Utilization
      AlarmDescription: Alarm when server CPU exceeds 70%
      ComparisonOperator: GreaterThanThreshold
      EvaluationPeriods: 1
      MetricName: CPUUtilization
      Namespace: AWS/EC2
      Period: 60
      Statistic: Average
      Threshold: 70.0
      ActionsEnabled: false
      Dimensions:
        - Name: InstanceId
          Value: !Ref EC2InstanceHighCPUUtilDemo
      Unit: Percent
Mappings:
  RegionMap:
    us-east-1:
      AL2023: ami-085ad6ae776d8f09c
    us-west-2:
      AL2023: ami-0005ee01bca55ab66
Outputs:
  AIOpsQDeveloperCliS3Bucket1:
    Description: S3 bucket created for testing AIOps
    Value:
      Ref: AIOpsQDeveloperCliS3Bucket1
  AIOpsQDeveloperCliS3Bucket2:
    Description: S3 bucket created for testing AIOps
    Value:
      Ref: AIOpsQDeveloperCliS3Bucket2
  AIOpsQDeveloperCliS3Bucket3:
    Description: S3 bucket created for testing AIOps
    Value:
      Ref: AIOpsQDeveloperCliS3Bucket3
  AIOpsQDeveloperKBS3Bucket:
    Description: S3 bucket created for testing AIOps
    Value:
      Ref: AIOpsQDeveloperKBS3Bucket
  EC2InstanceHighCPUUtilDemo:
    Description: EC2 instance for testing AIOps
    Value:
      Ref: EC2InstanceHighCPUUtilDemo
  EC2InstanceOpenPortDemo:
    Description: EC2 instance for testing AIOps
    Value:
      Ref: EC2InstanceOpenPortDemo 
 
Validate that the template deployed two EC2 instances, which are in Running state. 
 
Additionally, validate that the template created three S3 buckets with the names aiops-qdevcli-bucketX-&lt;your-AWS-account-Id&gt; and one bucket with the name aiops-qdevcli-&lt;your-AWS-account-Id&gt; in your selected Region. 
 
Create an Amazon Bedrock knowledge base 
Upload the sample high CPU utilization runbook to the aiops-qdevcli-&lt;your-AWS-account-Id&gt; bucket. Create a knowledge base pointing to the bucket, and note the knowledge base ID to use in the first example use case. 
Use case 1: Identify and remediate high CPU utilization in an EC2 instance 
In this use case, you introduce CPU stress in one of the EC2 instances and then use Amazon Q Developer CLI to identify and remediate it. 
 
 On the Amazon EC2 console, log in to the aiops-qdevcli-high-cpu-util instance using EC2 Instance Connect. 
 Run the following command to install stress-ng: 
 
 
 sudo dnf install stress-ng 
 
 
 Run the following command to stress the EC2 instance for 1 hour: 
 
 
 stress-ng --cpu 1 --timeout 3600s 
 
You must wait approximately 10 minutes for the Amazon CloudWatch alarm to get triggered. 
 
 Return to the Amazon EC2 console and check that the aiops-qdevcli-high-cpu-util instance is currently in Alarm state. 
 From the Amazon Q Developer CLI, use a natural language query to check for operation issues in your account. Use the knowledge base ID that you saved in the previous section. 
 
Amazon Q Developer CLI autocorrects the errors that it encountered while running the commands. 
Watch the following video for more details. 
 
 
  
   
  
  
 
Due to the inherent nondeterministic nature of the FMs, the responses you receive from Amazon Q Developer CLI might not be exactly the same as those shown in the demo. 
Use case 2: Identify and remove public access from an S3 bucket 
In this use case, you will simulate an accidental security issue by unblocking public access for one of the buckets and then use Amazon Q Developer CLI to identify and remediate the issue. 
 
 On the Amazon S3 console, open one of the aiops-qdevcli-xxxx buckets, and on the Permissions tab, choose Edit and change Block all public access to Off. 
 
 
 
 Return to the Amazon Q Developer CLI and ask questions in natural language to identify and remediate the operational issue. 
 
Watch the following video for more details. 

 
  
 
 
Use case 3: Identify and block a specific unwanted open port for inbound connection to an EC2 instance 
In this use case, you will use Amazon Q Developer CLI to identify the EC2 instance that has a specific port open and then close the port. 
 
 On the Amazon EC2 console, note that the aiops-qdevcli-open-port-demo instance has port 5080 open for all inbound TCP connections. This is an unwanted security risk that you want to identify and remediate. 
 
 
 
 Return to Amazon Q Developer CLI and use natural language queries to identify the EC2 instance with port 5080 open and fix the issue. 
 
Watch the following video for details. 

 
  
 
 
Clean up 
Properly decommissioning provisioned AWS resources is an important best practice to optimize costs and enhance security posture after concluding proofs of concept and demonstrations. Complete the following steps to delete the resources created in your AWS account: 
 
 On the Amazon Bedrock console, delete the Amazon Bedrock knowledge base. 
 On the Amazon S3 console, empty the aiops-qdevcli-kb-xxx bucket. 
 On the AWS CloudFormation console, delete the CloudFormation stack. 
 
As an alternative, try the preceding steps using natural language queries in Amazon Q Developer CLI. 
 
 Finally, delete the .amazonq/mcp.json file from your workspace folder to remove the MCP configuration for Amazon Q Developer CLI. 
 
Conclusion 
In this post, we showed how Amazon Q Developer CLI interprets natural language queries, automatically converts them into appropriate commands, and identifies the necessary tools for execution. The solutionâ€™s intelligent error-handling capabilities analyze logs and perform auto-corrections, minimizing manual intervention. By implementing Amazon Q Developer CLI, you can enhance your teamâ€™s operational efficiency, reduce human errors, and manage complex environments more effectively through a conversational interface.We encourage you to explore additional use cases and share your feedback with us. For more information on Amazon Q Developer CLI and AWS MCP servers, refer to the following resources: 
 
 Using Amazon Q Developer on the command line 
 Using MCP with Amazon Q Developer 
 AWS MCP Servers 
 AWS MCP Servers GitHub 
 
 
About the authors 
Biswanath Mukherjee&nbsp;is a Senior Solutions Architect at Amazon Web Services. He works with large strategic customers of AWS by providing them technical guidance to migrate and modernize their applications on AWS Cloud. With his extensive experience in cloud architecture and migration, he partners with customers to develop innovative solutions that leverage the scalability, reliability, and agility of AWS to meet their business needs. His expertise spans diverse industries and use cases, enabling customers to unlock the full potential of the AWS Cloud. 
Upendra V&nbsp;is a Senior Solutions Architect at Amazon Web Services, specializing in Generative AI and cloud solutions. He helps enterprise customers design and deploy production-ready Generative AI workloads, implement Large Language Models (LLMs) and Agentic AI systems, and optimize cloud deployments. With expertise in cloud adoption and machine learning, he enables organizations to build and scale AI-driven applications efficiently.
â€¢ Containerize legacy Spring Boot application using Amazon Q Developer CLI and MCP server
  Organizations can optimize their migration and modernization projects by streamlining the containerization process for legacy applications. With the right tools and approaches, teams can transform traditional applications into containerized solutions efficiently, reducing the time spent on manual coding, testing, and debugging while enhancing developer productivity and accelerating time-to-market. During containerization initiatives, organizations can address compatibility, dependencies, and configurations efficiently using automated tools and best practices, helping to keep projects on schedule and within budget parameters. Development teams can focus more on innovation by automating routine tasks such as application architecture analysis, deployment script creation, and environment configuration, leading to smoother transitions across different stages of the modernization journey. 
In this post, youâ€™ll learn how you can use Amazon Q Developer command line interface (CLI) with Model Context Protocol (MCP) servers integration to modernize a legacy Java Spring Boot application running on premises and then migrate it to Amazon Web Services (AWS) by deploying it on Amazon Elastic Kubernetes Service (Amazon EKS). The Amazon Q Developer CLI helps automate common tasks in the modernization process. Youâ€™ll introduce chaos into the system after successful modernization. Then youâ€™ll troubleshoot it using Amazon Q Developer CLI. Youâ€™ll perform all these activities using natural language prompts without writing code. 
Amazon Q Developer goes beyond coding to help developers and IT professionals with many of their tasksâ€”from coding, testing, and deploying to troubleshooting, performing security scanning and fixes, modernizing applications, optimizing AWS resources, and creating data engineering pipelines. Amazon Q for the command line integrates contextual information, providing Amazon Q with an enhanced understanding of your use case, enabling it to provide relevant and context-aware responses. The MCP is an open standard that enables AI assistants to interact with external tools and services. It defines a structured way for AI models to discover available tools, request tool execution with specific parameters, and receive and process tool results. Youâ€™ll use MCP to extend the capabilities of Amazon Q Developer CLI by connecting it to custom tools and services. 
Although weâ€™re showcasing the capability of Amazon Q Developer CLI in this end -to-end migration and modernization journey, if youâ€™re using one of the supported integrated development environments (IDEs) and Java versions, you can use the /transform command to perform the step 2. For more information, visit Upgrading Java versions from Amazon Q Developer. 
Solution overview 
MCP servers act like a universal connector for AI models, enabling them to interact with external systems, fetch live data, and integrate with various tools seamlessly. This allows Amazon Q to provide more contextually relevant assistance by accessing the information it needs in real-time. The following architecture diagram shows how Amazon Q Developer CLI connects to external data sources through MCP servers. 
 
The following is a summary of the functionality of the architecture: 
 
 Youâ€™ll configure MCP client in Amazon Q Developer CLI using mcp.json file. 
 Youâ€™ll log in to Amazon Q Developer CLI and ask queries in natural language. 
 Depending on your query, Amazon Q Developer decides which MCP server(s) that you configured or existing tools to invoke for performing the task. At present, Amazon Q Developer supports stdio local MCP servers only. 
 The MCP server interacts with the respective external system to get the live data that is used by Amazon Q to perform the required task. 
 
The solution follows these high-level steps, as shown in the following graphic: 
 
 Create legacy Java Spring Boot application 
 Upgrade Java and Spring Boot versions 
 Containerize the upgraded application 
 Deploy the application on Amazon EKS 
 Introduce chaos 
 Troubleshoot and fix 
 
 
Prerequisites 
You need to have the following configured before you start setting up the demo: 
 
 Create an AWS account if you donâ€™t already have one. 
 Have access to an AWS account through the AWS Management Console and the AWS Command Line Interface (AWS CLI). The AWS Identity and Access Management (IAM) user that you use must have permissions to make the necessary AWS service calls and manage AWS resources mentioned in this post. While providing permissions to the IAM user, follow the principle of least privilege. 
 Have Amazon Q for command line installed. Refer to Supported command line environments before installation. 
 
Configure MCP in Amazon Q Developer CLI 
MCP configuration in Amazon Q Developer CLI is managed through JSON files. Youâ€™ll configure Amazon Bedrock EKS MCP Server. At the time of this writing, only the stdio transport is supported in Amazon Q Developer CLI. 
Amazon Q Developer CLI supports two levels of MCP configuration: 
 
 Global configuration: ~/.aws/amazonq/mcp.json â€“ Applies to all workspaces 
 Workspace configuration: .amazonq/mcp.json â€“ Specific to the current workspace 
 
In this demonstration, weâ€™re using workspace configuration, but you can use either of them. Follow these steps: 
 
 Create a new workspace folder and inside that folder create .amazonq/mcp.json file with the following content: 
 
 
 {
  "mcpServers": {
    "awslabs.eks-mcp-server": {
      "command": "uvx",
      "args": [
        "awslabs.eks-mcp-server",
        "--allow-write",
        "--allow-sensitive-data-access"
      ],
      "env": {
        "AWS_PROFILE": "your-profile-name",
        "AWS_REGION": "your-region",        
        "FASTMCP_LOG_LEVEL": "ERROR"
      },
      "autoApprove": [
        "manage_eks_stacks",
        "manage_k8s_resource",
        "list_k8s_resources",
        "get_pod_logs",
        "get_k8s_events",
        "get_cloudwatch_logs",
        "get_cloudwatch_metrics",
        "get_policies_for_role",
        "search_eks_troubleshoot_guide",
        "list_api_versions"
      ],
      "disabled": false
    }    
  }
} 
 
 
 Open a terminal, navigate to the workspace folder that you created in step 1, and enter the following command to log into Amazon Q Developer CLI. Follow the instruction on the screen to login to Amazon Q Developer on the command line: 
 
q login 
 
 Initiate the chat session by entering q and then /tools to validate that the Amazon EKS MCP server is configured, as shown in the following screenshot. By default, it wonâ€™t be trusted. 
 
 
Migrate and modernize Java Spring Boot application 
To migrate and modernize a Java Spring Boot application, complete the steps in the following sections. 
Create legacy Java Spring Boot application 
To create a legacy Java Spring Boot application, you first build a legacy Java 8, Spring Boot 2.3.x bookstore application, which youâ€™ll modernize and migrate to AWS. Go back to Amazon Q Developer CLI and use natural language query to create the preceding application. Follow these steps: 
 
 You can use your own words or use the following prompt to generate the code. The prompt generates the sample payloads to test the application. Keep a copy of those payloads for later use. To understand more about best practices for prompt engineering, refer to Mastering Amazon Q Developer Part 1: Crafting Effective Prompts in the AWS DevOps &amp; Developer Productivity Blog. 
 
 
 You will bootstrap the current directory with a java 8 spring boot RESTful microservice application which provides an API. The microservice provides operations for storing, updating, deleting and finding book information. The supported attributes are isbn, book_title, author, price, and currency. The price attribute is numeric and everything else is String. The isbn attribute format needs to be validated as per standard ISBN code format. You can use regex for that. Store the book information in local cache. It should also provide an Actuator endpoint. The project should be built using Maven. Share example payloads to test the microservice now. Once I review and approve the payload proceed with bootstrapping.  
 
 
 Provide approval to generate the legacy application. 
 
 
 Approved. Go ahead. 
 
Amazon Q Developer CLI generates the working code with Java 8 using Spring Boot 2.3.x framework. 
 
 Explore the generated project files and validate the Java and Spring Boot versions. 
 Provide the following prompt to run the application. 
 
 
 Can you run the microservice? 
 
 
 Test the microservice using a REST API client or using curl command. You can also ask Amazon Q Developer CLI to test the application and fix errors, preparing a fully functional service! 
 After testing is complete, stop the microservice. Your legacy application is now ready to be modernized. 
 (Optional) Ask Amazon Q Developer CLI to generate a component and sequence diagram for the legacy application. 
 
Refer to the following video for a quick demo. 

 
  
 
 
Upgrade Java and Spring Boot versions 
Upgrade the legacy Java Spring Boot application that you created in the previous step using Amazon Q Developer CLI. 
As mentioned previously, if youâ€™re using one of the supported integrated development environments (IDEs) and Java versions, you can use the /transform command within your IDE to perform this step. 
 
 Use your own words or the following prompt to update the legacy application. Amazon Q Developer performs required changes in both maven pom.xml and Java code to upgrade to Java 21 and Spring Boot 3.5.0. It builds the code after the upgrade. If the build fails, then Amazon Q Developer iteratively tries to fix the build by applying necessary code and configuration changes. 
 
 
 Can you update the microservice from Java 8 to Java 21? Also update the spring-boot version to version 3.5.0?   
 
 
 After the project upgrade is complete, validate the pom.xml for Java and Spring Boot versions. Explore the changes made to the Java code. The following example code from pom.xml validates the updated Java and Spring Boot versions: 
 
 
     &lt;properties&gt;
        &lt;java.version&gt;21&lt;/java.version&gt;
    &lt;/properties&gt;
â€¦
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;3.5.0&lt;/version&gt;
        &lt;relativePath/&gt;
    &lt;/parent&gt; 
 
 
 Provide the following prompt to run the application: 
 
 
 Can you run the microservice? 
 
 
 Retest the microservice and make sure that itâ€™s still working as expected. You can use Amazon Q Developer CLI to test, troubleshoot, and fix the upgraded application, if needed. 
 After testing is complete, stop the microservice. Your legacy application is now upgraded to Java 21 and Spring Boot 3.5.0. 
 
Refer to the following video to know more. 

 
  
 
 
Containerize the upgraded application 
Containerize the application so that the application can be run on both x86_64 and ARM64 hardware: 
 
 Use your own words or the following prompt to create docker image for the application Amazon Q Developer creates the Dockerfile for your application and builds it to create images that can be run on x86_64 and ARM64 systems. 
 
 
 Can you containerize this application? Create a Dockerfile, build the container image and tag with "eks-bookstore-java-microservice"? Run and test the endpoints. Make sure the container is built as a multi-architecture image supporting both x86_64 and ARM64.   
 
 
 Explore and validate the Dockerfile created by Amazon Q Developer for your application. 
 Provide the following prompt to run the application on your local system: 
 
 
 Can you run the docker image on my laptop? 
 
 
 Test the microservice using a REST API client or using curl command. When itâ€™s done, stop the docker container using the following prompt: 
 
 
 Stop the container. 
 
Your application is now containerized and tested on the local system. The heavy lifting of the making the code and configuration changes, updating the dependency, and writing Dockerfile is done by Amazon Q Developer. 
Refer to the following video for a demo. 

 
  
 
 
Deploy the application on Amazon EKS 
Deploy the containerized application on Amazon EKS. To do so, create a new EKS cluster and use Helm Chart to deploy the application. Amazon Q Developer CLI uses Amazon EKS MCP server to perform some of these actions. Amazon Q Developer CLI uses the default profile unless instructed to use another. 
 
 Use your own words or the following prompt to push the docker image to an Amazon Elastic Container Registry (Amazon ECR) repository: 
 
 
 Build the Dockerfile and push this image to an Amazon ECR repository called "eks-bookstore-java-microservice" in the AWS account. Provide the image URL once this is complete.   
 
 
 Provide the following prompt to deploy the image into a new EKS cluster using Helm chart: 
 
 
 Create a new Amazon EKS cluster. Deploy the microservice to the EKS cluster using Helm chart. I want to test the microservice over the public Internet. Share the microservice URL to test once done.  
 
 
 Enter the following command in the Amazon Q chat session to check the application pods are running. Alternately, ask Amazon Q chat to get the pods using kubectl: 
 
 
 !kubectl get pods 
 
 
 Test the microservice again to make sure that the deployed application is working as expected. 
 
Your containerized application is now running successfully on the EKS cluster. This completes the migration and modernization of the legacy Java Spring Boot application. 
Refer to the following video for a demo. 

 
  
 
 
Introduce chaos 
In real-world complex applications, while Amazon Q Developer performs the heavy lifting of upgrading, containerizing, and deploying the application on AWS, you might encounter application-specific environmental issues. In this step, youâ€™ll simulate an out-of-memory (OOM) issue by introducing chaos into the system. You can introduce the chaos using one of the below options: 
You can introduce the chaos using AWS Fault Injection Service EKS Pod actions or by following the below steps: 
 
 Apply a patch deployment to reduce memory allocation: 
 
 
 apiVersion: apps/v1
kind: Deployment
metadata:
  name: bookstore-bookstore
spec:
  template:
    spec:
      containers:
      - name: bookstore
        env:
        - name: JAVA_OPTS
          value: "-Xms200m -Xmx200m -XX:+CrashOnOutOfMemoryError"
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
          requests:
            memory: "64Mi"
            cpu: "100m" 
 
 
 Introduce stress: 
 
 
 apiVersion: batch/v1
kind: Job
metadata:
  name: stress-test
spec:
  template:
    spec:
      containers:
      - name: stress-test
        image: polinux/stress
        command: ["stress"]
        args: ["--vm", "1", "--vm-bytes", "350M", "--vm-hang", "0"]
        resources:
          limits:
            memory: "400Mi"
            cpu: "500m"
          requests:
            memory: "200Mi"
            cpu: "200m"
        env:
        - name: TARGET_POD
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      restartPolicy: Never 
 
Wait until the pods crashes with an OOM error. 
Refer to the following video for a demo. 

 
  
 
 
Troubleshoot and fix 
Troubleshoot the issue using Amazon Q Developer CLI with EKS MCP server: 
 
 Use your own words or the following prompt to start troubleshooting the application using Amazon Q Developer CLI. It might take multiple iterations to identify the root cause and potential fix. 
 
 
 I have used Helm chart to deploy the application on EKS cluster. But application is not running. Can you identify the root cause of this the issue and share the potential fix for the issue? 
 
 
 After you validate that Amazon Q Developer CLI can identify the root cause of the issue and suggest a potential solution, provide approval to let it fix the issue: 
 
 
 Please go ahead and fix. 
 
 
 Validate the application is running fine by checking the pod status and invoking the APIs using curl command or a REST API client. 
 
Modifications related to security in Amazon EKS are out of scope for this post. Follow the security best practices before moving into production. Using Amazon Q Developer, you can accelerate the migration and modernization journey, but as the owner of the code, you need to do the due diligence on the changes. 
Due to the inherent nondeterministic nature of the FMs, the responses of the Amazon Q Developer CLI might not be exactly same as those shown in the demo. You need to adjust the prompts accordingly. 
Refer to the following video for a demo. 

 
  
 
 
Clean up 
Properly decommissioning provisioned AWS resources is an important best practice to optimize costs and enhance security posture after concluding proofs of concept and demonstrations. Follow the steps to delete the resources created in your AWS account: 
 
 Use your own words or the following prompt to identify the resources that were created during this demonstration. 
 
 
 I have tested the application. It is time for clean-up. Can you list down the AWS resources that you created for this microservices? Do not delete anything, give me the list. You will delete only after I confirm. 
 
 
 Carefully validate whether Amazon Q Developer has correctly identified only the desired resources to be deleted and then provide approval. If in doubt, manually delete them. 
 
 
 Ok, please go ahead and delete. 
 
 
 Delete the .amazonq/mcp.json file from your workspace folder to remove MCP configuration for Amazon Q Developer CLI. 
 
Conclusion 
In this post, you learned how Amazon Q Developer CLI with Amazon EKS MCP server integration interprets natural language queries, automatically converts them into appropriate commands, and identifies the necessary tools for execution. You upgraded a legacy Java Spring Boot application, then containerized it to support deployment on multi-architectural computes. You deployed the application on Amazon EKS, introduced chaos, and resolved the issues using natural language queries. Using Amazon Q Developer CLI, you can improve your developerâ€™s productivity many times over. We encourage you to explore additional use cases and share your feedback with us! 
Further study 
For more information on Amazon Q Developer CLI and AWS MCP servers: 
 
 Using Amazon Q Developer on the command line 
 Using MCP with Amazon Q Developer 
 AWS MCP Servers 
 AWS MCP Servers GitHub 
 
 
About the authors 
 
Biswanath Mukherjee&nbsp;is a Senior Solutions Architect at Amazon Web Services. He works with large strategic customers of AWS by providing them technical guidance to migrate and modernize their applications on AWS Cloud. With his extensive experience in cloud architecture and migration, he partners with customers to develop innovative solutions that leverage the scalability, reliability, and agility of AWS to meet their business needs. His expertise spans diverse industries and use cases, enabling customers to unlock the full potential of the AWS Cloud. 
Upendra V&nbsp;is a Senior Solutions Architect at Amazon Web Services, specializing in Generative AI and cloud solutions. He helps enterprise customers design and deploy production-ready Generative AI workloads, implement Large Language Models (LLMs) and Agentic AI systems, and optimize cloud deployments. With expertise in cloud adoption and machine learning, he enables organizations to build and scale AI-driven applications efficiently.

â¸»