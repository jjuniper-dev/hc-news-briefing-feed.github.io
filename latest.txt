âœ… Morning News Briefing â€“ September 02, 2025 10:48

ğŸ“… Date: 2025-09-02 10:48
ğŸ·ï¸ Tags: #briefing #ai #publichealth #digitalgov

â¸»

ğŸ§¾ Weather
â€¢ Current Conditions:  11.8Â°C
  Temperature: 11.8&deg;C Pressure / Tendency: 102.2 kPa falling Humidity: 96 % Humidity is 96 % Dewpoint: 11 .2&deg:C Wind: SW 4 km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Tuesday 2 September 2025 . Weather forecast: 10/11
â€¢ Tuesday: Chance of showers. High 25. POP 30%
  30 percent chance of showers this afternoon with risk of thunderstorm . High 25. UV index 6 or high . 30% chance of rain this afternoon; risk of a thunderstorm is possible . High of 25.UV index 6.5 or high; high of 6.6.5.50% UV index is 6.7.50/10.50Â° Caterette .
â€¢ Tuesday night: Chance of showers. Low 12. POP 30%
  30 percent chance of showers early this evening with risk of a thunderstorm . Partly cloudy. Low 12.50% chance of rain this evening . Low 12/10/50/50 . Forecast issued 5:00 AM EDT Tuesday 2 September 2025 . Weather forecast: Showery, thundery, rainy showers, thunderstorms, low humidity, breezes, breezy

ğŸŒ International News
No updates.

ğŸ Canadian News
No updates.

ğŸ‡ºğŸ‡¸ U.S. Top Stories
â€¢ As China commemorates 80th anniversary of WWII, battle over legacy of war continues
  A military parade in Beijing marking the end of World War II will draw leaders from around the world . It's an opportunity for the Communist Party to shape the narrative surrounding the war . The parade will be a chance for China to shape its role in shaping the story of the war's end . The event is expected to attract world leaders from all over the world, including the world's top
â€¢ How one Canadian's misplaced signature caused a diplomatic incident at the end of WWII
  On Sept. 2, 1945, the Japanese and the Allies gathered to mark the end of WWII . The process went smoothly until Col. Lawrence Cosgrave signed his name on the wrong line . Cosgrave was the only person to sign the wrong name in the wrong way . The Japanese and Allies gathered in Japan for the official end of World War II to celebrate the end in 1945 . Cos
â€¢ After his parents' divorce, a guidance counselor's kindness left a lasting mark
  Patrick Furlong's parents divorced when he was in 8th grade . His father left, so he needed to navigate daily routines without a paternal influence in his life . Patrick's life was turbulent after his parents left him with no father in the family . Patrick is the author of a new book, "Furlong, The Hunger Games," on PBS.com/Heroes .
â€¢ Brazil's ex-President Bolsonaro faces coup trial â€” here's what to know
  Brazil's Supreme Court begins the verdict and sentencing phase of Jair Bolsonaro's coup trial Tuesday . Former president faces a possible 40-year sentence . Bolsonara is accused of leading a coup against Brazil's president in the fall of the country's first term . The former president is facing up to 40 years in prison if found guilty of a coup in Brazil's first coup .
â€¢ Starter homes are scarce, so Utah set a target to build more. Here's how it's going
  Utah's leaders worry young people are shut out from building wealth . But despite new incentives, few developers are signing on to build smaller homes . Utah's housing market is one of the country's priciest housing markets . Young people are being shut out of building wealth, but Utah leaders worry they are not being able to afford to build small homes . In Utah, developers are offering incentives to

ğŸ§  Artificial Intelligence
No updates.

ğŸ’» Digital Strategy
â€¢ Huawei counts cost of Western bans as UK business withers
  Brit limb books just Â£188M in revenue â€“ down 85% since 2019 . Huawei's business in Britain has dwindled in the half-decade since the UK acquiesced to demands from the US to ban the Chinese networking giant from local telco networks . The UK has now banned Huawei from local telecoms networks in the past half a decade . Huawei is now just 85% of
â€¢ Frostbyte10 bugs put thousands of refrigerators at major grocery chains at risk
  Copeland controllers are found in thousands of devices used by the world's largest supermarket chains and cold storage companies . They could have allowed miscreants to manipulate temperatures and spoil food and medicine, leading to massive supply-chain disruptions . Patch now available to fix ten vulnerabilities in the controllers, which could have been exploited by miscreachers . The flaws could have led to supply chain disruptions .
â€¢ Reg readers have spoken: 93% back move away from Microsoft in UK public sector
  Register readers back a shift away from Microsoft software as a default across the UK public sector . Government confirms it expects to spend Â£9 billion with the software giant over five years . Government says Â£9B could end up in Redmond, says it's time for new thinking . Register readers are backing a shift from Microsoft to Microsoft software in the public sector, poll says itâ€™s time
â€¢ Europe Putin the blame on Russia after GPS jamming disrupts presidentâ€™s plane
  EU Bloc working on anti-jamming measures and plans extra sat to help . Plane carrying European Commission (EC) president Ursula von der Leyen forced to resort to manual navigation techniques after GPS jamming that authorities have pinned on Russia . Bloc also working on plans to increase the number of extra-sats on the plane to Bulgaria, which was forced to use manual navigation
â€¢ In the rush to adopt hot new tech, security is often forgotten. AI is no exception
  Ciscoâ€™s Talos security research team has found over 1,100 Ollama servers exposed to the public internet . The servers are open to unauthorized access, creating various nasty risks . Cisco finds hundreds of Ollamas servers open to the internet, where miscreants can use them to do nasty things . The company says it is working with the U.S. government to

ğŸ¥ Public Health
No updates.

ğŸ”¬ Science
â€¢ Chinaâ€™s chikungunya virus outbreak is a wake up call
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Veterinarians need to be part of West Nile disease storytelling
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Efficacy of digital interventions for smoking cessation by type and method: a systematic review and network meta-analysis
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Development and validation of a risk prediction model for pulmonary tuberculosis in presumptive tuberculosis patients in Tigray, northern Ethiopia
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
â€¢ Do social-media bans benefit young people? These data could offer clues
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

ğŸ§¾ Government & Policy
No updates.

ğŸ›ï¸ Enterprise Architecture & IT Governance
No updates.

ğŸ¤– AI & Emerging Tech
â€¢ Can an AI doppelgÃ¤nger help me do my job?
  Everywhere I look, I see AI clones. On X and LinkedIn, â€œthought leadersâ€ and influencers offer their followers a chance to ask questions of their digital replicas. OnlyFans creators are having AI models of themselves chat, for a price, with followers. â€œVirtual humanâ€ salespeople in China are reportedly outselling real humans.&nbsp;



Digital clonesâ€”AI models that replicate a specific personâ€”package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But theyâ€™re also offering something the ChatGPTs of the world cannot: an AI thatâ€™s not smart in the general sense, but that &#8216;thinks&#8217; like you do.Â 



Who are they for? Delphi, a startup that recently raised $16 million from funders including Anthropic and actor/director Olivia Wildeâ€™s venture capital firm, Proximity Ventures, helps famous people create replicas that can speak with their fans in both chat and voice calls. It feels like MasterClassâ€”the platform for instructional seminars led by celebritiesâ€”vaulted into the AI age. On its website, Delphi writes that modern leaders â€œpossess potentially life-altering knowledge and wisdom, but their time is limited and access is constrained.â€



It has a library of official clones created by famous figures that you can speak with. Arnold Schwarzenegger, for example, told me, â€œIâ€™m here to cut the crap and help you get stronger and happier,â€ before informing me cheerily that Iâ€™ve now been signed up to receive the Arnoldâ€™s Pump Club newsletter. Even if his or other celebritiesâ€™ clones fall short of Delphiâ€™s lofty vision of spreading â€œpersonalized wisdom at scale,â€ they at least seem to serve as a funnel to find fans, build mailing lists, or sell supplements.



But what about for the rest of us? Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. I could see a replica popping into a virtual meeting with a PR representative, not to trick them into thinking itâ€™s the real me, but simply to take a brief call on my behalf. A recording of this call might summarize how it went.&nbsp;



To find out, I tried making a clone. Tavus, a Y Combinator alum that raised $18 million last year, will build a video avatar of you (plans start at $59 per month) that can be coached to reflect your personality and can join video calls. These clones have the â€œemotional intelligence of humans, with the reach of machines,â€ according to the company. â€œReporterâ€™s assistantâ€ does not appear on the companyâ€™s site as an example use case, but it does mention therapists, physicianâ€™s assistants, and other roles that could benefit from an AI clone.



For Tavusâ€™s onboarding process, I turned on my camera, read through a script to help it learn my voice (which also acted as a waiver, with me agreeing to lend my likeness to Tavus), and recorded one minute of me just sitting in silence. Within a few hours, my avatar was ready. Upon meeting this digital me, I found it looked and spoke like I do (though I hated its teeth). But faking my appearance was the easy part. Could it learn enough about me and what topics I cover to serve as a stand-in with minimal risk of embarrassing me?



Via a helpful chatbot interface, Tavus walked me through how to craft my cloneâ€™s personality, asking what I wanted the replica to do. It then helped me formulate instructions that became its operating manual. I uploaded three dozen of my stories that it could use to reference what I cover. It may have benefited from having more of my contentâ€”interviews, reporting notes, and the likeâ€”but I would never share that data for a host of reasons, not the least of which being that the other people who appear in it have not consented to their sides of our conversations being used to train an AI replica.



So in the realm of AIâ€”where models learn from entire libraries of dataâ€”I didnâ€™t give my clone all that much to learn from, but I was still hopeful it had enough to be useful.&nbsp;



Alas, conversationally it was a wild card. It acted overly excited about story pitches I would never pursue. It repeated itself, and it kept saying it was checking my schedule to set up a meeting with the real me, which it could not do as I never gave it access to my calendar. It spoke in loops, with no way for the person on the other end to wrap up the conversation.&nbsp;



These are common early quirks, Tavusâ€™s cofounder Quinn Favret told me. The clones typically rely on Metaâ€™s Llama model, which â€œoften aims to be more helpful than it truly is,â€ Favret says, and developers building on top of Tavusâ€™s platform are often the ones who set instructions for how the clones finish conversations or access calendars.



For my purposes, it was a bust. To be useful to me, my AI clone would need to show at least some basic instincts for understanding what I cover, and at the very least not creep out whoeverâ€™s on the other side of the conversation. My clone fell short.





Such a clone could be helpful in other jobs, though. If youâ€™re an influencer looking for ways to engage with more fans, or a salesperson for whom work is a numbers game and a clone could give you a leg up, it might just work. You run the risk that your replica could go off the rails or embarrass the real you, but the tradeoffs might be reasonable.&nbsp;



Favret told me some of Tavusâ€™s bigger customers are companies using clones for health-care intake and job interviews. Replicas are also being used in corporate role-play, for practicing sales pitches or having HR-related conversations with employees, for example.



But companies building clones are promising that they will be much more than cold-callers or telemarketing machines. Delphi says its clones will offer â€œmeaningful, personal interactions at infinite scale,â€ and Tavus says its replicas have â€œa face, a brain, and memoriesâ€ that enable â€œmeaningful face-to-face conversations.â€ Favret also told me a growing number of Tavusâ€™s customers are building clones for mentorship and even decision-making, like AI loan officers who use clones to qualify and filter applicants.



Which is sort of the crux of it. Teaching an AI clone discernment, critical thinking, and tasteâ€”never mind the quirks of a specific personâ€”is still the stuff of science fiction. Thatâ€™s all fine when the person chatting with a clone is in on the bit (most of us know that Schwarzeneggerâ€™s replica, for example, will not coach me to be a better athlete).



But as companies polish clones with â€œhumanâ€ features and exaggerate their capabilities, I worry that people chasing efficiency will start using their replicas at best for roles that are cringeworthy, and at worst for making decisions they should never be entrusted with. In the end, these models are designed for scale, not fidelity. They can flatter us, amplify us, even sell for usâ€”but they canâ€™t quite become us.



This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&nbsp;sign up here.
â€¢ Therapists are secretly using ChatGPT. Clients are triggered.
  Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.



â€œSuddenly, I was watching him use ChatGPT,â€ says Declan, 31, who lives in Los Angeles. â€œHe was taking what I was saying and putting it into ChatGPT, and then summarizing or cherry-picking answers.â€



Declan was so shocked he didnâ€™t say anything, and for the rest of the session he was privy to a real-time stream of ChatGPT analysis rippling across his therapistâ€™s screen. The session became even more surreal when Declan began echoing ChatGPT in his own responses, preempting his therapist.&nbsp;



â€œI became the best patient ever,â€ he says, â€œbecause ChatGPT would be like, â€˜Well, do you consider that your way of thinking might be a little too black and white?â€™ And I would be like, â€˜Huh, you know, I think my way of thinking might be too black and white,â€™ and [my therapist would] be like, â€˜Exactly.â€™ Iâ€™m sure it was his dream session.â€



Among the questions racing through Declanâ€™s mind was, â€œIs this legal?â€ When Declan raised the incident with his therapist at the next sessionâ€”â€œIt was super awkward, like a weird breakupâ€â€”the therapist cried. He explained he had felt theyâ€™d hit a wall and had begun looking for answers elsewhere. â€œI was still charged for that session,â€ Declan says, laughing.



The large language model (LLM) boom of the past few years has had unexpected ramifications for the field of psychotherapy, mostly due to the growing number of people substituting the likes of ChatGPT for human therapists. But less discussed is how some therapists themselves are integrating AI into their practice. As in many other professions, generative AI promises tantalizing efficiency savings, but its adoption risks compromising sensitive patient data and undermining a relationship in which trust is paramount.



Suspicious sentiments



Declan is not alone, as I can attest from personal experience. When I received a recent email from my therapist that seemed longer and more polished than usual, I initially felt heartened. It seemed to convey a kind, validating message, and its length made me feel that sheâ€™d taken the time to reflect on all of the points in my (rather sensitive) email.



On closer inspection, though, her email seemed a little strange. It was in a new font, and the text displayed several AI â€œtells,â€ including liberal use of the Americanized em dash (weâ€™re both from the UK), the signature impersonal style, and the habit of addressing each point made in the original email line by line.





My positive feelings quickly drained away, to be replaced by disappointment and mistrust, once I realized ChatGPT likely had a hand in drafting the messageâ€”which my therapist confirmed when I asked her.



Despite her assurance that she simply dictates longer emails using AI, I still felt uncertainty over the extent to which she, as opposed to the bot, was responsible for the sentiments expressed. I also couldnâ€™t entirely shake the suspicion that she might have pasted my highly personal email wholesale into ChatGPT.



When I took to the internet to see whether others had had similar experiences, I found plenty of examples of people receiving what they suspected were AI-generated communiquÃ©s from their therapists. Many, including Declan, had taken to Reddit to solicit emotional support and advice.



So had Hope, 25, who lives on the east coast of the US, and had direct-messaged her therapist about the death of her dog. She soon received a message back. It would have been consoling and thoughtfulâ€”expressing how hard it must be â€œnot having him by your side right nowâ€â€”were it not for the reference to the AI prompt accidentally preserved at the top: â€œHereâ€™s a more human, heartfelt version with a gentle, conversational tone.â€



Hope says she felt â€œhonestly really surprised and confused.â€ â€œIt was just a very strange feeling,â€ she says. â€œThen I started to feel kind of betrayed. â€¦ It definitely affected my trust in her.â€ This was especially problematic, she adds, because â€œpart of why I was seeing her was for my trust issues.â€



Hope had believed her therapist to be competent and empathetic, and therefore â€œnever would have suspected her to feel the need to use AI.â€ Her therapist was apologetic when confronted, and she explained that because sheâ€™d never had a pet herself, sheâ€™d turned to AI for help expressing the appropriate sentiment.&nbsp;



A disclosure dilemmaÂ 



Betrayal or not, there may be some merit to the argument that AI could help therapists better communicate with their clients. A 2025 study published in PLOS Mental Health asked therapists to use ChatGPT to respond to vignettes describing problems of the kind patients might raise in therapy. Not only was a panel of 830 participants unable to distinguish between the human and AI responses, but AI responses were rated as conforming better to therapeutic best practice.&nbsp;



However, when participants suspected responses to have been written by ChatGPT, they ranked them lower. (Responses written by ChatGPT but misattributed to therapists received the highest ratings overall.)&nbsp;



Similarly, Cornell University researchers found in a 2023 study that AI-generated messages can increase feelings of closeness and cooperation between interlocutors, but only if the recipient remains oblivious to the role of AI. The mere suspicion of its use was found to rapidly sour goodwill.



â€œPeople value authenticity, particularly in psychotherapy,â€ says Adrian Aguilera, a clinical psychologist and professor at the University of California, Berkeley. â€œI think [using AI] can feel like, â€˜Youâ€™re not taking my relationship seriously.â€™ Do I ChatGPT a response to my wife or my kids? That wouldnâ€™t feel genuine.â€



In 2023, in the early days of generative AI, the online therapy service Koko conducted a clandestine experiment on its users, mixing in responses generated by GPT-3 with ones drafted by humans. They discovered that users tended to rate the AI-generated responses more positively. The revelation that users had unwittingly been experimented on, however, sparked outrage.



The online therapy provider BetterHelp has also been subject to claims that its therapists have used AI to draft responses. In a Medium post, photographer Brendan Keen said his BetterHelp therapist admitted to using AI in their replies, leading to â€œan acute sense of betrayalâ€ and persistent worry, despite reassurances, that his data privacy had been breached. He ended the relationship thereafter.&nbsp;



A BetterHelp spokesperson told us the company â€œprohibits therapists from disclosing any memberâ€™s personal or health information to third-party artificial intelligence, or using AI to craft messages to members to the extent it might directly or indirectly have the potential to identify someone.â€



All these examples relate to undisclosed AI usage. Aguilera believes time-strapped therapists can make use of LLMs, but transparency is essential. â€œWe have to be up-front and tell people, â€˜Hey, Iâ€™m going to use this tool for X, Y, and Zâ€™ and provide a rationale,â€ he says. People then receive AI-generated messages with that prior context, rather than assuming their therapist is â€œtrying to be sneaky.â€



Psychologists are often working at the limits of their capacity, and levels of burnout in the profession are high, according to 2023 research conducted by the American Psychological Association. That context makes the appeal of AI-powered tools obvious.&nbsp;



But lack of disclosure risks permanently damaging trust. Hope decided to continue seeing her therapist, though she stopped working with her a little later for reasons she says were unrelated. â€œBut I always thought about the AI Incident whenever I saw her,â€ she says.



Risking patient privacy



Beyond the transparency issue, many therapists are leery of using LLMs in the first place, says Margaret Morris, a clinical psychologist and affiliate faculty member at the University of Washington.



â€œI think these tools might be really valuable for learning,â€ she says, noting that therapists should continue developing their expertise over the course of their career. â€œBut I think we have to be super careful about patient data.â€ Morris calls Declanâ€™s experience â€œalarming.â€&nbsp;



Therapists need to be aware that general-purpose AI chatbots like ChatGPT are not approved by the US Food and Drug Administration and are not HIPAA compliant, says Pardis Emami-Naeini, assistant professor of computer science at Duke University, who has researched the privacy and security implications of LLMs in a health context. (HIPAA is a set of US federal regulations that protect peopleâ€™s sensitive health information.)



â€œThis creates significant risks for patient privacy if any information about the patient is disclosed or can be inferred by the AI,â€ she says.



In a recent paper, Emami-Naeini found that many users wrongly believe ChatGPT is HIPAA compliant, creating an unwarranted sense of trust in the tool. â€œI expect some therapists may share this misconception,â€ she says.



As a relatively open person, Declan says, he wasnâ€™t completely distraught to learn how his therapist was using ChatGPT. â€œPersonally, I am not thinking, â€˜Oh, my God, I have deep, dark secrets,â€™â€ he said. But it did still feel violating: â€œI can imagine that if I was suicidal, or on drugs, or cheating on my girlfriend â€¦ I wouldnâ€™t want that to be put into ChatGPT.â€



When using AI to help with email, â€œitâ€™s not as simple as removing obvious identifiers such as names and addresses,â€ says Emami-Naeini. â€œSensitive information can often be inferred from seemingly nonsensitive details.â€



She adds, â€œIdentifying and rephrasing all potential sensitive data requires time and expertise, which may conflict with the intended convenience of using AI tools. In all cases, therapists should disclose their use of AI to patients and seek consent.â€&nbsp;



A growing number of companies, including Heidi Health, Upheal, Lyssn, and Blueprint, are marketing specialized tools to therapists, such as AI-assisted note-taking, training, and transcription services. These companies say they are HIPAA compliant and store data securely using encryption and pseudonymization where necessary. But many therapists are still wary of the privacy implicationsâ€”particularly of services that necessitate the recording of entire sessions.



â€œEven if privacy protections are improved, there is always some risk of information leakage or secondary uses of data,â€ says Emami-Naeini.



A 2020 hack on a Finnish mental health company, which resulted in tens of thousands of clientsâ€™ treatment records being accessed, serves as a warning. People on the list were blackmailed, and subsequently the entire trove was publicly released, revealing extremely sensitive details such as peoplesâ€™ experiences of child abuse and addiction problems.



What therapists stand to lose



In addition to violation of data privacy, other risks are involved when psychotherapists consult LLMs on behalf of a client. Studies have found that although some specialized therapy bots can rival human-delivered interventions, advice from the likes of ChatGPT can cause more harm than good.



A recent Stanford University study, for example, found that chatbots can fuel delusions and psychopathy by blindly validating a user rather than challenging them, as well as suffer from biases and engage in sycophancy. The same flaws could make it risky for therapists to consult chatbots on behalf of their clients. They could, for example, baselessly validate a therapistâ€™s hunch, or lead them down the wrong path.



Aguilera says he has played around with tools like ChatGPT while teaching mental health trainees, such as by entering hypothetical symptoms and asking the AI chatbot to make a diagnosis. The tool will produce lots of possible conditions, but itâ€™s rather thin in its analysis, he says. The American Counseling Association recommends that AI not be used for mental health diagnosis at present.



A study published in 2024 of an earlier version of ChatGPT similarly found it was too vague and general to be truly useful in diagnosis or devising treatment plans, and it was heavily biased toward suggesting people seek cognitive behavioral therapy as opposed to other types of therapy that might be more suitable.



Daniel Kimmel, a psychiatrist and neuroscientist at Columbia University, conducted experiments with ChatGPT where he posed as a client having relationship troubles. He says he found the chatbot was a decent mimic when it came to â€œstock-in-tradeâ€ therapeutic responses, like normalizing and validating, asking for additional information, or highlighting certain cognitive or emotional associations.



However, â€œit didnâ€™t do a lot of digging,â€ he says. It didnâ€™t attempt â€œto link seemingly or superficially unrelated things together into something cohesive â€¦ to come up with a story, an idea, a theory.â€



â€œI would be skeptical about using it to do the thinking for you,â€ he says. Thinking, he says, should be the job of therapists.



Therapists could save time using AI-powered tech, but this benefit should be weighed against the needs of patients, says Morris: â€œMaybe youâ€™re saving yourself a couple of minutes. But what are you giving away?â€
â€¢ The Download: AI doppelgÃ¤ngers in the workplace, and using lidar to measure climate disasters
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Â Can an AI doppelgÃ¤nger help me do my job?



â€”James O&#8217;Donnell



Digital clonesâ€”AI models that replicate a specific personâ€”package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention.&nbsp;



But theyâ€™re also offering something the ChatGPTs of the world cannot: an AI thatâ€™s not smart in the general sense, but that â€˜thinksâ€™ like you do.Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. To find out, I tried making a clone of myself. Read the full story to find out how it got on.



This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.







How lidar measures the cost of climate disasters



The wildfires that swept through Los Angeles County this January left an indelible mark on the Southern California landscape. The Eaton and Palisades fires raged for 24 days, killing 29 people and destroying 16,000 structures, with losses estimated at $60 billion. More than 55,000 acres were consumed, and the landscape itself was physically transformed.



Now, researchers are using lidar (light detection and ranging) technology to precisely measure these changes in the landscapeâ€™s geometryâ€”helping them understand and track the cascading effects of climate disasters. Read the full story.â€”Jon KeeganThis story is from our new print edition, which is all about the future of security. Subscribe here to catch future copies when they land.







Hereâ€™s how we picked this yearâ€™s Innovators Under 35



Next Monday weâ€™ll publish our 2025 list of Innovators Under 35. The list highlights smart and talented people working across many areas of emerging technology. This new class features 35 accomplished founders, hardware engineers, roboticists, materials scientists, and others who are already tackling tough problems and making big moves in their careers.Â 



MIT Technology Review first published a list of Innovators Under 35 in 1999. Itâ€™s a grand tradition for us, and we often follow the work of various featured innovators for years, even decades, after they appear on the list. So before the big announcement, weâ€™d like to take a moment to explain how we select the people we recognize each year. Read the full story.



â€”Amy Nordrum







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 Meta created flirty chatbots of celebrities without their permissionTo make matters worse, the bots generated risquÃ© pictures on demand. (Reuters)+ Metaâ€™s relationship with Scale AI appears to be under pressure. (TechCrunch)+ An AI companion site is hosting sexually charged conversations with underage celebrity bots. (MIT Technology Review)



2 The FTC has warned Big Tech not to comply with EU lawsIf they jeopardize the freedom of expression or safety of US citizens, at least. (Wired $)



3 Ukraine is using drones to drop supplies to its troops in trenchesTheyâ€™re delivering everything from cigarettes to roasted chicken. (WP $)+ Meet the radio-obsessed civilian shaping Ukraineâ€™s drone defense. (MIT Technology Review)



4 What the collapse of this AI company says about the wider industryBuilder.ai was an early industry darling. Its downfall is a dire warning. (NYT $)



5 US shoppers are racing to land an EV bargainFederal tax credits on the vehicles expire at the end of the month. (WSJ $)+ The US could really use an affordable electric truck. (MIT Technology Review)



6 A major new project will use AI to research vaccinesThe Oxford Vaccine Group hopes the jabs will protect against deadly pathogens. (FT $)+ Why US federal health agencies are abandoning mRNA vaccines. (MIT Technology Review)



7 A lot of people stop taking weight-loss drugs within one yearHow should doctors encourage the ones who need to stay on them? (Undark)+ Weâ€™re learning more about what weight-loss drugs do to the body. (MIT Technology Review)



8 Chatbots can be manipulated into breaking their own rulesIt turns out theyâ€™re susceptible to both flattery and peer pressure. (The Verge)+ Forcing LLMs to be evil during training can make them nicer in the long run. (MIT Technology Review)



9 Tennis is trying to reach a new generation of fans Throughâ€¦the metaverse? (The Information $)10 The age of cheap online shopping is endingAnd consumers are the ones paying the price. (The Atlantic $)+ AI is starting to shake up the digital shopping experience, too. (FT $)+ Your most important customer may be AI. (MIT Technology Review)







Quote of the day



â€œStop being a clanker!â€



â€”How Jay Pinkert, a marketing manager, scolds ChatGPT when it isnâ€™t fulfilling his requests, he tells the New York Times.







One more thing







The algorithms around usA metronome ticks. A record spins. And as a feel-good pop track plays, a giant compactor slowly crushes a Jenga tower of material creations. Paint cans burst. Chess pieces topple. Camera lenses shatter. An alarm clock shrills and then goes silent. A guitar neck snaps. But wait! The jaunty tune starts up again, and the jaws open to reveal â€¦ an iPad.Watching Appleâ€™s now-infamous â€œCrush!â€ ad, itâ€™s hard not to feel uneasy about the ways in which digitization is remaking human life. Sure, weâ€™re happy for computers to take over tasks we donâ€™t want to do or arenâ€™t particularly good at, like shopping or navigating. But what does it mean when the things we hold dear and thought were uniquely oursâ€”our friendships, our art, even our language and creativityâ€”can be reduced to software? Read the full story.



â€”Ariel Bleicher







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Minnesotaâ€™s Llama-Alpaca Costume Contest looks an utter delightÂ  (thanks Amy!)+ In fascinating collab news, David Byrne and Paramoreâ€™s Hayley Williams are working on a song for a Netflix adaptation of Roald Dahlâ€™s The Twits.+ Happy birthday to Gloria Estefan, 68 years old today!+ M. Night Shyamalanâ€™s oeuvre is a decidedly mixed bag. Check out this list of his movies to see where your favorites (and least-favorites) rank.
â€¢ Hereâ€™s how we picked this yearâ€™s Innovators Under 35
  Next week, weâ€™ll publish our 2025 list of Innovators Under 35, highlighting smart and talented people who are working in many areas of emerging technology. This new class features 35 accomplished founders, hardware engineers, roboticists, materials scientists, and others who are already tackling tough problems and making big moves in their careers. All are under the age of 35.&nbsp;





One is developing a technology to reduce emissions from shipping, while two others are improving fertility treatments and creating new forms of contraception. Another is making it harder for people to maliciously share intimate images online. And quite a few are applying artificial intelligence to their respective fields in novel ways.&nbsp;



Weâ€™ll also soon reveal our 2025 Innovator of the Year, whose technical prowess is helping physicians diagnose and treat critically ill patients more quickly. Whatâ€™s more (hereâ€™s your final hint), our winner even set a world record as a result of this work.&nbsp;



MIT Technology Review first published a list of Innovators Under 35 in 1999. Itâ€™s a grand tradition for us, and we often follow the work of various featured innovators for years, even decades, after they appear on the list. So before the big announcement, I want to take a moment to explain how we select the people we recognize each year.&nbsp;



Step 1: Call for nominations



Our process begins with a call for nominations, which typically goes out in the final months of the previous year and is open to anyone, anywhere in the world. We encourage people to nominate themselves, which takes just a few minutes. This method helps us discover people doing important work that we might not otherwise encounter.&nbsp;



This year we had 420 nominations. Two-thirds of our candidates were put forward by someone else and one-third nominated themselves. We received nominations for people located in about 40 countries. Nearly 70% were based in the United States, with the UK, Switzerland, China, and the United Arab Emirates, respectively, having the next-highest concentrations.&nbsp;



After nominations close, a few editors then spend several weeks reviewing the nominees and selecting semifinalists. During this phase, we look for people who have developed practical solutions to societal issues or made important scientific advances that could translate into new technologies. Their work should have the potential for broad impactâ€”it canâ€™t be niche or incremental. And whatâ€™s unique about their approach must be clear.&nbsp;



Step 2: Semifinalist applications&nbsp;



This year, we winnowed our initial list of hundreds of nominees to 108 semifinalists. Then we asked those entrants for more information to help us get to know them better and evaluate their work.&nbsp;



We request three letters of reference and a rÃ©sumÃ© from each semifinalist, and we ask all of them to answer a few short questions about their work. We also give them the option to share a video or pass along relevant journal articles or other links to help us learn more about what they do.



Step 3: Expert judges weigh in



Next, we bring in dozens of experts to vet the semifinalists. This year, 38 judges evaluated and scored the applications. We match the contenders with judges who work in similar fields whenever possible. At least two judges review each entrant, though most are seen by three.&nbsp;



All these judges volunteer their time, and some return to help year after year. A few of our longtime judges include materials scientists Yet-Ming Chiang (MIT) and Julia Greer (Caltech), MIT neuroscientist Ed Boyden, and computer scientist Ben Zhao of the University of Chicago.&nbsp;



John Rogers, a materials scientist and biomedical engineer at Northwestern University, has been a judge for more than a decade (and was featured on our very first Innovators list, in 1999). Hereâ€™s what he had to say about why he stays involved: â€œThis award is compelling because it recognizes young people with scientific achievements that are not only of fundamental interest but also of practical significance, at the highest levels.â€&nbsp;



Step 4: Editors make the final calls&nbsp;



In a final layer of vetting, editors who specialize in covering biotechnology, climate and energy, and artificial intelligence review the semifinalists whom judges scored highly in their respective areas. Staff editors and reporters can also nominate people theyâ€™ve come across in their coverage, and we add them to the mix for consideration.&nbsp;



Last, a small team of senior editors reviews all the semifinalists and the judgesâ€™ scores, as well as our own staffâ€™s recommendations, and selects 35 honorees. We aim for a good combination of people from a variety of disciplines working in different regions of the world. And we take a staff vote to pick an Innovator of the Yearâ€”someone whose work we particularly admire.&nbsp;



In the end, itâ€™s impossible to include every deserving individual on our list. But by incorporating both external nominations and outside expertise from our judges, we aim to make the evaluation process as rigorous and open as possible.&nbsp;&nbsp;



So who made the cut this year? Come back on September 8 to find out.
â€¢ The Download: humans in space, and Indiaâ€™s thorium ambitions
  This is today&#8217;s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



The case against humans in space



Elon Musk and Jeff Bezos are bitter rivals in the commercial space race, but they agree on one thing: Settling space is an existential imperative. Space is the place. The final frontier. It is our human destiny to transcend our home world and expand our civilization to extraterrestrial vistas.This belief has been mainstream for decades, but its rise has been positively meteoric in this new gilded age of astropreneurs.But as visions of giant orbital stations and Martian cities dance in our heads, a case against human space colonization has found its footing in a number of recent books, from doubts about the practical feasibility of off-Earth communities, to realism about the harsh environment of space and the enormous tax it would exact on the human body. Read the full story.â€”Becky Ferreira



This story is from our new print edition, which is all about the future of security. Subscribe here to catch future copies when they land.







This American nuclear company could help Indiaâ€™s thorium dream



For just the second time in nearly two decades, the United States has granted an export license to an American company planning to sell nuclear technology to India, MIT Technology Review has learned.&nbsp;



The decision to greenlight Clean Core Thorium Energyâ€™s license is a major step toward closer cooperation between the two countries on atomic energy and marks a milestone in the development of thorium as an alternative to uranium for fueling nuclear reactors. Read more about why itâ€™s such a big deal.



â€”Alexander C. Kaufman







RFK Jrâ€™s plan to improve Americaâ€™s diet is missing the point



A lot of Americans donâ€™t eat well. And theyâ€™re paying for it with their health. A diet high in sugar, sodium, and saturated fat can increase the risk of problems like diabetes, heart disease, and kidney disease, to name a few. And those are among the leading causes of death in the US.



This is hardly news. But this week Robert F Kennedy Jr., who heads the US Department of Health and Human Services, floated a new solution to the problem: teaching medical students more about the role of nutrition in health could help turn things around.



It certainly sounds like a good idea. If more Americans ate a healthier diet, we could expect to see a decrease in those diseases.&nbsp;



But this framing of Americaâ€™s health crisis is overly simplistic, especially given that plenty of the administrationâ€™s other actions have directly undermined health in multiple waysâ€”including by canceling a vital nutrition education program. And at any rate, there are other, more effective ways to tackle the chronic-disease crisis. Read the full story.



â€”Jessica Hamzelou



This article first appeared in The Checkup, MIT Technology Reviewâ€™s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.







The must-reads



Iâ€™ve combed the internet to find you todayâ€™s most fun/important/scary/fascinating stories about technology.



1 RFK Jrâ€™s deputy has been chosen to be the new acting head of the CDCJim Oâ€™Neill is likely to greenlight his bossâ€™s federal vaccine policy plans. (WP $)+ The future of the department looks decidedly precarious. (The Atlantic $)+ Everything you need to know about Jim Oâ€™Neill, the longevity enthusiast who is now RFK Jr.â€™s right-hand man. (MIT Technology Review)



2 A man killed his mother and himself after conversing with ChatGPTThe chatbot encouraged Stein-Erik Soelbergâ€™s paranoia while repeatedly assuring him he was sane. (WSJ $)+ An AI chatbot told a user how to kill himselfâ€”but the company doesnâ€™t want to â€œcensorâ€ it. (MIT Technology Review)



3 China is cracking down on excess competition in its AI sectorThe country is hellbent on avoiding wasteful investment. (Bloomberg $)+ China is laser-focused on engineering, not so much on litigating. (Wired $)+ China built hundreds of AI data centers to catch the AI boom. Now many stand unused. (MIT Technology Review)



4 The EU should be prepared to walk away from a US trade dealIts competition commissioner worries Trump may act on his threats to target the bloc. (FT $)+ The French President had a similar warning for his ministers. (Politico)



5 xAI has released a new Grok agentic coding modelAt a significantly lower price than its rivals. (Reuters)+ This no-code website builder has been valued at $2 billion. (TechCrunch)+ The second wave of AI coding is here. (MIT Technology Review)



6 A US mail change has thrown online businesses into turmoilAll package deliveries are due to face duties from this week. (Insider $)



7 A former DOGE official is running Americaâ€™s biggest MDMA companyAnd Antonio Gracias is not the only member of the department with ties to the psychedelics industry. (The Guardian)+ Other DOGE workers are joining Trumpâ€™s new National Design Studio. (Wired $)+ The FDA said no to the use of MDMA as a therapy last year. (MIT Technology Review)



8 How chatbots fake having personalitiesThey have no persistent selfâ€”despite what they may tell you. (Ars Technica)+ What is AI? (MIT Technology Review)



9 The future of podcasting is murkyHundreds of shows have folded. The medium is in desperate need of an archive. (NY Mag $)+ The race to save our online lives from a digital dark age. (MIT Technology Review)10 Do we even know what we want to watch anymore?Weâ€™re so reliant on algorithms, itâ€™s hard to know. (New Yorker $)







Quote of the day



â€œWeâ€™re scared for ourselves and for the country.â€&nbsp;



â€”An anonymous CDC worker tells the New York Times about the mood inside the agency following the firing of their new director Susan Monarez.







One more thing







How a tiny Pacific Island became the global capital of cybercrimeTokelau, a string of three isolated atolls strung out across the Pacific, is so remote that it was the last place on Earth to be connected to the telephoneâ€”only in 1997. Just three years later, the islands received a fax with an unlikely business proposal that would change everything.



It was from an early internet entrepreneur from Amsterdam, named Joost Zuurbier. He wanted to manage Tokelauâ€™s country-code top-level domain, or ccTLDâ€”the short string of characters that is tacked onto the end of a URLâ€”in exchange for money.



In the succeeding years, tiny Tokelau became an unlikely internet giantâ€”but not in the way it may have hoped. Until recently, its .tk domain had more users than any other countryâ€™s: a staggering 25 millionâ€”but the vast majority were spammers, phishers, and cybercriminals.



Now the territory is desperately trying to clean up .tk. Its international standing, and even its sovereignty, may depend on it. Read the full story.Â â€”Jacob Judah







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ Scientists are using yeast to help save the bees.+ How to become super productive + Why North American mammoths were genetic freaks of nature.+ I love Sealâ€™s steadfast refusal to explain his lyrics to Kiss from a Rose.

ğŸ”’ Cybersecurity & Privacy
â€¢ The Ongoing Fallout from a Breach at AI Chatbot Maker Salesloft
  The recent mass-theft of authentication tokens from Salesloft, whose AI chatbot is used by a broad swath of corporate America to convert customer interaction into Salesforce leads, has left many companies racing to invalidate the stolen credentials before hackers can exploit them. Now Google warns the breach goes far beyond access to Salesforce data, noting the hackers responsible also stole valid authentication tokens for hundreds of online services that customers can integrate with Salesloft, including Slack, Google Workspace, Amazon S3, Microsoft Azure, and OpenAI.
Salesloft says its products are trusted by 5,000+ customers. Some of the bigger names are visible on the company&#8217;s homepage.
Salesloft disclosed on August 20 that, &#8220;Today, we detected a security issue in the Drift application,&#8221; referring to the technology that powers an AI chatbot used by so many corporate websites. The alert urged customers to re-authenticate the connection between the Drift and Salesforce apps to invalidate their existing authentication tokens, but it said nothing then to indicate those tokens had already been stolen.
On August 26, the Google Threat Intelligence Group (GTIG) warned that unidentified hackers tracked as UNC6395 used the access tokens stolen from Salesloft to siphon large amounts of data from numerous corporate Salesforce instances. Google said the data theft began as early as Aug. 8, 2025 and lasted through at least Aug. 18, 2025, and that the incident did not involve any vulnerability in the Salesforce platform.
Google said the attackers have been sifting through the massive data haul for credential materials such as AWS keys, VPN credentials, and credentials to the cloud storage provider Snowflake.
&#8220;If successful, the right credentials could allow them to further compromise victim and client environments, as well as pivot to the victim&#8217;s clients or partner environments,&#8221; the GTIG report stated.
The GTIG updated its advisory on August 28 to acknowledge the attackers used the stolen tokens to access email from &#8220;a very small number of Google Workstation accounts&#8221; that were specially configured to integrate with Salesloft. More importantly, it warned organizations to immediately invalidate all tokens stored in or connected to their Salesloft integrations &#8212; regardless of the third-party service in question.
&#8220;Given GTIG&#8217;s observations of data exfiltration associated with the campaign, organizations using Salesloft Drift to integrate with third-party platforms (including but not limited to Salesforce) should consider their data compromised and are urged to take immediate remediation steps,&#8221; Google advised.
On August 28, Salesforce blocked Drift from integrating with its platform, and with its productivity platforms Slack and Pardot.
The Salesloft incident comes on the heels of a broad social engineering campaign that used voice phishing to trick targets into connecting a malicious app to their organization&#8217;s Salesforce portal. That campaign led to data breaches and extortion attacks affecting a number of companies including Adidas, Allianz Life and Qantas.
On August 5, Google disclosed that one of its corporate Salesforce instances was compromised by the attackers, which the GTIG has dubbed UNC6040 (&#8220;UNC&#8221; is Google&#8217;s shorthand for &#8220;uncategorized threat group&#8221;). Google said the extortionists consistently claimed to be the threat group ShinyHunters,Â and that the group appeared to be preparing to escalate its extortion attacks by launching a data leak site.
ShinyHunters is an amorphous threat group known for using social engineering to break into cloud platforms and third-party IT providers, and for posting dozens of stolen databases to cybercrime communities like the now-defunct Breachforums.
The ShinyHunters brand dates back to 2020, and the group has been credited with or taken responsibility for dozens of data leaks that exposed hundreds of millions of breached records. The group&#8217;s member roster is thought to be somewhat fluid, drawing mainly from active denizens of the Com, a mostly English-language cybercrime community scattered across an ocean of Telegram and Discord servers.
Recorded Future&#8217;s Alan Liska told Bleeping Computer that the overlap in the &#8220;tools, techniques and procedures&#8221; used by ShinyHunters and the Scattered Spider extortion group likely indicate some crossover between the two groups.
To muddy the waters even further, on August 28 a Telegram channel that now has nearly 40,000 subscribers was launched under the intentionally confusing banner &#8220;Scattered LAPSUS$ Hunters 4.0,&#8221; wherein participants have repeatedly claimed responsibility for the Salesloft hack without actually sharing any details to prove their claims.
The Telegram group has been trying to attract media attention by threatening security researchers at Google and other firms. It also is using the channel&#8217;s sudden popularity to promote a new cybercrime forum called &#8220;Breachstars,&#8221; which they claim will soon host data stolen from victim companies who refuse to negotiate a ransom payment.
The &#8220;Scattered Lapsus$ Hunters 4.0&#8221; channel on Telegram now has roughly 40,000 subscribers.
But Austin Larsen, a principal threat analyst at Google&#8217;s threat intelligence group, said there is no compelling evidence to attribute the Salesloft activity to ShinyHunters or to other known groups at this time.
&#8220;Their understanding of the incident seems to come from public reporting alone,&#8221; Larsen told KrebsOnSecurity, referring to the most active participants in the Scattered LAPSUS$ Hunters 4.0 Telegram channel.
Joshua Wright, a senior technical director at Counter Hack,Â is credited with coining the term &#8220;authorization sprawl&#8221; to describe one key reason that social engineering attacks from groups like Scattered Spider and ShinyHunters so often succeed: They abuse legitimate user access tokens to move seamlessly between on-premises and cloud systems.
Wright said this type of attack chain often goes undetected because the attacker sticks to the resources and access already allocated to the user.
&#8220;Instead of the conventional chain of initial access, privilege escalation and endpoint bypass, these threat actors are using centralized identity platforms that offer single sign-on (SSO) and integrated authentication and authorization schemes,&#8221; Wright wrote in a June 2025 column. &#8220;Rather than creating custom malware, attackers use the resources already available to them as authorized users.&#8221;
It remains unclear exactly how the attackers gained access to all Salesloft Drift authentication tokens. Salesloft announced on August 27 that it hired Mandiant, Google Cloud&#8217;s incident response division, to investigate the root cause(s).
&#8220;We are working with Salesloft Drift to investigate the root cause of what occurred and then itâ€™ll be up to them to publish that,&#8221; Mandiant Consulting CTO Charles Carmakal told Cyberscoop. &#8220;There will be a lot more tomorrow, and the next day, and the next day.&#8221;
â€¢ Affiliates Flock to â€˜Soullessâ€™ Scam Gambling Machine
  Last month, KrebsOnSecurity tracked the sudden emergence of hundreds of polished online gaming and wagering websites that lure people with free credits and eventually abscond with any cryptocurrency funds deposited by players. We&#8217;ve since learned that these scam gambling sites have proliferated thanks to a new Russian affiliate program called &#8220;Gambler Panel&#8221; that bills itself as a &#8220;soulless project that is made for profit.&#8221;
A machine-translated version of Gambler Panel&#8217;s affiliate website.
The scam begins with deceptive ads posted on social media that claim the wagering sites are working in partnership with popular athletes or social media personalities. The ads invariably state that by using a supplied &#8220;promo code,&#8221; interested players can claim a $2,500 credit on the advertised gaming website.
The gaming sites ask visitors to create a free account to claim their $2,500 credit, which they can use to play any number of extremely polished video games that ask users to bet on each action. However, when users try to cash out any &#8220;winnings&#8221; the gaming site will reject the request and prompt the user to make a â€œverification depositâ€ of cryptocurrency â€” typically around $100 â€” before any money can be distributed.
Those who deposit cryptocurrency funds are soon pressed into more wagering and making additional deposits. And &#8212; shocker alert &#8212; all players eventually lose everything they&#8217;ve invested in the platform.
The number of scam gambling or &#8220;scambling&#8221; sites has skyrocketed in the past month, and now we know why: The sites all pull their gaming content and detailed strategies for fleecing players straight from the playbook created by Gambler Panel, a Russian-language affiliate program that promises affiliates up to 70 percent of the profits.

Gambler Panel&#8217;s website gambler-panel[.]com links to a helpful wiki that explains the scam from cradle to grave, offering affiliates advice on how best to entice visitors, keep them gambling, and extract maximum profits from each victim.
&#8220;We have a completely self-written from scratch FAKE CASINO engine that has no competitors,&#8221; Gambler Panel&#8217;s wiki enthuses. &#8220;Carefully thought-out casino design in every pixel, a lot of audits, surveys of real people and test traffic floods were conducted, which allowed us to create something that has no doubts about the legitimacy and trustworthiness even for an inveterate gambling addict with many years of experience.&#8221;
Gambler Panel explains that the one and only goal of affiliates is to drive traffic to these scambling sites by any and all means possible.
A machine-translated portion of Gambler Panel&#8217;s singular instruction for affiliates: Drive traffic to these scambling sites by any means available.
&#8220;Unlike white gambling affiliates, we accept absolutely any type of traffic, regardless of origin, the only limitation is the CIS countries,&#8221; the wiki continued, referring to a common prohibition against scamming people in Russia and former Soviet republics in the Commonwealth of Independent States.
The program&#8217;s website claims it has more than 20,000 affiliates, who earn a minimum of $10 for each verification deposit. Interested new affiliates must first get approval from the group&#8217;s Telegram channel, which currently has around 2,500 active users.
The Gambler Panel channel is replete with images of affiliate panels showing the daily revenue of top affiliates, scantily-clad young women promoting the Gambler logo, and fast cars that top affiliates claimed they bought with their earnings.
A machine-translated version of the wiki for the affiliate program Gambler Panel.
The apparent popularity of this scambling niche is a consequence of the program&#8217;s ease of use and detailed instructions for successfully reproducing virtually every facet of the scam. Indeed, much of the tutorial focuses on advice and ready-made templates to help even novice affiliates drive traffic via social media websites, particularly on Instagram and TikTok.
Gambler Panel also walks affiliates through a range of possible responses to questions from users who are trying to withdraw funds from the platform. This section, titled &#8220;Rules for working in Live chat,&#8221; urges scammers to respond quickly to user requests (1-7 minutes), and includes numerous strategies for keeping the conversation professional and the user on the platform as long as possible.
A machine-translated version of the Gambler Panel&#8217;s instructions on managing chat support conversations with users.
The connection between Gambler Panel and the explosion in the number of scambling websites was made by a 17-year-old developer who operates multiple Discord servers that have been flooded lately with misleading ads for these sites.
The researcher, who asked to be identified only by the nickname &#8220;Thereallo,&#8221; said Gambler Panel has built a scalable business product for other criminals.
&#8220;The wiki is kinda like a &#8216;how to scam 101&#8217; for criminals written with the clarity you would expect from a legitimate company,&#8221; Thereallo said. &#8220;It&#8217;s clean, has step by step guides, and treats their scam platform like a real product. You could swap out the content, and it could be any documentation for startups.&#8221;
&#8220;They&#8217;ve minimized their own risk &#8212; spreading the links on Discord / Facebook / YT Shorts, etc. &#8212; and outsourced it to a hungry affiliate network, just like a franchise,&#8221; Thereallo wrote in response to questions.
&#8220;A centralized platform that can serve over 1,200 domains with a shared user base, IP tracking, and a custom API is not at all a trivial thing to build,&#8221; Thereallo said. &#8220;It&#8217;s a scalable system designed to be a resilient foundation for thousands of disposable scam sites.&#8221;
The security firm Silent Push has compiled a list of the latest domains associated with the Gambler Panel, available here (.csv).

ğŸ“ University AI
No updates.

ğŸ¢ Corporate AI
â€¢ Detect Amazon Bedrock misconfigurations with Datadog Cloud Security
  This post was co-written with Nick Frichette and Vijay George from Datadog.&nbsp; 
As organizations increasingly adopt Amazon Bedrock for generative AI applications, protecting against misconfigurations that could lead to data leaks or unauthorized model access becomes critical. The AWS Generative AI Adoption Index, which surveyed 3,739 senior IT decision-makers across nine countries, revealed that 45% of organizations selected generative AI tools as their top budget priority in 2025. As more AWS and Datadog customers accelerate their adoption of AI, building AI security into existing processes will become essential, especially as more stringent regulations emerge. But looking at AI risks in a silo isnâ€™t enough; AI risks must be contextualized alongside other risks such as identity exposures and misconfigurations. The combination of Amazon Bedrock and Datadogâ€™s comprehensive security monitoring helps organizations innovate faster while maintaining robust security controls. 
Amazon Bedrock delivers enterprise-grade security by incorporating built-in protections across data privacy, access controls, network security, compliance, and responsible AI safeguards. Customer data is encrypted both in transit using TLS 1.2 or above and at rest with AWS Key Management Service (AWS KMS), and organizations have full control over encryption keys. Data privacy is central: your input, prompts, and outputs are not shared with model providers nor used to train or improve foundation models (FMs). Fine-tuning and customizations occur on private copies of models, providing data confidentiality. Access is tightly governed through AWS Identity and Access Management (IAM) and resource-based policies, supporting granular authorization for users and roles. Amazon Bedrock integrates with AWS PrivateLink and supports virtual private cloud (VPC) endpoints for private, internal communication, so traffic doesnâ€™t leave the Amazon network. The service complies with key industry standards such as ISO, SOC, CSA STAR, HIPAA eligibility, GDPR, and FedRAMP High, making it suitable for regulated industries. Additionally, Amazon Bedrock includes configurable guardrails to filter sensitive or harmful content and promote responsible AI use. Security is structured under the AWS Shared Responsibility Model, where AWS manages infrastructure security and customers are responsible for secure configurations and access controls within their Amazon Bedrock environment. 
Building on these robust AWS security features, Datadog and AWS have partnered to provide a holistic view of AI infrastructure risks, vulnerabilities, sensitive data exposure, and other misconfigurations. Datadog Cloud Security employs both agentless and agent-based scanning to help organizations identify, prioritize, and remediate risks across cloud resources. This integration helps AWS users prioritize risks based on business criticality, with security findings enriched by observability data, thereby enhancing their overall security posture in AI implementations. 
Weâ€™re excited to announce new security capabilities in Datadog Cloud Security that can help you detect and remediate Amazon Bedrock misconfigurations before they become security incidents. This integration helps organizations embed robust security controls and secure their use of the powerful capabilities of Amazon Bedrock by offering three critical advantages: holistic AI security by integrating AI security into your broader cloud security strategy, real-time risk detection through identifying potential AI-related security issues as they emerge, and simplified compliance to help meet evolving AI regulations with pre-built detections. 
AWS and Datadog: Empowering customers to adopt AI securely 
The partnership between AWS and Datadog is focused on helping customers operate their cloud infrastructure securely and efficiently. As organizations rapidly adopt AI technologies, extending this partnership to include Amazon Bedrock is a natural evolution. Amazon Bedrock is a fully managed service that makes high-performing FMs from leading AI companies and Amazon available through a unified API, making it an ideal starting point for Datadogâ€™s AI security capabilities. 
The decision to prioritize Amazon Bedrock integration is driven by several factors, including strong customer demand, comprehensive security needs, and the existing integration foundation. With over 900 integrations and a partner-built Marketplace, Datadogâ€™s long-standing partnership with AWS and deep integration capabilities have helped Datadog quickly develop comprehensive security monitoring for Amazon Bedrock while using their existing cloud security expertise. 
Throughout Q4 2024, Datadog Security Research observed increasing threat actor interest in cloud AI environments, making this integration particularly timely. By combining the powerful AI capabilities of AWS with Datadogâ€™s security expertise, you can safely accelerate your AI adoption while maintaining robust security controls. 
How Datadog Cloud Security helps secure Amazon Bedrock resources 
After adding the AWS integration to your Datadog account and enabling Datadog Cloud Security, Datadog Cloud Security continuously monitors your AWS environment, identifying misconfigurations, identity risks, vulnerabilities, and compliance violations. These detections use the Datadog Severity Scoring system to prioritize them based on infrastructure context. The scoring considers a variety of variables, including if the resource is in production, is publicly accessible, or has access to sensitive data. This multi-layer analysis can help you reduce noise and focus your attention to the most critical misconfigurations by considering runtime behavior. 
Partnering with AWS, Datadog is excited to offer detections for Datadog Cloud Security customers, such as: 
 
 Amazon Bedrock custom models should not output model data to publicly accessible S3 buckets 
 Amazon Bedrock custom models should not train from publicly writable S3 buckets 
 Amazon Bedrock guardrails should have a prompt attack filter enabled and block prompt attacks at high sensitivity 
 Amazon Bedrock agent guardrails should have the sensitive information filter enabled and block highly sensitive PII entities 
 
Detect AI misconfigurations with Datadog Cloud Security 
To understand how these detections can help secure your Amazon Bedrock infrastructure, letâ€™s look at a specific use case, in which Amazon Bedrock custom models should not train from publicly writable Amazon Simple Storage Service (Amazon S3) buckets. 
With Amazon Bedrock, you can customize AI models by fine-tuning on domain specific data. To do this, that data is stored in an S3 bucket. Threat actors are constantly evaluating the configuration of S3 buckets, looking for the potential to access sensitive data or even the ability to write to S3 buckets. 
If a threat actor finds an S3 bucket that was misconfigured to permit public write access, and that same bucket contained data that was used to train an AI model, a bad actor could poison that dataset and introduce malicious behavior or output to the model. This is known as a data poisoning attack. 
Normally, detecting these types of misconfigurations requires multiple steps: one to identify the S3 bucket misconfigured with write access, and one to identify that the bucket is being used by Amazon Bedrock. With Datadog Cloud Security, this detection is one of hundreds that are activated out of the box. 
In the Datadog Cloud Security system, you can view this issue alongside surrounding infrastructure using Cloud Map. This provides live diagrams of your cloud architecture, as shown in the following screenshot. AI risks are then contextualized alongside sensitive data exposure, identity risks, vulnerabilities, and other misconfigurations to give you a 360-view of risks. 
 
For example, you might see that your application is using Anthropicâ€™s Claude 3.7 on Amazon Bedrock and accessing training or prompt data stored in an S3 bucket that also has public write access. This could inadvertently impact model integrity by introducing unapproved data to the large language model (LLM), so you will want to update this configuration. Though basic, the first step for most security initiatives is identifying the issue. With agentless scanning, Datadog scans your AWS environment at intervals between 15 minutes and 2 hours, so users can identify misconfigurations as they are introduced to their environment. The next step is to remediate this risk. Datadog Cloud Security offers automatically generated remediation guidance, specifically for each risk (see the following screenshot). You will get a step-by-step explanation of how to fix each finding. In this situation, we can remediate this issue by modifying the S3 bucketâ€™s policy, helping prevent public write access. You can do this directly in AWS, create a JIRA ticket, or use the built-in workflow automation tools. From here, you can apply remediation steps directly within Datadog and confirm that the misconfiguration has been resolved. 
 
Resolving this issue will positively impact your compliance posture, as illustrated by the posture score in Datadog Cloud Security, helping teams meet internal benchmarks and regulatory standards. Teams can also create custom frameworks or iterate on existing ones for tailored compliance controls. 
 
As generative AI is embraced across industries, the regulatory environment will evolve. Datadog will continue partnering with AWS to expand their detection library and support secure AI adoption and compliance. 
How Datadog Cloud Security detects misconfigurations in your cloud environment 
You can deploy Datadog Cloud Security either with the Datadog agent, agentlessly, or both to maximize security coverage in your cloud environment. Datadog customers can start monitoring their AWS accounts for misconfigurations by first adding the AWS integration to Datadog. This enables Datadog to crawl cloud resources in customer AWS accounts. 
As the Datadog system finds resources, it runs through a catalog of hundreds of out-of-the-box detection rules against these resources, looking for misconfigurations and threat paths that adversaries can exploit. 
Secure your AI infrastructure with Datadog 
Misconfigurations in AI systems can be risky, but with the right tools, you can have the visibility and context needed to manage them. With Datadog Cloud Security, teams gain visibility into these risks, detect threats early, and remediate issues with confidence. In addition, Datadog has also released numerous agentic AI security features, designed to help teams gain visibility into the health and security of critical AI workload, which includes new announcements made to Datadogâ€™s LLM observability features. 
Lastly, Datadog announced Bits AI Security Analyst alongside other Bits AI agents at DASH. Included as part of Cloud SIEM, Bits is an agentic AI security analyst that automates triage for AWS CloudTrail signals. Bits investigates each alert like a seasoned analyst: pulling in relevant context from across your Datadog environment, annotating key findings, and offering a clear recommendation on whether the signal is likely benign or malicious. By accelerating triage and surfacing real threats faster, Bits helps reduce mean time to remediation (MTTR) and frees analysts to focus on important threat hunting and response initiatives. This helps across different threats, including AI-related threats. 
To learn more about how Datadog helps secure your AI infrastructure, see Monitor Amazon Bedrock with Datadog or check out our security documentation. If youâ€™re not already using Datadog, you can get started with Datadog Cloud Security with a 14-day free trial. 
 
About the Authors 
Nina Chen is a Customer Solutions Manager at AWS specializing in leading software companies to use the power of the AWS Cloud to accelerate their product innovation and growth. With over 4 years of experience working in the strategic independent software vendor (ISV) vertical, Nina enjoys guiding ISV partners through their cloud transformation journeys, helping them optimize their cloud infrastructure, driving product innovation, and delivering exceptional customer experiences. 
 Sujatha Kuppuraju is a Principal Solutions Architect at AWS, specializing in cloud and generative AI security. She collaborates with software companiesâ€™ leadership teams to architect secure, scalable solutions on AWS and guide strategic product development. Using her expertise in cloud architecture and emerging technologies, Sujatha helps organizations optimize offerings, maintain robust security, and bring innovative products to market in an evolving tech landscape. 
Nick Frichette is a Staff Security Researcher for Cloud Security Research at Datadog. 
Vijay George is a Product Manager for AI Security at Datadog.
â€¢ Set up custom domain names for Amazon Bedrock AgentCore Runtime agents
  When deploying AI agents to Amazon Bedrock AgentCore Runtime (currently in preview), customers often want to use custom domain names to create a professional and seamless experience. 
By default, AgentCore Runtime agents use endpoints like https://bedrock-agentcore.{region}.amazonaws.com/runtimes/{EncodedAgentARN}/invocations. 
In this post, we discuss how to transform these endpoints into user-friendly custom domains (like https://agent.yourcompany.com) using Amazon CloudFront as a reverse proxy. The solution combines CloudFront, Amazon Route 53, and AWS Certificate Manager (ACM) to create a secure, scalable custom domain setup that works seamlessly with your existing agents. 
Benefits of Amazon Bedrock AgentCore Runtime 
If youâ€™re building AI agents, you have probably wrestled with hosting challenges: managing infrastructure, handling authentication, scaling, and maintaining security. Amazon Bedrock AgentCore Runtime helps address these problems. 
Amazon Bedrock AgentCore Runtime is framework agnostic; you can use it with LangGraph, CrewAI, Strands Agents, or custom agents you have built from scratch. It supports extended execution times up to 8 hours, perfect for complex reasoning tasks that traditional serverless functions canâ€™t handle. Each user session runs in its own isolated microVM, providing security thatâ€™s crucial for enterprise applications. 
The consumption-based pricing model means you only pay for what you use, not what you provision. And unlike other hosting solutions, Amazon Bedrock AgentCore Runtime includes built-in authentication and specialized observability for AI agents out of the box. 
Benefits of custom domains 
When using Amazon Bedrock AgentCore Runtime with Open Authorization (OAuth) authentication, your applications make direct HTTPS requests to the service endpoint. Although this works, custom domains offer several benefits: 
 
 Custom branding â€“ Client-side applications (web browsers, mobile apps) display your branded domain instead of AWS infrastructure details in network requests 
 Better developer experience â€“ Development teams can use memorable, branded endpoints instead of copying and pasting long AWS endpoints across code bases and configurations 
 Simplified maintenance â€“ Custom domains make it straightforward to manage endpoints when deploying multiple agents or updating configurations across environments 
 
Solution overview 
In this solution, we use CloudFront as a reverse proxy to transform requests from your custom domain into Amazon Bedrock AgentCore Runtime API calls. Instead of using the default endpoint, your applications can make requests to a user-friendly URL like https://agent.yourcompany.com/. 
The following diagram illustrates the solution architecture. 
 
The workflow consists of the following steps: 
 
 A client application authenticates with Amazon Cognito and receives a bearer token. 
 The client makes an HTTPS request to your custom domain. 
 Route 53 resolves the DNS request to CloudFront. 
 CloudFront forwards the authenticated request to the Amazon Bedrock Runtime agent. 
 The agent processes the request and returns the response through the same path. 
 
You can use the same CloudFront distribution to serve both your frontend application and backend agent endpoints, avoiding cross-origin resource sharing (CORS) issues because everything originates from the same domain. 
Prerequisites 
To follow this walkthrough, you must have the following in place: 
 
 An AWS account with appropriate permissions 
 The AWS Cloud Development Kit (AWS CDK) version 2.x or later 
 An AWS Identity and Access Management (IAM) execution role with appropriate permissions for Amazon Bedrock AgentCore Runtime 
 
Although Amazon Bedrock AgentCore Runtime can be in other supported AWS Regions, CloudFront requires SSL certificates to be in the us-east-1 Region. 
You can choose from the following domain options: 
 
 Use an existing domain â€“ Add a subdomain like agent.yourcompany.com 
 Register a new domain â€“ Use Route 53 to register a domain if you donâ€™t have one 
 Use the default URL from CloudFront â€“ No domain registration or configuration required 
 
Choose the third option if you want to test the solution quickly before setting up a custom domain. 
Create an agent with inbound authentication 
If you already have an agent deployed with OAuth authentication, you can skip to the next section to set up the custom domain. Otherwise, follow these steps to create a new agent using Amazon Cognito as your OAuth provider: 
 
 Create a new directory for your agent with the following structure: 
 
 
 your_project_directory/
â”œâ”€â”€ agent_example.py # Your main agent code
â”œâ”€â”€ requirements.txt # Dependencies for your agent
â””â”€â”€ __init__.py # Makes the directory a Python package 
 
 
 Create the main agent code in agent_example.py: 
 
 
 # agent_example.py
from strands import Agent
from bedrock_agentcore.runtime import BedrockAgentCoreApp

agent = Agent()
app = BedrockAgentCoreApp()
@app.entrypoint
def invoke(payload):
    """Process user input and return a response"""
    user_message = payload.get("prompt", "Hello")
    response = agent(user_message)
    return str(response) # response should be json serializable
if __name__ == "__main__":
    app.run() 
 
 
 Add dependencies to requirements.txt: 
 
 
 # requirements.txt
strands-agents
bedrock-agentcore 
 
 
 Run the following commands to create an Amazon Cognito user pool and test user: 
 
 
 # Create User Pool and capture Pool ID
export POOL_ID=$(aws cognito-idp create-user-pool \
  --pool-name "MyUserPool" \
  --policies '{"PasswordPolicy":{"MinimumLength":8}}' \
  --region us-east-1 | jq -r '.UserPool.Id')

# Create App Client and capture Client ID
export CLIENT_ID=$(aws cognito-idp create-user-pool-client \
  --user-pool-id $POOL_ID \
  --client-name "MyClient" \
  --no-generate-secret \
  --explicit-auth-flows "ALLOW_USER_PASSWORD_AUTH" "ALLOW_REFRESH_TOKEN_AUTH" \
  --region us-east-1 | jq -r '.UserPoolClient.ClientId')

# Create and configure a test user
aws cognito-idp admin-create-user \
  --user-pool-id $POOL_ID \
  --username "testuser" \
  --temporary-password "Temp1234" \
  --region us-east-1 \
  --message-action SUPPRESS

aws cognito-idp admin-set-user-password \
  --user-pool-id $POOL_ID \
  --username "testuser" \
  --password "MyPassword123" \
  --region us-east-1 \
  --permanent

echo "Pool ID: $POOL_ID"
echo "Discovery URL: https://cognito-idp.us-east-1.amazonaws.com/$POOL_ID/.well-known/openid-configuration"
echo "Client ID: $CLIENT_ID" 
 
 
 Deploy the agent using the Amazon Bedrock AgentCore command line interface (CLI) provided by the starter toolkit: 
 
 
 pip install bedrock-agentcore-starter-toolkit #install the starter toolkit

agentcore configure --entrypoint agent_example.py \
--name my_agent \
--execution-role your-execution-role-arn \
--requirements-file requirements.txt \
--authorizer-config "{\"customJWTAuthorizer\":{\"discoveryUrl\":\"https://cognito-idp.us-east-1.amazonaws.com/$POOL_ID/.well-known/openid-configuration\",\"allowedClients\":[\"$CLIENT_ID\"]}}"

agentcore launch 
 
Make note of your agent runtime Amazon Resource Name (ARN) after deployment. You will need this for the custom domain configuration. 
For additional examples and details, see Authenticate and authorize with Inbound Auth and Outbound Auth. 
Set up the custom domain solution 
Now letâ€™s implement the custom domain solution using the AWS CDK. This section shows you how to create the CloudFront distribution that proxies your custom domain requests to Amazon Bedrock AgentCore Runtime endpoints. 
 
 Create a new directory and initialize an AWS CDK project: 
 
 
 mkdir agentcore-custom-domain
cd agentcore-custom-domain
cdk init app --language python
source .venv/bin/activate
pip install aws-cdk-lib constructs 
 
 
 Encode the agent ARN and prepare the CloudFront origin configuration: 
 
 
 # agentcore_custom_domain_stack.py 
import urllib.parse

agent_runtime_arn = "arn:aws:bedrock-agentcore:us-east-1:accountId:runtime/my_agent-xbcDkz4FR9"
encoded_arn = urllib.parse.quote(agent_runtime_arn, safe='') # URL-encode the ARN
region = agent_runtime_arn.split(':')[3]  # Extract region from ARN 
 
If your frontend application runs on a different domain than your agent endpoint, you must configure CORS headers. This is common if your frontend is hosted on a different domain (for example, https://app.yourcompany.com calling https://agent.yourcompany.com), or if youâ€™re developing locally (for example, http://localhost:3000 calling your production agent endpoint). 
 
 To handle CORS requirements, create a CloudFront response headers policy: 
 
 
 # agentcore_custom_domain_stack.py 
from aws_cdk.aws_cloudfront import ResponseHeadersPolicy, ResponseHeadersCorsBehavior

# Create CORS response headers policy
cors_policy = ResponseHeadersPolicy(self, 'CorsPolicy',
    cors_behavior=ResponseHeadersCorsBehavior(
        access_control_allow_origins=['*'], # Or specify your frontend domains
        access_control_allow_headers=[
            'Authorization',
            'Content-Type', 
            'X-Amzn-*',
            'X-Requested-With'
        ],
        access_control_allow_methods=['GET', 'POST', 'OPTIONS'],
        access_control_allow_credentials=False,
        access_control_expose_headers=['*'],
        origin_override=True # Overrides CORS headers from origin
    )
) 
 
 
 Create a CloudFront distribution to act as a reverse proxy for your agent endpoints: 
 
 
 # agentcore_custom_domain_stack.py
 from aws_cdk.aws_cloudfront import (
    Distribution, BehaviorOptions, CachePolicy, 
    AllowedMethods, ViewerProtocolPolicy,
    OriginProtocolPolicy, OriginRequestPolicy
)
from aws_cdk.aws_cloudfront_origins import HttpOrigin

bedrock_agentcore_hostname = f"bedrock-agentcore.{region}.amazonaws.com"
origin_path = f"/runtimes/{encoded_arn}/invocations"

distribution = Distribution(self, 'Distribution',
    default_behavior=BehaviorOptions(
        origin=HttpOrigin(
            bedrock_agentcore_hostname,
            origin_path=origin_path, 
            protocol_policy=OriginProtocolPolicy.HTTPS_ONLY,
            read_timeout=Duration.seconds(120) # Optional: for responses &gt;30s, adjust as needed
        ),
        viewer_protocol_policy=ViewerProtocolPolicy.REDIRECT_TO_HTTPS,
        cache_policy=CachePolicy.CACHING_DISABLED,  # Critical for dynamic APIs
        allowed_methods=AllowedMethods.ALLOW_ALL,
        response_headers_policy=cors_policy,  # Add CORS policy if created
        origin_request_policy=OriginRequestPolicy.ALL_VIEWER,  # Forward headers for MCP
    ),
    # Add domain configuration if using custom domains
    domain_names=[domain_name] if domain_name else None,
    certificate=certificate if domain_name else None,
) 
 
Set cache_policy=CachePolicy.CACHING_DISABLED to make sure your agent responses remain dynamic and arenâ€™t cached by CloudFront. 
 
 If youâ€™re using a custom domain, add an SSL certificate and DNS configuration to your stack: 
 
 
 # agentcore_custom_domain_stack.py 
from aws_cdk.aws_certificatemanager import Certificate, CertificateValidation
from aws_cdk.aws_route53 import HostedZone, ARecord, RecordTarget
from aws_cdk.aws_route53_targets import CloudFrontTarget

# For existing domains
hosted_zone = HostedZone.from_lookup(self, 'HostedZone',
    domain_name='yourcompany.com'
)
# SSL certificate with automatic DNS validation
certificate = Certificate(self, 'Certificate',
    domain_name='my-agent.yourcompany.com',
    validation=CertificateValidation.from_dns(hosted_zone),
)
# DNS record pointing to CloudFront
ARecord(self, 'AliasRecord',
    zone=hosted_zone,
    record_name='my-agent.yourcompany.com',
    target=RecordTarget.from_alias(CloudFrontTarget(distribution)),
) 
 
The following code is the complete AWS CDK stack that combines all the components: 
 
 # agentcore_custom_domain_stack.py
import urllib.parse
from aws_cdk import Stack, CfnOutput, Duration
from aws_cdk.aws_cloudfront import (
    Distribution, BehaviorOptions,
    CachePolicy, AllowedMethods,
    ViewerProtocolPolicy, OriginProtocolPolicy,
    ResponseHeadersPolicy, ResponseHeadersCorsBehavior,
    OriginRequestPolicy
)
from aws_cdk.aws_cloudfront_origins import HttpOrigin
from aws_cdk.aws_certificatemanager import Certificate, CertificateValidation
from aws_cdk.aws_route53 import HostedZone, ARecord, RecordTarget
from aws_cdk.aws_route53_targets import CloudFrontTarget
from constructs import Construct

class AgentcoreCustomDomainStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs) -&gt; None:
        super().__init__(scope, construct_id, **kwargs)

        # Configuration - Update these for your setup
        agent_runtime_arn = "arn:aws:bedrock-agentcore:us-east-1:accountId:runtime/my_agent-xbcDkz4FR9"
        region = agent_runtime_arn.split(':')[3]  # Extract region from ARN
        domain_name = "agent.yourcompany.com"  # Using your hosted zone
        hosted_zone_id = "Z1234567890ABC"  # Your hosted zone ID
        enable_cors = True  # Set to False if serving frontend and backend from same domain

        # Encode the agent ARN for the origin path
        encoded_arn = urllib.parse.quote(agent_runtime_arn, safe='')
        bedrock_agentcore_hostname = f"bedrock-agentcore.{region}.amazonaws.com"
        origin_path = f"/runtimes/{encoded_arn}/invocations"

        # Create CORS response headers policy if needed
        cors_policy = None
        if enable_cors:
            cors_policy = ResponseHeadersPolicy(self, 'CorsPolicy',
                cors_behavior=ResponseHeadersCorsBehavior(
                    access_control_allow_origins=['*'],  # Or specify your frontend domains
                    access_control_allow_headers=[
                        'Authorization',
                        'Content-Type', 
                        'X-Amzn-*',
                        'X-Requested-With'
                    ],
                    access_control_allow_methods=['GET', 'POST', 'OPTIONS'],
                    access_control_expose_headers=['*'],
                    access_control_allow_credentials=False,
                    origin_override=True  # Overrides CORS headers from origin
                )
            )

        # Base distribution configuration
        distribution_props = {
            "default_behavior": BehaviorOptions(
                origin=HttpOrigin(
                    bedrock_agentcore_hostname,
                    origin_path=origin_path,  # Direct path to agent endpoint
                    protocol_policy=OriginProtocolPolicy.HTTPS_ONLY,
                    read_timeout=Duration.seconds(120) # Optional: for responses &gt;30s, adjust as needed
                ),
                viewer_protocol_policy=ViewerProtocolPolicy.REDIRECT_TO_HTTPS,
                cache_policy=CachePolicy.CACHING_DISABLED,
                allowed_methods=AllowedMethods.ALLOW_ALL,
                response_headers_policy=cors_policy,  # Add CORS policy if enabled
                origin_request_policy=OriginRequestPolicy.ALL_VIEWER,  # Forward headers for MCP
            )
        }

        # Optional: Add custom domain
        if domain_name:
            # Use from_hosted_zone_attributes for specific zone
            hosted_zone = HostedZone.from_hosted_zone_attributes(self, 'HostedZone',
                                                                 zone_name='yourcompany.com',  # Your root domain
                                                                 hosted_zone_id=hosted_zone_id
                                                                 )

            certificate = Certificate(self, 'Certificate',
                                      domain_name=domain_name,
                                      validation=CertificateValidation.from_dns(
                                          hosted_zone),
                                      )

            # Add custom domain to distribution
            distribution_props["domain_names"] = [domain_name]
            distribution_props["certificate"] = certificate

        distribution = Distribution(self, 'Distribution', **distribution_props)

        # Create DNS record if using custom domain
        if domain_name:
            ARecord(self, 'AliasRecord',
                    zone=hosted_zone,
                    record_name=domain_name,
                    target=RecordTarget.from_alias(
                        CloudFrontTarget(distribution)),
                    )

        # Outputs
        if domain_name:
            domain_url = f"https://{domain_name}/"
            CfnOutput(self, "AgentEndpoint",
                      value=domain_url,
                      description="Your custom domain endpoint"
                      )

        CfnOutput(self, "CloudFrontDistribution",
                  value=f"https://{distribution.distribution_domain_name}/",
                  description="CloudFront default domain (works without custom domain)"
                  ) 
 
 
 Configure the AWS CDK app entry point: 
 
 
 # app.py
#!/usr/bin/env python3
import aws_cdk as cdk
from agentcore_custom_domain.agentcore_custom_domain_stack import AgentCoreCustomDomainStack

app = cdk.App()
AgentcoreCustomDomainStack(app, "AgentCoreCustomDomainStack",
    # CloudFront requires certificates in us-east-1
    env=cdk.Environment(region='us-east-1'),
)
app.synth() 
 
Deploy your custom domain 
Now you can deploy the solution and verify it works with both custom and default domains. Complete the following steps: 
 
 Update the following values in agentcore_custom_domain_stack.py: 
   
   Your Amazon Bedrock AgentCore Runtime ARN 
   Your domain name (if using a custom domain) 
   Your hosted zone ID (if using a custom domain) 
    
 Deploy using the AWS CDK: 
 
 
 cdk deploy 
 
Test your endpoint 
After you deploy the custom domain, you can test your endpoints using either the custom domain or the CloudFront default domain.First, get a JWT token from Amazon Cognito: 
 
 export TOKEN=$(aws cognito-idp initiate-auth \
  --client-id "your-client-id" \
  --auth-flow USER_PASSWORD_AUTH \
  --auth-parameters USERNAME='testuser',PASSWORD='MyPassword123' \
  --region us-east-1 | jq -r '.AuthenticationResult.AccessToken') 
 
Use the following code to test with your custom domain: 
 
 curl -X POST "https://my-agent.yourcompany.com/" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -H "X-Amzn-Bedrock-AgentCore-Runtime-Session-Id: session-12345678901234567890123456789012345" \
  -d '{"prompt": "Hello, how can you help me today?"}' 
 
Alternatively, use the following code to test with the CloudFront default domain: 
 
 curl -X POST "https://d1234567890123.cloudfront.net/" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -H "X-Amzn-Bedrock-AgentCore-Runtime-Session-Id: session-12345678901234567890123456789012345" \
  -d '{"prompt": "Hello, how can you help me today?"}' 
 
 
 If everything works correctly, you will receive a response from your agent through either endpoint. Youâ€™ve successfully created a custom domain for your Amazon Bedrock AgentCore Runtime agent! 
 
Considerations 
As you implement this solution in production, the following are some important considerations: 
 
 Cost implications â€“ CloudFront adds costs for data transfer and requests. Review Amazon CloudFront pricing to understand the impact for your usage patterns. 
 Security enhancements â€“ Consider implementing the following security measures: 
   
   AWS WAF rules to help protect against common web exploits. 
   Rate limiting to help prevent abuse. 
   Geo-restrictions if your agent should only be accessible from specific Regions. 
    
 Monitoring â€“ Enable CloudFront access logs and set up Amazon CloudWatch alarms to monitor error rates, latency, and request volume. 
 
Clean up 
To avoid ongoing costs, delete the resources when you no longer need them: 
 
 cdk destroy 
 
You might need to manually delete the Route 53 hosted zones and ACM certificates from their respective service consoles. 
Conclusion 
In this post, we showed you how to create custom domain names for your Amazon Bedrock AgentCore Runtime agent endpoints using CloudFront as a reverse proxy. This solution provides several key benefits: simplified integration for development teams, custom domains that align with your organization, cleaner infrastructure abstraction, and straightforward maintenance when endpoints need updates. By using CloudFront as a reverse proxy, you can also serve both your frontend application and backend agent endpoints from the same domain, avoiding common CORS challenges. 
We encourage you to explore this solution further by adapting it to your specific needs. You might want to enhance it with additional security features, set up monitoring, or integrate it with your existing infrastructure. 
To learn more about building and deploying AI agents, see the Amazon Bedrock AgentCore Developer Guide. For advanced configurations and best practices with CloudFront, refer to the Amazon CloudFront documentation. You can find detailed information about SSL certificates in the AWS Certificate Manager documentation, and domain management in the Amazon Route 53 documentation. 
Amazon Bedrock AgentCore is currently in preview and subject to change. Standard AWS pricing applies to additional services used, such as CloudFront, Route 53, and Certificate Manager. 
 
About the authors 
Rahmat Fedayizada is a Senior Solutions Architect with the AWS Energy and Utilities team. He works with energy companies to design and implement scalable, secure, and highly available architectures. Rahmat is passionate about translating complex technical requirements into practical solutions that drive business value. 
Paras Bhuva is a Senior Manager of Solutions Architecture at AWS, where he leads a team of solution architects helping energy customers innovate and accelerate their transformation. Having started as a Solution Architect in 2012, Paras is passionate about architecting scalable solutions and building organizations focused on application modernization and AI initiatives.
â€¢ Introducing auto scaling on Amazon SageMaker HyperPod
  Today, weâ€™re excited to announce that Amazon SageMaker HyperPod now supports managed node automatic scaling with Karpenter, so you can efficiently scale your SageMaker HyperPod clusters to meet your inference and training demands. Real-time inference workloads require automatic scaling to address unpredictable traffic patterns and maintain service level agreements (SLAs). As demand spikes, organizations must rapidly adapt their GPU compute without compromising response times or cost-efficiency. Unlike self-managed Karpenter deployments, this service-managed solution alleviates the operational overhead of installing, configuring, and maintaining Karpenter controllers, while providing tighter integration with the resilience capabilities of SageMaker HyperPod. This managed approach supports scale to zero, reducing the need for dedicated compute resources to run the Karpenter controller itself, improving cost-efficiency. 
SageMaker HyperPod offers a resilient, high-performance infrastructure, observability, and tooling optimized for large-scale model training and deployment. Companies like Perplexity, HippocraticAI, H.AI, and Articul8 are already using SageMaker HyperPod for training and deploying models. As more customers transition from training foundation models (FMs) to running inference at scale, they require the ability to automatically scale their GPU nodes to handle real production traffic by scaling up during high demand and scaling down during periods of lower utilization. This capability necessitates a powerful cluster auto scaler. Karpenter, an open source Kubernetes node lifecycle manager created by AWS, is a popular choice among Kubernetes users for cluster auto scaling due to its powerful capabilities that optimize scaling times and reduce costs. 
This launch provides a managed Karpenter-based solution for automatic scaling that is installed and maintained by SageMaker HyperPod, removing the undifferentiated heavy lifting of setup and management from customers. The feature is available for SageMaker HyperPod EKS clusters, and you can enable auto scaling to transform your SageMaker HyperPod cluster from static capacity to a dynamic, cost-optimized infrastructure that scales with demand. This combines Karpenterâ€™s proven node lifecycle management with the purpose-built and resilient infrastructure of SageMaker HyperPod, designed for large-scale machine learning (ML) workloads. In this post, we dive into the benefits of Karpenter, and provide details on enabling and configuring Karpenter in your SageMaker HyperPod EKS clusters. 
New features and benefits 
Karpenter-based auto scaling in your SageMaker HyperPod clusters provides the following capabilities: 
 
 Service managed lifecycle â€“ SageMaker HyperPod handles Karpenter installation, updates, and maintenance, alleviating operational overhead 
 Just-in-time provisioning â€“ Karpenter observes your pending pods and provisions the required compute for your workloads from an on-demand pool 
 Scale to zero â€“ You can scale down to zero nodes without maintaining dedicated controller infrastructure 
 Workload-aware node selection â€“ Karpenter chooses optimal instance types based on pod requirements, Availability Zones, and pricing to minimize costs 
 Automatic node consolidation â€“ Karpenter regularly evaluates clusters for optimization opportunities, shifting workloads to avoid underutilized nodes 
 Integrated resilience â€“ Karpenter uses the built-in fault tolerance and node recovery mechanisms of SageMaker HyperPod 
 
These capabilities are built on top of recently launched continuous provisioning capabilities, which enables SageMaker HyperPod to automatically provision remaining capacity in the background while workloads start immediately on available instances. When node provisioning encounters failures due to capacity constraints or other issues, SageMaker HyperPod automatically retries in the background until clusters reach their desired scale, so your auto scaling operations remain resilient and non-blocking. 
Solution overview 
The following diagram illustrates the solution architecture. 
 
Karpenter works as a controller in the cluster and operates in the following steps: 
 
 Watching â€“ Karpenter watches for un-schedulable pods in the cluster through the Kubernetes API server. These could be pods that go into pending state when deployed or automatically scaled to increase the replica count. 
 Evaluating â€“ When Karpenter finds such pods, it computes the shape and size of a NodeClaim to fit the set of pods requirements (GPU, CPU, memory) and topology constraints, and checks if it can pair them with an existing NodePool. For each NodePool, it queries the SageMaker HyperPod APIs to get the instance types supported by the NodePool. It uses the information about instance type metadata (hardware requirements, zone, capacity type) to find a matching NodePool. 
 Provisioning â€“ If Karpenter finds a matching NodePool, it creates a NodeClaim and tries to provision a new instance to be used as the new node. Karpenter internally uses the sagemaker:UpdateCluster API to increase the capacity of the selected instance group. 
 Disrupting â€“ Karpenter periodically checks if a new node is needed or not. If itâ€™s not needed, Karpenter deletes it, which internally translates to a delete node request to the SageMaker HyperPod cluster. 
 
Prerequisites 
Verify you have the required quotas for the instances you will create in the SageMaker HyperPod cluster. To review your quotas, on the Service Quotas console, choose AWS services in the navigation pane, then choose SageMaker. For example, the following screenshot shows the available quota for g5.12xlarge instances (three). 
 
To update the cluster, you must first create AWS Identity and Access Management (IAM) permissions for Karpenter. For instructions, see Create an IAM role for HyperPod autoscaling with Karpenter. 
Create and configure a SageMaker HyperPod cluster 
To begin, launch and configure your SageMaker HyperPod EKS cluster and verify that continuous provisioning mode is enabled on cluster creation. Complete the following steps: 
 
 On the SageMaker AI console, choose HyperPod clusters in the navigation pane. 
 Choose Create HyperPod cluster and Orchestrated on Amazon EKS. 
 For Setup options, select Custom setup. 
 For Name, enter a name. 
 For Instance recovery, select Automatic. 
 For Instance provisioning mode, select Use continuous provisioning. 
 Choose Submit. 
 
 
This setup creates the necessary configuration such as virtual private cloud (VPC), subnets, security groups, and EKS cluster, and installs operators in the cluster. You can also provide existing resources such as an EKS cluster if you want to use an existing cluster instead of creating a new one. This setup will take around 20 minutes. 
Verify that each InstanceGroup is limited to one zone by opting for the OverrideVpcConfig and selecting only one subnet per each InstanceGroup. 
 
After you create the cluster, you must update it to enable Karpenter. You can do this using Boto3 or the AWS Command Line Interface (AWS CLI) using the UpdateCluster API command (after configuring the AWS CLI to connect to your AWS account). 
The following code uses Python Boto3: 
 
 import boto3
client = boto3.client('sagemaker')
response = client.update_cluster(
    ClusterName=&lt;Your_Cluster_Name&gt;,
    AutoScaling = { "Mode": "Enable", "AutoScalerType": "Karpenter" },
    ClusterRole = &lt;Cluster_Role_ARN&gt;,
) 
 
 
 The following code uses the AWS CLI: 
 
 
 aws sagemaker update-cluster \
&nbsp; &nbsp; --cluster-name &lt;clustername&gt;&nbsp;\
&nbsp; &nbsp; --auto-scaling '{ "Mode": "Enable", "AutoScalerType": "Karpenter" }` \
&nbsp; &nbsp; --cluster-role &lt;clusterrole&gt; 
 
After you run this command and update the cluster, you can verify that Karpenter has been enabled by running the DescribeCluster API. 
The following code uses Python: 
 
 import&nbsp;boto3
client&nbsp;=&nbsp;boto3.client('sagemaker')
print(sagemaker_client.describe_cluster(ClusterName=&lt;Your_Cluster_Name&gt;).get("AutoScaling")) 
 
The following code uses the AWS CLI: 
 
 aws sagemaker describe-cluster --cluster-name &lt;clustername&gt; --query AutoScaling 
 
The following code shows our output: 
 
 {'Mode': 'Enable',
&nbsp;'AutoScalerType': 'Karpenter',
&nbsp;'Status': 'Enabled'} 
 
Now you have a working cluster. The next step is to set up some custom resources in your cluster for Karpenter. 
Create HyperpodNodeClass 
HyperpodNodeClass is a custom resource that maps to pre-created instance groups in SageMaker HyperPod, defining constraints around which instance types and Availability Zones are supported for Karpenterâ€™s auto scaling decisions. To use HyperpodNodeClass, simply specify the names of the InstanceGroups of your SageMaker HyperPod cluster that you want to use as the source for the AWS compute resources to use to scale up your pods in your NodePools. 
The HyperpodNodeClass name that you use here is carried over to the NodePool in the next section where you reference it. This tells the NodePool which HyperpodNodeClass to draw resources from. To create a HyperpodNodeClass, complete the following steps: 
 
 Create a YAML file (for example, nodeclass.yaml) similar to the following code. Add InstanceGroup names that you used at the time of the SageMaker HyperPod cluster creation. You can also add new instance groups to an existing SageMaker HyperPod EKS cluster. 
 Reference the HyperPodNodeClass name in your NodePool configuration. 
 
The following is a sample HyperpodNodeClass that uses ml.g6.xlarge and ml.g6.4xlarge instance types: 
 
 apiVersion: karpenter.sagemaker.amazonaws.com/v1
kind: HyperpodNodeClass
metadata:
&nbsp;&nbsp;name:&nbsp;multiazg6
spec:
&nbsp;&nbsp;instanceGroups:
&nbsp; &nbsp; #&nbsp;name of&nbsp;InstanceGroup in HyperPod cluster. InstanceGroup needs to pre-created
&nbsp; &nbsp; # before this step can be completed.
&nbsp; &nbsp; #&nbsp;MaxItems: 10
&nbsp;&nbsp; &nbsp;- auto-g6-az1
&nbsp;&nbsp; &nbsp;- auto-g6-4xaz2 
 
 
 Apply the configuration to your EKS cluster using kubectl: 
 
 
 kubectl apply -f nodeclass.yaml 
 
 
 Monitor the HyperpodNodeClass status to verify the Ready condition in status is set to True to ensure it was successfully created: 
 
 
 kubectl get hyperpodnodeclass multiazc5 -oyaml 
 
The SageMaker HyperPod cluster must have AutoScaling enabled and the AutoScaling status must change to InService before the HyperpodNodeClass can be applied. 
For more information and key considerations, see Autoscaling on SageMaker HyperPod EKS. 
Create NodePool 
The NodePool sets constraints on the nodes that can be created by Karpenter and the pods that can run on those nodes. The NodePool can be set to perform various actions, such as: 
 
 Define labels and taints to limit the pods that can run on nodes Karpenter creates 
 Limit node creation to certain zones, instance types, and computer architectures, and so on 
 
For more information about NodePool, refer to NodePools. SageMaker HyperPod managed Karpenter supports a limited set of well-known Kubernetes and Karpenter requirements, which we explain in this post. 
To create a NodePool, complete the following steps: 
 
 Create a YAML file named nodepool.yaml with your desired NodePool configuration. 
 
The following code is a sample configuration to create a sample NodePool. We specify the NodePool to include our ml.g6.xlarge SageMaker instance type, and we additionally specify it for one zone. Refer to NodePools for more customizations. 
 
 apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
&nbsp;name:&nbsp;gpunodepool
spec:
&nbsp;template:
&nbsp;&nbsp; spec:
&nbsp; &nbsp; &nbsp;nodeClassRef:
&nbsp;&nbsp; &nbsp; &nbsp;group: karpenter.sagemaker.amazonaws.com
&nbsp;&nbsp; &nbsp; &nbsp;kind: HyperpodNodeClass
&nbsp;&nbsp; &nbsp; &nbsp;name: multiazg6
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expireAfter:&nbsp;Never
&nbsp;&nbsp; &nbsp; requirements:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;- key: node.kubernetes.io/instance-type
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;operator: Exists
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;- key: "node.kubernetes.io/instance-type"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;operator: In
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;values: ["ml.g6.xlarge"]
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;- key: "topology.kubernetes.io/zone"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;operator: In
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;values: ["us-west-2a"] 
 
 
 Apply the NodePool to your cluster: 
 
 
 kubectl apply -f nodepool.yaml 
 
 
 Monitor the NodePool status to ensure the Ready condition in the status is set to True: 
 
 
 kubectl get nodepool gpunodepool -oyaml 
 
This example shows how a NodePool can be used to specify the hardware (instance type) and placement (Availability Zone) for pods. 
Launch a simple workload 
The following workload runs a Kubernetes deployment where the pods in deployment are requesting for 1 CPU and 256 MB memory per replica, per pod. The pods have not been spun up yet. 
 
 kubectl apply -f https://raw.githubusercontent.com/aws/karpenter-provider-aws/refs/heads/main/examples/workloads/inflate.yaml 
 
When we apply this, we can see a deployment and a single node launch in our cluster, as shown in the following screenshot. 
 
To scale this component, use the following command: 
 
 kubectl scale deployment inflate --replicas 10 
 
Within a few minutes, we can see Karpenter add the requested nodes to the cluster. 
 
Implement advanced auto scaling for inference with KEDA and Karpenter 
To implement an end-to-end auto scaling solution on SageMaker HyperPod, you can set up Kubernetes Event-driven Autoscaling (KEDA) along with Karpenter. KEDA enables pod-level auto scaling based on a wide range of metrics, including Amazon CloudWatch metrics, Amazon Simple Queue Service (Amazon SQS) queue lengths, Prometheus queries, and resource utilization patterns. By configuring Keda ScaledObject resources to target your model deployments, KEDA can dynamically adjust the number of inference pods based on real-time demand signals. 
When integrating KEDA and Karpenter, this combination creates a powerful two-tier auto scaling architecture. As KEDA scales your pods up or down based on workload metrics, Karpenter automatically provisions or deletes nodes in response to changing resource requirements. This integration delivers optimal performance while controlling costs by making sure your cluster has precisely the right amount of compute resources available at all times. For effective implementation, consider the following key factors: 
 
 Set appropriate buffer thresholds in KEDA to accommodate Karpenterâ€™s node provisioning time 
 Configure cooldown periods carefully to prevent scaling oscillations 
 Define clear resource requests and limits to help Karpenter make optimal node selections 
 Create specialized NodePools tailored to specific workload characteristics 
 
The following is a sample spec of a KEDA ScaledObject file that scales the number of pods based on CloudWatch metrics of Application Load Balancer (ALB) request count: 
 
 apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
&nbsp;&nbsp;name: nd-deepseek-llm-scaler
&nbsp;&nbsp;namespace: default
spec:
&nbsp;&nbsp;scaleTargetRef:
&nbsp;&nbsp; &nbsp;name: nd-deepseek-llm-r1-distill-qwen-1-5b
&nbsp;&nbsp; &nbsp;apiVersion: apps/v1
&nbsp;&nbsp; &nbsp;kind: Deployment
&nbsp;&nbsp;minReplicaCount: 1
&nbsp;&nbsp;maxReplicaCount: 3
&nbsp;&nbsp;pollingInterval: 30 &nbsp; &nbsp; # seconds between checks
&nbsp;&nbsp;cooldownPeriod: 300 &nbsp; &nbsp; # seconds before scaling down
&nbsp;&nbsp;triggers:
&nbsp;&nbsp; &nbsp;- type: aws-cloudwatch
&nbsp;&nbsp; &nbsp; &nbsp;metadata:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;namespace: AWS/ApplicationELB &nbsp; &nbsp; &nbsp; &nbsp;# or your metric namespace
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;metricName: RequestCount &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# or your metric name
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;dimensionName: LoadBalancer &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # or your dimension key
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;dimensionValue: app/k8s-default-albnddee-cc02b67f20/0991dc457b6e8447
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;statistic: Sum
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;threshold: "3" &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# change to your desired threshold
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;minMetricValue: "0" &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # optional floor
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;region: us-east-2 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # your AWS region
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;identityOwner: operator &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # use the IRSA SA bound to keda-operator 
 
Clean up 
To clean up your resources to avoid incurring more charges, delete your SageMaker HyperPod cluster. 
Conclusion 
With the launch of Karpenter node auto scaling on SageMaker HyperPod, ML workloads can automatically adapt to changing workload requirements, optimize resource utilization, and help control costs by scaling precisely when needed. You can also integrate it with event-driven pod auto scalers such as KEDA to scale based on custom metrics. 
To experience these benefits for your ML workloads, enable Karpenter in your SageMaker HyperPod clusters. For detailed implementation guidance and best practices, refer to Autoscaling on SageMaker HyperPod EKS. 
 
About the authors 
Vivek Gangasani is a Worldwide Lead GenAI Specialist Solutions Architect for SageMaker Inference. He drives Go-to-Market (GTM) and Outbound Product strategy for SageMaker Inference. He also helps enterprises and startups deploy, manage, and scale their GenAI models with SageMaker and GPUs. Currently, he is focused on developing strategies and content for optimizing inference performance and GPU efficiency for hosting Large Language Models. In his free time, Vivek enjoys hiking, watching movies, and trying different cuisines. 
Adam Stanley is a Solution Architect for Software, Internet and Model Provider customers at Amazon Web Services (AWS). He supports customers adopting all AWS services, but focuses primarily on Machine Learning training and inference infrastructure. Prior to AWS, Adam went to the University of New South Wales and graduated with degrees in Mathematics and Accounting. You can connect with him on LinkedIn. 
Kunal Jha is a Principal Product Manager at AWS, where he focuses on building Amazon SageMaker HyperPod to enable scalable distributed training and fine-tuning of foundation models. In his spare time, Kunal enjoys skiing and exploring the Pacific Northwest. You can connect with him on LinkedIn. 
Ty Bergstrom is a Software Engineer at Amazon Web Services. He works on the HyperPod Clusters platform for Amazon SageMaker.
â€¢ Meet Boti: The AI assistant transforming how the citizens of Buenos Aires access government information with Amazon Bedrock
  This post is co-written with Julieta Rappan, Macarena Blasi, and MarÃ­a Candela Blanco from the Government of the City of Buenos Aires. 
The Government of the City of Buenos Aires continuously works to improve citizen services. In February 2019, it introduced an AI assistant named Boti available through WhatsApp, the most widely used messaging service in Argentina. With Boti, citizens can conveniently and quickly access a wide variety of information about the city, such as renewing a driverâ€™s license, accessing healthcare services, and learning about cultural events. This AI assistant has become a preferred communication channel and facilitates more than 3 million conversations each month. 
As Boti grows in popularity, the Government of the City of Buenos Aires seeks to provide new conversational experiences that harness the latest developments in generative AI. One challenge that citizens often face is navigating the cityâ€™s complex bureaucratic landscape. The City Governmentâ€™s website includes over 1,300 government procedures, each of which has its own logic, nuances, and exceptions. The City Government recognized that Boti could improve access to this information by directly answering citizensâ€™ questions and connecting them to the right procedure. 
To pilot this new solution, the Government of the City of Buenos Aires partnered with the AWS Generative AI Innovation Center (GenAIIC). The teams worked together to develop an agentic AI assistant using LangGraph and Amazon Bedrock. The solution includes two main components: an input guardrail system and a government procedures agent. The input guardrail uses a custom LLM classifier to analyze incoming user queries, determining whether to approve or block requests based on their content. Approved requests are handled by the government procedures agent, which retrieves relevant procedural information and generates responses. Since most user queries focus on a single procedure, we developed a novel reasoning retrieval system to improve retrieval accuracy. This system initially retrieves comparative summaries that disambiguate similar procedures and then applies a large language model (LLM) to select the most relevant results. The agent uses this information to craft responses in Botiâ€™s characteristic style, delivering short, helpful, and expressive messages in Argentinaâ€™s Rioplatense Spanish dialect. We focused on distinctive linguistic features of this dialect including the voseo (using â€œvosâ€ instead of â€œtÃºâ€) and periphrastic future (using â€œir aâ€ before verbs). 
In this post, we dive into the implementation of the agentic AI system. We begin with an overview of the solution, explaining its design and main features. Then, we discuss the guardrail and agent subcomponents and assess their performance. Our evaluation shows that the guardrails effectively block harmful content, including offensive language, harmful opinions, prompt injection attempts, and unethical behaviors. The agent achieves up to 98.9% top-1 retrieval accuracy using the reasoning retriever, which marks a 12.5â€“17.5% improvement over standard retrieval-augmented generation (RAG) methods. Subject matter experts found that Botiâ€™s responses were 98% accurate in voseo usage and 92% accurate in periphrastic future usage. The promising results of this solution establish a new era of citizen-government interaction. 
Solution overview 
The Government of the City of Buenos Aires and the GenAIIC built an agentic AI assistant using Amazon Bedrock and LangGraph that includes an input guardrail system to enable safe interactions and a government procedures agent to respond to user questions. The workflow is shown in the following diagram. 
 
The process begins when a user submits a question. In parallel, the question is passed to the input guardrail system and government procedures agent. The input guardrail system determines whether the question contains harmful content. If triggered, it stops graph execution and redirects the user to ask questions about government procedures. Otherwise, the agent continues to formulate its response. The agent either calls a retrieval tool, which allows it to obtain relevant context and metadata from government procedures stored in Amazon Bedrock Knowledge Bases, or responds to the user. Both the input guardrail and government procedures agent use the Amazon Bedrock Converse API for LLM inference. This API provides access to a wide selection of LLMs, helping us optimize performance and latency across different subtasks. 
Input guardrail system 
Input guardrails help prevent the LLM system from processing harmful content. Although Amazon Bedrock Guardrails offers one implementation approach with filters for specific words, content, or sensitive information, we developed a custom solution. This provided us greater flexibility to optimize performance for Rioplatense Spanish and monitor specific types of content. The following diagram illustrates our approach, in which an LLM classifier assigns a primary category (â€œapprovedâ€ or â€œblockedâ€) as well as a more detailed subcategory. 
 
Approved queries are within the scope of the government procedures agent. They consist of on-topic requests, which focus on government procedures, and off-topic requests, which are low-risk conversation questions that the agent responds to directly. Blocked queries contain high-risk content that Boti should avoid, including offensive language, harmful opinions, prompt injection attacks, or unethical behaviors. 
We evaluated the input guardrail system on a dataset consisting of both normal and harmful user queries. The system successfully blocked 100% of harmful queries, while occasionally flagging normal queries as harmful. This performance balance makes sure that Boti can provide helpful information while maintaining safe and appropriate interactions for users. 
Agent system 
The government procedures agent is responsible for answering user questions. It determines when to retrieve relevant procedural information using its retrieval tool and generates responses in Botiâ€™s characteristic style. In the following sections, we examine both processes. 
Reasoning retriever 
The agent can use a retrieval tool to provide accurate and up-to-date information about government procedures. Retrieval tools typically employ a RAG framework to perform semantic similarity searches between user queries and a knowledge base containing document chunks stored as embeddings, and then provide the most relevant samples as context to the LLM. Government procedures, however, present challenges to this standard approach. Related procedures, such as renewing and reprinting driversâ€™ licenses, can be difficult to disambiguate. Additionally, each user question typically requires information from one specific procedure. The mixture of chunks returned from standard RAG approaches increases the likelihood of generating incorrect responses. 
To better disambiguate government procedures, the Buenos Aires and GenAIIC teams developed a reasoning retrieval method that uses comparative summaries and LLM selection. An overview of this approach is shown in the following diagram. 
 
A necessary preprocessing step before retrieval is the creation of a government procedures knowledge base. To capture both the key information contained in procedures and how they related to each other, we created comparative summaries. Each summary contains basic information, such as the procedureâ€™s purpose, intended audience, and content, such as costs, steps, and requirements. We clustered the base summaries into small groups, with an average cluster size of 5, and used an LLM to generate descriptions about what made each procedure different from its neighbors. We appended the distinguishing descriptions to the base information to create the final summary. We note that this approach shares similarities to Anthropicâ€™s Contextual Retrieval, which prepends explanatory context to document chunk. 
With the knowledge base in place, we are able to retrieve relevant government procedures based on the user query. The reasoning retriever completes three steps: 
 
 Retrieve M Summaries: We retrieve between 1 and M comparative summaries using semantic search. 
 Optional Reasoning: In some cases, the initial retrieval surfaces similar procedures. To make sure that the most relevant procedures are returned to the agent, we apply an optional LLM reasoning step. The condition for this step occurs when the ratio of the first and second retrieval scores falls below a threshold value. An LLM follows a chain-of-thought (CoT) process in which it compares the user query to the retrieved summaries. It discards irrelevant procedures and reorders the remaining ones based on relevance. If the user query is specific enough, this process typically returns one result. By applying this reasoning step selectively, we minimize latency and token usage while maintaining high retrieval accuracy. 
 Retrieve N Full-Text Procedures: After the most relevant procedures are identified, we fetch their complete documents and metadata from an Amazon DynamoDB table. The metadata contains information like the source URL and the sentiment of the procedure. The agent typically receives between 1 and N results, where N â‰¤ M. 
 
The agent receives the retrieved full text procedures in its context window. It follows its own CoT process to determine the relevant content and URL source attributions when generating its answer. 
We evaluated our reasoning retriever against standard RAG techniques using a synthetic dataset of 1,908 questions derived from known source procedures. The performance was measured by determining whether the correct procedure appeared in the top-k retrieved results for each question. The following plot compares the top-k retrieval accuracy for each approach across different models, arranged in order of ascending performance from left to right. The metrics are proportionally weighted based on each procedureâ€™s webpage visit frequency, making sure that our evaluation reflects real-world usage patterns. 
 
The first three approaches represent standard vector-based retrieval methods. The first method, Section Titan, involved chunking procedures by document sections, targeting approximately 250 words per chunk, and then embedding the chunks using Amazon Titan Text Embeddings v2. The second method, Summaries Titan, consisted of embedding the procedure summaries using the same embedding model. By embedding summaries rather than document text, the retrieval accuracy improved by 7.8â€“15.8%. The third method, Summaries Cohere, involved embedding procedure summaries using Cohere Multilingual v3 on Amazon Bedrock. The Cohere Multilingual embedding model provided a noticeable improvement in retrieval accuracy compared to the Amazon Titan embedding models, with all top-k values above 90%. 
The next three approaches use the reasoning retriever. We embedded the procedure summaries using the Cohere Multilingual model, retrieved 10 summaries during the initial retrieval step, and optionally applied the LLM-based reasoning step using either Anthropicâ€™s Haiku 3, Claude 3 Sonnet, or Claude 3.5 Sonnet on Amazon Bedrock. All three reasoning retrievers consistently outperform standard RAG techniques, achieving 12.5â€“17.5% higher top-k accuracies. Anthropicâ€™s Claude 3.5 Sonnet delivered the highest performance with 98.9% top-1 accuracy. These results demonstrate how combining embedding-based retrieval with LLM-powered reasoning can improve RAG performance. 
Answer generation 
After collecting the necessary information, the agent responds using Botiâ€™s distinctive communication style: concise, helpful messages in Rioplatense Spanish. We maintained this voice through prompt engineering that specified the following: 
 
 Personality â€“ Convey a warm and friendly tone, providing quick solutions to everyday problems 
 Response length â€“ Limit responses to a few sentences 
 Structure â€“ Organize content using lists and highlights key information using bold text 
 Expression â€“ Use emojis to mark important requirements and add visual cues 
 Dialect â€“ Incorporate Rioplatense linguistic features, including voseo, periphrastic future, and regional vocabulary (for example, â€œacordate,â€ â€œentrar,â€ â€œacÃ¡,â€ and â€œallÃ¡â€). 
 
Government procedures often address sensitive topics, like accidents, health, or security. To facilitate appropriate responses, we incorporated sentiment analysis into our knowledge base as metadata. This allows our system to route to different prompt templates. Sensitive topics are directed to prompts with reduced emoji usage and more empathetic language, whereas neutral topics receive standard templates. 
The following figure shows a sample response to a question about borrowing library books. It has been translated to English for convenience. 
 
To validate our prompt engineering approach, subject matter experts at the Government of the City of Buenos Aires reviewed a sample of Botiâ€™s responses. Their analysis confirmed high fidelity to Rioplatense Spanish, with 98% accuracy in voseo usage and 92% in periphrastic future usage. 
Conclusion 
This post described the agentic AI assistant built by the Government of the City of Buenos Aires and the GenAIIC to respond to citizensâ€™ questions about government procedures. The solution consists of two primary components: an input guardrail system that helps prevent the system from responding to harmful user queries and a government procedures agent that retrieves relevant information and generates responses. The input guardrails effectively block harmful content, including queries with offensive language, harmful opinions, prompt injection, and unethical behaviors. The government procedures agent employs a novel reasoning retrieval method that disambiguates similar government procedures, achieving up to 98.9% top-1 retrieval accuracy and a 12.5â€“17.5% improvement over standard RAG methods. Through prompt engineering, responses are delivered in Rioplatense Spanish using Botiâ€™s voice. Subject matter experts rated Botiâ€™s linguistic performance highly, with 98% accuracy in voseo usage and 92% in periphrastic future usage. 
As generative AI advances, we expect to continuously improve our solution. The expanding catalog of LLMs available in Amazon Bedrock makes it possible to experiment with newer, more powerful models. This includes models that process text, as explored in the solution in this post, as well as models that process speech, allowing for direct speech-to-speech interactions. We might also explore the fine-tuning capabilities of Amazon Bedrock to customize models so that they better capture the linguistic features of Rioplatense Spanish. Beyond model improvements, we can iterate on our agent framework. The agentâ€™s tool set can be expanded to support other tasks associated with government procedures like account creation, form completion, and appointment scheduling. As the City Government develops new experiences for citizens, we can consider implementing multi-agent frameworks in which specialist agents, like the government procedures agent, handle specific tasks. 
To learn more about Boti and AWSâ€™s generative AI capabilities, check out the following resources: 
 
 Boti: The City Chatbot 
 Government of the City of Buenos Aires: Procedures 
 Amazon Bedrock 
 Amazon Bedrock Knowledge Bases 
 
 
 
About the authors 
Julieta Rappan is Director of the Digital Channels Department of the Buenos Aires City Government, where she coordinates the landscape of digital and conversational interfaces. She has extensive experience in the comprehensive management of strategic and technological projects, as well as in leading high-performance teams focused on the development of digital products and services. Her leadership drives the implementation of technological solutions with a focus on scalability, coherence, public value, and innovationâ€”where generative technologies are beginning to play a central role. 
Macarena Blasi is Chief of Staff at the Digital Channels Department of the Buenos Aires City Government, working across the cityâ€™s main digital services, including Botiâ€”the WhatsApp-based virtual assistantâ€”and the official Buenos Aires website. She began her journey working in conversational experience design, later serving as product owner and Operations Manager and then as Head of Experience and Content, leading multidisciplinary teams focused on improving the quality, accessibility, and usability of public digital services. Her work is driven by a commitment to building clear, inclusive, and human-centered experiences in the public sector. 
MarÃ­a Candela Blanco is Operations Manager for Quality Assurance, Usability, and Continuous Improvement at the Buenos Aires Government, where she leads the content, research, and conversational strategy across the cityâ€™s main digital channels, including the Boti AI assistant and the official Buenos Aires website. Outside of tech, Candela studies literature at UNSAM and is deeply passionate about language, storytelling, and the ways they shape our interactions with technology. 
Leandro Micchele is a Software Developer focused on applying AI to real-world use cases, with expertise in AI assistants, voice, and vision solutions. He serves as the technical lead and consultant for the Boti AI assistant at the Buenos Aires Government and works as a Software Developer at Telecom Argentina. Beyond tech, his discipline extends to martial arts: he has over 20 years of experience and currently teaches Aikido. 
Hugo Albuquerque is a Deep Learning Architect at the AWS Generative AI Innovation Center. Before joining AWS, Hugo had extensive experience working as a data scientist in the media and entertainment and marketing sectors. In his free time, he enjoys learning other languages like German and practicing social dancing, such as Brazilian Zouk. 
Enrique Balp is a Senior Data Scientist at the AWS Generative AI Innovation Center working on cutting-edge AI solutions. With a background in the physics of complex systems focused on neuroscience, he has applied data science and machine learning across healthcare, energy, and finance for over a decade. He enjoys hikes in nature, meditation retreats, and deep friendships. 
Diego Galaviz is a Deep Learning Architect at the AWS Generative AI Innovation Center. Before joining AWS, he had over 8 years of expertise as a data scientist across diverse sectors, including financial services, energy, big tech, and cybersecurity. He holds a masterâ€™s degree in artificial intelligence, which complements his practical industry experience. 
Laura Kulowski is a Senior Applied Scientist at the AWS Generative AI Innovation Center, where she works with customers to build generative AI solutions. Before joining Amazon, Laura completed her PhD at Harvardâ€™s Department of Earth and Planetary Sciences and investigated Jupiterâ€™s deep zonal flows and magnetic field using Juno data. 
Rafael Fernandes is the LATAM leader of the AWS Generative AI Innovation Center, whose mission is to accelerate the development and implementation of generative AI in the region. Before joining Amazon, Rafael was a co-founder in the financial services industry space and a data science leader with over 12 years of experience in Europe and LATAM.
â€¢ Empowering air quality research with secure, ML-driven predictive analytics
  Air pollution remains one of Africaâ€™s most pressing environmental health crises, causing widespread illness across the continent. Organizations like sensors.AFRICA have deployed hundreds of air quality sensors to address this challenge, but face a critical data problem: significant gaps in PM2.5 (particulate matter with diameter less than or equal to 2.5 micrometers) measurement records because of power instability and connectivity issues in high-risk regions where physical maintenance is limited. Missing data in PM2.5 datasets reduces statistical power and introduces bias into parameter estimates, leading to unreliable trend detection and flawed conclusions about air quality patterns. These data gaps ultimately compromise evidence-based decision-making for pollution control strategies, health impact assessments, and regulatory compliance. 
In this post, we demonstrate&nbsp;the time-series forecasting capability of&nbsp;Amazon SageMaker Canvas,&nbsp;a&nbsp;low-code no-code (LCNC) machine learning (ML) platform to predict PM2.5 from incomplete datasets. PM2.5 exposure contributes to millions of premature deaths globally through cardiovascular disease, respiratory illness, and systemic health effects, making accurate air quality forecasting a critical public health tool. A key advantage of the forecasting capability of SageMaker Canvas is its robust handling of incomplete data. Traditional air quality monitoring systems often require complete datasets to function properly, meaning they canâ€™t be relied on when sensors malfunction or require maintenance. In contrast, SageMaker Canvas can generate reliable predictions even when faced with gaps in sensor data. This resilience enables continuous operation of air quality monitoring networks despite inevitable sensor failures or maintenance periods, eliminating costly downtime and data gaps. Environmental agencies and public health officials benefit from uninterrupted access to critical air quality information, enabling timely pollution alerts and more comprehensive long-term analysis of air quality trends. By maintaining operational continuity even with imperfect data inputs, SageMaker Canvas significantly enhances the reliability and practical utility of environmental monitoring systems. 
In this post, we provide a data imputation solution using Amazon SageMaker AI, AWS Lambda, and AWS Step Functions. This solution is designed for environmental analysts, public health officials, and business intelligence professionals who need reliable PM2.5 data for trend analysis, reporting, and decision-making. We sourced our sample training dataset from openAFRICA. Our solution predicts PM2.5 values using time-series forecasting. The sample training dataset contained over 15 million records from March 2022 to Oct 2022 in various parts of Kenya and Nigeriaâ€”data coming from 23 sensor devices from 15 unique locations. The sample code and workflows can be adapted to create prediction models for your PM2.5 datasets. See our solutionâ€™s README for detailed instructions. 
Solution overview 
The solution consists of two main ML components: a training workflow and an inference workflow. These workflows are built using the following services: 
 
 SageMaker Canvas is used to prepare data and train the prediction model through its no-code interface 
 Batch Transform for inference with Amazon SageMaker AI&nbsp;is used for inference, processing the dataset in bulk to generate predictions 
 Step Functions orchestrates the inferencing process by coordinating the workflow between data retrieval, batch transforming, and database updates, managing workflow state transitions, and making sure that data flows properly through each processing stage 
 Lambda functions perform critical operations at each workflow step: retrieving sensor data from the database in required format, transforming data for model input, sending batches to SageMaker for inferencing, and updating the database with prediction results after processing is complete 
 
At a high level, the solution works by taking a set of PM2.5 data with gaps and predicts the missing values within the range of plus or minus 4.875 micrograms per cubic meter of the actual PM2.5 concentration. It does this by first training a model on the data using inputs for the specific schema and a historical set of values from the user to guide the training process, which is completed with SageMaker Canvas. After the model is trained on a representative dataset and schema, SageMaker Canvas exports the model for use with batch processing. The Step Functions orchestration calls a Lambda function every 24 hours that takes a dataset of new sensor data that has gaps and initiates a SageMaker batch transform job to predict the missing values. The batch transform job processes the entire dataset at once, and the Lambda function then updates the existing dataset with the results. The new completed dataset with predicted values can now be distributed to&nbsp;public health decision-makers who need complete datasets to effectively analyze the patterns of PM2.5 data. 
We dive into each of these steps in later sections of this post. 
Solution walkthrough 
The following diagram shows our solution architecture: 
 
Letâ€™s explore the architecture step by step: 
 
 To&nbsp;systematically collect, identify, and fill PM2.5 data gaps caused by sensor limitations and connectivity issues,&nbsp;Amazon EventBridge Scheduler invokes a Step Functions state machine every 24 hours.&nbsp;Step Functions orchestrates the calling of various Lambda functions to perform different steps without handling the complexities of error handling, retries, and state management, providing a serverless workflow that seamlessly coordinates the PM2.5 data imputation process. 
 The State Machine invokes a Lambda function in your&nbsp;Amazon Virtual Private Cloud (Amazon VPC) that retrieves records containing missing air quality values from the userâ€™s air quality database on Amazon Aurora PostgreSQL-Compatible Edition and stores the records in a CSV file in an Amazon Simple Storage Service (Amazon S3) bucket. 
 The State Machine then runs a Lambda function that retrieves the records from Amazon S3 and initiates the SageMaker batch transform job in your VPC using your SageMaker model created from your SageMaker Canvas predictive model trained on historical PM2.5 data. 
 To streamline the batch transform workflow, this solution uses an event-driven approach with EventBridge and Step Functions. EventBridge captures completion events from SageMaker batch transform jobs, while the task token functionality of Step Functions enables extended waiting periods beyond the time limits of Lambda. After processing completes, SageMaker writes the prediction results directly to an S3 bucket. 
 The final step in the state machine retrieves the predicted values from the S3 bucket and then updates the database in&nbsp;Aurora PostgreSQL-Compatible with the values including a predicted label set to true. 
 
Prerequisites 
To implement the PM2.5 data imputation solution, you must have the following: 
 
 An AWS account with&nbsp;AWS Identity and Access Management (IAM)&nbsp;permissions sufficient to deploy the solution and interact with the database. 
 The following AWS services: 
   
   Amazon SageMaker AI 
   AWS Lambda 
   AWS Step Functions 
   Amazon S3 
   Aurora&nbsp;PostgreSQL-Compatible 
   Amazon CloudWatch 
   AWS CloudFormation 
   Amazon Virtual Private Cloud (VPC) 
   Amazon EventBridge 
   IAM for authentication to&nbsp;Aurora&nbsp;PostgreSQL-Compatible 
   AWS Systems Manager Parameter Store 
    
 A local desktop set up with AWS Command Line Interface (AWS CLI) version 2, Python 3.10, AWS Cloud Development Kit (AWS CDK) v2.x, and Git version 2.x. 
 The AWS CLI set up with the necessary credentials in the desired AWS Region. 
 Historical air quality sensor data. Note that our solution requires a fixed schema described in the GitHub repoâ€™s README. 
 
Deploy the solution 
You will run the following steps to complete the deployment: 
 
 Prepare your environment by building Python modules locally for Lambda layers, deploying infrastructure using the AWS CDK, and initializing your Aurora PostgreSQL database with sensor data. 
 Perform steps in the Build your air quality prediction model section to configure a SageMaker Canvas application, followed by training and registering your model in Amazon SageMaker Model Registry. 
 Create SageMaker model using your registered SageMaker Canvas model by updating infrastructure using the AWS CDK. 
 Manage future configuration changes using the AWS CDK. 
 
Step 1: Deploy AWS infrastructure and upload air quality sensor data 
Complete the following steps to deploy the PM2.5 data imputation solution AWS Infrastructure and upload air quality sensor data to Amazon Aurora RDS: 
 
 Clone the repository to your local desktop environment using the following command: 
 
 
 git clone git@github.com:aws-samples/sample-empowering-air-quality-research-secure-machine-learning-predictive-analytics.git 
 
 
 Change to the project directory: 
 
cd &lt;BASE_PROJECT_FOLDER&gt; 
 
 Follow the deployment steps in the README&nbsp;file up to Model Setup for Batch Transform Inference. 
 
Step 2: Build your air quality prediction model 
After you create the SageMaker AI domain and the SageMaker AI user profile as part of the CDK deployment steps, follow these steps to build your air quality prediction model 
Configure your SageMaker Canvas application 
 
 On the AWS Management Console, go to the&nbsp;SageMaker AI&nbsp;console and select the domain and the user profile that was created under Admin, Configurations, and Domains. 
 Choose the App Configurations tab, scroll down to the Canvas section, and select Edit. 
 In Canvas storage configuration, select Encryption and select the dropdown for aws/s3. 
 In the ML Ops Configuration, turn on the option to Enable Model Registry registration permissions for this user profile. 
   
   Optionally, in the Local file upload configuration&nbsp;section in your domainâ€™s Canvas App Configuration, you can turn on Enable local file upload. 
    
 Choose Submit to save your configuration choices. 
 In your Amazon SageMaker AI home page, go to the Applications and IDEs section and select Canvas. 
 Select the SageMaker AI user profile that was created for you by the CDK deployment and choose Open Canvas. 
 In a new tab, SageMaker Canvas will start creating your application. This takes a few minutes. 
 
Create and register your prediction model 
In this phase, you develop a prediction model using your historical air quality sensor data. 
 
The preceding architecture diagram illustrates the end-to-end process for training the SageMaker Canvas prediction model, registering that model and creating a SageMaker model for running inference on newly found PM2.5 data gaps.&nbsp;The training process starts by extracting air quality sensor dataset from the database. The dataset is imported into SageMaker Canvas for predictive analysis. This training dataset is transformed and prepared through data wrangling steps implemented by SageMaker Canvas for building and training ML models. 
Prepare data 
Our solution supports a SageMaker Canvas model trained for a single-target variable prediction based on historical data and performs corresponding data imputation for PM2.5 data gaps. To train your model for predictive analysis, follow the comprehensive End to End Machine Learning workflow in the AWS Canvas Immersion Day workshop, adapting each step to prepare your air quality sensor dataset. Begin with the standard workflow until you reach the data preparation section. Here, you can make several customizations: 
 
 Filter dataset for single-target value prediction: Your air quality dataset might contain multiple sensor parameters. For single-target value prediction using this solution, filter the dataset to include only PM2.5 measurements. 
 Clean sensor data: Remove records containing sensor fault values. For example, we filtered out values that equal 65535, because 65535 is a common error code for malfunctioning sensors. Adjust this filtering based on the specific error codes your air quality monitoring equipment produces. 
 
The following image shows our data wrangling Data Flow implemented using above guidance: 
Data Wrangler &gt; Data Flow 
 
 
 Review generated insights and remove irrelevant data: Review the SageMaker Canvas generated insights and analyses. Evaluate them based on time-series forecasting and geospatial temporal data for air quality patterns and relationships between other columns of impact. See chosen columns of impact in GitHub for guidance. Analyze your dataset to identify rows and columns that impact the prediction and remove data that can reduce prediction accuracy. 
 
The following image shows our data wrangling&nbsp;Analyses obtained with implementing the above guidance: 
Data Wrangler &gt; Analyses 
 
Training your prediction model 
After completing your data preparation, proceed to the Train the Model section of the workshop and continue with these specifications: 
 
 Select problem type: Select Predictive Analysis as your ML approach. Because our dataset is tabular and contains a timestamp, a target column that has values weâ€™re using to forecast future values, and a device ID column, SageMaker Canvas will choose time series forecasting. 
 Define target column: Set Value as your target column for predicting PM2.5 values. 
 Build configuration: Use the Standard Build option for model training because it generally has a higher accuracy. See What happens when you build a model in How custom models work&nbsp;for more information. 
 
By following these steps, you can create a model optimized for PM2.5 dataset predictive analysis, capable of generating valuable insights. Note that SageMaker Canvas supports retraining the ML model for updated PM2.5 datasets. 
Evaluate the model 
After training your model, proceed to Evaluate the model and review column impact, root mean square error (RMSE) score and other advanced metrics to understand your modelâ€™s performance for generating predictions for PM2.5. 
The following image shows our model evaluation statistics achieved. 
 
Add the model to the registry 
Once you are satisfied with your model performance, follow the steps in Register a model version to the SageMaker AI model registry. Make sure to change the approval status to Approved before continuing to run this solution. At the time of this postâ€™s publication, the approval must be updated in Amazon SageMaker Studio. 
Log out of SageMaker Canvas 
After completing your work in SageMaker Canvas, you can log out or configure your application to automatically terminate the&nbsp;workspace instance. A workspace instance is dedicated for your use every time you launch a Canvas application, and you are billed for as long as the instance runs. Logging out or terminating the workspace instance stops the workspace instance billing. For more information, see billing and cost in SageMaker Canvas. 
Step 3: Create a SageMaker model using your registered SageMaker Canvas model 
In the previous steps, you created a SageMaker domain and user profile through CDK deployment (Step 1) and successfully registered your model (Step 2). Now, itâ€™s time to create the SageMaker model in your VPC using the SageMaker Canvas model you registered. Follow Model Setup for Batch Inference and Re-Deploy with Updated Configuration sections in the code README for creating SageMaker model. 
Step 4: Manage future configuration changes 
The same deployment pattern applies to any future configuration modifications you might require, including: 
 
 Batch transform instance type optimizations 
 Transform job scheduling changes 
 
Update the relevant parameters in your configuration and run cdk deploy to propagate these changes throughout your solution architecture. 
For a comprehensive list of configurable parameters and their default values, see the configuration file in the repository. 
Execute cdk deploy again to update your infrastructure stack with the your model ID for batch transform operations, replacing the placeholder value initially deployed. This infrastructure-as-code approach helps ensure consistent, version-controlled updates to your data imputation workflow. 
Security best practices 
Security and compliance is a shared responsibility between AWS and the customer, as outlined in the Shared Responsibility Model. We encourage you to review this model for a comprehensive understanding of the respective responsibilities. 
In this solution, we enhanced security by implementing encryption at rest for Amazon S3, Aurora PostgreSQL-Compatible database, and the SageMaker Canvas application. We also enabled encryption in transit by requiring SSL/TLS for all connections from the Lambda functions. We implemented secure database access by providing temporary dynamic credentials through IAM authentication for Amazon RDS, eliminating the need for static passwords. Each Lambda function operates with least privilege access, receiving only the minimal permissions required for its specific function. Finally, we deployed the Lambda functions, Aurora PostgreSQL-Compatible instance, and SageMaker Batch Transform jobs in private subnets of the VPC that do not traverse the public internet. This private network architecture is enabled through VPC endpoints for Amazon S3, SageMaker AI, and&nbsp;AWS Secrets Manager. 
Results 
As shown in the following image, our model, developed using SageMaker Canvas, predicts PM2.5 values with an R-squared of 0.921. Because ML models for PM2.5 prediction frequently achieve R-squared values between 0.80 and 0.98 (see this example from ScienceDirect), our solution is within the range of higher-performing PM2.5 prediction models available today. SageMaker Canvas delivers this performance through its no-code experience, automatically handling model training and optimization without requiring ML expertise from users. 
 
Clean up 
Complete the following steps to clean up your resources: 
 
 SageMaker Canvas application cleanup: 
   
   On the go to the&nbsp;SageMaker AI&nbsp;console and select the domain that was created under Admin&nbsp;Configurations, and Domains. 
   Select the user created under User Profiles&nbsp;for that domain. 
   On the User Details page, navigate to&nbsp;Spaces and Apps, and choose Delete to manually delete your SageMaker AI canvas application and clean up resources. 
    
 SageMaker Domain EFS storage cleanup: 
   
   Open Amazon EFS&nbsp;and in File systems, delete filesystem tagged as ManagedByAmazonSageMakerResource. 
   Open VPC and under Security, navigate to Security groups. 
   On Security groups, select security-group-for-inbound-nfs-&lt;your-sagemaker-domain-id&gt; and delete all Inbound rules associated with that group. 
   On Security groups, select security-group-for-outbound-nfs-&lt;your-sagemaker-domain-id&gt; and delete all associated Outbound rules. 
   Finally, delete both the security groups:&nbsp;security-group-for-inbound-nfs-&lt;your-sagemaker-domain-id&gt; and&nbsp;security-group-for-outbound-nfs-&lt;your-sagemaker-domain-id&gt;. 
    
 Use the AWS CDK to clean up the remaining AWS resources: 
   
   After the preceding steps are complete, return to your local desktop environment where the GitHub repo was cloned, and change to the projectâ€™s infra directory: cd &lt;BASE_PROJECT_FOLDER&gt;/infra 
   Destroy the resources created with AWS CloudFormation using the AWS CDK: cdk destroy 
   Monitor the AWS CDK process deleting resources created by the solution. If there are any errors, troubleshoot using the CloudFormation console and then retry deletion. 
    
 
Conclusion 
The development of accurate PM2.5 prediction models has traditionally required extensive technical expertise, presenting significant challenges for public health researchers studying air pollutionâ€™s impact on disease outcomes. From data preprocessing and feature engineering to model selection and hyperparameter tuning, these technical requirements diverted substantial time and effort away from researchersâ€™ core work of analyzing health outcomes and developing evidence-based interventions.SageMaker Canvas transforms this landscape by dramatically reducing the effort required to develop high-performing PM2.5 prediction models. Public health researchers can now generate accurate predictions without mastering complex ML algorithms, iterate quickly through an intuitive interface, and validate models across regions without manual hyperparameter tuning. With this shift to streamlined, accessible prediction capabilities, researchers can dedicate more time to interpreting results, understanding air pollutionâ€™s impact on community health, and developing protective interventions for vulnerable populations. The result is more efficient research that responds quickly to emerging air quality challenges and informs timely public health decisions. We invite you to implement this solution for your air quality research or ML-based predictive analytics projects. Our comprehensive deployment steps and customization guidance will help you launch quickly and efficiently. As we continue enhancing this solution, your feedback is invaluable for improving its capabilities and maximizing its impact. 
 
About the authors 
Nehal Sangoi is a Senior Technical Account Manager at Amazon Web Services. She provides strategic technical guidance to help independent software vendors plan and build solutions using AWS best practices. Connect with Nehal on LinkedIn. 
Ben Peterson is a Senior Technical Account Manager with AWS. He is passionate about enhancing the developer experience and driving customer success. In his role, he provides strategic guidance on using the comprehensive AWS suite of services to modernize legacy systems, optimize performance, and unlock new capabilities. Connect with Ben on LinkedIn. 
Shashank Shrivastava is a Senior Delivery Consultant and Serverless TFC member at AWS. He is passionate about helping customers and developers build modern applications on serverless architecture. As a pragmatic developer and blogger, he promotes community-driven learning and sharing of technology. His interests are software architecture, developer tools, GenAI, and serverless computing. Connect with Shashank on LinkedIn. 
Akshay Singhal is a Senior Technical Account Manager at Amazon Web Services supporting Enterprise Support customers focusing on the Security ISV segment. He provides technical guidance for customers to implement AWS solutions, with expertise spanning serverless architectures and cost optimization. Outside of work, Akshay enjoys traveling, Formula 1, making short movies, and exploring new cuisines. Connect with Akshay on LinkedIn.

â¸»