‚úÖ Morning News Briefing ‚Äì October 01, 2025 10:44

üìÖ Date: 2025-10-01 10:44
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ FROST ADVISORY, Pembroke
  Persons in or near this area should be on the lookout for adverse weather conditions and take necessary safety precautions . People in or around this area are advised to take necessary precautions . Weather conditions are expected to worsen in the coming years . People should be prepared for the worst of the worst weather conditions in the area . The weather is expected to deteriorate rapidly in the years of the 2025 period .
‚Ä¢ Current Conditions:  1.7¬∞C
  Temperature: 1.7&deg;C Pressure / Tendency: 102.9 kPa rising Humidity: 92 % Dewpoint: 0.5&deg:C Wind: WNW 3 km/h . Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Wednesday 1 October 2025 . Weather forecast: 1/7¬∞C Pem
‚Ä¢ Wednesday: Sunny. High 16.
  Sunny. Sunny. High 16. UV index 6 or high . Sunny . High 16 . Sunny. Humidity 6 or low . High 17.50 . Humidity 7.6.50% . High 18.40% Humidity 9.50%. Humidity 8.50%, UV index 5 or high; UV index 4 or low; UV 9.20% UV 10 .

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Kimmel and Colbert appear as guests on each other's shows
  Jimmy Kimmel Live! on ABC and The Late Show with Stephen Colbert on CBS on Tuesday night, in New York City, they united in a special talk show crossover . Jimmy Kimmel and Stephen Colbert appeared together for the first time in a week . Kimmel, Colbert and Colbert appeared on a special edition of the two shows, which aired on ABC's "Jimmy Kimmel Live!" and CBS' "
‚Ä¢ Fool me once: the magical origin of the word hoax
  Frauds, swindles, cons, scams, and deceptions are collectively known as hoaxes . But there's more than meets the eye . Frauds are known as scams, but they are also known as 'hoaxes' and 'deceptions' Frauds and scams are known to be hoaxes, but there is more than the eye to be seen in the world
‚Ä¢ China's ride-hailing companies try to quell the smell in cars where some drivers sleep
  China's ride-hailing car drivers work long hours to get enough fares, and often live in their cars . Companies and passengers are penalizing drivers for smelly vehicles . Drivers are penalized for having smelly cars, according to the report . China's drivers are working long hours, often living in their vehicles, to earn enough money to get the fares and live in them .
‚Ä¢ A GOP push to restrict voting by overseas U.S. citizens continues before 2026 midterms
  Republican officials are pushing for more voting restrictions on U.S. citizens who were born abroad and have never lived in the country . They unsuccessfully challenged their ballots in 2024 after unsuccessfully challenging their ballots . Republican officials want more restrictions on those born abroad who have never been in the United States . They want to see more restrictions in order to prevent the influx of illegal immigrants from moving to the U
‚Ä¢ Fans of the mysterious Mothman bring its West Virginia hometown new life
  Mothman started in the 1960s, when two couples told a harrowing story about being chased by a large flying creature on a rural road . It grew from there ‚Äî and now 20,000 people come to celebrate Mothsman . Two couples told each other a harrowing tale of being chased and chased by the flying creature in the 1970s . The event is now held in honor of

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Judge dismisses Arm's last legal claim against Qualcomm in licensing spat
  Chip designer tells The Reg it plans to appeal Qualcomm is claiming complete victory over Arm in licensing spat . Court in Delaware ruled it has not breached terms of any architecture license agreement (ALA) with chip designer . Arm says it will appeal Qualcomm's decision, which was made in court in Delaware, and it will continue to appeal the decision . Arm chip designer tells the Reg that it plans
‚Ä¢ Imgur yanks Brit access to memes as parent company faces fine
  UK data watchdog describes Imgur's move to block UK users as "commercial decision" after signaling plans to fine parent company MediaLab . ICO investigation into platform's lack of age assurance continues . Imgur blocked UK users from using the platform in the U.S. for the first time since November 2013 . MediaLab is set to be fined by the UK's data watchdog for the breach
‚Ä¢ Explain digital ID or watch it fizzle out, UK PM Starmer told
  UK prime minister Keir Starmer avoided mentioning the mandatory digital ID scheme in his keynote speech to the Labour Party conference . Calls for him to put meat on the bones of the plans or risk it failing fast . Politico avoids the topic at Labour conference speech, homes in on AI instead instead of the issue of ID cards . The Labour leader has been criticised for not putting meat in the bones
‚Ä¢ Schools are swotting up on security yet still flunk recovery when cyberattacks strike
  Coursework 'gone forever' as 10% report critical damage from cyberattacks . Schools and colleges hit by cyberattacks are taking longer to restore their networks . The consequences are severe, with students' coursework being permanently lost in some cases . Students' course work may be permanently lost as schools and colleges take longer to get back on their networks, experts say . Students may not be able
‚Ä¢ UK's digital hospital plan meets analog reality check
  Experts ask: Where will staff come from, and what about gran's flip phone? The government has announced a new "digital hospital" service in England . It will provide online appointments with consultants as an alternative to visiting a National Health Service (NHS) hospital . Experts ask if staff will come from and if gran has a flip phone, how will she use it? And what about

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ The role of the patient in rheumatology
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Effects of plyometrics training on lower limb strength, power, agility, and body composition in athletically trained adults: systematic review and meta-analysis
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Make cities more walkable, in the real world and in virtual reality
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Long-term effects of multicomponent training on body composition and physical fitness in breast cancer survivors: a controlled study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Forest soundscapes improve mood, restoration and cognition, but not physiological stress or immunity, relative to industrial soundscapes
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ Designing CPUs for next-generation supercomputing
  Recent predictions anticipate that GPU and accelerator installations will increase by 17% year over year through 2030 . CPUs are still responsible for the vast majority of today‚Äôs most cutting-edge scientific, engineering, and research workloads . A new wave of CPU innovation, including high-bandwidth memory (HBM), is delivering major performance gains without requiring costly architectural resets . To learn more, watch the new webcast &#8220;Powering HPC with next-generation CPUs .
‚Ä¢ Powering HPC with next-generation CPUs
  For all the excitement around GPUs, the central processing unit (CPU) remains the backbone of high-performance computing . CPUs still handle 80% to 90% of HPC workloads globally, powering everything from climate modeling to semiconductor design . The relationship between CPUs, GPUs, and specialized processors will define the future of Hpc . For many organizations, the CPU is the strategic choice that balances speed, efficiency, and cost .
‚Ä¢ The Download: our thawing permafrost, and a drone-filled future
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Scientists can see Earth‚Äôs permafrost thawing from space



Something is rotten in the city of Nunapitchuk. In recent years, sewage has leached into the earth. The ground can feel squishy, sodden.This small town in northern Alaska is experiencing a sometimes overlooked consequence of climate change: thawing permafrost. And Nunapitchuk is far from the only Arctic town to find itself in such a predicament.¬†



Now scientists think they may be able to use satellite data to delve deep beneath the ground‚Äôs surface and get a better understanding of how the permafrost thaws, and which areas might be most severely affected. Read the full story.



‚ÄîSarah Scoles







The US may be heading toward a drone-filled future



‚ÄîJames O&#8217;Donnell



Last week, I published a story about the police-tech giant Flock Safety selling its drones to the private sector to track shoplifters. Keith Kauffman, a former police chief who now leads Flock‚Äôs drone efforts, described the ideal scenario: A security team at a Home Depot, say, launches a drone from the roof that follows shoplifting suspects to their car. The drone tracks their car through the streets, transmitting its live video feed directly to the police.It‚Äôs a vision that, unsurprisingly, alarms civil liberties advocates. But the fate of drones in the US pretty much comes down to one rule. It‚Äôs a Federal Aviation Administration regulation that stipulates where and how drones can be flown‚Äîand it is about to change. Read the full story.



This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.







Trump‚Äôs impact on the next generation of innovators



Every year, MIT Technology Review recognizes dozens of young researchers on our Innovators Under 35 list. This year Amy Nordrum, our executive editor, and our senior investigative reporter Eileen Guo checked back in with recent honorees to see how they‚Äôre faring amid sweeping changes to science and technology policy within the US.Join us tomorrow at 1.30pm ET for an exclusive Roundtables conversation with Amy and Eileen to learn about the complex realities of what life has been like for those aiming to build their labs and companies in today‚Äôs political climate. Register here!







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 California‚Äôs governor has signed America‚Äôs first AI law¬†It‚Äôll require AI developers to publicly disclose their safety and security protocols. (Politico)+ The landmark bill has received a mixed reception from the AI industry. (TechCrunch)



2 The Trump administration is pressuring TaiwanIt‚Äôs pushing officials to move 50% of chip production to the US‚Äîor else. (Ars Technica)+ The US argues it‚Äôs the best way to counter invasion threats from China. (Bloomberg $)+ Taiwan‚Äôs ‚Äúsilicon shield‚Äù could be weakening. (MIT Technology Review)



3 US ChatGPT users can now buy stuff without leaving the chatbotIt‚Äôs laying the groundwork for AI agent-based shopping. (WSJ $)+ Etsy is among the first retailers to sign up for the service. (CNBC)+ It‚Äôs a direct challenge to Google‚Äôs business model. (Fortune $)+ Your most important customer may be AI. (MIT Technology Review)



4 YouTube has agreed to settle a lawsuit brought by Trump¬†It‚Äôs handing over $24.5 million after his account was suspended in the wake of the US Capitol riot in 2021. (WSJ $)+ It‚Äôs the third giant tech platform to bend to the President‚Äôs will. (The Verge)



5 Meta is expanding use of its facial recognition toolsIn a bid to combat account impersonation in Europe, the UK, and South Korea. (Engadget) 



6 The US Energy Department has banned the term ‚Äúclimate change‚ÄùSee also: ‚Äúgreen‚Äù and ‚Äúdecarbonization.‚Äù (Politico)+ Even ‚Äúemissions‚Äù isn‚Äôt safe. (TechCrunch)+ How to make clean energy progress under Trump in the States. (MIT Technology Review)



7 AI data centers are sending the cost of electricity skyrocketingAnd it‚Äôs regular citizens who are left paying the price. (Bloomberg $)+ Sam Altman wants a staggering amount of energy. (The Information $)+ The data center boom in the desert. (MIT Technology Review)



8 Elon Musk‚Äôs senior staff are leaving in their drovesThey‚Äôre burnt out and tired of their leader‚Äôs erratic strategies. (FT $)



9 Do black holes actually exist?The evidence says yes, but proving it is a different matter. (New Scientist $)10 California police tried to ticket a driverless car¬†But who‚Äôs to blame for its illegal U-turn if there‚Äôs no driver? (The Guardian)+ It turns out officers don‚Äôt currently have any way to issue tickets to robots. (Insider $)







Quote of the day



‚ÄúThere are certainly people in [the] tech world who would like to see no regulation of anything in any respect whatsoever, but that‚Äôs not tenable.‚Äù



‚ÄîUS Senator Scott Wiener, who proposed the original AI Safety Bill last year, explains why he believes the revised version that‚Äôs been passed into law is a reasonable approach to the New York Times.







One more thing











How mobile money supercharged Kenya‚Äôs sports betting addictionMobile money has mostly been hugely beneficial for Kenyans. But it has also turbo-charged the country‚Äôs sports betting sector.Since the middle of the last decade, experts and public figures across the African continent have been sounding the alarm over the rising popularity of sports betting. The practice has produced tales of riches, but it has also broken families, consumed college tuitions, and even driven some to suicide.Nowhere, though, is the craze as acute as it is in Kenya, the country often dubbed Africa‚Äôs ‚ÄúSilicon Savannah‚Äù for its status as a regional tech powerhouse. But while Kenya‚Äôs mobile money revolution has played a well-documented role in encouraging savings and democratizing access to finance, today, it‚Äôs easier than ever for those in fragile economic circumstances to squander everything. Read the full story.



‚ÄîJonathan W. Rosen







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ It took one man 16 years to type the numbers from one to a million‚Äîusing words and just one finger.+ Furnishing your home with books you have no interest in reading is certainly a choice.+ What it‚Äôs like to play SimCity 2000 as a responsible adult.+ It&#8217;s almost pumpkin season!
‚Ä¢ The US may be heading toward a drone-filled future
  Police-tech giant Flock Safety is selling its drones to the private sector to track shoplifters . The company is in the middle of a federal lawsuit in Norfolk, Virginia, that alleges just that . Civil liberties advocates say it will expand the surveillance state created by police drones, license-plate readers, and other crime tech . In August, the FAA released a new proposed rule to allow drone operators to fly beyond visual line of sight .
‚Ä¢ Scientists can see Earth‚Äôs permafrost thawing from space
  Something is rotten in the city of Nunapitchuk. In recent years, a crack has formed in the middle of a house. Sewage has leached into the earth. Soil has eroded around buildings, leaving them perched atop precarious lumps of dirt. There are eternal puddles. And mold. The ground can feel squishy, sodden.&nbsp;



This small town in northern Alaska is experiencing a sometimes overlooked consequence of climate change: thawing permafrost. And Nunapitchuk is far from the only Arctic town to find itself in such a predicament.&nbsp;



Permafrost, which lies beneath about 15% of the land in the Northern Hemisphere, is defined as ground that has remained frozen for at least two years. Historically, much of the world‚Äôs permafrost has remained solid and stable for far longer, allowing people to build whole towns atop it. But as the planet warms, a process that is happening more rapidly near the poles than at more temperate latitudes, permafrost is thawing and causing a host of infrastructural and environmental problems.



Now scientists think they may be able to use satellite data to delve deep beneath the ground‚Äôs surface and get a better understanding of how the permafrost thaws, and which areas might be most severely affected because they had more ice to start with. Clues from the short-term behavior of those especially icy areas, seen from space, could portend future problems.



Using information gathered both from space and on the ground, they are working with affected communities to anticipate whether a house‚Äôs foundation will crack‚Äîand whether it is worth mending that crack or is better to start over in a new house on a stable hilltop. These scientists‚Äô permafrost predictions are already helping communities like Nunapitchuk make those tough calls.



But it‚Äôs not just civilian homes that are at risk. One of the top US intelligence agencies, the National Geospatial-Intelligence Agency (NGA), is also interested in understanding permafrost better. That‚Äôs because the same problems that plague civilians in the high north also plague military infrastructure, at home and abroad. The NGA is, essentially, an organization full of space spies‚Äîpeople who analyze data from surveillance satellites and make sense of it for the country‚Äôs national security apparatus.&nbsp;



Understanding the potential instabilities of the Alaskan military infrastructure‚Äîwhich includes radar stations that watch for intercontinental ballistic missiles, as well as military bases and National Guard posts‚Äîis key to keeping those facilities in good working order and planning for their strengthened future. Understanding the potential permafrost weaknesses that could affect the infrastructure of countries like Russia and China, meanwhile, affords what insiders might call ‚Äúsituational awareness‚Äù about competitors.&nbsp;



The work to understand this thawing will only become more relevant, for civilians and their governments alike, as the world continues to warm.&nbsp;



The ground beneath



If you live much below the Arctic Circle, you probably don‚Äôt think a lot about permafrost. But it affects you no matter where you call home.



In addition to the infrastructural consequences for real towns like Nunapitchuk, thawing permafrost contains sequestered carbon‚Äîtwice as much as currently inhabits the atmosphere. As the permafrost thaws, the process can release greenhouse gases into the atmosphere. That release can cause a feedback loop: Warmer temperatures thaw permafrost, which releases greenhouse gases, which warms the air more, which then‚Äîyou get it.&nbsp;



The microbes themselves, along with previously trapped heavy metals, are also set dangerously free.



For many years, researchers‚Äô primary options for understanding some of these freeze-thaw changes involved hands-on, on-the-ground surveys. But in the late 2000s, Kevin Schaefer, currently a senior scientist at the Cooperative Institute for Research in Environmental Sciences at the University of Colorado Boulder, started to investigate a less labor-intensive idea: using radar systems aboard satellites to survey the ground beneath.&nbsp;



This idea implanted itself in his brain in 2009, when he traveled to a place called Toolik Lake, southwest of the oilfields of Prudhoe Bay in Alaska. One day, after hours of drilling sample cores out of the ground to study permafrost, he was relaxing in the Quonset hut, chatting with colleagues. They began to discuss how&nbsp; space-based radar could potentially detect how the land sinks and heaves back up as temperatures change.&nbsp;



Huh, he thought. Yes, radar probably could do that.&nbsp;



Scientists call the ground right above permafrost the active layer. The water in this layer of soil contracts and expands with the seasons: during the summer, the ice suffusing the soil melts and the resulting decrease in volume causes the ground to dip. During the winter, the water freezes and expands, bulking the active layer back up. Radar can help measure that height difference, which is usually around one to five centimeters.&nbsp;



Schaefer realized that he could use radar to measure the ground elevation at the start and end of the thaw. The electromagnetic waves that bounce back at those two times would have traveled slightly different distances. That difference would reveal the tiny shift in elevation over the seasons and would allow him to estimate how much water had thawed and refrozen in the active layer and how far below the surface the thaw had extended.



With radar, Schaefer realized, scientists could cover a lot more literal ground, with less effort and at lower cost.





‚ÄúIt took us two years to figure out how to write a paper on it,‚Äù he says; no one had ever made those measurements before. He and colleagues presented the idea at the 2010 meeting of the American Geophysical Union and published a paper in 2012 detailing the method, using it to estimate the thickness of the active layer on Alaska‚Äôs North Slope.



When they did, they helped start a new subfield that grew as large-scale data sets started to become available around 5 to 10 years ago, says Roger Michaelides, a geophysicist at Washington University in St. Louis and a collaborator of Schaefer‚Äôs. Researchers‚Äô efforts were aided by the growth in space radar systems and smaller, cheaper satellites.&nbsp;



With the availability of global data sets (sometimes for free, from government-run satellites like the European Space Agency‚Äôs Sentinel) and targeted observations from commercial companies like Iceye, permafrost studies are moving from bespoke regional analyses to more automated, large-scale monitoring and prediction.



The remote view



Simon Zwieback, a geospatial and environmental expert at the University of Alaska Fairbanks, sees the consequences of thawing permafrost firsthand every day. His office overlooks a university parking lot, a corner of which is fenced off to keep cars and pedestrians from falling into a brand-new sinkhole. That area of asphalt had been slowly sagging for more than a year, but over a week or two this spring, it finally started to collapse inward.&nbsp;



Kevin Schaefer stands on top of a melting layer of ice near the Alaskan pipeline on the North Slope of Alaska.COURTESY OF KEVIN SCHAEFER




The new remote research methods are a large-scale version of Zwieback taking in the view from his window. Researchers look at the ground and measure how its height changes as ice thaws and refreezes. The approach can cover wide swaths of land, but it involves making assumptions about what‚Äôs going on below the surface‚Äînamely, how much ice suffuses the soil in the active layer and permafrost. Thawing areas with relatively low ice content could mimic thinner layers with more ice. And it‚Äôs important to differentiate the two, since more ice in the permafrost means more potential instability.&nbsp;



To check that they‚Äôre on the right track, scientists have historically had to go out into the field. But a few years ago, Zwieback started to explore a way to make better and deeper estimates of ice content using the available remote sensing data. Finding a way to make those kinds of measurements on a large scale was more than an academic exercise: Areas of what he calls ‚Äúexcess ice‚Äù are most liable to cause instability at the surface. ‚ÄúIn order to plan in these environments, we really need to know how much ice there is, or where those locations are that are rich in ice,‚Äù he says.





Zwieback, who did his undergraduate and graduate studies in Switzerland and Austria, wasn‚Äôt always so interested in permafrost, or so deeply affected by it. But in 2014, when he was a doctoral student in environmental engineering, he joined an environmental field campaign in Siberia, at the Lena River Delta, which resembles a gigantic piece of coral fanning out into the Arctic Ocean. Zwieback was near a town called Tiksi, one of the world‚Äôs northernmost settlements. It‚Äôs a military outpost and starting point for expeditions to the North Pole, featuring an abandoned plane near the ocean. Its Soviet-era concrete buildings sometimes bring it to the front page of the r/UrbanHell subreddit.&nbsp;



Here, Zwieback saw part of the coastline collapse, exposing almost pure ice. It looked like a subterranean glacier, but it was permafrost. ‚ÄúThat really had an indelible impact on me,‚Äù he says.&nbsp;



Later, as a doctoral student in Zurich and postdoc in Canada, he used his radar skills to understand the rapid changes that the activity of permafrost impressed upon the landscape.&nbsp;



And now, with his job in Fairbanks and his ideas about the use of radar sensing, he has done work funded by the NGA, which has an open Arctic data portal.&nbsp;



In his Arctic research, Zwieback started with the approach underlying most radar permafrost studies: looking at the ground‚Äôs seasonal subsidence and heave. ‚ÄúBut that‚Äôs something that happens very close to the surface,‚Äù he says. ‚ÄúIt doesn‚Äôt really tell us about these long-term destabilizing effects,‚Äù he adds.



In warmer summers, he thought, subtle clues would emerge that could indicate how much ice is buried deeper down.



For example, he expected those warmer-than-average periods to exaggerate the amount of change seen on the surface, making it easier to tell which areas are ice-rich. Land that was particularly dense with ice would dip more than it ‚Äúshould‚Äù‚Äîa precursor of bigger dips to come.



The first step, then, was to measure subsidence directly, as usual. But from there, Zwieback developed an algorithm to ingest data about the subsidence over time‚Äîas measured by radar‚Äîand other environmental information, like the temperatures at each measurement. He then created a digital model of the land that allowed him to adjust the simulated amount of ground ice and determine when it matched the subsidence seen in the real world. With that, researchers could infer the amount of ice beneath.



Next, he made maps of that ice that could potentially be useful to engineers‚Äîwhether they were planning a new subdivision or, as his funders might be, keeping watch on a military airfield.



‚ÄúWhat was new in my work was to look at these much shorter periods and use them to understand specific aspects of this whole system, and specifically how much ice there is deep down,‚Äù Zwieback says.&nbsp;



The NGA, which has also funded Schaefer‚Äôs work, did not respond to an initial request for comment but did later provide feedback for fact-checking. It removed an article on its website about Zwieback‚Äôs grant and its application to agency interests around the time that the current presidential administration began to ban mention of climate change in federal research. But the thawing earth is of keen concern.&nbsp;



To start, the US has significant military infrastructure in Alaska: It‚Äôs home to six military bases and 49 National Guard posts, as well as 21 missile-detecting radar sites. Most are vulnerable to thaw now or in the near future, given that 85% of the state is on permafrost.&nbsp;



Beyond American borders, the broader north is in a state of tension. Russia‚Äôs relations with Northern Europe are icy. Its invasion of Ukraine has left those countries fearing that they too could be invaded, prompting Sweden and Finland, for instance, to join NATO. The US has threatened takeovers of Greenland and Canada. And China‚Äîwhich has shipping and resource ambitions for the region‚Äîis jockeying to surpass the US as the premier superpower.&nbsp;



Permafrost plays a role in the situation. ‚ÄúAs knowledge has expanded, so has the understanding that thawing permafrost can affect things NGA cares about, including the stability of infrastructure in Russia and China,‚Äù read the NGA article. Permafrost covers 60% of Russia, and thaws have affected more than 40% of buildings in northern Russia already, according to statements from the country‚Äôs minister of natural resources in 2021. Experts say critical infrastructure like roads and pipelines is at risk, along with military installations. That could weaken both Russia‚Äôs strategic position and the security of its residents. In China, meanwhile, according to a report from the Council on Strategic Risks, important moving parts like the Qinghai-Tibet Railway, ‚Äúwhich allows Beijing to more quickly move military personnel near contested areas of the Indian border,‚Äù is susceptible to ground thaw‚Äîas are oil and gas pipelines linking Russia and China.&nbsp;



In the field



Any permafrost analysis that relies on data from space requires verification on Earth. The hope is that remote methods will become reliable enough to use on their own, but while they‚Äôre being developed, researchers must still get their hands muddy with more straightforward and longer tested physical methods. Some use a network called Circumpolar Active Layer Monitoring, which has existed since 1991, incorporating active-layer data from hundreds of measurement sites across the Northern Hemisphere.&nbsp;



Sometimes, that data comes from people physically probing an area; other sites use tubes permanently inserted into the ground, filled with a liquid that indicates freezing; still others use underground cables that measure soil temperature. Some researchers, like Schaefer, lug ground-penetrating radar systems around the tundra. He‚Äôs taken his system to around 50 sites and made more than 200,000 measurements of the active layer.



The field-ready ground-penetrating radar comes in a big box‚Äîthe size of a steamer trunk‚Äîthat emits radio pulses. These pulses bounce off the bottom of the active layer, or the top of the permafrost. In this case, the timing of that reflection reveals how thick the active layer is. With handles designed for humans, Schaefer‚Äôs team drags this box around the Arctic‚Äôs boggier areas.&nbsp;



The box floats. ‚ÄúI do not,‚Äù he says. He has vivid memories of tromping through wetlands, his legs pushing straight down through the muck, his body sinking up to his hips.



Andy Parsekian and Kevin Schaefer haul a ground penetrating radar unit through the tundra near Utqiagvik.COURTESY OF KEVIN SCHAEFER




Zwieback also needs to verify what he infers from his space data. And so in 2022, he went to the Toolik Field station, a National Science Foundation‚Äìfunded ecology research facility along the Dalton Highway and adjacent to Schaefer‚Äôs Toolik Lake. This road, which goes from Fairbanks up to the Arctic Ocean, is colloquially called the Haul Road; it was made famous in the TV show Ice Road Truckers. From this access point, Zwieback‚Äôs team needed to get deep samples of soil whose ice content could be analyzed in the lab.



Every day, two teams would drive along the Dalton Highway to get close to their field sites. Slamming their car doors, they would unload and hop on snow machines to travel the final distance. Often they would see musk oxen, looking like bison that never cut their hair. The grizzlies were also interested in these oxen, and in the nearby caribou.&nbsp;



At the sites they could reach, they took out a corer, a long, tubular piece of equipment driven by a gas engine, meant to drill deep into the ground. Zwieback or a teammate pressed it into the earth. The barrel‚Äôs two blades rotated, slicing a cylinder about five feet down to ensure that their samples went deep enough to generate data that can be compared with the measurements made from space. Then they pulled up and extracted the cylinder, a sausage of earth and ice.



All day every day for a week, they gathered cores that matched up with the pixels in radar images taken from space. In those cores, the ice was apparent to the eye. But Zwieback didn‚Äôt want anecdata. ‚ÄúWe want to get a number,‚Äù he says.



So he and his team would pack their soil cylinders back to the lab. There they sliced them into segments and measured their volume, in both their frozen and their thawed form, to see how well the measured ice content matched estimates from the space-based algorithm.&nbsp;





The initial validation, which took months, demonstrated the value of using satellites for permafrost work. The ice profiles that Zwieback‚Äôs algorithm inferred from the satellite data matched measurements in the lab down to about 1.1 feet, and farther in a warm year, with some uncertainty near the surface and deeper into the permafrost.&nbsp;



Whereas it cost tens of thousands of dollars to fly in on a helicopter, drive in a car, and switch to a snowmobile to ultimately sample a small area using your hands, only to have to continue the work at home, the team needed just a few hundred dollars to run the algorithm on satellite data that was free and publicly available.&nbsp;



Michaelides, who is familiar with Zwieback‚Äôs work, agrees that estimating excess ice content is key to making infrastructural decisions, and that historical methods of sussing it out have been costly in all senses. Zwieback‚Äôs method of using late-summer clues to infer what‚Äôs going on at that depth ‚Äúis a very exciting idea,‚Äù he says, and the results ‚Äúdemonstrate that there is considerable promise for this approach.‚Äù&nbsp;



He notes, though, that using space-based radar to understand the thawing ground is complicated: Ground ice content, soil moisture, and vegetation can differ even within a single pixel that a satellite can pick out. ‚ÄúTo be clear, this limitation is not unique to Simon&#8217;s work,‚Äù Michaelides says; it affects all space-radar methods. There is also excess ice below even where Zwieback‚Äôs algorithm can probe‚Äîsomething the labor-intensive on-ground methods can pick up that still can‚Äôt be seen from space.&nbsp;



Mapping out the future



After Zwieback did his fieldwork, NGA decided to do its own. The agency‚Äôs attempt to independently validate his work‚Äîin Prudhoe Bay, Utqiagvik, and Fairbanks‚Äîwas part of a project it called Frostbyte.&nbsp;



Its partners in that project‚Äîthe Army‚Äôs Cold Regions Research Engineering Laboratory and Los Alamos National Laboratory‚Äîdeclined requests for interviews. As far as Zwieback knows, they‚Äôre still analyzing data.&nbsp;



But the intelligence community isn‚Äôt the only group interested in research like Zwieback‚Äôs. He also works with Arctic residents, reaching out to rural Alaskan communities where people are trying to make decisions about whether to relocate or where to build safely. ‚ÄúThey typically can‚Äôt afford to do expensive coring,‚Äù he says. ‚ÄúSo the idea is to make these data available to them.‚Äù&nbsp;



Zwieback and his team haul their gear out to gather data from drilled core samples, a process which can be arduous  and costly.ANDREW JOHNSON




Schaefer is also trying to bridge the gap between his science and the people it affects. Through a company called Weather Stream, he is helping communities identify risks to infrastructure before anything collapses, so they can take preventative action.



Making such connections has always been a key concern for Erin Trochim, a geospatial scientist at the University of Alaska Fairbanks. As a researcher who works not just on permafrost but also on policy, she‚Äôs seen radar science progress massively in recent years‚Äîwithout commensurate advances on the ground.



For instance, it‚Äôs still hard for residents in her town of Fairbanks‚Äîor anywhere‚Äîto know if there‚Äôs permafrost on their property at all, unless they‚Äôre willing to do expensive drilling. She‚Äôs encountered this problem, still unsolved, on property she owns. And if an expert can‚Äôt figure it out, non-experts hardly stand a chance. ‚ÄúIt‚Äôs just frustrating when a lot of this information that we know from the science side, and [that‚Äôs] trickled through the engineering side, hasn‚Äôt really translated into the on-the-ground construction,‚Äù she says.&nbsp;



There is a group, though, trying to turn that trickle into a flood: Permafrost Pathways, a venture that launched with a $41 million grant through the TED Audacious Project. In concert with affected communities, including Nunapitchuk, it is building a data-gathering network on the ground, and combining information from that network with satellite data and local knowledge to help understand permafrost thaw and develop adaptation strategies.&nbsp;



‚ÄúI think about it often as if you got a diagnosis of a disease,‚Äù says Sue Natali, the head of the project. ‚ÄúIt‚Äôs terrible, but it‚Äôs also really great, because when you know what your problem is and what you‚Äôre dealing with, it‚Äôs only then that you can actually make a plan to address it.‚Äù&nbsp;



And the communities Permafrost Pathways works with are making plans. Nunapitchuk has decided to relocate, and the town and the research group have collaboratively surveyed the proposed new location: a higher spot on hardpacked sand. Permafrost Pathways scientists were able to help validate the stability of the new site‚Äîand prove to policymakers that this stability would extend into the future.&nbsp;



Radar helps with that in part, Natali says, because unlike other satellite detectors, it penetrates clouds. ‚ÄúIn Alaska, it‚Äôs extremely cloudy,‚Äù she says. ‚ÄúSo other data sets have been very, very challenging. Sometimes we get one image per year.‚Äù



And so radar data, and algorithms like Zwieback‚Äôs that help scientists and communities make sense of that data, dig up deeper insight into what‚Äôs going on beneath northerners‚Äô feet‚Äîand how to step forward on firmer ground.&nbsp;



Sarah Scoles is a freelance science journalist based in southern Colorado and the author, most recently, of the book Countdown: The Blinding Future of Nuclear Weapons.

üîí Cybersecurity & Privacy
No updates.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Modernize fraud prevention: GraphStorm v0.5 for real-time inference
  Fraud continues to&nbsp;cause significant financial damage globally, with U.S. consumers alone losing $12.5 billion in 2024‚Äîa 25% increase from the previous year according to the Federal Trade Commission. This surge stems not from more frequent attacks, but from fraudsters‚Äô increasing sophistication. As fraudulent activities become more complex and interconnected, conventional machine learning approaches fall short by analyzing transactions in isolation, unable to capture the networks of coordinated activities that characterize modern fraud schemes. 
Graph neural networks (GNNs) effectively address this challenge by modeling relationships between entities‚Äîsuch as users sharing devices, locations, or payment methods. By analyzing both network structures and entity attributes, GNNs&nbsp;are effective at identifying sophisticated fraud schemes where perpetrators mask individual suspicious activities but leave traces in their relationship networks. However, implementing GNN-based online fraud prevention in production environments presents unique challenges: achieving sub-second inference responses, scaling to billions of nodes and edges, and maintaining operational efficiency for model updates.&nbsp;In this post, we show you how to overcome these challenges using GraphStorm, particularly the new real-time inference capabilities of GraphStorm v0.5. 
Previous solutions required tradeoffs between capability and simplicity. Our initial DGL approach provided comprehensive real-time capabilities but demanded intricate service orchestration‚Äîincluding manually updating endpoint configurations and payload formats after retraining with new hyperparameters. This approach also lacked model flexibility, requiring customization of GNN models and configurations when using architectures beyond relational graph convolutional networks (RGCN). Subsequent in-memory DGL implementations reduced complexity but&nbsp;encountered scalability limitations with enterprise data volumes. We built GraphStorm to bridge this gap, by introducing distributed training and high-level APIs that help simplify GNN development at enterprise scale. 
In a recent blog post, we illustrated GraphStorm‚Äôs enterprise-scale GNN model training and offline inference capability and simplicity. While offline GNN fraud detection can identify fraudulent transactions after they occur‚Äîpreventing financial loss requires stopping fraud before it happens. GraphStorm v0.5&nbsp;makes this possible through native real-time inference support through Amazon SageMaker AI. GraphStorm v0.5&nbsp;delivers two innovations: streamlined endpoint deployment that reduces weeks of custom engineering‚Äîcoding SageMaker entry point files, packaging model artifacts, and calling SageMaker deployment APIs‚Äîto a single-command operation, and standardized payload specification that helps simplify client integration with real-time inference services. These capabilities enable sub-second node classification tasks like fraud prevention, empowering organizations to proactively counter fraud threat with scalable, operationally straightforward GNN solutions. 
To showcase these capabilities, this post presents a fraud prevention solution. Through this solution, we show how a data scientist can transition a trained GNN model to production-ready inference endpoints with minimal operational overhead. If you‚Äôre interested in implementing GNN-based models for real-time fraud prevention or similar business cases, you can adapt the approaches presented here to create your own solutions. 
Solution overview 
Our proposed solution is a 4-step pipeline as shown in the following figure. The pipeline starts at step 1 with transaction graph export from an online transaction processing (OLTP) graph database to scalable storage (Amazon Simple Storage Service (Amazon S3) or Amazon EFS), followed by distributed model training in step 2. Step 3 is GraphStorm v0.5‚Äôs simplified deployment process that creates SageMaker&nbsp;real-time inference endpoints with one command. After SageMaker AI has deployed the endpoint successfully, a client application integrates with the OLTP graph database that processes live transaction streams in step 4. By querying the graph database, the client prepares subgraphs around to-be predicted transactions, convert the subgraph into standardized payload format, and invoke deployed endpoint for real-time prediction. 
 
To provide concrete implementation details for each step in the real-time inference solution, we demonstrate the complete workflow using the publicly available IEEE-CIS fraud detection task. 
Note: This example uses a Jupyter notebook as the controller of the overall four-step pipeline for simplicity. For more production-ready design, see the architecture described in Build a GNN-based real-time fraud detection solution. 
Prerequisites 
To run this example, you need an AWS account&nbsp;that&nbsp;the example‚Äôs AWS Cloud Development Kit (AWS CDK) code uses to create required resources, including Amazon Virtual Private Cloud (Amazon VPC), an Amazon Neptune database, Amazon SageMaker AI,&nbsp;Amazon Elastic Container Registry (Amazon ECR), Amazon S3, and related roles and permission. 
Note: These resources incur costs during execution (approximately $6 per hour with default settings). Monitor usage carefully and review pricing pages for these services before proceeding. Follow cleanup instructions at the end to avoid ongoing charges. 
Hands-on example: Real-time fraud prevention with IEEE-CIS dataset 
All implementation code for this example, including Jupyter notebooks and supporting Python scripts, is available in our public repository. The repository provides a complete end-to-end implementation that you can directly execute and adapt for your own fraud prevention use cases. 
Dataset and task overview 
This example uses the IEEE-CIS fraud detection dataset, containing 500,000 anonymized transactions with approximately 3.5% fraudulent cases. The dataset includes 392 categorical and numerical features, with key attributes like card types, product types, addresses, and email domains forming the graph structure shown in the following figure. Each transaction (with an isFraud&nbsp;label) connects to Card Type, Location, Product Type, and Purchaser and Recipient email domain entities, creating a heterogeneous graph that enables GNN models to detect fraud patterns through entity relationships. 
 
Unlike our previous post that demonstrated GraphStorm plus Amazon Neptune Analytics for offline analysis workflows, this example uses&nbsp;a Neptune database as the OLTP graph store, optimized for the quick subgraph extraction required during real-time inference. Following the graph design, the tabular IEEE-CIS data is converted to a set CSV files compatible with Neptune database format, allowing direct loading into both the Neptune database and GraphStorm‚Äôs GNN model training pipeline with a single set of files. 
Step 0: Environment setup 
Step 0 establishes the running environment required for the four-step fraud prevention pipeline. Complete setup instructions are available in the implementation repository. 
To run the example solution, you need to deploy an AWS CloudFormation stack through the AWS CDK. This stack creates the Neptune DB instance, the VPC to place it in, and appropriate roles and security groups. It additionally creates a SageMaker AI notebook instance, from which you run the example notebooks&nbsp;that come with the repository. 
 
 git clone https://github.com/aws-samples/amazon-neptune-samples.git
cd neptune-database-graphstorm-online-inference/neptune-db-cdk
# Ensure you have CDK installed and have appropriate credentials set up
cdk deploy 
 
When deployment is finished (it takes approximately 10 minutes for required resources to be ready), the AWS CDK prints a few outputs, one of which is the name of the SageMaker notebook instance you use to run through the notebooks: 
 
 # Example output
NeptuneInfraStack.NotebookInstanceName = arn:aws:sagemaker:us-east-1:012345678912:notebook-instance/NeptuneNotebook-9KgSB9XXXXXX 
 
You can navigate to the SageMaker AI notebook UI, find the corresponding notebook instance, and select its Open Jupyterlab link to access the notebook. 
Alternatively, you can use the AWS Command Line Interface (AWS CLI) to get a pre-signed URL to access the notebook. You will need to replace the &lt;notebook-instance-name&gt; with the actual notebook instance name. 
 
 aws sagemaker create-presigned-notebook-instance-url --notebook-instance-name &lt;notebook-instance-name&gt; 
 
When you‚Äôre in the notebook instance web console, open the first notebook, 0-Data-Preparation.ipynb, to start going through the example. 
Step 1: Graph construction 
In the Notebook 0-Data-Preparation, you transform the tabular IEEE-CIS dataset into the heterogeneous graph structure shown in the figure at the start of this section. The provided Jupyter Notebook extracts entities from transaction features, creating Card Type nodes from card1‚Äìcard6 features, Purchaser and Recipient nodes from email domains, Product Type nodes from product codes, and Location nodes from geographic information. The transformation establishes relationships between transactions and these entities, generating graph data in Neptune import format for direct ingestion into the OLTP graph store. The create_neptune_db_data() function orchestrates this entity extraction and relationship creation process across all node types (which takes approximately 30 seconds). 
 
 GRAPH_NAME&nbsp;= "ieee-cis-fraud-detection"
PROCESSED_PREFIX&nbsp;= f"./{GRAPH_NAME}"
ID_COLS&nbsp;= "card1,card2,card3,card4,card5,card6,ProductCD,addr1,addr2,P_emaildomain,R_emaildomain"
CAT_COLS&nbsp;= "M1,M2,M3,M4,M5,M6,M7,M8,M9"
# Lists of columns to keep from each file
COLS_TO_KEEP&nbsp;= {
&nbsp;&nbsp; &nbsp;"transaction.csv": (
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;ID_COLS.split(",")
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;+ CAT_COLS.split(",")
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;+
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;# Numerical features without missing values
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;[f"C{idx}"&nbsp;for&nbsp;idx&nbsp;in&nbsp;range(1, 15)]
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;+ ["TransactionID", "TransactionAmt", "TransactionDT", "isFraud"]
&nbsp;&nbsp; &nbsp;),
&nbsp;&nbsp; &nbsp;"identity.csv": ["TransactionID", "DeviceType"],
}

create_neptune_db_data(
&nbsp;&nbsp; &nbsp;data_prefix="./input-data/",
&nbsp;&nbsp; &nbsp;output_prefix=PROCESSED_PREFIX,
&nbsp;&nbsp; &nbsp;id_cols=ID_COLS,
&nbsp;&nbsp; &nbsp;cat_cols=CAT_COLS,
&nbsp;&nbsp; &nbsp;cols_to_keep=COLS_TO_KEEP,
&nbsp;&nbsp; &nbsp;num_chunks=1,
) 
 
This notebook also generates the JSON configuration file required by GraphStorm‚Äôs GConstruct command and executes the graph construction process. This GConstruct command transforms the Neptune-formatted data into a distributed binary graph format optimized for GraphStorm‚Äôs training pipeline, which partitions the heterogeneous graph structure across compute nodes to enable scalable model training on industry-scale graphs (measured in billions of nodes and edges). For the IEEE-CIS data, the GConstruct command takes 90 seconds to complete. 
In the Notebook&nbsp;1-Load-Data-Into-Neptune-DB, you load the CSV data into the Neptune database instance (takes approximately 9 minutes), which makes them available for online inference. During online inference, after selecting a transaction node, you query the Neptune database to get the graph neighborhood of the target node, retrieving the features of every node in the neighborhood and the subgraph structure around the target. 
Step 2: Model training 
After you have converted the data into the distributed binary graph format, it‚Äôs time to train a GNN model. GraphStorm provides command-line scripts to train a model without writing code. In the Notebook 2-Model-Training, you&nbsp;train a GNN model using GraphStorm‚Äôs node classification command with configuration managed through YAML files. The baseline configuration defines a two-layer RGCN model with 128-dimensional hidden layers, training for 4 epochs with a 0.001 learning rate and 1024 batch size, which takes approximately 100 seconds for 1 epoch of model training and evaluation in an ml.m5.4xlarge instance. To improve fraud detection accuracy, the notebook provides more advanced model configurations like the command below. 
 
 !python -m&nbsp;graphstorm.run.gs_node_classification \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --workspace ./&nbsp;\
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --part-config ieee_gs/ieee-cis.json \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --num-trainers 1&nbsp;\
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --cf ieee_nc.yaml \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --eval-metric roc_auc \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --save-model-path ./model-simple/&nbsp;\
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --topk-model-to-save 1&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--imbalance-class-weights 0.1,1.0 
 
Arguments in this command address the dataset‚Äôs label imbalance challenge where only 3.5% of transactions are fraudulent by using AUC-ROC as the evaluation metric and using class weights. The command also saves the best-performing model along with essential configuration files required for endpoint deployment. Advanced configurations can further enhance model performance through techniques like HGT encoders, multi-head attention, and class-weighted cross entropy loss function, though these optimizations increase computational requirements. GraphStorm enables these changes through run time arguments and YAML configurations, reducing the need for code modifications. 
Step 3: Real-time endpoint deployment 
In the Notebook 3-GraphStorm-Endpoint-Deployment, you deploy the real-time endpoint through GraphStorm v0.5‚Äôs straightforward launch script. The deployment requires three model artifacts generated during training: the saved model file that contains weights, the updated graph construction JSON file with feature transformation metadata, and the runtime-updated training configuration YAML file. These artifacts enable GraphStorm to recreate the exact training configurations and model for consistent inference behavior. Notably, the updated graph construction JSON and training configuration YAML file contains crucial configurations that are essential for restoring the trained model on the endpoint and processing incoming request payloads. It is crucial to use the updated JSON and YAML files for endpoint deployment.GraphStorm uses SageMaker AI bring your own container (BYOC) to deploy a consistent inference environment. You need to build and push the GraphStorm real-time Docker image to Amazon ECR using the provided shell scripts. This containerized approach provides consistent runtime environments compatible with the SageMaker AI managed infrastructure. The Docker image contains the necessary dependencies for GraphStorm‚Äôs real-time inference capabilities on the deployment environment. 
To deploy the endpoint, you can use the GraphStorm-provided launch_realtime_endpoint.py script that helps you gather required artifacts and creates the necessary SageMaker AI resources to deploy an endpoint. The script accepts the Amazon ECR image URI, IAM role, model artifact paths, and S3 bucket configuration, automatically handling endpoint provisioning and configuration. By default, the script waits for endpoint deployment to be complete before exiting. When completed, it prints the name and AWS Region of the deployed endpoint for subsequent inference requests. You will need to replace the fields enclosed by &lt;&gt; with the actual values of your environment. 
 
 !python ~/graphstorm/sagemaker/launch/launch_realtime_endpoint.py \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--image-uri &lt;account_id&gt;.dkr.ecr.&lt;aws_region&gt;.amazonaws.com/graphstorm:sagemaker-endpoint-cpu \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--role arn:aws:iam::&lt;account_id&gt;:role/&lt;your_role&gt; \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--region &lt;aws_region&gt; \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--restore-model-path &lt;restore-model-path&gt;/models/epoch-1/ \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--model-yaml-config-file &lt;restore-model-path&gt;/models/GRAPHSTORM_RUNTIME_UPDATED_TRAINING_CONFIG.yaml \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--graph-json-config-file &lt;restore-model-path&gt;/models/data_transform_new.json \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--infer-task-type&nbsp;node_classification \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--upload-tarfile-s3 s3://&lt;cdk-created-bucket&gt; \
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;--model-name ieee-fraud-detect 
 
Step 4: Real-time inference 
In the Notebook 4-Sample-Graph-and-Invoke-Endpoint, you build a basic client application that integrates with the deployed GraphStorm endpoint to perform real-time fraud prevention on incoming transactions. The inference process accepts transaction data through standardized JSON payloads, executes node classification predictions in a few hundreds of milliseconds, and returns fraud probability scores that enable immediate decision-making. 
An end-to-end inference call for a node that already exists in the graph has three distinct stages: 
 
 Graph sampling from the Neptune database. For a given target node that already exists in the graph, retrieve its k-hop neighborhood with a fanout limit, that is, limiting the number of neighbors retrieved at each hop by a threshold. 
 Payload preparation for inference. Neptune returns graphs using GraphSON, a specialized JSON-like data format used to describe graph data. At this step, you need to convert the returned GraphSON to GraphStorm‚Äôs own JSON specification. This step is performed on the inference client, in this case a SageMaker notebook instance. 
 Model inference using a SageMaker endpoint. After the payload is prepared, you send an inference request to a SageMaker endpoint that has loaded a previously trained model snapshot. The endpoint receives the request, performs any feature transformations needed (such as converting categorical features to one-hot encoding), creates the binary graph representation in memory, and makes a prediction for the target node using the graph neighborhood and trained model weights. The response is encoded to JSON and sent back to the client. 
 
An example response from the endpoint would look like: 
 
 {'status_code': 200,
&nbsp;'request_uid': '877042dbc361fc33',
&nbsp;'message': 'Request&nbsp;processed&nbsp;successfully.',
&nbsp;'error': '',
&nbsp;'data': {
&nbsp;&nbsp; &nbsp;'results': [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;'node_type': 'Transaction',
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;'node_id': '2991260',
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;'prediction': [0.995966911315918, 0.004033133387565613]
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;]
&nbsp;&nbsp; &nbsp;}
} 
 
The data of interest for the single transaction you made a prediction for are in the prediction key and corresponding node_id. The prediction gives you the raw scores the model produces for class 0 (legitimate) and class 1 (fraudulent) at the corresponding 0 and 1 indexes of the predictions list. In this example, the model marks the transaction as most likely legitimate. You can find the full GraphStorm response specification in the GraphStorm documentation. 
Complete implementation examples, including client code and payload specifications, are provided in the repository to guide integration with production systems. 
Clean up 
To stop accruing costs on your account, you need to delete the AWS resources that you created with the AWS CDK at the Environment Setup step. 
You must first delete the SageMaker endpoint created during the Step 3 for cdk destroy to complete.&nbsp;See the Delete Endpoints and Resources for more options to delete an endpoint. When done, you can run the following from the repository‚Äôs root: 
 
 cd&nbsp;neptune-database-graphstorm-online-inference/neptune-db-cdk
cdk destroy 
 
See the AWS CDK docs for more information about how to use cdk destroy, or see the CloudFormation docs for how to delete a stack from the console UI.&nbsp;By default, the cdk destroy command does not delete the model artifacts and processed graph data stored in the S3 bucket during the training and deployment process. You must remove them manually. See Deleting a general purpose bucket for information about how to empty and delete an S3 bucket the AWS CDK has created. 
Conclusion 
Graph neural networks address complex fraud prevention challenges by modeling relationships between entities that traditional machine learning approaches miss when analyzing transactions in isolation. GraphStorm v0.5&nbsp;helps simplify deployment of GNN real-time inference with one command for endpoint creation that previously required coordination of multiple services and a standardized payload specification that helps simplify client integration with real-time inference services. Organizations can now deploy enterprise-scale fraud prevention endpoints through streamlined commands that reduce custom engineering from weeks to single-command operations. 
To implement GNN-based fraud prevention with your own data: 
 
 Review the GraphStorm documentation for model configuration options and deployment specifications. 
 Adapt this IEEE-CIS example to your fraud prevention dataset by modifying the graph construction and feature engineering steps using the complete source code and tutorials available in our GitHub repository. 
 Access step-by-step implementation guidance to build production-ready fraud prevention solutions with GraphStorm v0.5‚Äôs enhanced capabilities using your enterprise data. 
 
 
 
About the authors 
Jian Zhang&nbsp;is a Senior Applied Scientist who has been using machine learning techniques to help customers solve various problems, such as fraud detection, decoration image generation, and more. He has successfully developed graph-based machine learning, particularly graph neural network, solutions for customers in China, the US, and Singapore. As an enlightener of AWS graph capabilities, Zhang has given many public presentations about GraphStorm, the GNN, the Deep Graph Library (DGL), Amazon Neptune, and other AWS services. 
Theodore Vasiloudis&nbsp;is a Senior Applied Scientist at AWS, where he works on distributed machine learning systems and algorithms. He led the development of GraphStorm Processing, the distributed graph processing library for GraphStorm and is a core developer for GraphStorm. He received his PhD in Computer Science from KTH Royal Institute of Technology, Stockholm, in 2019. 
Xiang Song&nbsp;is a Senior Applied Scientist at AWS AI Research and Education (AIRE), where he develops deep learning frameworks including GraphStorm, DGL, and DGL-KE. He led the development of Amazon Neptune ML, a new capability of Neptune that uses graph neural networks for graphs stored in graph database. He is now leading the development of GraphStorm, an open source graph machine learning framework for enterprise use cases. He received his PhD in computer systems and architecture at the Fudan University, Shanghai, in 2014. 
Florian Saupe&nbsp;is a Principal Technical Product Manager at AWS AI/ML research supporting science teams like the graph machine learning group, and ML Systems teams working on large scale distributed training, inference, and fault resilience. Before joining AWS, Florian lead technical product management for automated driving at Bosch, was a strategy consultant at McKinsey &amp; Company, and worked as a control systems and robotics scientist‚Äîa field in which he holds a PhD. 
Ozan Eken&nbsp;is a Product Manager at AWS, passionate about building cutting-edge Generative AI and Graph Analytics products. With a focus on simplifying complex data challenges, Ozan helps customers unlock deeper insights and accelerate innovation. Outside of work, he enjoys trying new foods, exploring different countries, and watching soccer.
‚Ä¢ Building health care agents using Amazon Bedrock AgentCore
  This blog was co-authored with Kuldeep Singh, Head of AI Platform at Innovaccer. 
The integration of agentic AI is ushering in a transformative era in health care, marking a significant departure from traditional AI systems. Agentic AI demonstrates autonomous decision-making capabilities and adaptive learning in complex medical environments, enabling it to monitor patient progress, coordinate care teams, and adjust treatment strategies in real time. These intelligent systems are becoming deeply embedded in healthcare operations, from enhancing diagnostic precision through advanced pattern recognition to optimizing clinical workflows and accelerating drug discovery processes. Agentic AI combines proactive problem-solving abilities with real-time adaptability so that healthcare professionals can focus on high-value, patient-centered activities while the AI handles routine tasks and complex data analysis. 
Innovaccer, a pioneering healthcare AI company, recently launched Innovaccer Gravity, built using Amazon Bedrock AgentCore, a new healthcare intelligence platform set to revolutionize data integration and AI-driven healthcare transformation. Building on their impressive track record‚Äîwhere their existing solutions serve more than 1,600 US care locations, manage more than 80 million unified health records, and have generated $1.5B in cost savings‚Äîthis exemplifies how AWS customers are leading the agentic AI evolution by creating intelligent solutions that transform healthcare delivery while delivering significant ROI. 
Health care demands precision and accountability. AI agents operating within this domain must handle sensitive patient data securely, adhere to rigorous compliance regulations (like HIPAA), and maintain consistent interoperability across diverse clinical workflows. Standard, generalized protocols fall short when dealing with complex healthcare systems and patient data protection requirements. Healthcare organizations need a robust service to convert their existing APIs into Model Context Protocol (MCP) compatible tools that can scale effectively while providing built-in authentication, authorization, encryption, and comprehensive audit trails. Amazon Bedrock AgentCore Gateway offers health care providers and digital health companies a straightforward and secure way to build, deploy, discover, and connect to tools at scale that they can use to create AI-powered healthcare solutions while maintaining the highest standards of security and compliance. 
Problem 
Healthcare organizations face significant data silo challenges because of diverse electronic health record (EHR) formats across different systems, often maintaining multiple systems to serve specialized departmental needs and legacy systems. FHIR (Fast Healthcare Interoperability Resources) solves these interoperability challenges by standardizing healthcare data into exchangeable resources (like patient records and lab results), enabling seamless communication between different systems while maintaining security and improving care coordination. However, implementing FHIR presents its own challenges, including technical complexity in integrating with legacy systems and the need for specialized expertise in healthcare informatics and API development. 
The implementation of AI agents introduces new layers of complexity, requiring careful design and maintenance of interfaces with existing systems. AI agents need secure access to the FHIR data and other healthcare tools with authentication (both inbound and outbound) and end-to-end encryption. MCP is a standardized communication framework that enables AI systems to seamlessly interact with external tools, data sources, and services through a unified interface. However, the development and scaling of MCP servers require substantial resources and expertise. Hosting these services demands ongoing development time and attention to maintain optimal performance and reliability. As healthcare organizations navigate this complex terrain, addressing these challenges becomes critical for achieving true interoperability and harnessing the full potential of modern healthcare technology. 
Deploy, enhance, and monitor AI agents at scale using Amazon Bedrock AgentCore 
By using Amazon Bedrock AgentCore, you can deploy and operate highly capable AI agents securely at scale. It offers infrastructure purpose-built for dynamic agent workloads, powerful tools to enhance agents, and essential controls for real-world deployment. Bedrock AgentCore offers a set of composable services with the services most relevant to the solution in this post mentioned in the following list. For more information, see the Bedrock AgentCore documentation. 
 
 AgentCore Runtime provides a secure, serverless runtime purpose-built for deploying and scaling dynamic AI agents and tools using any open source framework, protocol, and model. Runtime was built to work for agentic workloads with industry-leading extended runtime support, fast cold starts, true session isolation, built-in identity, and support for multi-modal payloads. 
 AgentCore Gateway provides a secure way for agents to discover and use tools along with straightforward transformation of APIs, AWS Lambda functions, and existing services into agent-compatible tools. Gateway speeds up custom code development, infrastructure provisioning, and security implementation so developers can focus on building innovative agent applications. 
 AgentCore Identity provides a secure, scalable agent identity and access management capability accelerating AI agent development. It is compatible with existing identity providers, avoiding the need to migrate uses or rebuild authentication flows. 
 AgentCore Observability helps developers trace, debug, and monitor agent performance in production through unified operational dashboards. With support for OpenTelemetry compatible telemetry and detailed visualizations of each step of the agent workflow. 
 
In this solution, we demonstrate how the user (a parent) can interact with a Strands or LangGraph agent in conversational style and get information about the immunization history and schedule of their child, inquire about the available slots, and book appointments. With some changes, AI agents can be made event-driven so that they can automatically send reminders, book appointments, and so on. This reduces the administrative burden on healthcare organizations and the parents who no longer need to keep track of the paperwork or make multiple calls to book appointments. 
 
As shown in the preceding diagram, the workflow for the healthcare appointment book built using Amazon Bedrock AgentCore is the following: 
 
 User interacts with Strands or LangGraph agent: The solution contains both Strands and LangGraph agents. You can also use other frameworks such as AutoGen and CrewAI. 
 Reasoning LLM from Amazon Bedrock: Claude 3.5 Sonnet large language model (LLM) is used from Amazon Bedrock. The model demonstrates advanced reasoning by grasping nuances and complex instructions, along with strong tool-calling capabilities that allow it to effectively integrate with external applications and services to automate various tasks such as web browsing, calculations, or data interactions. 
 Tools exposed using AgentCore Gateway: AgentCore Gateway provides secure access to the necessary tools required for the Strands or LangGraph agent using standard MCP clients. In this solution, REST APIs are hosted on Amazon API Gateway and exposed as MCP tools using AgentCore Gateway. 
 Ingress authentication for AgentCore Gateway: AgentCore Gateway is protected with oAuth 2.0 using Amazon Cognito as the identity provider. You can use other oAuth 2.0 compatible identity providers such as Auth0, and Keycloak as needed to fit your use case. 
 OpenAPI specs converted into tools with AgentCore Gateway: Amazon API Gateway is used as the backend to expose the APIs. By importing the OpenAPI specs, AgentCore Gateway provides an MCP compatible server without additional configuration for tool metadata. The following are the tools used in the solution. 
   
   get_patient_emr(): Gets the parent‚Äôs and child‚Äôs demographics information. 
   search_immunization_emr() ‚Äì Gets the immunization history and schedule for the child. 
   get_available_slots() ‚Äì Gets the pediatrician‚Äôs schedule around parent‚Äôs preferred date. 
   book_appointment() ‚Äì Books an appointment and returns the confirmation number. 
    
 AWS Healthlake as the FHIR server: HealthLake is used to manage patient data related to demographics, immunization history, schedule and appointments, and so on. HealthLake is a HIPAA-eligible service offering healthcare companies a complete view of individual and patient population health data using FHIR API-based transactions to securely store and transform their data into a queryable format at petabyte scale, and further analyze this data using machine learning (ML) models. 
 Egress authentication from AgentCore Gateway to tools: OAuth 2.0 with Amazon Cognito as the identity provider is used to do the authentication between AgentCore Gateway and the tools used in the solution. 
 
Solution setup 
 
  
   
   Important: The following code example is meant for learning and demonstration purposes only. For production implementations, it is recommended to add required error handling, input validation, logging, and security controls. 
   
  
 
The code and instructions to set up and clean up this example solution are available on GitHub. When set up, the solution looks like the following and is targeted towards parents to use the for immunization related appointments. 
 
Customizing the solution 
The solution can be customized to extend the same or a different use case through the following mechanisms: 
 
 OpenAPI specification: The solution uses a sample OpenAPI specification (named fhir-openapi-spec.yaml) with APIs hosted on API Gateway. The OpenAPI specification can be customized to add more tools or use entirely different tools by editing the YAML file. You must recreate the AgentCore gateway after making changes to the OpenAPI spec. 
 Agent instructions and LLM: The strands_agent.py or langgraph_agent.py can be modified to make changes to the goal or instructions for the Agent or to work with a different LLM. 
 
Future enhancements 
We‚Äôre already looking forward and planning future enhancements for this solution. 
 
 AgentCore Runtime: Host strands or a LangGraph agent on AgentCore Runtime. 
 AgentCore Memory: Use AgentCore Memory to preserve session information in short-term (in session) as well as long-term (across sessions) to provide a more personalized experience to the agent users. 
 
Innovaccer‚Äôs use case for Bedrock AgentCore 
Innovaccer‚Äôs gravity platform includes more than 400 connectors to unify data from EHRs from sources such as Epic, Oracle Cerner, and MEDITECH, more than 20 pre-trained models, 15 pre-built AI agents, 100 FHIR resources, and 60 out-of-the-box solutions with role based access control, comprehensive audit trail, end-to-end encryption, and secure personal health information (PHI) handling. They also provide a low-code or no-code interface to build additional AI agents with the tools exposed using Healthcare Model Context Protocol (HMCP) servers. 
Innovaccer uses Bedrock AgentCore for the following purposes: 
 
 AgentCore Gateway to turn their OpenAPI specifications into HMCP compatible tools without the heavy lifting required to build, secure, or scale MCP servers. 
 AgentCore Identity to handle the inbound and outbound authentication integrating with Innovaccer- or customer-provided OAuth servers. 
 AgentCore Runtime to deploy and scale the AI agents with multi-agent collaboration, along with logging, traceability and ability to plug in custom guardrails. 
 
Bedrock AgentCore supports enterprise-grade security with encryption in transit and at rest, complete session isolation, audit trails using AWS CloudTrail, and comprehensive controls to help Innovaccer agents operate reliably and securely at scale. 
Pricing for Bedrock AgentCore Gateway: 
AgentCore Gateway offers a consumption-based pricing model with billing based on API invocations (such as ListTools, InvokeTool and Search API), and indexing of tools. For more information, see the pricing page. 
Conclusion 
The integration of Amazon Bedrock AgentCore with healthcare systems represents a significant leap forward in the application of AI to improve patient care and streamline healthcare operations. By using the suite of services provided by Bedrock AgentCore, healthcare organizations can deploy sophisticated AI agents that securely interact with existing systems, adhere to strict compliance standards, and scale efficiently. 
The solution architecture presented in this post demonstrates the practical application of these technologies, showcasing how AI agents can simplify complex processes such as immunization scheduling and appointment booking. This can reduce administrative burdens on healthcare providers and enhance the patient experience by providing straightforward access to critical health information and services. 
As we look to the future, the potential for AI agents in the healthcare industry is vast. From improving diagnostic accuracy to personalizing treatment plans and streamlining clinical workflows, the possibilities are endless. Tools like Amazon Bedrock AgentCore can help healthcare organizations confidently navigate the complexities of implementing AI while maintaining the highest standards of security, compliance, and patient care. 
The healthcare industry stands at the cusp of a transformative era, where AI agents will play an increasingly central role in delivering efficient, personalized, and high-quality care. By embracing these technologies and continuing to innovate, we can create a healthcare network that is more responsive, intelligent, and patient-centric than ever before. 
 
About the Authors 
Kamal Manchanda is a Senior Solutions Architect at AWS with 17 years of experience in cloud, data, and AI technologies. He works closely with C-level executives and technical teams of AWS customers to drive cloud adoption and digital transformation initiatives. Prior to AWS, he led global teams delivering cloud-centric systems, data-driven applications, and AI/ML solutions across consulting and product organizations. Kamal specializes in translating complex business challenges into scalable, secure solutions that deliver measurable business value. 
Kuldeep Singh is AVP and Head of AI Platform at Innovaccer. He leads the work on AI agentic workflow layers for Gravity by Innovaccer, a healthcare intelligence platform designed to unify data, agents, and compliant workflows so health systems can deploy AI at scale. With deep experience in data engineering, AI, and product leadership, Kuldeep focuses on making healthcare more efficient, safe, and patient-centered. He plays a key role in building tools that allow care teams to automate complex, multi-step tasks (like integrating payer or EHR data, orchestrating clinical agents) without heavy engineering. He‚Äôs passionate about reducing clinician burnout, improving patient outcomes, and turning pilot projects into enterprise-wide AI solutions.
‚Ä¢ Build multi-agent site reliability engineering assistants with Amazon Bedrock AgentCore
  Site reliability engineers (SREs) face an increasingly complex challenge in modern distributed systems. During production incidents, they must rapidly correlate data from multiple sources‚Äîlogs, metrics, Kubernetes events, and operational runbooks‚Äîto identify root causes and implement solutions. Traditional monitoring tools provide raw data but lack the intelligence to synthesize information across these diverse systems, often leaving SREs to manually piece together the story behind system failures. 
With a generative AI solution, SREs can ask their infrastructure questions in natural language. For example, they can ask ‚ÄúWhy are the payment-service pods crash looping?‚Äù or ‚ÄúWhat‚Äôs causing the API latency spike?‚Äù and receive comprehensive, actionable insights that combine infrastructure status, log analysis, performance metrics, and step-by-step remediation procedures. This capability transforms incident response from a manual, time-intensive process into a time-efficient, collaborative investigation. 
In this post, we demonstrate how to build a multi-agent SRE assistant using Amazon Bedrock AgentCore, LangGraph, and the Model Context Protocol (MCP). This system deploys specialized AI agents that collaborate to provide the deep, contextual intelligence that modern SRE teams need for effective incident response and infrastructure management. We walk you through the complete implementation, from setting up the demo environment to deploying on Amazon Bedrock AgentCore Runtime for production use. 
Solution overview 
This solution uses a comprehensive multi-agent architecture that addresses the challenges of modern SRE operations through intelligent automation. The solution consists of four specialized AI agents working together under a supervisor agent to provide comprehensive infrastructure analysis and incident response assistance. 
The examples in this post use synthetically generated data from our demo environment. The backend servers simulate realistic Kubernetes clusters, application logs, performance metrics, and operational runbooks. In production deployments, these stub servers would be replaced with connections to your actual infrastructure systems, monitoring services, and documentation repositories. 
The architecture demonstrates several key capabilities: 
 
 Natural language infrastructure queries ‚Äì You can ask complex questions about your infrastructure in plain English and receive detailed analysis combining data from multiple sources 
 Multi-agent collaboration ‚Äì Specialized agents for Kubernetes, logs, metrics, and operational procedures work together to provide comprehensive insights 
 Real-time data synthesis ‚Äì Agents access live infrastructure data through standardized APIs and present correlated findings 
 Automated runbook execution ‚Äì Agents retrieve and display step-by-step operational procedures for common incident scenarios 
 Source attribution ‚Äì Every finding includes explicit source attribution for verification and audit purposes 
 
The following diagram illustrates the solution architecture. 
 
The architecture demonstrates how the SRE support agent integrates seamlessly with Amazon Bedrock AgentCore components: 
 
 Customer interface ‚Äì Receives alerts about degraded API response times and returns comprehensive agent responses 
 Amazon Bedrock AgentCore Runtime ‚Äì Manages the execution environment for the multi-agent SRE solution 
 SRE support agent ‚Äì Multi-agent collaboration system that processes incidents and orchestrates responses 
 Amazon Bedrock AgentCore Gateway ‚Äì Routes requests to specialized tools through OpenAPI interfaces: 
   
   Kubernetes API for getting cluster events 
   Logs API for analyzing log patterns 
   Metrics API for analyzing performance trends 
   Runbooks API for searching operational procedures 
    
 Amazon Bedrock AgentCore Memory ‚Äì Stores and retrieves session context and previous interactions for continuity 
 Amazon Bedrock AgentCore Identity ‚Äì Handles authentication for tool access using Amazon Cognito integration 
 Amazon Bedrock AgentCore Observability ‚Äì Collects and visualizes agent traces for monitoring and debugging 
 Amazon Bedrock LLMs ‚Äì Powers the agent intelligence through Anthropic‚Äôs Claude large language models (LLMs) 
 
The multi-agent solution uses a supervisor-agent pattern where a central orchestrator coordinates five specialized agents: 
 
 Supervisor agent ‚Äì Analyzes incoming queries and creates investigation plans, routing work to appropriate specialists and aggregating results into comprehensive reports 
 Kubernetes infrastructure agent ‚Äì Handles container orchestration and cluster operations, investigating pod failures, deployment issues, resource constraints, and cluster events 
 Application logs agent ‚Äì Processes log data to find relevant information, identifies patterns and anomalies, and correlates events across multiple services 
 Performance metrics agent ‚Äì Monitors system metrics and identifies performance issues, providing real-time analysis and historical trending 
 Operational runbooks agent ‚Äì Provides access to documented procedures, troubleshooting guides, and escalation procedures based on the current situation 
 
Using Amazon Bedrock AgentCore primitives 
The solution showcases the power of Amazon Bedrock AgentCore by using multiple core primitives. The solution supports two providers for Anthropic‚Äôs LLMs. Amazon Bedrock supports Anthropic‚Äôs Claude 3.7 Sonnet for AWS integrated deployments, and Anthropic API supports Anthropic‚Äôs Claude 4 Sonnet for direct API access. 
The Amazon Bedrock AgentCore Gateway component converts the SRE agent‚Äôs backend APIs (Kubernetes, application logs, performance metrics, and operational runbooks) into Model Context Protocol (MCP) tools. This enables agents built with an open-source framework supporting MCP (such as LangGraph in this post) to seamlessly access infrastructure APIs. 
Security for the entire solution is provided by Amazon Bedrock AgentCore Identity. It supports ingress authentication for secure access control for agents connecting to the gateway, and egress authentication to manage authentication with backend servers, providing secure API access without hardcoding credentials. 
The serverless execution environment for deploying the SRE agent in production is provided by Amazon Bedrock AgentCore Runtime. It automatically scales from zero to handle concurrent incident investigations while maintaining complete session isolation. Amazon Bedrock AgentCore Runtime supports both OAuth and AWS Identity and Access Management (IAM) for agent authentication. Applications that invoke agents must have appropriate IAM permissions and trust policies. For more information, see Identity and access management for Amazon Bedrock AgentCore. 
Amazon Bedrock AgentCore Memory transforms the SRE agent from a stateless system into an intelligent learning assistant that personalizes investigations based on user preferences and historical context. The memory component provides three distinct strategies: 
 
 User preferences strategy (/sre/users/{user_id}/preferences) ‚Äì Stores individual user preferences for investigation style, communication channels, escalation procedures, and report formatting. For example, Alice (a technical SRE) receives detailed systematic analysis with troubleshooting steps, whereas Carol (an executive) receives business-focused summaries with impact analysis. 
 Infrastructure knowledge strategy (/sre/infrastructure/{user_id}/{session_id}) ‚Äì Accumulates domain expertise across investigations, enabling agents to learn from past discoveries. When the Kubernetes agent identifies a memory leak pattern, this knowledge becomes available for future investigations, enabling faster root cause identification. 
 Investigation memory strategy (/sre/investigations/{user_id}/{session_id}) ‚Äì Maintains historical context of past incidents and their resolutions. This enables the solution to suggest proven remediation approaches and avoid anti-patterns that previously failed. 
 
The memory component demonstrates its value through personalized investigations. When both Alice and Carol investigate ‚ÄúAPI response times have degraded 3x in the last hour,‚Äù they receive identical technical findings but completely different presentations. 
Alice receives a technical analysis: 
 
 memory_client.retrieve_user_preferences(user_id="Alice")
# Returns: {"investigation_style": "detailed_systematic_analysis", "reports": "technical_exposition_with_troubleshooting_steps"} 
 
Carol receives an executive summary: 
 
 memory_client.retrieve_user_preferences(user_id="Carol") 
# Returns: {"investigation_style": "business_impact_focused","reports": "executive_summary_without_technical_details"} 
 
Adding observability to the SRE agent 
Adding observability to an SRE agent deployed on Amazon Bedrock AgentCore Runtime is straightforward using the Amazon Bedrock AgentCore Observability primitive. This enables comprehensive monitoring through Amazon CloudWatch with metrics, traces, and logs. Setting up observability requires three steps: 
 
 Add the OpenTelemetry packages to your pyproject.toml: 
   
   dependencies = [
    # ... other dependencies ...
    "opentelemetry-instrumentation-langchain",
    "aws-opentelemetry-distro~=0.10.1",
	] 
    
 Configure observability for your agents to enable metrics in CloudWatch. 
 Start your container using the opentelemetry-instrument utility to automatically instrument your application. 
 
The following command is added to the Dockerfile for the SRE agent: 
 
 # Run application with OpenTelemetry instrumentation 
CMD ["uv", "run", "opentelemetry-instrument", "uvicorn", "sre_agent.agent_runtime:app", "--host", "0.0.0.0", "--port", "8080"] 
 
As shown in the following screenshot, with observability enabled, you gain visibility into the following: 
 
 LLM invocation metrics ‚Äì Token usage, latency, and model performance across agents 
 Tool execution traces ‚Äì Duration and success rates for each MCP tool call 
 Memory operations ‚Äì Retrieval patterns and storage efficiency 
 End-to-end request tracing ‚Äì Complete request flow from user query to final response 
 
 
The observability primitive automatically captures these metrics without additional code changes, providing production-grade monitoring capabilities out of the box. 
Development to production flow 
The SRE agent follows a four-step structured deployment process from local development to production, with detailed procedures documented in Development to Production Flow in the accompanying GitHub repo: 
 
The deployment process maintains consistency across environments: the core agent code (sre_agent/) remains unchanged, and the deployment/ folder contains deployment-specific utilities. The same agent works locally and in production through environment configuration, with Amazon Bedrock AgentCore Gateway providing MCP tools access across different stages of development and deployment. 
Implementation walkthrough 
In the following section, we focus on how Amazon Bedrock AgentCore Gateway, Memory, and Runtime work together to build this multi-agent collaboration solution and deploy it end-to-end with MCP support and persistent intelligence. 
We start by setting up the repository and establishing the local runtime environment with API keys, LLM providers, and demo infrastructure. We then bring core AgentCore components online by creating the gateway for standardized API access, configuring authentication, and establishing tool connectivity. We add intelligence through AgentCore Memory, creating strategies for user preferences and investigation history while loading personas for personalized incident response. Finally, we configure individual agents with specialized tools, integrate memory capabilities, orchestrate collaborative workflows, and deploy to AgentCore Runtime with full observability. 
Detailed instructions for each step are provided in the repository: 
 
 Use Case Setup Guide ‚Äì Backend deployment and development setup 
 Deployment Guide ‚Äì Production containerization and Amazon Bedrock AgentCore Runtime deployment 
 
Prerequisites 
You can find the port forwarding requirements and other setup instructions in the README file‚Äôs Prerequisites section. 
Convert APIs to MCP tools with Amazon Bedrock AgentCore Gateway 
Amazon Bedrock AgentCore Gateway demonstrates the power of protocol standardization by converting existing backend APIs into MCP tools that agent frameworks can consume. This transformation happens seamlessly, requiring only OpenAPI specifications. 
Upload OpenAPI specifications 
The gateway process begins by uploading your existing API specifications to Amazon Simple Storage Service (Amazon S3). The create_gateway.sh script automatically handles uploading the four API specifications (Kubernetes, Logs, Metrics, and Runbooks) to your configured S3 bucket with proper metadata and content types. These specifications will be used to create API endpoint targets in the gateway. 
Create an identity provider and gateway 
Authentication is handled seamlessly through Amazon Bedrock AgentCore Identity. The main.py script creates both the credential provider and gateway: 
 
 # Create AgentCore Gateway with JWT authorization
def create_gateway(
    client: Any,
    gateway_name: str,
    role_arn: str,
    discovery_url: str,
    allowed_clients: list = None,
    description: str = "AgentCore Gateway created via SDK",
    search_type: str = "SEMANTIC",
    protocol_version: str = "2025-03-26",
) -&gt; Dict[str, Any]:
    
    # Build auth config for Cognito
    auth_config = {"customJWTAuthorizer": {"discoveryUrl": discovery_url}}
    if allowed_clients:
        auth_config["customJWTAuthorizer"]["allowedClients"] = allowed_clients
    
    protocol_configuration = {
        "mcp": {"searchType": search_type, "supportedVersions": [protocol_version]}
    }

    response = client.create_gateway(
        name=gateway_name,
        roleArn=role_arn,
        protocolType="MCP",
        authorizerType="CUSTOM_JWT",
        authorizerConfiguration=auth_config,
        protocolConfiguration=protocol_configuration,
        description=description,
        exceptionLevel='DEBUG'
    )
    return response 
 
Deploy API endpoint targets with credential providers 
Each API becomes an MCP target through the gateway. The solution automatically handles credential management: 
 
 def create_api_endpoint_target(
    client: Any,
    gateway_id: str,
    s3_uri: str,
    provider_arn: str,
    target_name_prefix: str = "open",
    description: str = "API Endpoint Target for OpenAPI schema",
) -&gt; Dict[str, Any]:
    
    api_target_config = {"mcp": {"openApiSchema": {"s3": {"uri": s3_uri}}}}

    # API key credential provider configuration
    credential_config = {
        "credentialProviderType": "API_KEY",
        "credentialProvider": {
            "apiKeyCredentialProvider": {
                "providerArn": provider_arn,
                "credentialLocation": "HEADER",
                "credentialParameterName": "X-API-KEY",
            }
        },
    }
    
    response = client.create_gateway_target(
        gatewayIdentifier=gateway_id,
        name=target_name_prefix,
        description=description,
        targetConfiguration=api_target_config,
        credentialProviderConfigurations=[credential_config],
    )
    return response 
 
Validate MCP tools are ready for agent framework 
Post-deployment, Amazon Bedrock AgentCore Gateway provides a standardized /mcp endpoint secured with JWT tokens. Testing the deployment with mcp_cmds.sh reveals the power of this transformation: 
 
 Tool summary:
================
Total tools found: 21

Tool names:
‚Ä¢ x_amz_bedrock_agentcore_search
‚Ä¢ k8s-api___get_cluster_events
‚Ä¢ k8s-api___get_deployment_status
‚Ä¢ k8s-api___get_node_status
‚Ä¢ k8s-api___get_pod_status
‚Ä¢ k8s-api___get_resource_usage
‚Ä¢ logs-api___analyze_log_patterns
‚Ä¢ logs-api___count_log_events
‚Ä¢ logs-api___get_error_logs
‚Ä¢ logs-api___get_recent_logs
‚Ä¢ logs-api___search_logs
‚Ä¢ metrics-api___analyze_trends
‚Ä¢ metrics-api___get_availability_metrics
‚Ä¢ metrics-api___get_error_rates
‚Ä¢ metrics-api___get_performance_metrics
‚Ä¢ metrics-api___get_resource_metrics
‚Ä¢ runbooks-api___get_common_resolutions
‚Ä¢ runbooks-api___get_escalation_procedures
‚Ä¢ runbooks-api___get_incident_playbook
‚Ä¢ runbooks-api___get_troubleshooting_guide
‚Ä¢ runbooks-api___search_runbooks 
 
Universal agent framework compatibility 
This MCP-standardized gateway can now be configured as a Streamable-HTTP server for MCP clients, including AWS Strands, Amazon‚Äôs agent development framework, LangGraph, the framework used in our SRE agent implementation, and CrewAI, a multi-agent collaboration framework. 
The advantage of this approach is that existing APIs require no modification‚Äîonly OpenAPI specifications. Amazon Bedrock AgentCore Gateway handles the following: 
 
 Protocol translation ‚Äì Between REST APIs to MCP 
 Authentication ‚Äì JWT token validation and credential injection 
 Security ‚Äì TLS termination and access control 
 Standardization ‚Äì Consistent tool naming and parameter handling 
 
This means you can take existing infrastructure APIs (Kubernetes, monitoring, logging, documentation) and instantly make them available to AI agent frameworks that support MCP‚Äîthrough a single, secure, standardized interface. 
Implement persistent intelligence with Amazon Bedrock AgentCore Memory 
Whereas Amazon Bedrock AgentCore Gateway provides seamless API access, Amazon Bedrock AgentCore Memory transforms the SRE agent from a stateless system into an intelligent, learning assistant. The memory implementation demonstrates how a few lines of code can enable sophisticated personalization and cross-session knowledge retention. 
Initialize memory strategies 
The SRE agent memory component is built on Amazon Bedrock AgentCore Memory‚Äôs event-based model with automatic namespace routing. During initialization, the solution creates three memory strategies with specific namespace patterns: 
 
 from sre_agent.memory.client import SREMemoryClient
from sre_agent.memory.strategies import create_memory_strategies

# Initialize memory client
memory_client = SREMemoryClient(
    memory_name="sre_agent_memory",
    region="us-east-1"
)

# Create three specialized memory strategies
strategies = create_memory_strategies()
for strategy in strategies:
    memory_client.create_strategy(strategy) 
 
The three strategies each serve distinct purposes: 
 
 User preferences (/sre/users/{user_id}/preferences) ‚Äì Individual investigation styles and communication preferences 
 Infrastructure Knowledge: /sre/infrastructure/{user_id}/{session_id} ‚Äì Domain expertise accumulated across investigations 
 Investigation Summaries: /sre/investigations/{user_id}/{session_id} ‚Äì Historical incident patterns and resolutions 
 
Load user personas and preferences 
The solution comes preconfigured with user personas that demonstrate personalized investigations. The manage_memories.py script loads these personas: 
 
 # Load Alice - Technical SRE Engineer
alice_preferences = {
    "investigation_style": "detailed_systematic_analysis",
    "communication": ["#alice-alerts", "#sre-team"],
    "escalation": {"contact": "alice.manager@company.com", "threshold": "15min"},
    "reports": "technical_exposition_with_troubleshooting_steps",
    "timezone": "UTC"
}

# Load Carol - Executive/Director
carol_preferences = {
    "investigation_style": "business_impact_focused",
    "communication": ["#carol-executive", "#strategic-alerts"],
    "escalation": {"contact": "carol.director@company.com", "threshold": "5min"},
    "reports": "executive_summary_without_technical_details",
    "timezone": "EST"
}

# Store preferences using memory client
memory_client.store_user_preference("Alice", alice_preferences)
memory_client.store_user_preference("Carol", carol_preferences) 
 
Automatic namespace routing in action 
The power of Amazon Bedrock AgentCore Memory lies in its automatic namespace routing. When the SRE agent creates events, it only needs to provide the actor_id‚ÄîAmazon Bedrock AgentCore Memory automatically determines which namespaces the event belongs to: 
 
 # During investigation, the supervisor agent stores context
memory_client.create_event(
    memory_id="sre_agent_memory-abc123",
    actor_id="Alice",  # AgentCore Memory routes this automatically
    session_id="investigation_2025_01_15",
    messages=[("investigation_started", "USER")]
)

# Memory system automatically:
# 1. Checks strategy namespaces &lt;!-- "all" is necessary here for technical accuracy --&gt;
# 2. Matches actor_id "Alice" to /sre/users/Alice/preferences
# 3. Stores event in User Preferences Strategy
# 4. Makes event available for future retrievals 
 
Validate the personalized investigation experience 
The memory component‚Äôs impact becomes clear when both Alice and Carol investigate the same issue. Using identical technical findings, the solution produces completely different presentations of the same underlying content. 
Alice‚Äôs technical report contains detailed systematic analysis for technical teams: 
 
 Technical Investigation Summary

Root Cause: Payment processor memory leak causing OOM kills

Analysis:
- Pod restart frequency increased 300% at 14:23 UTC
- Memory utilization peaked at 8.2GB (80% of container limit)
- JVM garbage collection latency spiked to 2.3s

Next Step:
1. Implement heap dump analysis (`kubectl exec payment-pod -- jmap`)
2. Review recent code deployments for memory management changes
3. Consider increasing memory limits and implementing graceful shutdown 
 
Carol‚Äôs executive summary contains business impact focused for executive stakeholders: 
 
 Business Impact Assessment
Status: CRITICAL - Customer payment processing degraded
Impact: 23% transaction failure rate, $47K revenue at risk
Timeline: Issue detected 14:23 UTC, resolution ETA 45 minutes
Business Actions: - Customer communication initiated via status page - Finance team alerted for revenue impact tracking - Escalating to VP Engineering if not resolved by 15:15 UTC 
 
The memory component enables this personalization while continuously learning from each investigation, building organizational knowledge that improves incident response over time. 
Deploy to production with Amazon Bedrock AgentCore Runtime 
Amazon Bedrock AgentCore makes it straightforward to deploy existing agents to production. The process involves three key steps: containerizing your agent, deploying to Amazon Bedrock AgentCore Runtime, and invoking the deployed agent. 
Containerize your agent 
Amazon Bedrock AgentCore Runtime requires ARM64 containers. The following code shows the complete Dockerfile: 
 
 # Use uv's ARM64 Python base image
FROM --platform=linux/arm64 ghcr.io/astral-sh/uv:python3.12-bookworm-slim

WORKDIR /app

# Copy uv files
COPY pyproject.toml uv.lock ./

# Install dependencies
RUN uv sync --frozen --no-dev

# Copy SRE agent module
COPY sre_agent/ ./sre_agent/

# Set environment variables
# Note: Set DEBUG=true to enable debug logging and traces
ENV PYTHONPATH="/app" \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Expose port
EXPOSE 8080

# Run application with OpenTelemetry instrumentation
CMD ["uv", "run", "opentelemetry-instrument", "uvicorn", "sre_agent.agent_runtime:app", "--host", "0.0.0.0", "--port", "8080"] 
 
Existing agents just need a FastAPI wrapper (agent_runtime:app) to become compatible with Amazon Bedrock AgentCore, and we add opentelemetry-instrument to enable observability through Amazon Bedrock AgentCore. 
Deploy to Amazon Bedrock AgentCore Runtime 
Deploying to Amazon Bedrock AgentCore Runtime is straightforward with the deploy_agent_runtime.py script: 
 
 import boto3

# Create AgentCore client
client = boto3.client('bedrock-agentcore', region_name=region)

# Environment variables for your agent
env_vars = {
    'GATEWAY_ACCESS_TOKEN': gateway_access_token,
    'LLM_PROVIDER': llm_provider,
    'ANTHROPIC_API_KEY': anthropic_api_key  # if using Anthropic
}

# Deploy container to AgentCore Runtime
response = client.create_agent_runtime(
    agentRuntimeName=runtime_name,
    agentRuntimeArtifact={
        'containerConfiguration': {
            'containerUri': container_uri  # Your ECR container URI
        }
    },
    networkConfiguration={"networkMode": "PUBLIC"},
    roleArn=role_arn,
    environmentVariables=env_vars
)

print(f"Agent Runtime ARN: {response['agentRuntimeArn']}") 
 
Amazon Bedrock AgentCore handles the infrastructure, scaling, and session management automatically. 
Invoke your deployed agent 
Calling your deployed agent is just as simple with invoke_agent_runtime.py: 
 
 # Prepare your query with user_id and session_id for memory personalization
payload = json.dumps({
    "input": {
        "prompt": "API response times have degraded 3x in the last hour",
        "user_id": "Alice",  # User for personalized investigation
        "session_id": "investigation-20250127-123456"  # Session for context
    }
})

# Invoke the deployed agent
response = agent_core_client.invoke_agent_runtime(
    agentRuntimeArn=runtime_arn,
    runtimeSessionId=session_id,
    payload=payload,
    qualifier="DEFAULT"
)

# Get the response
response_data = json.loads(response['response'].read())
print(response_data)  # Full response includes output with agent's investigation 
 
Key benefits of Amazon Bedrock AgentCore Runtime 
Amazon Bedrock AgentCore Runtime offers the following key benefits: 
 
 Zero infrastructure management ‚Äì No servers, load balancers, or scaling to configure 
 Built-in session isolation ‚Äì Each conversation is completely isolated 
 AWS IAM integration ‚Äì Secure access control without custom authentication 
 Automatic scaling ‚Äì Scales from zero to thousands of concurrent sessions 
 
The complete deployment process, including building containers and handling AWS permissions, is documented in the Deployment Guide. 
Real-world use cases 
Let‚Äôs explore how the SRE agent handles common incident response scenarios with a real investigation. 
When facing a production issue, you can query the system in natural language. The solution uses Amazon Bedrock AgentCore Memory to personalize the investigation based on your role and preferences: 
 
 export USER_ID=Alice
sre-agent --prompt "API response times have degraded 3x in the last hour" 
 
The supervisor retrieves Alice‚Äôs preferences from memory (detailed systematic analysis style) and creates an investigation plan tailored to her role as a Technical SRE: 
 
 Investigation Plan
1. Use metrics_agent to analyze API performance metrics including response times, error rates, and resource utilization to identify the extent and pattern of slowdown
2. Use logs_agent to examine application logs for errors related to slow API responses, focusing on database connection issues and memory errors
3. Use kubernetes_agent to check pod status and resource constraints, especially for web-service and database pods, looking for CrashLoopBackOff states and missing ConfigMaps
Complexity: Simple
Auto-execute: Yes
Agents involved: Metrics Agent, Logs Agent, Kubernetes Agent 
 
The agents investigate sequentially according to the plan, each contributing their specialized analysis. The solution then aggregates these findings into a comprehensive executive summary: 
 
 Executive Summary
Key Insights
- Root Cause: Database service failure due to missing ConfigMap 'database-config' in production namespace, causing database pod to crash repeatedly
- Impact: Severe performance degradation with API response times increased from 150ms to 5000ms (33x slower)
- Severity: High - Database unavailability, memory exhaustion (100%), and CPU saturation (95%) causing 75% error rate
Next Steps
1. Immediate (&lt; 1 hour): Create/update ConfigMap 'database-config' in production namespace and restart database pod
2. Short-term (&lt; 24 hours): 
   - Fix permissions on '/var/lib/postgresql/data' directory
   - Increase Java heap space for web-service to address OutOfMemoryErrors
   - Optimize UserService.loadAllUsers method causing memory issues
3. Long-term (&lt; 1 week): 
   - Implement resource monitoring with alerts for CPU (&gt;80%), memory (&gt;90%)
   - Optimize slow database queries, particularly "SELECT * FROM users WHERE status='active'"
   - Scale up resources or implement autoscaling for web-service
Critical Alerts
- Database pod (database-pod-7b9c4d8f2a-x5m1q) in CrashLoopBackOff state
- Web-service experiencing OutOfMemoryErrors in UserService.loadAllUsers(UserService.java:45)
- Node-3 experiencing memory pressure (&gt;85% usage)
- Web-app-deployment showing readiness probe failures with 503 errors
Troubleshooting Steps
1. Verify ConfigMap status: `kubectl get configmap database-config -n production`
2. Check database pod logs: `kubectl logs database-pod-7b9c4d8f2a-x5m1q -n production`
3. Create/update ConfigMap: `kubectl create configmap database-config --from-file=database.conf -n production`
4. Fix data directory permissions: `kubectl exec database-pod-7b9c4d8f2a-x5m1q -n production -- chmod -R 700 /var/lib/postgresql/data`
5. Restart database pod: `kubectl delete pod database-pod-7b9c4d8f2a-x5m1q -n production` 
 
This investigation demonstrates how Amazon Bedrock AgentCore primitives work together: 
 
 Amazon Bedrock AgentCore Gateway ‚Äì Provides secure access to infrastructure APIs through MCP tools 
 Amazon Bedrock AgentCore Identity ‚Äì Handles ingress and egress authentication 
 Amazon Bedrock AgentCore Runtime ‚Äì Hosts the multi-agent solution with automatic scaling 
 Amazon Bedrock AgentCore Memory ‚Äì Personalizes Alice‚Äôs experience and stores investigation knowledge for future incidents 
 Amazon Bedrock AgentCore Observability ‚Äì Captures detailed metrics and traces in CloudWatch for monitoring and debugging 
 
The SRE agent demonstrates intelligent agent orchestration, with the supervisor routing work to specialists based on the investigation plan. The solution‚Äôs memory capabilities make sure each investigation builds organizational knowledge and provides personalized experiences based on user roles and preferences. 
This investigation showcases several key capabilities: 
 
 Multi-source correlation ‚Äì It connects database configuration issues to API performance degradation 
 Sequential investigation ‚Äì Agents work systematically through the investigation plan while providing live updates 
 Source attribution ‚Äì Findings include the specific tool and data source 
 Actionable insights ‚Äì It provides a clear timeline of events and prioritized recovery steps 
 Cascading failure detection ‚Äì It can help show how one failure propagates through the system 
 
Business impact 
Organizations implementing AI-powered SRE assistance report significant improvements in key operational metrics. Initial investigations that previously took 30‚Äì45 minutes can now be completed in 5‚Äì10 minutes, providing SREs with comprehensive context before diving into detailed analysis. This dramatic reduction in investigation time translates directly to faster incident resolution and reduced downtime.The solution improves how SREs interact with their infrastructure. Instead of navigating multiple dashboards and tools, engineers can ask questions in natural language and receive aggregated insights from relevant data sources. This reduction in context switching enables teams to maintain focus during critical incidents and reduces cognitive load during investigations.Perhaps most importantly, the solution democratizes knowledge across the team. All team members can access the same comprehensive investigation techniques, reducing dependency on tribal knowledge and on-call burden. The consistent methodology provided by the solution makes sure investigation approaches remain uniform across team members and incident types, improving overall reliability and reducing the chance of missed evidence. 
The automatically generated investigation reports provide valuable documentation for post-incident reviews and help teams learn from each incident, building organizational knowledge over time. Furthermore, the solution extends existing AWS infrastructure investments, working alongside services like Amazon CloudWatch, AWS Systems Manager, and other AWS operational tools to provide a unified operational intelligence system. 
Extending the solution 
The modular architecture makes it straightforward to extend the solution for your specific needs. 
For example, you can add specialized agents for your domain: 
 
 Security agent ‚Äì For compliance checks and security incident response 
 Database agent ‚Äì For database-specific troubleshooting and optimization 
 Network agent ‚Äì For connectivity and infrastructure debugging 
 
You can also replace the demo APIs with connections to your actual systems: 
 
 Kubernetes integration ‚Äì Connect to your cluster APIs for pod status, deployments, and events 
 Log aggregation ‚Äì Integrate with your log management service (Elasticsearch, Splunk, CloudWatch Logs) 
 Metrics platform ‚Äì Connect to your monitoring service (Prometheus, Datadog, CloudWatch Metrics) 
 Runbook repository ‚Äì Link to your operational documentation and playbooks stored in wikis, Git repositories, or knowledge bases 
 
Clean up 
To avoid incurring future charges, use the cleanup script to remove the billable AWS resources created during the demo: 
 
 # Complete cleanup - deletes AWS resources and local files
./scripts/cleanup.sh 
 
This script automatically performs the following actions: 
 
 Stop backend servers 
 Delete the gateway and its targets 
 Delete Amazon Bedrock AgentCore Memory resources 
 Delete the Amazon Bedrock AgentCore Runtime 
 Remove generated files (gateway URIs, tokens, agent ARNs, memory IDs) 
 
For detailed cleanup instructions, refer to Cleanup Instructions. 
Conclusion 
The SRE agent demonstrates how multi-agent systems can transform incident response from a manual, time-intensive process into a time-efficient, collaborative investigation that provides SREs with the insights they need to resolve issues quickly and confidently. 
By combining the enterprise-grade infrastructure of Amazon Bedrock AgentCore with standardized tool access in MCP, we‚Äôve created a foundation that can adapt as your infrastructure evolves and new capabilities emerge. 
The complete implementation is available in our GitHub repository, including demo environments, configuration guides, and extension examples. We encourage you to explore the solution, customize it for your infrastructure, and share your experiences with the community. 
To get started building your own SRE assistant, refer to the following resources: 
 
 Automate tasks in your application using AI agents 
 Amazon Bedrock AgentCore Samples GitHub repository 
 Model Context Protocol documentation 
 LangGraph documentation 
 
 
About the authors 
Amit Arora is an AI and ML Specialist Architect at Amazon Web Services, helping enterprise customers use cloud-based machine learning services to rapidly scale their innovations. He is also an adjunct lecturer in the MS data science and analytics program at Georgetown University in Washington, D.C. 
Dheeraj Oruganty is a Delivery Consultant at Amazon Web Services. He is passionate about building innovative Generative AI and Machine Learning solutions that drive real business impact. His expertise spans Agentic AI Evaluations, Benchmarking and Agent Orchestration, where he actively contributes to research advancing the field. He holds a master‚Äôs degree in Data Science from Georgetown University. Outside of work, he enjoys geeking out on cars, motorcycles, and exploring nature.

‚∏ª