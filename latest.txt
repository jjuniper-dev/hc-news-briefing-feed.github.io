‚úÖ Morning News Briefing ‚Äì August 21, 2025 10:45

üìÖ Date: 2025-08-21 10:45
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ Current Conditions: Fog Patches, 10.6¬∞C
  Temperature: 10.6&deg;C Pressure: 102.1 kPa Visibility: 16 km Visibility : 16 km . Humidity: 96 % Dewpoint: 10 .0&deg:C Wind: W 4 km/h Air Quality Health Index: n/a . Air Quality health index is n/A . Weather forecast is August 21, 2025 at Garrison Pet
‚Ä¢ Thursday: Sunny. High 26.
  Fog patches dissipating this morning . High 26. Humidex 29. UV index 8 or very high . Sunny. Sunny. High 26 . Fog patches are dissipating in the morning . Forecast issued 5:00 AM EDT Thursday 21 August 2025. Forecast also issued Thursday morning. For the rest of the day, see www.jenn.com/jennennenn
‚Ä¢ Thursday night: Clear. Low 12.
  Fog patches developing near midnight . Clear. Clear. Fog patches develop near midnight. Clear . Clear . Forecast issued 5:00 AM EDT Thursday 21 August 2025 . Low 12.50% of the day will be sunny sunny, breezy and breezy in the morning . Low 40% of today's weather is expected to be sunny, sunny, cloudy, cloudy and sunny again .

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ The transitions of aging: How parents and adult children can adjust
  Adult children or caretakers can do a lot to help older people adjust to a new reality . As people age, they may be surprised to find that younger folks don't understand what they're going through . Adult children can help older adults adjust to their new reality, experts say . For more information, visit CNN.com/Heroes for more information on caring for older people .
‚Ä¢ Far fewer Canadians are visiting the U.S. this year, new numbers show
  Canadian residents made just 1.7 million return trips by motor vehicle back into their country from the U.S. in July, a nearly 37% decline over the same month in 2024, according to Statistics Canada . The decline is nearly a quarter of the drop in return trips made by Canadian residents from the United States from July to August 2024, the report says . Canadian residents have made
‚Ä¢ Major Russian drone and missile attack on Ukraine kills 1, injures 15
  The attack mostly targeted western regions of the country, the air force said . The region is where much of the military aid provided by Ukraine's Western allies is believed to be delivered and stored . Ukraine's air force says the attack mainly targeted the western regions, where most of the aid is delivered to Ukraine's western regions . The air force is said to be in charge of Ukraine's military
‚Ä¢ The National Guard has been deployed to enforce the law before. What's different now?
  Experts say the president's decision to deploy the National Guard as a blanket response to crime in D.C. is a departure from its intended mission . The National Guard has been deployed many times historically . Experts say it's a departure of its intended purpose to combat crime in the city . The president has deployed the Guard many times in the U.S. in the past, including in
‚Ä¢ Try this when your doctor says 'yes' to a preventive test but insurance says 'no'
  Health insurance wouldn't cover one child's hearing tests . Reporters with Health Care Helpline investigated and share advice for what to do if preventive care gets denied . Do you have insurance? Share your story with CNN iReport.com: Share it with us on Facebook and Twitter iReport it with CNN.com/Heroes . Share your own story with us at CNN Health Care

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ AI crawlers and fetchers are blowing up websites, with Meta and OpenAI the worst offenders
  AI crawlers slurp up sites at a rate that accounts for 80 percent of all AI bot traffic . Bots and fetchers can hit websites hard, demanding data from a single site in thousands of requests per minute . One fetcher bot seen smacking a website with 39,000 requests per hour . AI crawler crawlers account for 80% of all bot traffic, with the remaining
‚Ä¢ Microsoft makes MCP in Visual Studio GA but researchers warn of risks
  Microsoft declares general availability for MCP (model context protocol) servers in Visual Studio . It is likely to be the second most popular IDE after Visual Studio Code and with wide enterprise use . Compositional risk from multiple MCP Servers highlighted by report Microsoft has declared general availability . MCP servers are a model context protocol server that allows developers to use multiple servers in the same way as other
‚Ä¢ FydeOS offers ChromeOS without the Google strings attached
  Fork runs Android apps and keeps old PCs ticking over without signing into an account with the mothership . FydeOS is an alternative to ChromeOS Flex, but with a few significant differences ‚Äì including Google-account-free operation . Fork runs an Android app that can run on old PCs and runs apps without the need to sign up with the company . Fork is available on Google's
‚Ä¢ The UK Online Safety Act is about censorship, not safety
  UK's Online Safety Act is giving internet users real-time proof that such laws impinge on everyone's rights to speak, read, and view freely . US policymakers should take heed, says the Electronic Frontier Foundation . U.S. states are moving to enact their own age verification laws, say the foundation . The group says such laws should be taken to account for the rights of internet
‚Ä¢ AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'
  Amazon Web Services CEO Matt Garman has suggested firing junior workers because AI can do their jobs is "the dumbest thing I've ever heard" Garman: "They're cheap and grew up with AI ‚Ä¶ so you're firing them why?" Garman's suggestion is the "dumbest thing" he's ever heard from a CEO who says firing junior employees is the dumbest

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Explainable AI reveals tissue pathology and psychosocial drivers of opioid prescription for non-specific chronic low back pain
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Rethinking suicide prevention in schools starts with implementation
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Network analysis reveals causal relationships among individual background risk factors leading to influenza susceptibility
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Factors determining the overlap between recipients of the first and second dose of measles vaccine in nineteen surveys
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Economic impact of tariffs on healthcare costs in urology
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ Why recycling isn‚Äôt enough to address the plastic problem
  UN talks about a plastic treaty to address plastic waste broke down on Friday . The material is widely recognized as a huge source of environmental pollution, but it's also a contributor to climate change . Plastic production has increased at an average rate of 9% every year since 1950 . An estimated 52 million metric tons are dumped into the environment or burned each year . We need to be smarter about the volume of plastic we produce, and we need new ways to make plastic .
‚Ä¢ On the ground in Ukraine‚Äôs largest Starlink repair shop
  Oleh Kovalskyy thinks that Starlink terminals are built as if someone assembled them with their feet. Or perhaps with their hands behind their back.&nbsp;



To demonstrate this last image, Kovalskyy‚Äîa large, 47-year-old Ukrainian, clad in sweatpants and with tattoos stretching from his wrists up to his neck‚Äîleans over to wiggle his fingers in the air behind him, laughing as he does. Components often detach, he says through bleached-white teeth, and they‚Äôre sensitive to dust and moisture. ‚ÄúIt‚Äôs terrible quality. Very terrible.‚Äù&nbsp;



But even if he‚Äôs not particularly impressed by the production quality, he won‚Äôt dispute how important the satellite internet service has been to his country‚Äôs defense.&nbsp;



Starlink is absolutely critical to Ukraine‚Äôs ability to continue in the fight against Russia: It‚Äôs how troops in battle zones stay connected with faraway HQs; it‚Äôs how many of the drones essential to Ukraine‚Äôs survival hit their targets; it‚Äôs even how soldiers stay in touch with spouses and children back home.&nbsp;



At the time of my visit to Kovalskyy in March 2025, however, it had begun to seem like this vital support system may suddenly disappear. Reuters had just broken news that suggested Musk, who was then still deeply enmeshed in Trump world, would remove Ukraine‚Äôs access to the service should its government fail to toe the line in US-led peace negotiations. Musk denied the allegations shortly afterward, but given Trump‚Äôs fickle foreign policy and inconsistent support of Ukrainian president Volodymyr Zelensky, the uncertainty of the technology‚Äôs future had become‚Äîand remains‚Äîimpossible to ignore.¬†¬†






ELENA SUBACH






ELENA SUBACH






Kovalskyy‚Äôs unofficial Starlink repair shop may be the biggest of its kind in the world. Ordered chaos is the best way to describe it.




The stakes couldn‚Äôt be higher: Another Reuters report in late July revealed that Musk had ordered the restriction of Starlink in parts of Ukraine during a critical counteroffensive back in 2022. ‚ÄúUkrainian troops suddenly faced a communications blackout,‚Äù the story explains. ‚ÄúSoldiers panicked, drones surveilling Russian forces went dark, and long-range artillery units, reliant on Starlink to aim their fire, struggled to hit targets.‚Äù



None of this is lost on Kovalskyy‚Äîand for now Starlink access largely comes down to the unofficial community of users and engineers of which Kovalskyy is just one part: Narodnyi Starlink.



The group, whose name translates to ‚ÄúThe People‚Äôs Starlink,‚Äù was created back in March 2022 by a tech-savvy veteran of the previous battles against Russia-backed militias in Ukraine‚Äôs east. It started as a Facebook group for the country‚Äôs infant yet burgeoning community of Starlink users‚Äîa forum to share guidance and swap tips‚Äîbut it very quickly emerged as a major support system for the new war effort. Today, it has grown to almost 20,000 members, including the unofficial expert ‚ÄúDr. Starlink‚Äù‚Äîfamous for his creative ways of customizing the systems‚Äîand other volunteer engineers like Kovalskyy and his men. It‚Äôs a prime example of the many informal, yet highly effective, volunteer networks that have kept Ukraine in the fight, both on and off the front line.






ELENA SUBACH






ELENA SUBACH






Kovalskyy and his crew of eight volunteers have repaired or customized more than 15,000 terminals since the war began in February 2022. Here, they test repaired units in a nearby parking lot.




Kovalskyy gave MIT Technology Review exclusive access to his unofficial Starlink repair workshop in the city of Lviv, about 300 miles west of Kyiv. Ordered chaos is the best way to describe it: Spread across a few small rooms in a nondescript two-story building behind a tile shop, sagging cardboard boxes filled with mud-splattered Starlink casings form alleyways among the rubble of spare parts. Like flying buttresses, green circuit boards seem to prop up the walls, and coils of cable sprout from every crevice.



Those acquainted with the workshop refer to it as the biggest of its kind in Ukraine‚Äîand, by extension, maybe the world. Official and unofficial estimates suggest that anywhere from 42,000 to 160,000 Starlink terminals operate in the country. Kovalskyy says he and his crew of eight volunteers have repaired or customized more than 15,000 terminals since the war began.



The informal, accessible nature of the Narodnyi Starlink community has been critical to its success. One military communications officer was inspired by Kovalskyy to set up his own repair workshop as part of Ukraine‚Äôs armed forces, but he says that official processes can be slower than private ones by a factor of 10.ELENA SUBACH




Despite the pressure, the chance that they may lose access to Starlink was not worrying volunteers like Kovalskyy at the time of my visit; in our conversations, it was clear they had more pressing concerns than the whims of a foreign tech mogul. Russia continues to launch frequent aerial bombardments of Ukrainian cities, sometimes sending more than 500 drones in a single night. The threat of involuntary mobilization to the front line looms on every street corner. How can one plan for a hypothetical future crisis when crisis defines every minute of one‚Äôs day?







Almost every inch of every axis of the battlefield in Ukraine is enabled by Starlink. It connects pilots near the trenches with reconnaissance drones soaring kilometers above them. It relays the video feeds from those drones to command centers in rear positions. And it even connects soldiers, via encrypted messaging services, with their family and friends living far from the front.¬†¬†



Although some soldiers and volunteers, including members of Narodnyi Starlink, refer to Starlink as a luxury, the reality is that it‚Äôs an essential utility; without it, Ukrainian forces would need to rely on other, often less effective means of communication. These include wired-line networks, mobile internet, and older geostationary satellite technology‚Äîall of which provide connectivity that is either slower, more vulnerable to interference, or more difficult for untrained soldiers to set up.&nbsp;



‚ÄúIf not for Starlink, we would already be counting rubles in Kyiv,‚Äù Kovalskyy says.






ELENA SUBACH






ELENA SUBACH






The workshop‚Äôs crew has learned to perform adjustments to terminals, especially in adapting them for battlefield conditions. At right, a volunteer engineer shows the fragments of shrapnel he has extracted from the terminals.




Despite being designed primarily for commercial use, Starlink provides a fantastic battlefield solution. The low-latency, high-bandwidth connection its terminals establish with its constellation of low-Earth-orbit satellites can transmit large streams of data while remaining very difficult for the enemy to jam‚Äîin part because the satellites, unlike geostationary ones, are in constant motion.&nbsp;



It‚Äôs also fairly easy to use, so that soldiers with little or no technical knowledge can connect in minutes. And the system costs much less than other military technology; while the US and Polish governments pay business rates for many of Ukraine‚Äôs Starlink systems, individual soldiers or military units can purchase the hardware at the private rate of about $500, and subscribe for just $50 per month.



No alternatives match Starlink for cost, ease of use, or coverage‚Äîand none will in the near future. Its constellation of 8,000 satellites dwarfs that of its main competitor, a service called OneWeb sold by the French satellite operator Eutelsat, which has only 630 satellites. OneWeb‚Äôs hardware costs about 20 times more, and a subscription can run significantly higher, since OneWeb targets business customers. Amazon‚Äôs Project Kuiper, the most likely future competitor, started putting satellites in space only this year.&nbsp;







Volodymyr Stepanets, a 51-year-old Ukrainian self-described ‚Äúgeek,‚Äù had been living in Krakow, Poland, with his family when Russia invaded in 2022. But before that, he had volunteered for several years on the front lines of the war against Russian-supported paramilitaries that began in 2014.&nbsp;



He recalls, in those early months in eastern Ukraine, witnessing troops coordinating an air strike with rulers and a calculator; the whole process took them between 30 and 40 minutes. ‚ÄúAll these calculations can be done in one minute,‚Äù he says he told them. ‚ÄúAll we need is a very stupid computer and very easy software.‚Äù (The Ukrainian military declined to comment on this issue.)



Stepanets subsequently committed to helping this brigade, the 72nd, integrate modern technology into its operations. He says that within one year, he had taught them how to use modern communication platforms, positioning devices, and older satellite communication systems that predate Starlink.&nbsp;



Narodnyi Starlink members ask each other for advice about how to adapt the systems: how to camouflage them from marauding Russian drones or resolve glitches in the software, for example.ELENA SUBACH




So after Russian tanks rolled across the border, Stepanets was quick to see how Starlink‚Äôs service could provide an advantage to Ukraine‚Äôs armed forces. He also recognized that these units, as well as civilian users, would need support in utilizing the new technology. And that‚Äôs how he came up with the idea for Narodnyi Starlink, an open Facebook group he launched on March 21, just a few weeks after the full invasion began and the Ukrainian government requested the activation of Starlink.



Over the past few years, the Narodnyi Starlink digital community has grown to include volunteer engineers, resellers, and military service members interested in the satellite comms service. The group‚Äôs members post roughly three times per day, often sharing or asking for advice about adaptations, or seeking volunteers to fix broken equipment. A user called Igor Semenyak recently asked, for example, whether anyone knew how to mask his system from infrared cameras. ‚ÄúHow do you protect yourself from heat radiation?‚Äù he wrote, to which someone suggested throwing special heat-proof fabric over the terminal.



Its most famous member is probably a man widely considered the brains of the group: Oleg Kutkov, a 36-year-old software engineer otherwise known to some members as ‚ÄúDr. Starlink.‚Äù Kutkov had been privately studying Starlink technology from his home in Kyiv since 2021, having purchased a system to tinker with when service was still unavailable in the country; he believes that he may have been the country‚Äôs first Starlink user. Like Stepanets, he saw the immense potential for Starlink after Russia broke traditional communication lines ahead of its attack.



‚ÄúOur infrastructure was very vulnerable because we did not have a lot of air defense,‚Äù says Kutkov, who still works full time as an engineer at the US networking company Ubiquiti‚Äôs R&amp;D center in Kyiv. ‚ÄúStarlink quickly became a crucial part of our survival.‚Äù



Stepanets contacted Kutkov after coming across his popular Twitter feed and blog, which had been attracting a lot of attention as early Starlink users sought help. Kutkov still publishes the results of his own research there‚Äîexperiments he performs in his spare time, sometimes staying up until 3 a.m. to complete them. In May, for example, he published a blog post explaining how users can physically move a user account from one terminal to another when the printed circuit board in one is ‚Äúso severely damaged that repair is impossible or impractical.‚Äù&nbsp;



‚ÄúOleg Kutkov is the coolest engineer I‚Äôve met in my entire life,‚Äù Kovalskyy says.






ELENA SUBACH






ELENA SUBACH






When the fighting is at its worst, the workshop may receive 500 terminals to repair every month. The crew lives and sometimes even sleeps there.




Supported by Kutkov‚Äôs technical expertise and Stepanets‚Äôs organizational prowess, Kovalskyy‚Äôs warehouse became the major repair hub (though other volunteers also make repairs elsewhere). Over time, Kovalskyy‚Äîwho co-owned a regional internet service provider before the war‚Äîand his crew have learned to perform adjustments to Starlink terminals, especially to adapt them for battlefield conditions. For example, they modified them to receive charge at the right voltage directly from vehicles, years before Starlink released a proprietary car adapter. They‚Äôve also switched out Starlink‚Äôs proprietary SPX plugs‚Äîwhich Kovalskyy criticized as vulnerable to moisture and temperature changes‚Äîwith standard ethernet ports.&nbsp;



Together, the three civilians‚ÄîKutkov, Stepanets, and Kovalskyy‚Äîeffectively lead Narodnyi Starlink. Along with several other members who wished to remain anonymous, they hold meetings every Monday over Zoom to discuss their activities, including recent Starlink-related developments on the battlefield, as well as information security.&nbsp;



While the public group served as a suitable means of disseminating information in the early stages of the war when speed was critical, they have had to move a lot of their communications to private channels after discovering Russian surveillance; Stepanets says that at least as early as 2024, Russians had translated a 300-page educational document they had produced and shared online. Now, as administrators of the Facebook group, the three men block the publication of any posts deemed to reveal information that might be useful to Russian forces.&nbsp;



Stepanets believes the threat extends beyond the group‚Äôs intel to its members‚Äô physical safety. When we talked, he brought up the attempted assassination of the Ukrainian activist and volunteer Serhii Sternenko in May this year. Although Sternenko was unaffiliated with Narodnyi Starlink, the event served as a clear reminder of the risks even civilian volunteers undertake in wartime Ukraine. ‚ÄúThe Russian FSB and other [security] services still understand the importance of participation in initiatives like [Narodnyi Starlink],‚Äù Stepanets says. He stresses that the group is not an organization with a centralized chain of command, but a community that would continue operating if any of its members were no longer able to perform their roles.¬†



 ‚ÄúWe have extremely professional engineers who are extremely intelligent,‚Äù Kovalskyy told me. ‚ÄúRepairing Starlink terminals for them is like shooting ducks with HIMARS [a vehicle-borne GPS-guided rocket launcher].‚ÄùELENA SUBACH




The informal, accessible nature of this community has been critical to its success. Operating outside official structures has allowed Narodnyi Starlink to function much more efficiently than state channels. Yuri Krylach, a military communications officer who was inspired by Kovalskyy to set up his own repair workshop as part of Ukraine‚Äôs armed forces, says that official processes can be slower than private ones by a factor of 10; his own team‚Äôs work is often interrupted by other tasks that commanders deem more urgent, whereas members of the Narodnyi Starlink community can respond to requests quickly and directly. (The military declined to comment on this issue, or on any military connections with Narodnyi Starlink.)







Most of the Narodnyi Starlink members I spoke to, including active-duty soldiers, were unconcerned about the report that Musk might withdraw access to the service in Ukraine. They pointed out that doing so would involve terminating state contracts, including those with the US Department of Defense and Poland‚Äôs Ministry of Digitalization. Losing contracts worth hundreds of millions of dollars (the Polish government claims to pay $50 million per year in subscription fees), on top of the private subscriptions, would cost the company a significant amount of revenue. ‚ÄúI don‚Äôt really think that Musk would cut this money supply,‚Äù Kutkov says. ‚ÄúIt would be quite stupid.‚Äù Oleksandr Dolynyak, an officer in the 103rd Separate Territorial Defense Brigade and a Narodnyi Starlink member since 2022, says: ‚ÄúAs long as it is profitable for him, Starlink will work for us.‚Äù



Stepanets does believe, however, that Musk‚Äôs threats exposed an overreliance on the technology that few had properly considered. ‚ÄúStarlink has really become one of the powerful tools of defense of Ukraine,‚Äù he wrote in a March Facebook post entitled ‚ÄúIrreversible Starlink hegemony,‚Äù accompanied by an image of the evil Darth Sidious from Star Wars. ‚ÄúNow, the issue of the country&#8217;s dependence on the decisions of certain eccentric individuals ‚Ä¶ has reached [a] melting point.‚Äù





Even if telecommunications experts both inside and outside the military agree that Starlink has no direct substitute, Stepanets believes that Ukraine needs to diversify its portfolio of satellite communication tools anyway, integrating additional high-speed satellite communication services like OneWeb. This would relieve some of the pressure caused by Musk‚Äôs erratic, unpredictable personality and, he believes, give Ukraine some sense of control over its wartime communications. (SpaceX did not respond to a request for comment.)¬†



The Ukrainian military seems to agree with this notion. In late March, at a closed-door event in Kyiv, the country‚Äôs then-deputy minister of defense Kateryna Chernohorenko announced the formation of a special Space Policy Directorate ‚Äúto consolidate internal and external capabilities to advance Ukraine‚Äôs military space sector.‚Äù The announcement referred to the creation of a domestic ‚Äúsatellite constellation,‚Äù which suggests that reliance on foreign services like Starlink had been a catalyst. ‚ÄúUkraine needs to transition from the role of consumer to that of a full-fledged player in the space sector,‚Äù a government blog post stated. (Chernohorenko did not respond to a request for comment.)



Ukraine isn‚Äôt alone in this quandary. Recent discussions about a potential Starlink deal with the Italian government, for example, have stalled as a result of Musk‚Äôs behavior. And as Juliana S√ºss, an associate fellow at the UK‚Äôs Royal United Services Institute, points out, Taiwan chose SpaceX‚Äôs competitor Eutelsat when it sought a satellite communications partner in 2023.



‚ÄúI think we always knew that SpaceX is not always the most reliable partner,‚Äù says S√ºss, who also hosts RUSI‚Äôs War in Space podcast, citing Musk‚Äôs controversial comments about the country‚Äôs status. ‚ÄúThe Taiwan problems are a good example for how the rest of the world might be feeling about this.‚Äù



Nevertheless, Ukraine is about to become even more deeply enmeshed with Starlink; the country‚Äôs leading mobile operator Kyivstar announced in July that Ukraine will soon become the first European nation to offer Starlink direct-to-mobile services. S√ºss is cautious about placing too much emphasis on this development though. ‚ÄúThis step does increase dependency,‚Äù she says. ‚ÄúBut that dependency is already there.‚Äù Adding an additional channel of communications as a possible backup is otherwise a logical action for a country at war, she says.







These issues can feel far away for the many Ukrainians who are just trying to make it through to the next day. Despite its location in the far west of Ukraine, Lviv, home to Kovalskyy‚Äôs shop, is still frequently hit by Russian kamikaze drones, and local military-affiliated sites are popular targets.&nbsp;



Still, during our time together, Kovalskyy was far more worried by the prospect of his team‚Äôs possible mobilization. In March, the Ministry of Defense had removed the special status that had otherwise protected his people from involuntary conscription given the nature of their volunteer activities. They‚Äôre now at risk of being essentially picked up off the street by Ukraine‚Äôs dreaded military recruitment teams, known as the TCK, whenever they leave the house.



The repair shop displays patches from many different Ukrainian military units‚Äîeach given as a gift for their services. ‚ÄúWe sometimes perform miracles with Starlinks,‚Äù Kovalskyy said.COURTESY OF THE AUTHOR




This is true even though there‚Äôs so much demand for the workshop‚Äôs services that during my visit, Kovalskyy expressed frustration at the vast amount of time they‚Äôve had to dedicate solely to basic repairs. ‚ÄúWe have extremely professional engineers who are extremely intelligent,‚Äù he told me. ‚ÄúRepairing Starlink terminals for them is like shooting ducks with HIMARS [a vehicle-borne GPS-guided rocket launcher].‚Äù&nbsp;



At least the situation seemed to have become better on the front over the winter, Kovalskyy added, handing me a Starlink antenna whose flat, white surface had been ripped open by shrapnel. When the fighting is at its worst, the team might receive 500 terminals to repair every month, and the crew lives in the workshop, sometimes even sleeping there. But at that moment in time, it was receiving only a couple of hundred.



We ended our morning at the workshop by browsing its vast collection of varied military patches, pinned to the wall on large pieces of Velcro. Each had been given as a gift by a different unit as thanks for the services of Kovalskyy and his team, an indication of the diversity and size of Ukraine‚Äôs military: almost 1 million soldiers protecting a 600-mile front line. At the same time, it‚Äôs a physical reminder that they almost all rely on a single technology with just a few production factories located on another continent nearly 6,000 miles away.



‚ÄúWe sometimes perform miracles with Starlinks,‚Äù Kovalskyy says.&nbsp;



He and his crew can only hope that they will still be able to for the foreseeable future‚Äîor, better yet, that they won‚Äôt need to at all.&nbsp;&nbsp;



Charlie Metcalfe is a British journalist. He writes for magazines and newspapers including Wired, the Guardian, and MIT Technology Review.
‚Ä¢ Forging connections in space with cellular technology
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ NASA‚Äôs new AI model can predict when a solar storm may strike
  IBM and NASA have released an open-source machine learning model to predict solar storms . Surya, trained on over a decade‚Äôs worth of NASA data, should give scientists an early warning when a dangerous solar flare is likely to hit Earth . IBM claims it could double the warning time currently possible with state-of-the-art methods . The model's training data came from NASA's Solar Dynamics Observatory, which collects pictures of the sun at different wavelengths of light simultaneously .
‚Ä¢ The Download: churches in the age of AI, and how to run an LLM at home
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



How churches use data and AI as engines of surveillance



On a Sunday morning in a Midwestern megachurch, worshippers step through sliding glass doors into a bustling lobby‚Äîunaware they‚Äôve just passed through a gauntlet of biometric surveillance. High-speed cameras snap multiple face ‚Äúprobes‚Äù per second, before passing the results to a local neural network that distills these images into digital fingerprints. Before people find their seats, they are matched against an on-premises database‚Äîtagged with names, membership tiers, and watch-list flags‚Äîthat‚Äôs stored behind the church‚Äôs firewall.



This hypothetical scene reflects real capabilities increasingly woven into places of worship nationwide, where spiritual care and surveillance converge in ways few congregants ever realize.&nbsp;



Where Big Tech‚Äôs rationalist ethos and evangelical spirituality once mixed like oil and holy water, now they‚Äôre combining to redraw the contours of community and pastoral power in modern spiritual life. Read the full story.



‚ÄîAlex Ashley



This story is from our forthcoming print issue, which is all about security. If you haven‚Äôt already, subscribe now to receive future issues once they land.







MIT Technology Review Narrated: How to run an LLM on your laptop



For people who are concerned about privacy, want to break free from the control of the big LLM companies, or just enjoy tinkering, local models offer a compelling alternative to ChatGPT and its web-based peers. Here‚Äôs how to get started running one from the safety and comfort of your own computer.



This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we‚Äôre publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it‚Äôs released.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 US tech stocks are sliding over fears the AI bubble may be about to burstAfter an MIT report found that the vast majority of organizations are getting zero return on their AI investments. (FT $)+ Even Sam Altman thinks the current hype is unsustainable. (CNBC)



2 Meta is reportedly weighing up downsizing its AI divisionIt wants to split it into four groups‚Äîand layoffs could be imminent. (NYT $)+ What‚Äôs happening with the metaverse, then? (NY Mag $)+ Meta is desperately hoping its AI hiring spree will pay off. (Bloomberg $)



3 The American Academy of Pediatrics is defying RFK Jr



By releasing its own vaccination schedule for children. (Ars Technica)+ It‚Äôs breaking with current CDC recommendations. (CNN)+ Why US federal health agencies are abandoning mRNA vaccines. (MIT Technology Review)



4 Elon Musk‚Äôs America Party isn‚Äôt going so wellHe‚Äôs said to be refocusing his attention on his companies instead. (WSJ $)



5 The White House has a TikTok account nowThe very same TikTok that Donald Trump once tried to ban. (WP $)+ What appears to have changed Congress‚Äô stance? (The Verge)+ There‚Äôs still no sign of a sale on the horizon. (The Guardian)



6 Nvidia is working on another chip for ChinaOne that‚Äôs faster and more powerful than its current H20 model. (Reuters)



7 How AGI preppers are bracing themselves for an AI apocalypseSome are spending all their retirement savings along the way. (Insider $)



8 Demand for critical minerals is soaringIs there a less-invasive way to mine them? (New Scientist $)+ The race to produce rare earth elements. (MIT Technology Review)



9 What‚Äôs an automaker CEO to do?In our increasingly topsy turvy world, many of them feel like they can‚Äôt win. (Wired $)



10 This mattress company is building an AI agent for sleepEight Sleep‚Äôs agent could simulate digital twins of a user‚Äôs sleep habits. (The Information $)+ I tried to hack my insomnia with technology. Here‚Äôs what worked. (MIT Technology Review)







Quote of the day



‚ÄúToo many cooks, too many kitchens.‚Äù



‚ÄîTech investor M.G. Siegler wryly comments on the news Meta is planning to restructure its AI division in a post on Bluesky.







One more thing







Responsible AI has a burnout problemMargaret Mitchell had been working at Google for two years before she realized she needed a break. Only after she spoke with a therapist did she understand the problem: she was burnt out.Mitchell, who now works as chief ethics scientist at the AI startup Hugging Face, is far from alone in her experience. Burnout is becoming increasingly common in responsible AI teams.All the practitioners MIT Technology Review interviewed spoke enthusiastically about their work: it is fueled by passion, a sense of urgency, and the satisfaction of building solutions for real problems. But that sense of mission can be overwhelming without the right support. Read the full story.¬†



‚ÄîMelissa Heikkil√§







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Check out Wes Andersons‚Äô quirky love letter to New York + Uhoh‚Äîbeware the rise of the groomzilla.+ The Rocky Horror Picture Show is 50 years old, if you can believe it.+ Whisk me away to Lake George ASAP.

üîí Cybersecurity & Privacy
‚Ä¢ SIM-Swapper, Scattered Spider Hacker Gets 10 Years
  A 20-year-old Florida man at the center of a prolific cybercrime group known as &#8220;Scattered Spider&#8221; was sentenced to 10 years in federal prison today, and ordered to pay roughly $13 million in restitution to victims.
Noah Michael Urban of Palm Coast, Fla. pleaded guilty in April 2025 to charges of wire fraud and conspiracy. Florida prosecutors alleged Urban conspired with others to steal at least $800,000 from five victims via SIM-swapping attacks that diverted their mobile phone calls and text messages to devices controlled by Urban and his co-conspirators.
A booking photo of Noah Michael Urban released by the Volusia County Sheriff.
Although prosecutors had asked for Urban to serve eight years, Jacksonville news outlet News4Jax.com reports the federal judge in the case today opted to sentence Urban to 120 months in federal prison, ordering him to pay $13 million in restitution and undergo three years of supervised release after his sentence is completed.
In November 2024 Urban was charged by federal prosecutors in Los Angeles as one of five members of Scattered Spider (a.k.a. &#8220;Oktapus,&#8221; &#8220;Scatter Swine&#8221; and &#8220;UNC3944&#8221;), which specialized in SMS and voice phishing attacks that tricked employees at victim companies into entering their credentials and one-time passcodes at phishing websites. Urban pleaded guilty to one count of conspiracy to commit wire fraud in the California case, and the $13 million in restitution is intended to cover victims from both cases.
The targeted SMS scams spanned several months during the summer of 2022, asking employees to click a link and log in at a website that mimicked their employer‚Äôs Okta authentication page. Some SMS phishing messages told employees their VPN credentials were expiring and needed to be changed; other missives advised employees about changes to their upcoming work schedule.
That phishing spree netted Urban and others access to more than 130 companies, including Twilio, LastPass, DoorDash, MailChimp, and Plex. The government says the group used that access to steal proprietary company data and customer information, and that members also phished people to steal millions of dollars worth of cryptocurrency.
For many years, Urban&#8217;s online hacker aliases &#8220;King Bob&#8221; and &#8220;Sosa&#8221; were fixtures of the Com, a mostly Telegram and Discord-based community of English-speaking cybercriminals wherein hackers boast loudly about high-profile exploits and hacks that almost invariably begin with social engineering. King Bob constantly bragged on the Com about stealing unreleased rap music recordings from popular artists, presumably through SIM-swapping attacks. Many of those purloined tracks or &#8220;grails&#8221; he later sold or gave away on forums.
Noah &#8220;King Bob&#8221; Urban, posting to Twitter/X around the time of his sentencing today.
Sosa also was active in a particularly destructive group of accomplished criminal SIM-swappers known as &#8220;Star Fraud.&#8221; Cyberscoop‚Äôs AJ Vicens reported in 2023 that individuals within Star Fraud were likely involved in the high-profile Caesars Entertainment and MGM Resorts extortion attacks that same year.
The Star Fraud SIM-swapping group gained the ability to temporarily move targeted mobile numbers to devices they controlled by constantly phishing employees of the major mobile providers. In February 2023, KrebsOnSecurity published data taken from the Telegram channels for Star Fraud and two other SIM-swapping groups showing these crooks focused on SIM-swapping T-Mobile customers, and that they collectively claimed internal access to T-Mobile on 100 separate occasions over a 7-month period in 2022.
Reached via one of his King Bob accounts on Twitter/X, Urban called the sentence unjust, and said the judge in his case discounted his age as a factor.
&#8220;The judge purposefully ignored my age as a factor because of the fact another Scattered Spider member hacked him personally during the course of my case,&#8221; Urban said in reply to questions, noting that he was sending the messages from a Florida county jail. &#8220;He should have been removed as a judge much earlier on. But staying in county jail is torture.&#8221;
A court transcript (PDF) from a status hearing in February 2025 shows Urban was telling the truth about the hacking incident that happened while he was in federal custody. It involved an intrusion into a magistrate judge&#8217;s email account, where a copy of Urban&#8217;s sealed indictment was stolen. The judge told attorneys for both sides that a co-defendant in the California case was trying to find out about Mr. Urban&#8217;s activity in the Florida case.
&#8220;What it ultimately turned into a was a big faux pas,&#8221; Judge Harvey E. Schlesinger said. &#8220;The Court&#8217;s password&#8230;business is handled by an outside contractor. And somebody called the outside contractor representing Judge Toomey saying, &#8216;I need a password change.&#8217; And they gave out the password change. That&#8217;s how whoever was making the phone call got into the court.&#8221;
‚Ä¢ Oregon Man Charged in ‚ÄòRapper Bot‚Äô DDoS Service
  A 22-year-old Oregon man has been arrested on suspicion of operating &#8220;Rapper Bot,&#8221; a massive botnet used to power a service for launching distributed denial-of-service (DDoS) attacks against targets &#8212; including a March 2025 DDoS that knocked Twitter/X offline. The Justice Department asserts the suspect and an unidentified co-conspirator rented out the botnet to online extortionists, and tried to stay off the radar of law enforcement by ensuring that their botnet was never pointed at KrebsOnSecurity.
The control panel for the Rapper Bot botnet greets users with the message &#8220;Welcome to the Ball Pit, Now with refrigerator support,&#8221; an apparent reference to a handful of IoT-enabled refrigerators that were enslaved in their DDoS botnet.
On August 6, 2025, federal agents arrested Ethan J. Foltz of Springfield, Ore. on suspicion of operating Rapper Bot, a globally dispersed collection of tens of thousands of hacked Internet of Things (IoT) devices.
The complaint against Foltz explains the attacks usually clocked in at more than two terabits of junk data per second (a terabit is one trillion bits of data), which is more than enough traffic to cause serious problems for all but the most well-defended targets. The government says Rapper Bot consistently launched attacks that were &#8220;hundreds of times larger than the expected capacity of a typical server located in a data center,&#8221; and that some of its biggest attacks exceeded six terabits per second.
Indeed, Rapper Bot was reportedly responsible for the March 10, 2025 attack that caused intermittent outages on Twitter/X. The government says Rapper Bot&#8217;s most lucrative and frequent customers were involved in extorting online businesses &#8212; including numerous gambling operations based in China.
The criminal complaint was written by Elliott Peterson, an investigator with the Defense Criminal Investigative Service (DCIS), the criminal investigative division of the Department of Defense (DoD) Office of Inspector General. The complaint notes the DCIS got involved because several Internet addresses maintained by the DoD were the target of Rapper Bot attacks.
Peterson said he tracked Rapper Bot to Foltz after a subpoena to an ISP in Arizona that was hosting one of the botnet&#8217;s control servers showed the account was paid for via PayPal. More legal process to PayPal revealed Foltz&#8217;s Gmail account and previously used IP addresses. A subpoena to Google showed the defendant searched security blogs constantly for news about Rapper Bot, and for updates about competing DDoS-for-hire botnets.
According to the complaint, after having a search warrant served on his residence the defendant admitted to building and operating Rapper Bot, sharing the profits 50/50 with a person he claimed to know only by the hacker handle &#8220;Slaykings.&#8221; Foltz also shared with investigators the logs from his Telegram chats, wherein Foltz and Slaykings discussed how best to stay off the radar of law enforcement investigators while their competitors were getting busted.
Specifically, the two hackers chatted about a May 20 attack against KrebsOnSecurity.com that clocked in at more than 6.3 terabits of data per second. The brief attack was notable because at the time it was the largest DDoS that Google had ever mitigated (KrebsOnSecurity sits behind the protection of Project Shield, a free DDoS defense service that¬†Google provides to websites offering news, human rights, and election-related content).
The May 2025 DDoS was launched by an IoT botnet called Aisuru, which I discovered was operated by a 21-year-old man in Brazil named Kaike Southier Leite. This individual was more commonly known online as &#8220;Forky,&#8221; and Forky told me he wasn&#8217;t afraid of me or U.S. federal investigators. Nevertheless, the complaint against Foltz notes that Forky&#8217;s botnet seemed to diminish in size and firepower at the same time that Rapper Bot&#8217;s infection numbers were on the upswing.
&#8220;Both FOLTZ and Slaykings were very dismissive of attention seeking activities, the most extreme of which, in their view, was to launch DDoS attacks against the website of the prominent cyber security journalist Brian Krebs,&#8221; Peterson wrote in the criminal complaint.
&#8220;You see, they‚Äôll get themselves [expletive],&#8221; Slaykings wrote in response to Foltz&#8217;s comments about Forky and Aisuru bringing too much heat on themselves.
&#8220;Prob cuz [redacted] hit krebs,&#8221; Foltz wrote in reply.
&#8220;Going against Krebs isn‚Äôt a good move,&#8221; Slaykings concurred. &#8220;It isn‚Äôt about being a [expletive] or afraid, you just get a lot of problems for zero money. Childish, but good. Let them die.&#8221;
&#8220;Ye, it‚Äôs good tho, they will die,&#8221; Foltz replied.
The government states that just prior to Foltz&#8217;s arrest, Rapper Bot had enslaved an estimated 65,000 devices globally. That may sound like a lot, but the complaint notes the defendants weren&#8217;t interested in making headlines for building the world&#8217;s largest or most powerful botnet.
Quite the contrary: The complaint asserts that the accused took care to maintain their botnet in a &#8220;Goldilocks&#8221; size &#8212; ensuring that &#8220;the number of devices afforded powerful attacks while still being manageable to control and, in the hopes of Foltz and his partners, small enough to not be detected.&#8221;
The complaint states that several days later, Foltz and Slaykings returned to discussing what that they expected to befall their rival group, with Slaykings stating, &#8220;Krebs is very revenge. He won‚Äôt stop until they are [expletive] to the bone.&#8221;
&#8220;Surprised they have any bots left,&#8221; Foltz answered.
&#8220;Krebs is not the one you want to have on your back. Not because he is scary or something, just because he will not give up UNTIL you are [expletive] [expletive]. Proved it with Mirai and many other cases.&#8221;
[Unknown expletives aside, that may well be the highest compliment I&#8217;ve ever been paid by a cybercriminal. I might even have part of that quote made into a t-shirt or mug or something. It&#8217;s also nice that they didn&#8217;t let any of their customers attack my site &#8212; if even only out of a paranoid sense of self-preservation.]
Foltz admitted to wiping the user and attack logs for the botnet approximately once a week, so investigators were unable to tally the total number of attacks, customers and targets of this vast crime machine. But the data that was still available showed that from April 2025 to early August, Rapper Bot conducted over 370,000 attacks, targeting 18,000 unique victims across 1,000 networks, with the bulk of victims residing in China, Japan, the United States, Ireland and Hong Kong (in that order).
According to the government, Rapper Bot borrows much of its code from fBot, a DDoS malware strain also known as Satori. In 2020, authorities in Northern Ireland charged a then 20-year-old man named Aaron &#8220;Vamp&#8221; Sterritt with operating fBot with a co-conspirator. U.S. prosecutors are still seeking Sterritt&#8217;s extradition to the United States. fBot is itself a variation of the Mirai IoT botnet¬†that has ravaged the Internet with DDoS attacks since its source code was leaked back in 2016.
The complaint says Foltz and his partner did not allow most customers to launch attacks that were more than 60 seconds in duration &#8212; another way they tried to keep public attention to the botnet at a minimum. However, the government says the proprietors also had special arrangements with certain high-paying clients that allowed much larger and longer attacks.
The accused and his alleged partner made light of this blog post about the fallout from one of their botnet attacks.
Most people who have never been on the receiving end of a monster DDoS attack have no idea of the cost and disruption that such sieges can bring. The DCIS&#8217;s Peterson wrote that he was able to test the botnet&#8217;s capabilities while interviewing Foltz, and that found that &#8220;if this had been a server upon which I was running a website, using services such as load balancers, and paying for both outgoing and incoming data, at estimated industry average rates the attack (2+ Terabits per second times 30 seconds) might have cost the victim anywhere from $500 to $10,000.&#8221;
&#8220;DDoS attacks at this scale often expose victims to devastating financial impact, and a potential alternative, network engineering solutions that mitigate the expected attacks such as overprovisioning, i.e. increasing potential Internet capacity, or DDoS defense technologies, can themselves be prohibitively expensive,&#8221; the complaint continues. &#8220;This &#8216;rock and a hard place&#8217; reality for many victims can leave them acutely exposed to extortion demands ‚Äì &#8216;pay X dollars and the DDoS attacks stop&#8217;.&#8221;
The Telegram chat records show that the day before Peterson and other federal agents raided Foltz&#8217;s residence, Foltz allegedly told his partner he&#8217;d found 32,000 new devices that were vulnerable to a previously unknown exploit.
Foltz and Slaykings discussing the discovery of an IoT vulnerability that will give them 32,000 new devices.
Shortly before the search warrant was served on his residence, Foltz allegedly told his partner that &#8220;Once again we have the biggest botnet in the community.&#8221; The following day, Foltz told his partner that it was going to be a great day &#8212; the biggest so far in terms of income generated by Rapper Bot.
&#8220;I sat next to Foltz while the messages poured in &#8212; promises of $800, then $1,000, the proceeds ticking up as the day went on,&#8221; Peterson wrote. &#8220;Noticing a change in Foltz&#8217; behavior and concerned that Foltz was making changes to the botnet configuration in real time, Slaykings asked him &#8216;What&#8217;s up?&#8217; Foltz deftly typed out some quick responses. Reassured by Foltz&#8217; answer, Slaykings responded, &#8216;Ok, I&#8217;m the paranoid one.&#8221;
The case is being prosecuted by Assistant U.S. Attorney Adam Alexander in the District of Alaska (at least some of the devices found to be infected with Rapper Bot were located there, and it is where Peterson is stationed). Foltz faces one count of aiding and abetting computer intrusions. If convicted, he faces a maximum penalty of 10 years in prison, although a federal judge is unlikely to award anywhere near that kind of sentence for a first-time conviction.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ MindJourney enables AI to explore simulated 3D worlds to improve spatial interpretation
  A new research framework helps AI agents explore three-dimensional spaces they can‚Äôt directly detect. Called MindJourney, the approach addresses a key limitation in vision-language models (VLMs), which give AI agents their ability to interpret and describe visual scenes.¬†¬†



While VLMs&nbsp;are strong&nbsp;at identifying objects in&nbsp;static&nbsp;images,&nbsp;they struggle to&nbsp;interpret&nbsp;the interactive 3D world behind 2D images.&nbsp;This&nbsp;gap shows up&nbsp;in spatial&nbsp;questions&nbsp;like&nbsp;‚ÄúIf I sit on the couch&nbsp;that is on my right&nbsp;and face the chairs, will the kitchen be to my right or left?‚Äù‚Äîtasks that require an agent to&nbsp;interpret&nbsp;its&nbsp;position and movement through space.&nbsp;



People&nbsp;overcome this challenge by mentally exploring a space,&nbsp;imagining moving through it and combining those mental snapshots to work out where objects are.&nbsp;MindJourney&nbsp;applies the same process&nbsp;to&nbsp;AI agents,&nbsp;letting&nbsp;them roam a virtual&nbsp;space before answering spatial questions.&nbsp;



How&nbsp;MindJourney&nbsp;navigates 3D space



To perform this type of spatial navigation,&nbsp;MindJourney&nbsp;uses a&nbsp;world model‚Äîin this case,&nbsp;a video generation system trained on a large collection of videos captured from a single moving viewpoint, showing actions such as going forward and turning left of right, much like a 3D cinematographer. From this, it learns to predict how a new scene would appear from different perspectives.



At inference time, the model can generate photo-realistic images of a scene based on possible movements from the agent‚Äôs current position. It generates multiple possible views of a scene while the VLM acts as a filter, selecting the constructed perspectives that are most likely to answer the user&#8217;s question.



These are kept and expanded in the next iteration, while less promising paths are discarded. This process, shown in Figure 1, avoids the need to generate and evaluate thousands of possible movement sequences by focusing only on the most informative perspectives.



Figure 1. Given a spatial reasoning query, MindJourney searches through the imagined 3D space using a world model and improves the VLM&#8217;s spatial interpretation through generated observations when encountering new challenges.&nbsp;



&nbsp;



To make its search through¬†a simulated¬†space both effective and efficient,¬†MindJourney¬†uses a spatial beam search‚Äîan¬†algorithm that prioritizes the most promising paths. It works within a fixed number of steps, each representing a movement. By balancing breadth with depth, spatial beam search enables¬†MindJourney¬†to gather strong supporting evidence.¬†This process is illustrated in Figure 2.



Figure 2. The MindJourney workflow starts with a spatial beam search for a set number of steps before answering the query. The world model interactively generates new observations, while a VLM interprets the generated images, guiding the search throughout the process.



By iterating through¬†simulation,¬†evaluation, and integration,¬†MindJourney¬†can reason about spatial relationships far beyond what any single 2D image can convey, all without the need for additional training.¬†On¬†the¬†Spatial Aptitude Training (SAT)¬†benchmark,¬†it improved the accuracy of¬†VLMs¬†by¬†8%¬†over¬†their¬†baseline¬†performance.



	
		

	
	
						
				
					
				
			
			
			

									Azure AI Foundry Labs
				
								Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.
				
								
					
						
							Azure AI Foundry						
					
				
							
	
Opens in a new tab	
	








Building&nbsp;smarter agents&nbsp;&nbsp;



MindJourney&nbsp;showed&nbsp;strong performance&nbsp;on multiple 3D spatial-reasoning benchmarks, and even advanced VLMs&nbsp;improved&nbsp;when paired with its imagination loop. This suggests that the spatial patterns that world models learn from raw images, combined with the symbolic&nbsp;capabilities&nbsp;of VLMs, create a more complete spatial capability&nbsp;for agents. Together, they enable agents to infer what lies beyond the visible frame and&nbsp;interpret&nbsp;the physical world&nbsp;more accurately.&nbsp;



It also demonstrates that pretrained VLMs and trainable world models can work together in 3D without retraining either one‚Äîpointing toward general-purpose agents capable of¬†interpreting¬†and acting in real-world environments. This opens the way to¬†possible¬†applications in autonomous robotics, smart home technologies, and accessibility tools for people with visual impairments.¬†



By converting systems that simply describe static images into active agents that continually evaluate where to look next,&nbsp;MindJourney&nbsp;connects computer vision with planning. Because exploration occurs entirely within the model‚Äôs latent space‚Äîits internal representation of the scene‚Äîrobots would be able to test multiple viewpoints before determining their next move,&nbsp;potentially&nbsp;reducing wear, energy use, and collision risk.&nbsp;



Looking ahead, we plan to extend the framework to&nbsp;use&nbsp;world models that&nbsp;not only&nbsp;predict&nbsp;new viewpoints&nbsp;but also forecast&nbsp;how the scene might change over time.&nbsp;We envision&nbsp;MindJourney&nbsp;working&nbsp;alongside VLMs that interpret&nbsp;those predictions&nbsp;and use&nbsp;them to&nbsp;plan&nbsp;what to do&nbsp;next. This&nbsp;enhancement could enable&nbsp;agents&nbsp;more accurately&nbsp;interpret&nbsp;spatial relationships and physical dynamics, helping them to operate effectively&nbsp;in changing environments.
Opens in a new tabThe post MindJourney enables AI to explore simulated 3D worlds to improve spatial interpretation appeared first on Microsoft Research.
‚Ä¢ Create personalized products and marketing campaigns using Amazon Nova in Amazon Bedrock
  This post was written with Jake Friedman from Wildlife. 
Businesses are seeking innovative ways to differentiate themselves through hyper-personalization and enhanced customer experiences. At the Cannes Lions International Festival of Creativity 2025, AWS showcased The Fragrance Lab, an interactive and inspiring experience that demonstrates how generative AI can support the development of hyper-personalized consumer goods and accelerate advertising creative concept and campaign assets development. Following Cannes Lions 2025, The Fragrance Lab received a Gold and Silver Stevie Award from the International Business Awards in the Brand &amp; Experiences category. 
Built using Amazon Nova in Amazon Bedrock, The&nbsp;Fragrance Lab represents a comprehensive end-to-end application that illustrates the transformative power of generative AI in retail, consumer goods, advertising, and marketing. While our activation at Cannes Lions focused on personalized fragrance development and ad campaign creation, the underlying architecture and methodology can be adapted across diverse categories, from fashion to food and beverage, opening endless possibilities for customized customer experiences. 
Introducing The Fragrance Lab 
In this post, we explore the development of The Fragrance Lab. Our vision was to craft a unique blend of physical and digital experiences that would celebrate creativity, advertising, and consumer goods while capturing the spirit of the French Riviera. To bring this vision to life, we collaborated with Wildlife, a company that is exceptional at transforming AWS generative AI services into compelling physical experiences. Wildlife was fundamental in&nbsp;brainstorming ideas that would inspire customers and showcase novel use cases that AI makes possible. 

 
  
 
 
Crafting the fragrance 
As the first step, the experience used Amazon Nova Sonic, a speech-to-speech model that engages in intuitive dialogues with attendees to understand their personality and preferences. Nova Sonic extends its capabilities through tool integration, allowing it to manage user traits and interface actions through specialized tools such as addTraitTool, removeTraitTool, and uiActionIntentTool. These tools help maintain conversation state and a consistent flow throughout the experience. The collected conversation data and trait information are then processed through a custom Retrieval Augmented Generation (RAG) system built with Amazon Nova Pro, a highly capable multimodal model that offers our best combination of accuracy, speed, and cost. Nova Pro serves as the intelligence engine for analyzing interactions and extracting essential keywords to determine the perfect fragrance notes and composition. The application also used Amazon Bedrock Guardrails, which offers customizable safeguards and responsible AI policies to block undesirable topics‚Äîsuch as allergens or harmful content‚Äîto offer a seamless customer experience. 
For example, a customer might share with Nova Sonic that they are interested in travel. Nova Pro picked up that exploring new places often ‚Äúbrings a sense of freshness and excitement,‚Äù which resulted in a fragrance that feels fresh and invigorating, featuring ‚Äúa burst of citrus or a floral breeze.‚Äù The customer might also share that they enjoy early morning walks across spring fields, which Nova Pro translates into a top note of fresh bergamot, a middle note featuring floral honey, and a base of lavender.&nbsp;The customers‚Äô inputs guide the selection of fragrance notes‚Äîfrom base, to heart, to top notes‚Äîwhich were then expertly mixed by on-site perfumers to create truly personalized scents. Perfumers were able to customize and craft hundreds of unique fragrances per day, aided by AI. A process that would normally take hours for a perfumer was accelerated to minutes, empowering both the customer and the fragrance expert. 
 
Creating the campaign 
After the personalized fragrance formula was created and sent to the perfumer queue, Amazon Nova Canvas generated customized marketing creative, including the fragrance name, tagline, and imagery that captured the essence of the formula. Attendees were able to further customize the campaign assets using guest inputs such as moody, beachy, or playful. The resulting fragrance image was then transformed into dynamic video content through Amazon Nova Reel, which customers could further customize to meet their creative vision and download to save or share. To match the Cannes Lions atmosphere, the campaign videos were generated with a French-accented female voice using Amazon Polly.&nbsp;The entire experience is built in Amazon Bedrock, a fully managed service to build and scale generative AI applications with AI models. 
The following data flow diagram shows how multiple Amazon Nova models can be combined for a rich, cohesive, and personalized customer experience. 
 
Best practices for implementation 
The Fragrance Lab centers around interactions with Amazon Nova Sonic, providing users with a natural language interface to express their preferences for a custom scent. Through its tool integration capabilities, Nova Sonic orchestrates the entire experience by managing user traits and triggering appropriate workflows. These workflows seamlessly guide the experience from initial conversation to fragrance development and ultimately to campaign asset creation, driving both the visual elements and progression of the experience. The model‚Äôs ability to maintain a conversational state, while defining clear conversational flows, helps ensure a consistent and pleasant experience for every user. 
A well-defined workflow and conversational assistant are pivotal in guiding these conversations to uncover the qualities that are most important to each user. And the system prompt determines the personality, style, and content of your conversational assistant. 
Prompt example: 
 
 You are an AI assistant designed to help the user explore their personality and 
emotional landscape in the context of creating a unique fragrance. You engage in warm, 
free-flowing, playful conversation with the user to draw out their character, 
preferences, moods, and desires. Your end goal is to derive a set of 3 to 5 personality 
traits that best describe the user. These traits will later be used in a separate 
process to match appropriate fragrance ingredients. Your tone is warm, chic, and subtly 
playful. 
 
Additional contextual information within the prompt also plays a key role in Amazon Nova Sonic effectively maintaining state, while defining the conversational flow helps ensure consistent, pleasant, and concise experiences for every user. 
Prompt example: 
 
 1. **Welcoming Users**
    Welcome the user to the application experience with a brief overview of the
    process and ask if they are ready to continue.
2. **Assistant Turns** 
    Ask short and unique open ended questions to the user and choose a personality trait 
    that you think would suit the user best.
3. **Handling User Turns**
    Acknowledge the user's answers briefly and warmly.
    Focus on one trait per turn.
    Call the "addTraitTool", "removeTraitTool", "replaceTraitTool", or "clearTraitsTool" 
    tools to manage traits.
    If the user says to go back, skip, customize, or confirm/submit it means you should 
    call the "uiActionIntentTool"  
 
With direct references to our tools in the conversational flow, the user interface feels reactive and connected to the user‚Äôs input while providing opportunities for the assistant to demonstrate its expertise on this subject, which comes into the spotlight when user traits and preferences are later mapped to a set of available ingredients and raw fragrance materials. 
This complex fragrance recipe development is handled by Nova Pro, using its accuracy and speed to generate consistently high-quality scents. To draw from a wealth of fragrance knowledge in real time, RAG was implemented to extend Nova Pro capabilities beyond pre-trained knowledge with access to knowledge sources that include essential scent design principles, a deep understanding of each available ingredient, their profiles and potential roles within the fragrance, and their possible connections to users‚Äô aromatic identities. 
The resulting fragrances are then visualized using Nova Canvas and Nova Reel. The creative models generate original compositions that reveal the fragrance name, ingredients, and a visual identity within a high-end creative campaign asset. A set of conditioning images featuring unbranded fragrance bottles help to anchor each image (as shown in the following image). 
 
Prompt example: 
 
 A high-end fragrance ad environment inspired by a [persona description]. A clear, 
unbranded perfume bottle is visually centered and tightly framed. Key ingredients [top 
note ingredient], [middle note ingredient], [base note ingredient], and [booster 
ingredient] are arranged to surround the bottle in a balanced composition, appearing 
behind, besides, and partially in front of the base. The scene evokes [atmospheric/mood 
descriptors] using [light/color language]. The setting should feel [stylistic direction],
like a [reference style (e.g., fashion editorial, lifestyle spread, luxury campaign)]. 
 
Results 
Attendees at Cannes Lions took away a physical fragrance mixed by&nbsp;on-site perfumers. While developing hyper-personalized consumer goods might not be scalable across all use cases, brands can innovate with artificial intelligence and achieve manufacturing outcomes that weren‚Äôt previously possible. The advertising campaign concept and asset development use case is easy to implement for brands, agencies, and media networks, allowing users to iterate and optimize campaign creative quickly.&nbsp;Using Amazon Bedrock, additional features could be added like translations and sizes, depending on requirements. 
You can watch a video walk through of The Fragrance Lab onsite at Cannes Lions 2025, and check out the following example campaign outputs. 
 
Conclusion 
The Fragrance Lab demonstrates the power of Amazon Nova in Amazon Bedrock and how customers can create fully personalized consumer experiences. This use case can be replicated across various retail and consumer goods categories including skincare and cosmetics, fashion and accessories, food and beverage, home goods, and wellness products‚Äîall benefiting from natural conversation interaction, AI-powered product development, product identity, and creative marketing campaign generation. Get started with Amazon Nova in Amazon Bedrock today. 
 
About the authors 
Raechel Frick&nbsp;is a Sr Product Marketing Manager at AWS. With over 20 years of experience in the tech industry, she brings a customer-first approach and growth mindset to building integrated marketing programs. Based in the greater Seattle area, Raechel balances her professional life with being a soccer mom and after-school carpool manager, demonstrating her ability to excel both in the corporate world and family life. 
Gaby Ferreres is the Head of Industry Marketing for Media &amp; Entertainment, Sports, Games, Advertising &amp; Marketing at AWS, where she works with technology and industry leaders to accelerate innovation on behalf of customers. She is a global marketing leader and creator of experiences that elevate customer journeys. Before AWS, she held different positions at Microsoft, Telefonica, and more. 
Ashley Weston is Sr. Marketing Event Manager for Global Third-Party Programs at AWS, where she partners with industry marketing to deliver the highest visibility and most business-critical events for AWS. 
Tiffany Pfremmer is Sr. Industry Marketing Manager at Amazon Web Services (AWS) where she leads strategic integrated marketing initiatives across the Media &amp; Entertainment, Games, and Sports verticals to deliver marketing campaigns that connect AWS cloud solutions with customer opportunities. 
Jake Friedman is the President and Co-founder at Wildlife, where he leads a team launching interactive experiences and content campaigns for global brands. His work has been recognized with the Titanium Grand Prix at the Cannes Lions International Festival of Creativity for ‚Äúboundary-busting, envy-inspiring work that marks a new direction for the industry and moves it forward‚Äù. You can find him on LinkedIn. 
 
About Wildlife 
Wildlife fuses a digitally born skillset with a future proof mindset to deliver breakthrough products, experiences and campaigns for daring partners. We live by a motto: Technology changes, story doesn‚Äôt.
‚Ä¢ Tyson Foods elevates customer search experience with an AI-powered conversational assistant
  Tyson Foodservice operates as a critical division within Tyson Foods Inc., using its extensive protein production capabilities to supply a diverse array of foodservice clients across multiple sectors. As one of the largest protein providers in the US, Tyson Foods produces approximately 20% of the nation‚Äôs beef, pork, and chicken, which forms the foundation of its foodservice offerings. 
Tyson Foodservice operates through a B2B model, selling products to distributors rather than directly to end consumers, while serving diverse foodservice operators, including restaurants, schools, healthcare facilities, and convenience stores. Until recently, Tyson had limited direct engagement with over 1 million unattended operators who purchased their products through distributors without direct company relationships. To bridge this gap, Tyson has implemented a generative AI assistant on their website, enabling them to scale sales efforts, gather customer insights, and establish direct communication channels. The company‚Äôs website now functions as a critical interface where operators can explore products, access menu trends, and discover tailored solutions for their specific foodservice segments, all enhanced by AI-driven personalization that better serves both established customers and previously unattended operators. 
In this post, we explore how Tyson Foods collaborated with the AWS Generative AI Innovation Center to revolutionize their customer interaction through an intuitive AI assistant integrated into their website. The AI assistant was built using Amazon Bedrock, a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon through a single API, along with a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. 
 
Solution overview 
In this section, we describe the overall architecture of the solution. The workflow includes the following high-level steps: 
 
 A user uses the search bar in https://www.tysonfoodservice.com/. The query string is converted to embeddings using Amazon Bedrock and the Amazon Titan Text Embeddings model. The search application performs a k-nearest neighbors (k-NN) vector search to find relevant results in Amazon OpenSearch Serverless and return those results to the website. The search application is deployed in Amazon Elastic Container Service (Amazon ECS) using AWS Fargate as the capacity provider and exposed as a REST API using an Application Load Balancer protected by AWS WAF. 
 The user uses the AI assistant interface to ask questions in natural language. The query is processed by the agent node using Anthropic‚Äôs Claude 3.5 Sonnet on Amazon Bedrock. Depending on the subject of the query, the agent might orchestrate multiple agents to return relevant information to the user. The application is deployed using a similar architecture to the semantic search component with the addition of an Amazon Relational Database Service (Amazon RDS) database cluster to persist the user high-value actions for analytics purposes. 
 Products, recipes, ingredients and other relevant data are available from external sources in JSON format. These are processed using Amazon Bedrock and the Amazon Titan Text Embeddings model to create semantic search embeddings. Then these are ingested into OpenSearch Serverless. The ingestion process run in a different ECS cluster using Fargate as the capacity provider. 
 
The following diagram illustrates this architecture. 
 
In the following sections, we discuss the solution‚Äôs key components and benefits in more detail. 
Improved semantic search 
The earlier iteration of search on the Tyson Foodservice website relied on keyword-based search. Traditional keyword-based search on CPG websites like Tyson Foodservice often falters when customers search for products using industry terminology that varies from official catalog descriptions. Chefs searching for ‚Äúpulled chicken‚Äù might miss relevant products labeled as ‚Äúshredded chicken,‚Äù or those looking for ‚Äúwings‚Äù might not see results for ‚Äúparty wings‚Äù or ‚Äúdrummettes.‚Äù This disconnect frustrates food service professionals who need specific ingredients under tight deadlines and ultimately drives them to competitors where they can more quickly find what they need, resulting in lost revenue opportunities for Tyson. Semantic search transforms this experience by understanding the conceptual relationships between culinary terms, preparation methods, and product applications. A chef searching for ‚Äúbuffalo-style appetizers‚Äù would receive results for wings, boneless bites, and similar products regardless of exact keyword matches. By recognizing menu trends, cooking techniques, and professional kitchen terminology, semantic search helps foodservice operators quickly find the Tyson products that meet their exact operational needs, even when using language that differs from catalog descriptions. 
Tyson Foodservice implemented their semantic search capability using OpenSearch Serverless, a fully managed service that minimized the operational complexity of maintaining search infrastructure. This solution automatically scales compute and storage resources to match query volume and product catalog size without requiring dedicated administrative overhead. The serverless architecture helped Tyson rapidly deploy advanced natural language processing capabilities across their entire product database while maintaining cost-efficiency, because they only pay for the resources they actually use. With OpenSearch Serverless, Tyson incorporated vector embeddings and powerful query capabilities that understand foodservice terminology variations, preparation methods, and culinary applications, transforming how operators discover products that meet their specific needs even when their search terms don‚Äôt exactly match catalog descriptions. 
For indexing Tyson‚Äôs diverse content library of products, recipes, and articles, we implemented a preprocessing workflow that transforms raw metadata into optimized semantic search queries. We used large language models (LLMs) to analyze and extract only the most relevant elements from each content piece, creating meaningful search strings specifically designed for semantic indexing. This approach made sure that purely presentational website copy and non-essential informational text were filtered out, and search-critical elements like culinary applications, preparation methods, and ingredient specifications received proper emphasis in the index. By curating what content gets indexed rather than including everything verbatim, we dramatically improved search relevance while reducing index bloat, so OpenSearch Serverless delivered more precise results that truly match the intent behind chef and operator queries. For indexing the text as semantic vectors, we used Amazon Titan Text Embeddings V2 on Amazon Bedrock. 
The following example prompt illustrates the transformation using only the title, description, and reasons to buy metadata. This generic strategy can be customized according to the customer‚Äôs specific needs. 
 
 SEARCH_STRING_PROMPT = """ Given a product title, description, and reasons to
buy, create a single, concise search string suitable for indexing in a vector
database. This string should focus on distinguishing features, assuming all
products are for foodservice operators unless explicitly stated otherwise.
Enclose the generated search string within &lt;search_string&gt; XML tags. 

Follow these guidelines:
1. Start with the brand name and product line (if applicable).
2. Include the main product type and specific identifying features.
3. List concrete attributes such as preparation state, packaging, or quantity.
4. Mention specific varieties or assortments included in the product.
5. Incorporate key points from the reasons to buy, focusing on unique and
   specific selling points.
6. Avoid generic terms or those common to all products in the category (e.g.,
   "food service", "restaurant", "operator").
7. Omit clich√© marketing terms (e.g., "versatile", "high-quality", "innovative")
   unless they have a specific, demonstrable meaning in the context of the
   product.
8. Use precise descriptors that differentiate the product from others in its
   category.
9. Omit articles (a, an, the) and unnecessary connecting words.
10. Use lowercase for all terms except proper nouns.
11. Separate terms with single spaces.
12. Aim for a length of 15-20 words.
13. Prioritize terms that potential buyers are most likely to use in specific
    search queries.
    
Example input:
&lt;title&gt;Tyson¬Æ Heritage Valley‚Ñ¢ IF Unbreaded 8 Piece Cut Chicken&lt;/title&gt;
&lt;description&gt;Order a variety of crispy, seasoned chicken cuts with 
Heritage Valley‚Ñ¢ Uncooked, Ice Glazed 8 Piece Cut Chicken. Featuring an 
assortment of breasts, drumsticks, thighs and wings, our chicken portions 
are completely customizable and perfect for center-of-plate features. 
Separately packaged for quick and easy preparation and portion control, 
our packaging helps your staff reduce waste by allowing them to use what 
they need, when they need. Ready to cook from frozen, simply fry and 
serve as an assortment for a buffet protein choice.
&lt;/description&gt;
&lt;reasons_to_buy&gt;
['Bone-in assortment of breasts, drumsticks, thighs and wings.', 
'Individually quick frozen, locking in natural juices and tenderness.', 
'Different cuts separately bagged for quick and easy preparation and cleanup.', 
'Ready to cook from frozen.']
&lt;/reasons_to_buy&gt;

Example output: &lt;search_string&gt;tyson heritage valley unbreaded raw 8-piece
chicken bone-in breasts drumsticks thighs wings individually-frozen
separate-bags cook-from-frozen juicy center-of-plate&lt;/search_string&gt;

Now, create a similar search string for the following product:
&lt;title&gt;{title}&lt;/title&gt;
&lt;description&gt;{description}&lt;/description&gt;
&lt;reasons_to_buy&gt;{reasons_to_buy}&lt;/reasons_to_buy&gt;
"""
 
 
Agentic chat built using Anthropic‚Äôs Claude 3.5 Sonnet on Amazon Bedrock and LangGraph 
Tyson Foodservice has integrated a powerful generative AI assistant into their website, using Anthropic‚Äôs Claude 3.5 Sonnet on Amazon Bedrock and LangGraph. This AI assistant delivers a seamless conversational search experience that offers comprehensive support across Tyson‚Äôs extensive range of products, recipes, and articles, providing contextual guidance through natural conversation. Its capabilities include: 
 
 Personalized search ‚Äì Uses semantic search to find relevant products, recipes, and articles. The AI assistant customizes recommendations by learning about the user‚Äôs business and role, creating a tailored experience while gathering valuable customer insights for Tyson. 
 Detailed product information ‚Äì Provides comprehensive details about specific Tyson products, including descriptions, ingredients, preparation methods, and suggested applications. 
 Distributor services ‚Äì Helps users locate nearby distributors and check product availability in their area. 
 Purchasing assistance ‚Äì Offers information on how to buy Tyson products and connects customers with sales representatives when needed. 
 Promotion awareness ‚Äì Keeps customers informed about current Tyson Foodservice promotions and special offers. 
 Feedback channel ‚Äì Provides a streamlined way for customers to submit product and service feedback directly to Tyson. 
 Natural conversational flow ‚Äì Maintains context throughout the interaction, allowing users to reference previous results and ask follow-up questions for a more human-like conversation experience. 
 
The following diagram illustrates the high-level architecture of the AI assistant. The system uses the tool calling capabilities of Anthropic‚Äôs Claude to implement the AI assistant‚Äôs agentic behavior. We used LangGraph to streamline the implementation process, because it provides several convenient primitives specifically designed for building agentic systems with LLMs. 
 
The main components of the architecture are: 
 
 Agent node ‚Äì The agent node is implemented using a large prompt that directly receives the user message and responds using the conversational capabilities of the LLM. It also defines the agentic behavior by using the tool calling capability: whenever serving the user‚Äôs request requires calling a tool, the agent node issues a tool request. 
 Tool execution node ‚Äì This node implements a generic tool executor that connects to various tools. Whenever a tool call is issued by the agent node, this node handles the execution of the tool call. The tool calling node executes the tools, which are defined as Python functions, and returns the results to the agent node to be transformed or summarized and presented to the user. LangGraph provides a generic implementation of the ToolNode that can also be extended to implement additional functionality. 
 Tools layer ‚Äì Tools are implemented as simple programmatic functions that take inputs and return outputs. These tools augment the capabilities of LLMs by performing functions like retrieving data or submitting feedback. The tools are stateless and agnostic to the current conversation between the user and agent. The LLM agent extracts the input parameters required to execute these tools. These tools in our implementation are a thin wrapper around the services and database layer that implement the actual functionality. 
 
The following system prompt provides a general guidance for implementing the agent node: 
import date

AGENT_SYSTEM_PROMPT = """
# Tyson Foodservice (TFS) Customer Support Assistant

## Core Role and Purpose
You are a helpful customer support assistant for Tyson Foodservice a.k.a TFS
hosted on their https://www.tysonfoodservice.com/ website.  You will be helpful
and answer the customers questions. The customers are mainly interested in
learning about the products for their specific needs.
Refrain from engaging in any conversation unrelated to tyson food search of
products, recipes or distributors. If the user asks any unrelated questions the
politely decline and mention your purpose. Do not provide and additional
information or advice.
 
Your job is to stay factual and only provide relevant information from the
current context or retrieved using the tools. Do not offer your own suggestions.
Customers are looking for concrete information that is available in the Tyson
Foodservice database.

## About Tyson Foodservice
Tyson Foods is a major American multinational corporation and one of the world's
largest processors and marketers of chicken, beef, and pork.

### Distributors
Tyson foods mainly sells their products through distributors and does not sell
them directly. Each distributor is identified by a unique identifier named
distributor_id which is used as parameters for the tools, do not use the
distributor name as query parameter.

### Foodservice Operators
Foodservice Operators, or simply Operators, are Tyson Foods' primary customers.
These encompass diverse businesses in the foodservice sector, each with unique
needs. Understanding the distinct personas of various Operator types is crucial
for Tyson Foods to:
- Tailor product offerings effectively
- Develop targeted marketing strategies
- Create relevant recipe suggestions
- Address specific operational challenges
By analyzing different Operator segments (e.g., quick-service restaurants, fine
dining, educational institutions, healthcare facilities), Tyson Foods can
customize its products, offer innovative menu solutions, and provide value-added
services. This approach positions Tyson Foods as a strategic partner, driving
growth and maintaining competitiveness in the foodservice industry.

## Using Tools
You will be provide a variety of tools to perform your job, use them wisely and
ask the customer for relevant information that they have not provided. E.g. if
the search tool requires persona and the customer has not provided it then ask
the customer.
- Do not explicitly declare the tools to the users as the users are not aware of
  the internal workings of the tools.
- Do not try to intrepret the results of the search tool and show them as it is
  to the user.
- Operators may have their preferred distributor they buy from so let them
  confirm or select their distributor before checking for availability of
  products.
- Customers might sometimes search for things that are not available in tyson
  food catalog. If the search did not produce any results then just inform the
  user and do not suggest any external sources.
- When trying to determine the parameters for a tool, do not infer them from
  other parameters. E.g. do not infer the User's name from their email.
  Explicitly ask for the name.
- If the users complain or praise the chatbot then you can ask for their
  feedback in the chatbot and use the `submit_feedback` tool to submit the
  feedback. Ask the user to provide the relevant contact information.

## Product, Recipes, and Articles Search
Search functionality is a critical tool on Tyson's website, allowing users to
find products, recipes, and articles. It enables searches across three main
entity types:
- **Products**: The core offerings of Tyson Foods. These are identified by a
  unique GTIN (Global Trade Item Number).
- **Recipes**: Culinary ideas provided by Tyson Foods to encourage product use.
  Each recipe incorporates one or more Tyson products.
- **Articles**: Informative content on various topics, created by Tyson Foods
  for their customers.
- Do not provide any items or suggestions outside of the ones that are found
  through search.
- When the user asks to for details or a product or compare two or more
  products, retrieve the details of the products first using the tools to get
  product details.
- While users of the site are mainly looking for products, they might also be
interested in recipes and articles so it's important to not omit them when
displaying the search results.

### User Profile or Persona
In order to serve the user's better, the search tool can accept the user's
persona as an input. User profile or persona is a concise description of the
type of role that a user performs in the foodservice industry. A few examples
of persona are
- Restaurant owners looking to optimize costs
- Chef looking for unique ingredients
- K12 operators looking for healthy menu items
They can also be simple roles if the user has not provided any additional
information. Examples are
- Restaurant owner
- Chef
- Hotel Manager
The user persona should not include the search query that they are using for
finding products E.g. these are not good personas
- Restaurant owner looking for chicken nuggets
The above is not a good persona because it includes the product

### Search query string
Search queries should be simple and specific to the products or recipes and
should not contain the operator information
Here are some examples: 
- Instead of "healthy chicken wings for K12" use "chicken wings"
- Instead of "mexican beef patties for Deli operation" use "mexican beef
  patties"

### Product Results Display 
When listing the product results, always display them in the following format as
a numbered list. This will be displayed in the UI using markdown. 
1. **Title**
- GTIN
- description - This is a brief description
- [Product Page](Product url link)

### Recipes Results Display
When displaying recipes. Display the following
1. **Title**
- description - This is a brief description
- [Recipe Page](Recipe url link)

## Contact or provide feedback
- If the users want to reach out to Tyson foods team then they can use the form
  using this link [Contact
  Us](https://www.tysonfoodservice.com/connect/contact-us) 
- Users can submit their feedback using the chatbot using tools. When submitting
  feedback to Tyson extract user's message verbatim and do not rephrase it.

## How to buy
If the user wants to buy a product then they have two options. 
1. through distributor (preferred option)
2. reaching out to tysons sales representative by filling a form
If the user has not already indicated their preference then present these two
options. 
When the user asks for ordering information you do not need to retrieve all the
product details again, only specify the title of the product and be concise with
the details.

### Order through distributor
If they user is interested in buying through a distributor then let them
identify their preferred distributor and then for a specific product or products
they have identified provide the ordering link obtained through the user of
appropriate tool. Also help them check if a product is available with their
distributor.

### Find a tyson Sales Rep
If the user is not interested in a purchasing through a distributor then direct
them to submit a form through this link which will submit their information to a
sales team and someone will reach out to them. Here is the link to the form
https://www.tysonfoodservice.com/connect/find-a-sales-rep 

Current date (YYYY-MM-DD): """ + date.today().strftime("%Y-%m-%d") + "\n" 
 
Capturing high-value actions: Turning conversations into insights 
In designing Tyson Foodservice‚Äôs AI assistant, we implemented an innovative solution for capturing high-value actions that transforms customer interactions into strategic business intelligence. This capability provides deeper contextual understanding of customer interests and needs than traditional web analytics. Whereas conventional analytics tools track user behavior through page views, clicks, and time-on-site metrics, our solution uses the rich conversational data generated through natural dialogue. This provides Tyson with unprecedented visibility into customer interests, pain points, and purchase intentions. 
The system identifies and logs specific high-value interactions whenever users request detailed product information, inquire about specific product categories, ask about preparation methods or recipe ideas, seek distributor information in their region, or express interest in bulk purchasing or promotions. This approach creates a powerful feedback loop for Tyson Foodservice. As customers naturally express their needs and interests through conversation, the system captures these signals in an aggregate, privacy-respecting manner. Tyson can use these insights to identify trending product categories and potential gaps in their portfolio, understand regional variations in customer interests, recognize seasonal patterns in product inquiries, refine marketing strategies based on direct customer language, and improve inventory management through better demand forecasting. The technical implementation uses the tool-calling capabilities of Anthropic‚Äôs Claude 3.5 Sonnet in a straightforward but effective way. Rather than analyzing chat logs after the fact, we integrated the capture mechanism directly into the AI assistant‚Äôs operational workflow through LangGraph, allowing for real-time insight collection during customer interactions. When the LLM invokes certain tools to retrieve information requested by users, these tool calls simultaneously trigger the capture of high-value action data. We‚Äôve designed a configurable system where specific tools are designated as high-value action triggers that record meaningful interactions while fulfilling the user‚Äôs immediate request.This dual-purpose approach makes sure that valuable business intelligence is gathered as a natural byproduct of providing excellent customer service, without requiring additional processing or analysis steps. The system includes configurable parameters that allow Tyson to adjust which user intents and actions qualify as high value based on evolving business priorities. By transforming every customer conversation into structured, actionable data, Tyson Foodservice can now measure customer interest with unprecedented precision while delivering a superior search experience that feels natural to users. 
Conclusion 
In this post, we demonstrated a powerful approach to implementing natural conversational AI assistants that seamlessly integrate with existing website functionalities and provide intuitive language interactions for users. By using Amazon Bedrock FMs and OpenSearch Serverless, businesses can quickly expose their website‚Äôs capabilities through conversation rather than complex interfaces. The high-value action capture mechanism further enhances this solution by gathering valuable customer insights directly from natural interactions, creating a rich source of business intelligence without additional user friction. This framework provides a flexible blueprint for implementing AI-powered assistants across retail and CPG websites. Organizations can adapt this approach to their specific needs, such as product discovery, customer support, or personalized recommendations. The combination of semantic search with conversational AI creates experiences that understand user intent while maintaining the context necessary for natural dialogue. 
If you‚Äôre interested in building a similar AI assistant that orchestrates multiple tools, you can get started with Amazon Bedrock Agents, a fully managed AWS solution designed specifically for this purpose. Amazon Bedrock Agents simplifies the process of creating, testing, and deploying conversational experiences that can execute complex tasks across your business systems. With the right architecture and implementation approach demonstrated in this post, you can develop AI-powered interactions that deliver measurable business value while significantly enhancing your customer journey. 
For developers exploring AI agent frameworks today, AWS recently introduced Strands Agents, an open source SDK that takes a model-driven approach to building agents with just a model, tools, and a prompt. Unlike workflow-based frameworks, Strands adopts a model-first philosophy that uses advanced reasoning capabilities, offering an interesting alternative approach to frameworks like LangGraph. 
Try out these solutions for your own use case, and share your feedback in the comments. 
 
About the authors 
 Anveshi Charuvaka is a Senior Applied Scientist at AWS‚Äôs Generative AI Innovation Center, where he partners with customers to turn Generative AI into solutions for mission-critical business problems. He holds a PhD in Machine Learning and brings over 10 years of experience applying innovative ML and GenAI techniques to complex, real-world challenges. 
Barret Miller leads the Digital Enterprise Organization at Tyson Foods, where he spearheads progress in emerging technologies, artificial intelligence, and Smart Office initiatives. With more than 17 years of expertise in software development, data, analytics, and AI, Barret excels at leveraging innovative technology paradigms, including Agentic AI, to tackle and enhance complex business processes. 
 Vincil Bishop is a Senior Deep Learning Architect in the Generative AI Innovation Center. Vincil has 25 years of experience in the IT industry and holds a PhD in Systems Engineering from Colorado State University. Vincil specializes in the design and implementation of AI solutions that help solve customers‚Äô toughest business challenges. 
 Tesfagabir Meharizghi is an Applied Scientist at the AWS Generative AI Innovation Center, where he leads projects and collaborates with enterprise customers across various industries to leverage cutting-edge generative AI technologies in solving complex business challenges. He specializes in identifying and prioritizing high-impact use cases, developing scalable AI solutions, and fostering knowledge-sharing partnerships with stakeholders. 
&nbsp; Tanay Chowdhury is a Data Scientist at Generative AI Innovation Center at Amazon Web Services who helps customers solve their business problems using generative AI and machine learning. He has done MS with Thesis in Machine Learning from University of Illinois and has extensive experience in solving customer problem in the field of data science. 
 Angel Goni is a Principal Solutions Architect at AWS with 15+ years of IT experience across the Financial Services, Retail, and Consumer Packaged Goods sectors. Angel specializes in utilizing cloud technology to impact business KPIs, with particular expertise in multicloud strategies, SAP migrations, and supply chain improvement.
‚Ä¢ Enhance AI agents using predictive ML models with Amazon SageMaker AI and Model Context Protocol (MCP)
  Machine learning (ML) has evolved from an experimental phase to becoming an integral part of business operations. Organizations now actively deploy ML models for precise sales forecasting, customer segmentation, and churn prediction. While traditional ML continues to transform business processes, generative AI has emerged as a revolutionary force, introducing powerful and accessible tools that reshape customer experiences. 
Despite generative AI‚Äôs prominence, traditional ML solutions remain essential for specific predictive tasks. Sales forecasting, which depends on historical data and trend analysis, is most effectively handled by established ML algorithms including random forests, gradient boosting machines (like XGBoost), autoregressive integrated moving average (ARIMA) models, long short-term memory (LSTM) networks, and linear regression techniques. Traditional ML models, such as K-means and hierarchical clustering, also excel in customer segmentation and churn prediction applications. Although generative AI demonstrates exceptional capabilities in creative tasks such as content generation, product design, and personalized customer interactions, traditional ML models maintain their superiority in data-driven predictions. Organizations can achieve optimal results by using both approaches together, creating solutions that deliver accurate predictions while maintaining cost efficiency. 
To achieve this, we showcase in this post how customers can expand AI agents‚Äô capabilities by integrating predictive ML models and Model Context Protocol (MCP)‚Äîan open protocol that standardizes how applications provide context to large language models (LLMs)‚Äîon Amazon SageMaker AI. We demonstrate a comprehensive workflow that enables AI agents to make data-driven business decisions by using ML models hosted SageMaker. Through the use of Strands Agents SDK‚Äîan open source SDK that takes a model-driven approach to building and running AI agents in only a few lines of code‚Äîand flexible integration options, including direct endpoint access and MCP, we show you how to build intelligent, scalable AI applications that combine the power of conversational AI with predictive analytics. 
Solution overview 
This solution enhances AI agents by having ML models deployed on Amazon SageMaker AI endpoints integrate with AI Agents, to enable them to make data-driven business decisions through ML predictions. An AI agent is an LLM-powered application that uses an LLM as its core ‚Äúbrain‚Äù to autonomously observe its environment, plan actions, and execute tasks with minimal human input. It integrates reasoning, memory, and tool use to perform complex, multistep problem-solving by dynamically creating and revising plans, interacting with external systems, and learning from past interactions to optimize outcomes over time. This enables AI agents to go beyond simple text generation, acting as independent entities capable of decision-making and goal-directed actions in diverse real-world and enterprise scenarios.For this solution, the AI agent is developed using the Strands Agents SDK, which allows for rapid development from simple assistants to complex workflows. Predictive ML models are hosted on Amazon SageMaker AI and will be used as tools by the AI agent. This can happen in two ways: agents can directly invoke SageMaker endpoints for more direct access to model inference capabilities or use the MCP protocol to facilitate the interaction between AI agents and the ML models. Both options are valid: direct tool invocation doesn‚Äôt require additional infrastructure by embedding the tool calling directly in the agent code itself, whereas MCP enables dynamic discovery of the tools and decoupling of agent and tool execution through the introduction of an additional architectural component, the MCP server itself. For scalable and secure implementation of the tool calling logic, we recommend the MCP approach. Although we‚Äôre recommending MCP, we discuss and implement the direct endpoint access as well, to give readers the freedom to choose the approach that they prefer. 
Amazon SageMaker AI offers two methods to host multiple models behind a single endpoint: inference components and multi-model endpoints. This consolidated hosting approach enables efficient deployment of multiple models in one environment, which optimizes computing resources and minimizes response times for model predictions. For demonstration purposes, this post deploys only one model on one endpoint. If you want to learn more about inference components, refer to the Amazon SageMaker AI documentation Shared resource utilization with multiple models. To learn more about multi-model endpoints, refer to the Amazon SageMaker AI documentation Multi-model endpoints. 
Architecture 
In this post, we define a workflow for empowering AI agents to make data-driven business decisions by invoking predictive ML models using Amazon SageMaker AI. The process begins with a user interacting through an interface, such as a chat-based assistant or application. This input is managed by an AI agent developed using the open source Strands Agents SDK. Strands Agents adopts a model-driven approach, which means developers define agents with only a prompt and a list of tools, facilitating rapid development from simple assistants to complex autonomous workflows. 
When the agent is prompted with a request that requires a prediction (for example, ‚Äúwhat will be the sales for H2 2025?‚Äù), the LLM powering the agent decided to interact with the Amazon SageMaker AI endpoint hosting the ML model. This can happen in two ways: directly using the endpoint as a custom tool of the Strands Agents Python SDK or by calling the tool through MCP. With MCP, the client application can discover the tools exposed by the MCP server, obtain the list of required parameters, and format the request to the Amazon SageMaker inference endpoint. Alternatively, agents can directly invoke SageMaker endpoints using tool annotations (such as @tool), bypassing the MCP server for more direct access to model inference capabilities. 
Finally, the prediction generated by the SageMaker hosted model is routed back through the agent and ultimately delivered to the user interface, enabling real-time, intelligent responses. 
The following diagram illustrates this process. The complete code for this solution is available on GitHub. 
 
Prerequisites 
To get started with this solution, make sure you have: 
 
 An AWS account that will contain all your AWS resources. 
 An AWS Identity and Access Management (IAM) role to access SageMaker AI. To learn more about how IAM works with SageMaker AI, refer to AWS Identity and Access Management for Amazon SageMaker AI. 
 Access to Amazon SageMaker Studio and a SageMaker AI notebook instance or an interactive development environment (IDE) such as PyCharm or Visual Studio Code. We recommend using SageMaker Studio for straightforward deployment and inference. 
 Access to accelerated instances (GPUs) for hosting the LLMs. 
 
Solution implementation 
In this solution, we implement a complete workflow that demonstrates how to use ML models deployed on Amazon SageMaker AI as specialized tools for AI agents. This approach enables agents to access and use ML capabilities for enhanced decision-making without requiring deep ML expertise. We play the role of a data scientist tasked with building an agent that can predict demand for one product. To achieve this, we train a time-series forecasting model, deploy it, and expose it to an AI agent. 
The first phase involves training a model using Amazon SageMaker AI. This begins with preparing training data by generating synthetic time series data that incorporates trend, seasonality, and noise components to simulate realistic demand patterns. Following data preparation, feature engineering is performed to extract relevant features from the time series data, including temporal features such as day of week, month, and quarter to effectively capture seasonality patterns. In our example, we train an XGBoost model using the XGBoost container available as 1P container in Amazon SageMaker AI to create a regression model capable of predicting future demand values based on historical patterns. Although we use XGBoost for this example because it‚Äôs a well-known model used in many use cases, you can use your preferred container and model, according to the problem you‚Äôre trying to solve. For the sake of this post, we won‚Äôt detail an end-to-end example of training a model using XGBoost. To learn more about this, we suggest checking out the documentation Use XGBoost with the SageMaker Python SDK. Use the following code: 
 
 from&nbsp;sagemaker.xgboost.estimator import&nbsp;XGBoost

xgb_estimator = XGBoost(...)
xgb_estimator.fit({'train': train_s3_path, 'validation': val_s3_path}) 
 
Then, the trained model is packaged and deployed to a SageMaker AI endpoint, making it accessible for real-time inference through API calls: 
 
 predictor = xgb_estimator.deploy(
 &nbsp; &nbsp;initial_instance_count=1,
 &nbsp; &nbsp;instance_type=instance_type,
 &nbsp; &nbsp;serializer=JSONSerializer(),
 &nbsp; &nbsp;deserializer=JSONDeserializer()
) 
 
After the model is deployed and ready for inferences, you need to learn how to invoke the endpoint. To invoke the endpoint, write a function like this: 
 
 ENDPOINT_NAME = "serverless-xgboost"
REGION = boto3.session.Session().region_name

def invoke_endpoint(payload: list):
&nbsp;&nbsp; &nbsp;"""
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Use the model deployed on the Amazon SageMaker AI endpoint to generate predictions.
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Args:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;payload: a list of lists containing the inputs to generate predictions from
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Returns:
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;predictions: an NumPy array of predictions
&nbsp;&nbsp; &nbsp;"""
&nbsp;&nbsp; &nbsp;sagemaker_runtime = boto3.client("sagemaker-runtime", region_name=REGION)
&nbsp;&nbsp; &nbsp;response = sagemaker_runtime.invoke_endpoint(
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;EndpointName=ENDPOINT_NAME,
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Body=json.dumps(payload),
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;ContentType="application/json",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Accept="application/json"
&nbsp;&nbsp; &nbsp;)
&nbsp;&nbsp; &nbsp;predictions = json.loads(response['Body'].read().decode("utf-8"))
&nbsp;&nbsp; &nbsp;return np.array(predictions) 
 
Note that the function invoke_endpoint() has been written with proper docstring. This is key to making sure that it can be used as a tool by LLMs because the description is what allows them to choose the right tool for the right task. YOu can turn this function into a Strands Agents tool thanks to the @tool decorator: 
 
 from&nbsp;strands import&nbsp;tool

@tool()
def&nbsp;invoke_endpoint(payload: list):
&nbsp; &nbsp; .... 
 
And to use it, pass it to a Strands agent: 
 
 from&nbsp;strands import&nbsp;Agent

agent = Agent(
&nbsp; &nbsp; model="us.amazon.nova-pro-v1:0", 
&nbsp;&nbsp;&nbsp;&nbsp;tools=[generate_prediction_with_sagemaker]
)

agent(
&nbsp;&nbsp; &nbsp;"Invoke the endpoint with this input:\n\n"
&nbsp;&nbsp; &nbsp;f"&lt;input&gt;{test_sample}&lt;/input&gt;\n\n"
&nbsp;&nbsp; &nbsp;"Provide the output in JSON format {'predictions':&lt;predictions&gt;}"
) 
 
As you run this code, you can confirm the output from the agent, which correctly identifies the need to call the tool and executes the function calling loop: 
 
 &lt;thinking&gt; To fulfill the User's request, I need to invoke the Amazon SageMaker 
endpoint with the provided input data. The input is a list of lists, which is the 
required format for the 'generate_prediction_with_sagemaker' tool. I will use this 
tool to get the predictions. &lt;/thinking&gt; 

Tool #1: generate_prediction_with_sagemaker The predictions from the Amazon SageMaker
endpoint are as follows: 
```json {&nbsp; "predictions": [89.8525238, 52.51485062, 58.35247421, 62.79786301, 85.51475525] } ``` 
 
As the agent receives the prediction result from the endpoint tool, it can then use this as an input for other processes. For example, the agent could write the code to create a plot based on these predictions and show it to the user in the conversational UX. It could send these values directly to business intelligence (BI) tools such as Amazon QuickSight or Tableau and automatically update enterprise resource planning (ERP) or customer relationship management (CRM) tools such as SAP or Salesforce. 
Connecting to the endpoint through MCP 
You can further evolve this pattern by having an MCP server invoke the endpoint rather than the agent itself. This allows for the decoupling of agent and tool logic and an improved security pattern because the MCP server will be the one with the permission to invoke the endpoint. To achieve this, implement an MCP server using the FastMCP framework that wraps the SageMaker endpoint and exposes it as a tool with a well-defined interface. A tool schema must be specified that clearly defines the input parameters and return values for the tool, facilitating straightforward understanding and usage by AI agents. Writing the proper docstring when defining the function achieves this. Additionally, the server must be configured to handle authentication securely, allowing it to access the SageMaker endpoint using AWS credentials or AWS roles. In this example, we run the server on the same compute as the agent and use stdio as communication protocol. For production workloads, we recommend running the MCP server on its own AWS compute and using transport protocols based on HTTPS (for example, Streamable HTTP). If you want to learn how to deploy MCP servers in a serverless fashion, refer to this official AWS GitHub repository. Here‚Äôs an example MCP server: 
 
 from&nbsp;mcp.server.fastmcp import&nbsp;FastMCP

mcp =&nbsp;FastMCP("SageMaker App")
ENDPOINT_NAME =&nbsp;os.environ["SAGEMAKER_ENDPOINT_NAME"]

@mcp.tool()
async&nbsp;def&nbsp;invoke_endpoint(payload: list):
&nbsp;&nbsp; &nbsp;"""&nbsp;Use the model ... """
&nbsp; &nbsp; [...]
&nbsp;&nbsp;&nbsp;&nbsp;
if&nbsp;__name__&nbsp;==&nbsp;"__main__":
&nbsp;&nbsp; &nbsp;mcp.run(="stdio") 
 
Finally, integrate the ML model with the agent framework. This begins with setting up Strands Agents to establish communication with the MCP server and incorporate the ML model as a tool. A comprehensive workflow must be created to determine when and how the agent should use the ML model to enhance its capabilities. The implementation includes programming decision logic that enables the agent to make informed decisions based on the predictions received from the ML model. The phase concludes with testing and evaluation, where the end-to-end workflow is validated by having the agent generate predictions for test scenarios and take appropriate actions based on those predictions. 
 
 from&nbsp;mcp import&nbsp;StdioServerParameters
from&nbsp;mcp.client.stdio import&nbsp;stdio_client
from&nbsp;strands.tools.mcp import&nbsp;MCPClient

# Create server parameters for stdio connection
server_params = StdioServerParameters(
&nbsp;&nbsp; &nbsp;command="python3", &nbsp;# Executable
&nbsp;&nbsp; &nbsp;args=["server.py"], &nbsp;# Optional command line arguments
&nbsp;&nbsp; &nbsp;env={"SAGEMAKER_ENDPOINT_NAME":&nbsp;"&lt;your-endpoint-name&gt;"}
)

# Create an agent with MCP tools
with stdio_mcp_client:
&nbsp;&nbsp; &nbsp;# Get the tools from the MCP server
&nbsp;&nbsp; &nbsp;tools = stdio_mcp_client.list_tools_sync()
&nbsp;&nbsp; &nbsp;# Create an agent with these tools
&nbsp;&nbsp; &nbsp;agent = Agent(model="us.amazon.nova-pro-v1:0", tools=tools)
&nbsp;&nbsp; &nbsp;# Invoke the agent
&nbsp;&nbsp; &nbsp;agent(
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Invoke the endpoint with this input:\n\n"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;f"&lt;input&gt;{test_sample}&lt;/input&gt;\n\n"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;"Provide the output in JSON format {'predictions':&lt;predictions&gt;}"
&nbsp;&nbsp; &nbsp;) 
 
Clean up 
When you‚Äôre done experimenting with the Strands Agents Python SDK and models on Amazon SageMaker AI, you can delete the endpoint you‚Äôve created to stop incurring unwanted charges. To do that, you can use either the AWS Management Console, the SageMaker Python SDK, or the AWS SDK for Python (boto3): 
 
 # SageMaker Python SDK
predictor.delete_model()
predictor.delete_endpoint()

# Alternatively, boto3
sagemaker_runtime.delete_endpoint(EndpointName=endpoint_name) 
 
Conclusion 
In this post, we demonstrated how to enhance AI agents‚Äô capabilities by integrating predictive ML models using Amazon SageMaker AI and the MCP. By using the open source Strands Agents SDK and the flexible deployment options of SageMaker AI, developers can create sophisticated AI applications that combine conversational AI with powerful predictive analytics capabilities. The solution we presented offers two integration paths: direct endpoint access through tool annotations and MCP-based integration, giving developers the flexibility to choose the most suitable approach for their specific use cases. Whether you‚Äôre building customer service chat assistants that need predictive capabilities or developing complex autonomous workflows, this architecture provides a secure, scalable, and modular foundation for your AI applications. As organizations continue to seek ways to make their AI agents more intelligent and data-driven, the combination of Amazon SageMaker AI, MCP, and the Strands Agents SDK offers a powerful solution for building the next generation of AI-powered applications. 
For readers unfamiliar with connecting MCP servers to workloads running on Amazon SageMaker AI, we suggest Extend large language models powered by Amazon SageMaker AI using Model Context Protocol in the AWS Artificial Intelligence Blog, which details the flow and the steps required to build agentic AI solutions with Amazon SageMaker AI. 
To learn more about AWS commitment to the MCP standard, we recommend reading Open Protocols for Agent Interoperability Part 1: Inter-Agent Communication on MCP in the AWS Open Source Blog, where we announced that AWS is joining the steering committee for MCP to make sure developers can build breakthrough agentic applications without being tied to one standard. To learn more about how to use MCP with other technologies from AWS, such as Amazon Bedrock Agents, we recommend reading Harness the power of MCP servers with Amazon Bedrock Agents in the AWS Artificial Intelligence Blog. Finally, a great way to securely deploy and scale MCP servers on AWS is provided in the AWS Solutions Library at Guidance for Deploying Model Context Protocol Servers on AWS. 
 
About the authors 
Saptarshi Banerjee serves as a Senior Solutions Architect at AWS, collaborating closely with AWS Partners to design and architect mission-critical solutions. With a specialization in generative AI, AI/ML, serverless architecture, Next-Gen Developer Experience tools and cloud-based solutions, Saptarshi is dedicated to enhancing performance, innovation, scalability, and cost-efficiency for AWS Partners within the cloud ecosystem. 
Davide Gallitelli is a Senior Worldwide Specialist Solutions Architect for Generative AI at AWS, where he empowers global enterprises to harness the transformative power of AI. Based in Europe but with a worldwide scope, Davide partners with organizations across industries to architect custom AI agents that solve complex business challenges using AWS ML stack. He is particularly passionate about democratizing AI technologies and enabling teams to build practical, scalable solutions that drive organizational transformation.
‚Ä¢ Simplify access control and auditing for Amazon SageMaker Studio using trusted identity propagation
  AWS supports trusted identity propagation, a feature that allows AWS services to securely propagate a user‚Äôs identity across service boundaries. With trusted identity propagation, you have fine-grained access controls based on a physical user‚Äôs identity rather than relying on IAM roles. This integration allows for the implementation of access control through services such as Amazon S3 Access Grants and maintains detailed audit logs of user actions across supported AWS services such as Amazon EMR. Furthermore, it supports long-running user background sessions for training jobs, so you can log out of your interactive ML application while the background job continues to run. 
Amazon SageMaker Studio now supports trusted identity propagation, offering a powerful solution for enterprises seeking to enhance their ML system security. By integrating trusted identity propagation with SageMaker Studio, organizations can simplify access management by granting permissions to existing AWS IAM Identity Center&nbsp;identities. 
In this post, we explore how to enable and use trusted identity propagation in SageMaker Studio, demonstrating its benefits through practical use cases and implementation guidelines. We walk through the setup process, discuss key considerations, and showcase how this feature can transform your organization‚Äôs approach to security and access controls. 
Solution overview 
In this section, we review the architecture for the proposed solution and the steps to enable trusted identity propagation for your SageMaker Studio domain. 
The following diagram shows the interaction between the different components that allow the user‚Äôs identity to propagate from their identity provider and IAM Identity Center to downstream services such as Amazon EMR and Amazon Athena. 
 
With a trusted identity propagation-enabled SageMaker Studio domain, users can access data across supported AWS services using their end user identity and group membership, in addition to access allowed by their domain or user execution role. In addition, API calls from SageMaker Studio notebooks and supported AWS services and Amazon SageMaker AI features log the user identity in AWS CloudTrail. For a list of supported AWS services and SageMaker AI features, see Trusted identity propagation architecture and compatibility. In the following sections, we show how to enable trusted identity propagation for your domain. 
This solution applies for SageMaker Studio domains set up using IAM Identity Center as the method of authentication. If your domain is set up using IAM, see Implement user-level access control for multi-tenant ML platforms on Amazon SageMaker AI for best practices on managing and scaling access control. 
Prerequisites 
To follow along with this post, you must have the following: 
 
 An AWS account with an organization instance of IAM Identity Center configured through AWS Organizations 
 Administrator permissions (or elevated permissions allowing modification of IAM principals, and SageMaker administrator access to create and update domains) 
 
Create or update the SageMaker execution role 
For trusted identity propagation to work, the SageMaker execution role (domain and user profile execution role), should allow the sts:SetContext permissions, in addition to sts:AssumeRole, in its trust policy. For a new SageMaker AI domain, create a domain execution role by following the instructions in Create execution role. For existing domains, follow the instructions in Get your execution role to find the user or domain‚Äôs execution role. 
Next, to update the trust policy for the role, complete the following steps: 
 
 In the navigation pane of the IAM console, choose Roles. 
 In the list of roles in your account, choose the domain or user execution role. 
 On the Trust relationships tab, choose Edit trust policy. 
 Update the trust policy with the following statement: 
 
 
  
   
   {
  "Version": "2012-10-17",
  "Statement": [
     .....
    {
      "Effect": "Allow",
      "Principal": {
        "Service": [
          "sagemaker.amazonaws.com",
        ]
      },
      "Action": [
        "sts:AssumeRole",
        "sts:SetContext"
      ],
      "Condition": {
	"aws:SourceAccount": "&lt;account&gt;"
         }
       }
    }
  ]
} 
   
  
 
 
 Choose Update policy to save your changes. 
 
Trusted identity propagation only works for private spaces at the time of launch. 
Create a SageMaker AI domain with trusted identity propagation enabled 
SageMaker AI domains using IAM Identity Center for authentication can only be set up in the same AWS Region as the IAM Identity Center instance. To create a new SageMaker domain, follow the steps in Use custom setup for Amazon SageMaker AI. For Trusted identity propagation, select Enable trusted identity propagation for all users on this domain, and continue with the rest of the setup to create a domain and assign users and groups, choosing the role you created in the previous step. 
 
Update an existing SageMaker AI domain 
You can also update your existing SageMaker AI domain to enable trusted identity propagation. You can enable trusted identity propagation even while the domain or user has active SageMaker Studio applications. However, for the changes to be applied, the active applications must be restarted. You can use the EffectiveTrustedIdentityPropagationStatus field in the response to the DescribeApp API for running applications to determine if the application has trusted identity propagation enabled. 
To enable trusted identity propagation for the domain using the SageMaker AI console, choose Edit under Authentication and permissions on the Domain settings tab. 
 
For Trusted identity propagation, select Enable trusted identity propagation for all users on this domain, and choose Submit to save the changes. 
 
(Optional) Update user background session configuration in IAM Identity Center 
IAM Identity Center now supports running user background sessions, and the session duration is set by default to 7 days. With background sessions, users can launch long-running SageMaker training jobs that assume the user‚Äôs identity context along with the SageMaker execution role. As an administrator, you can enable or disable user background sessions, and modify the session duration for user background sessions. As of the time of writing, the maximum session duration that you can set for user background sessions is 90 days. The user‚Äôs session is stopped at the end of the specified duration, and consequently, the training job will also fail at the end of the session duration. 
To disable or update the session duration, navigate to the IAM Identity Center console, choose Settings in the navigation pane, and choose Configure under Session duration. 
 
For User background sessions, select Enable user background sessions and use the dropdown to change the session duration. If user background sessions are disabled, the user must be logged in for the duration of the training job; otherwise, the training job will fail once the user logs out. Updating this configuration doesn‚Äôt affect current running sessions and only applies to newly created user background sessions. Choose Save to save your settings. 
 
Use cases 
Imagine you‚Äôre an enterprise with hundreds or even thousands of users, each requiring varying levels of access to data across multiple teams. You‚Äôre responsible for maintaining an AI/ML system on SageMaker AI and managing access permissions across diverse data sources such as Amazon Simple Storage Service (Amazon S3), Amazon Redshift, and AWS Lake Formation. Traditionally, this has involved maintaining complex IAM policies for users, services, and resources, including bucket policies where applicable. This approach is not only tedious but also makes it challenging to track and audit data access without maintaining a separate role for each user. 
This is precisely the scenario that trusted identity propagation aims to address. With trusted identity propagation support, you can now maintain service-specific roles with minimal permissions, such as s3:GetDataAccess or LakeFormation:GetDataAccess, along with additional permissions to start jobs, view job statuses, and perform other necessary tasks. For data access, you can assign fine-grained policies directly to individual users. For instance, Jane might have read access to customer data and full access to sales and pricing data, whereas Laura might only have read access to sales trends. Both Jane and Laura can assume the same SageMaker AI role to access their SageMaker Studio applications, while maintaining separate data access permissions based on their individual identities.In the following sections, we explore how this can be achieved for common use cases, demonstrating the power and flexibility of trusted identity propagation in simplifying data access management while maintaining robust security and auditability. 
Scenario 1: Experiment with Amazon S3 data in notebooks 
S3 Access Grants provide a simplified way to manage data access at scale. Unlike traditional IAM roles and policies that require a detailed knowledge of IAM concepts, and frequent policy updates as new resources are added, with S3 Access Grants, you can define access to data based on familiar database-like grants that automatically scale with your data. This approach significantly reduces the operational overhead of managing thousands of IAM policies and bucket policies, and overcomes the limitations of IAM permissions, while strengthening security through access patterns. If you don‚Äôt have S3 Access Grants set up, see Create an S3 Access Grant instance to get started. For detailed architecture and use cases, you can also refer to Scaling data access with Amazon S3 Access Grants. After you have set up S3 Access Grants, you can grant access to your datasets to users based on their identity in IAM Identity Center. 
To use S3 Access Grants from SageMaker Studio, update the following IAM roles with policies and trust policies. 
For the domain or user execution role, add the following inline policy: 
 
  
  {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowDataAccessAPI",
            "Effect": "Allow",
            "Action": [
                "s3:GetDataAccess"
            ],
            "Resource": [
                "arn:aws:s3:&lt;region&gt;:&lt;account&gt;:access-grants/default"
            ]
        },
        {
            "Sid": "RequiredForTIP",
            "Effect": "Allow",
            "Action": "sts:SetContext",
            "Resource": "arn:aws:iam::&lt;account&gt;:role/&lt;s3-access-grants-role&gt;"
        }
    ]
} 
  
 
Make sure the S3 Access Grants role‚Äôs trust policy allows the sts:SetContext action in addition to sts:AssumeRole. The following is a sample trust policy: 
 
  
   
   {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": [
                    "access-grants.s3.amazonaws.com"
                ]
            },
            "Action": [
                "sts:AssumeRole",
                "sts:SetContext"
            ],
            "Condition": {
                "StringEquals": {
                    "aws:SourceArn": "arn:aws:s3:&lt;region&gt;:&lt;account&gt;:access-grants/default"
                }
            }
        }
    ]
 
   
   
  &nbsp; 
 Now, the user can access the data as allowed by S3 Access Grants for your user identity by calling the 
GetDataAccess API to return temporary credentials, and by assuming the temporary credentials to read or write to their prefixes. For example, the following code shows how to use Boto3 to get temporary credentials and assume the credentials to get access to Amazon S3 locations that are allowed through S3 Access Grants: 

  &nbsp; 
 import boto3
from botocore.config import Config

def get_access_grant_credentials(account_id: str, target: str, 
                                 permission: str = 'READ'):
    s3control = boto3.client('s3control')
    response = s3control.get_data_access(
        AccountId=account_id,
        Target=target,
        Permission=permission
    )
    return response['Credentials']

def create_s3_client_from_credentials(credentials) -&gt; boto3.client:
    return boto3.client(
        's3',
        aws_access_key_id=credentials['AccessKeyId'],
        aws_secret_access_key=credentials['SecretAccessKey'],
        aws_session_token=credentials['SessionToken']
    )

# Create client
credentials = get_access_grant_credentials('&lt;account&gt;',
                                        "s3://&lt;bucket&gt;/&lt;allowed-prefix&gt;/")
s3 = create_s3_client_from_credentials(credentials)

# Will succeed
s3.list_objects(Bucket="&lt;bucket&gt;", Prefix="&lt;allowed-prefix&gt;")

# Will fail
s3.list_objects(Bucket="&lt;bucket&gt;", Prefix="&lt;any-other-prefix&gt;") 
 
Scenario 2: Access Lake Formation through Athena 
Lake Formation provides centralized governance and fine-grained access control management for data stored in Amazon S3 and metadata in the AWS Glue Data Catalog. The Lake Formation permission model operates in conjunction with IAM permissions, offering granular controls at the database, table, column, row, and cell levels. This dual-layer security model provides comprehensive data governance while maintaining flexibility in access patterns. 
Data governed through Lake Formation can be accessed through various AWS analytics services. In this scenario, we demonstrate using Athena, a serverless query engine that integrates seamlessly with Lake Formation‚Äôs permission model. For other services like Amazon EMR on EC2, make sure the resource is configured to support trusted identity propagation, including setting up security configurations and making sure the EMR cluster is configured with IAM roles that support trusted identity propagation. 
The following instructions assume that you have already set up Lake Formation. If not, see Set up AWS Lake Formation and follow the AWS Lake Formation tutorials to set up Lake Formation and bring in your data. 
Complete the following steps to access your governed data in trusted identity propagation-enabled SageMaker Studio notebooks using Athena: 
 
 Integrate Lake Formation with IAM Identity Center by following the instructions in Integrating IAM Identity Center. At a high level, this includes creating an IAM role allowing creating and updating application configurations in Lake Formation and IAM Identity Center, and providing the single sign-on (SSO) instance ID. 
 Grant permissions to the IAM Identity Center user to the relevant resources (database, table, row or column) using Lake Formation. See Granting permissions on Data Catalog resources instructions. 
 Create an Athena workgroup that supports trusted identity propagation by following instructions in Create a workgroup and choosing IAM Identity Center as the method of authentication. Make sure the user has access to write to the query results location provided here using S3 Access Grants, because Athena uses access grants by default when choosing IAM Identity Center as the authentication method. 
 Update the Athena workgroup‚Äôs IAM role with the following trust policy (add sts:SetContext to the existing trust policy). You can find the IAM role by choosing the workgroup you created earlier and looking for Role name. 
 
 
  
  {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AthenaTrustPolicy",
            "Effect": "Allow",
            "Principal": {
                "Service": "athena.amazonaws.com"
            },
            "Action": [
                "sts:AssumeRole",
                "sts:SetContext"
            ],
            "Condition": {
                "StringEquals": {
                    "aws:SourceAccount": "&lt;account-id&gt;"
                },
                "ArnLike": {
                    "aws:SourceArn": "arn:aws:athena:&lt;region&gt;:&lt;account-id&gt;:workgroup/&lt;workgroup-name&gt;"
                }
            }
        }
    ]
} 
  
 
The setup is now complete. You can now launch SageMaker Studio using an IAM Identity Center user, launch a JupyterLab or Code Editor application, and query the database. See the following example code to get started: 
 
  
  import time
import boto3
import pandas as pd
athena_client = boto3.client("athena")

database = "&lt;database-name&gt;"
table = "&lt;table-name&gt;"
query = f"SELECT * FROM {database}.{table}"
output_location = "s3://&lt;bucket-name&gt;/queries"  # bucket name and location from Step 3

response = athena_client.start_query_execution(
    QueryString=query,
    QueryExecutionContext={'Database': database},
    ResultConfiguration={'OutputLocation': output_location}
)

# Get the query execution ID
query_execution_id = response['QueryExecutionId']

# wait for query to complete
while True:
    query_status = athena_client.get_query_execution(QueryExecutionId=query_execution_id)
    status = query_status['QueryExecution']['Status']['State']
    if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:
        break
    time.sleep(1)

# If the query succeeded, fetch and display results
if status == 'SUCCEEDED':
    results = athena_client.get_query_results(QueryExecutionId=query_execution_id)
    
    # Extract column names and data
    columns = [col['Name'] for col in results['ResultSet']['ResultSetMetadata']['ColumnInfo']]
    data = []
    for row in results['ResultSet']['Rows'][1:]:  # Skip the header row
        data.append([field.get('VarCharValue', '') for field in row['Data']])
    
    # Create a pandas DataFrame
    df = pd.DataFrame(data, columns=columns)
    
    # Display the first few rows
    print(df.head())
else:
    print(f"Query failed with status: {status}") 
  
 
Scenario 3: Create a training job supported with user background sessions 
For a trusted identity propagation-enabled domain, a user background session is a session that continues to run even if the end-user has logged out of their interactive session such as JupyterLab applications in SageMaker Studio. For example, the user can initiate a training job from their SageMaker Studio space, and the job can run in the background for days or weeks regardless of the user‚Äôs activity, and use the user‚Äôs identity to access data and log audit trails. If your domain doesn‚Äôt have trusted identity propagation enabled, you can continue to run training jobs and processing jobs as before; however, if trusted identity propagation is enabled, make sure your user background session time is updated to reflect the duration of your training jobs, because the default is set automatically to 7 days. If you have enabled user background sessions, update your SageMaker Studio domain or user‚Äôs execution role with the following permissions to provide a seamless experience for data scientists: 
 
 {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowDataAccessAPI",
            "Effect": "Allow",
            "Action": [
                "s3:GetDataAccess",
                "s3:GetAccessGrantsInstanceForPrefix"
            ],
            "Resource": [
                "arn:aws:s3:&lt;region&gt;:&lt;account&gt;:access-grants/default"
            ]
        },
        {
            "Sid": "RequiredForTIP",
            "Effect": "Allow",
            "Action": "sts:SetContext",
            "Resource": "arn:aws:iam::&lt;account&gt;:role/&lt;s3-access-grants-role&gt;"
        }
    ]
} 
 
With this setup, a data scientist can use an Amazon S3 location that they have access to through S3 Access Grants. SageMaker automatically looks for data access using S3 Access Grants and falls back to the job‚Äôs IAM role otherwise. For example, in the following SDK call to create the training job, the user provides the S3 Amazon URI where the data is stored, they have access to it through S3 Access Grants, and they can run this job without additional setup: 
 
  
   
       response = sm.create_training_job(
        TrainingJobName=training_job_name,
        AlgorithmSpecification={
            'TrainingImage': '763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04',
            'TrainingInputMode': 'File',
            ...
                    RoleArn='arn:aws:iam::&lt;account&gt;:role/tip-domain-role',
        InputDataConfig=[
            {
                'ChannelName': 'training',
                'DataSource': {
                    'S3DataSource': {
                        'S3DataType': 'S3Prefix',
                        'S3Uri': 's3://&lt;s3-ag-enabled-bucket&gt;/&lt;s3-ag-enabled-prefix&gt;',
                        'S3DataDistributionType': 'FullyReplicated'
                    }
                },
                'CompressionType': 'None',
                'RecordWrapperType': 'None'
            },
            ...
        } 
   
  
 
(Optional) View and manage user background sessions on IAM Identity Center 
When training jobs are run as user background sessions, you can view these sessions as user background sessions on IAM Identity Center. The administrator can view a list of all user background sessions and optionally stop a session if the user has left the team, for example. When the user background session is ended, the training job subsequently fails. 
To view a list of all user background sessions, on the IAM Identity Center console, choose Users and choose the user you want view the user background sessions for. Choose the Active sessions tab to view a list of sessions. The user background session can be identified by the Session type column, which shows if the session is interactive or a user background session. The list also shows the job‚Äôs Amazon Resource Name (ARN) under the Used by column. 
To end a session, select the session and choose End sessions. 
 
You will be prompted to confirm the action. Enter confirm to confirm that you want to end the session and choose End sessions to stop the user background session. 
 
Scenario 4: Auditing using CloudTrail 
After trusted identity propagation is enabled for your domain, you can now track the user that performed specific actions through CloudTrail. To try this out, log in to SageMaker Studio, and create and open a JupyterLab space. Open a terminal and enter aws s3 ls to list the available buckets in your Region. 
On the CloudTrail console, choose Event history in the navigation pane. Update the Lookup attributes to Event name and in the search box, enter ListBuckets. You should see a list of events, as shown in the following screenshot (it might take up to 5 minutes for the logs to be available in CloudTrail). 
 
Choose the event to view its details (verify the user name is SageMaker if you have also listed buckets through the AWS console or APIs). In the event details, you should be able to see an additional field called onBehalfOf that has the user‚Äôs identity. 
 
Supported services and SageMaker AI features called from a trusted identity propagation-enabled SageMaker Studio domain will have the OnBehalfOf field in CloudTrail. 
Clean up 
If you have created a SageMaker Studio domain for the purposes of trying out trusted identity propagation, delete the domain and its associated Amazon Elastic File System (Amazon EFS) volume to avoid incurring additional charges. Before deleting a domain, you must delete all the users and their associated spaces and applications. For detailed instructions, see Stop and delete your Studio running applications and spaces. 
If you created a SageMaker training job, they are ephemeral, and the compute is shut down automatically when the job is complete. 
Athena is a serverless analytics service that charges per query billing. No cleanup is necessary, but for best practices, delete the workgroup to remove unused resources. 
Conclusion 
In this post, we showed you how to enable trusted identity propagation for SageMaker AI domains that use IAM Identity Center as the mode of authentication. With trusted identity propagation, administrators can manage user authorization to other AWS services through the user‚Äôs physical identity in conjunction with IAM roles. Administrators can streamline permissions management by maintaining a single domain execution role and manage granular access to other AWS services and data sources through the user‚Äôs identity. In addition, trusted identity propagation supports auditing, so administrators can track user activity without the need for managing a role for each user profile. 
To learn more about enabling this feature and its use cases, see Trusted identity propagation use cases and Trusted identity propagation with Studio. This post covered a subset of supported applications; we encourage you to check out the documentation and choose the services that best serve your use case and share your feedback! 
 
About the authors 
Amit Shyam Jaisinghani is a Software Engineer on the SageMaker Studio team at Amazon Web Services, and he earned his Master‚Äôs degree in Computer Science from Rochester Institute of Technology. Since joining Amazon in 2019, he has built and enhanced several AWS services, including AWS WorkSpaces and Amazon SageMaker Studio. Outside of work, he explores hiking trails, plays with his two cats, Missy and Minnie, and enjoys playing Age of Empire. 
Durga Sury is a Senior Solutions Architect at Amazon SageMaker, where she helps enterprise customers build secure and scalable AI/ML systems. When she‚Äôs not architecting solutions, you can find her enjoying sunny walks with her dog, immersing herself in murder mystery books, or catching up on her favorite Netflix shows. 
Khushboo Srivastava is a Senior Product Manager for Amazon SageMaker. She enjoys building products that simplify machine learning workflows for customers, and loves playing with her 1-year old daughter. 
Krishnan Manivannan is a Senior Software Engineer at Amazon Web Services and a founding member of the SageMaker AI API team. He has 8 years of experience in the architecture and security of large-scale machine learning services. His specialties include API design, service scalability, identity and access management, and inventing new approaches for building and operating distributed systems. Krishnan has led multiple engineering efforts from design through global launch, delivering reliable and secure systems for customers worldwide.

‚∏ª