‚úÖ Morning News Briefing ‚Äì July 17, 2025 10:57

üìÖ Date: 2025-07-17 10:57
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions: Fog and Smoke, 19.6¬∞C
  Conditions: Fog and Smoke Temperature: 19.6&deg;C Pressure / Tendency: 100.6 kPa falling Visibility: 8 km Humidity: 90 % Dewpoint: 17.9&deg:C Wind: W 8 km/h Air Quality Health Index: n/a . The conditions were observed at Garrison Petawawa 6:00 AM EDT Thursday 17
‚Ä¢ Thursday: Showers. High 27.
  Showers beginning this morning then changing to 40 percent chance of showers this afternoon . Risk of a thunderstorm. Local amount 20 to 30 mm. Risk of thunderstorm . Wind becoming northwest 30 km/h gusting to 50 early this afternoon. High 27. Humidex 36. UV index 5 or moderate, with a high of 36 degrees in the mid-90s or lower

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Israel launches airstrikes on the Syrian capital of Damascus
  Israel says it targeted the Syrian military headquarters and near the presidential palace . It says it was in response to attacks on the Druze minority . Israel launched airstrikes Wednesday on Syria's capital of Damascus, saying it targeted military HQ and palace . Israel says Druze attacks on Druze minorities are a response to Israel's airstrikes on the Syrian government . The Syrian government has been fighting a civil war
‚Ä¢ Stand back! This explosive cucumber is bursting with seeds
  A small, hairy, toxic version of the cucumbers found in the produce aisle does have an advantage over its more palatable cousins . A feat of ballistic seed dispersal is a feat of spreading seed seeds, says Stanislav Gorb . A small hairy version of cucumbers has an advantage in dispersal, says Gorb, but does not have the same advantage as its more
‚Ä¢ Maryland taps Affordable Care Act fund to help pay for abortion care
  Like other states that still allow abortion, Maryland has seen an increase in people coming from out of state to get care . And it's found a new way to offer them financial support . Maryland is one of several states that allow abortion to be legal in the U.S. and has seen a rise in the number of people coming to the state to seek care for women in need of
‚Ä¢ Virginia is for ‚Ä¶ data centers? Residents are increasingly saying no
  The world's highest concentration of data centers is in Virginia . Many residents are not happy about that . Virginia is home to the world's most data centers, but residents say it's a good thing for them to live in the U.S. Virginia has the highest population in the world, but many residents don't want that . The state of Virginia is the home of the data centers
‚Ä¢ Ari Aster's 'Eddington' takes the tension of the pandemic to a violent end
  In pandemic-era New Mexico, a sheriff (Joaquin Phoenix) and a mayor (Pedro Pascal) face off against one another, and their differences boil over into chaos . The film stars Joaquin Phoenix and Pedro Pascal as a sheriff and mayor in pandemic era New Mexico . The movie is based on a novel about a pandemic outbreak in the state of New Mexico in

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ Boffins detail new algorithms to losslessly boost AI perf by up to 2.8x
  New spin on speculative decoding works with any model - now built into Transformers . New set of algorithms developed by researchers at the Weizmann Institute of Science, Intel Labs, and d-Matrix could significantly reduce the cost of serving up your favorite large language model (LLM) with just a few lines of code . AI is expensive, but new algorithms can significantly reduce that cost with just
‚Ä¢ Large Hadron Collider data hints at explanation for why everything exists
  The universe contains more matter than antimatter, according to a new paper . Scientists have analyzed data gathered from CERN‚Äôs Large Hadron Collider to advance our understanding of why anything exists . A paper hints at one reason for that happy disparity in matter and antimatter . It is the first study to suggest that antimatter is more likely to exist in the universe than in antimatter
‚Ä¢ Open, free, and completely ignored: The strange afterlife of Symbian
  The result of the pioneering joint Psion and Nokia smartphone effort is still out there on GitHub . It did get sourced, but nobody cared . The result was still out on GitHub, and it's still available to anyone who wants to see it . The Psion-Nokia smartphone project is still available on GitHub and is still open to the public . It's not the first time the
‚Ä¢ Microsoft offers vintage Exchange and Skype server users six more months of security updates
  Microsoft has extended its security update programs for Exchange Server 2016 and 2019, and Skype for Business 2015 and 2019 . It looks like enough of you are struggling to migrate that Redmond is willing to help out ‚Äì for a price that might buy nothing . Microsoft has also extended its . Exchange Server . 2016 and . 2019 security updates for Exchange . Server 2016, 2019 and 2019 updates for Skype . 2015
‚Ä¢ Meta used AI to concoct low-carbon concrete it poured for a datacenter floor
  Meta has created an AI model to come up with new forms of concrete and used one of the resulting recipes to underpin a new bit barn . Bayesian optimization apparently build better slabs . Meta also used a recipe to underpin the new bit of barn in a bid to build a bit barn in New York City, New York, with a new model of concrete that was created by Meta .

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Large language models as disrupters of misinformation
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Access to nature faces social and socioeconomic as well as travel barriers
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Temporal trends in suicide related emergency calls by age group and gender from 2014 to 2023
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Cross-sectional study of health impairment related to post COVID-19 condition among participants of a large population-based cohort in Germany
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Spatial heterogeneity and temporal trends of thyroid cancer incidence in Iran from 2014 to 2017
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ In defense of air-conditioning
  I‚Äôll admit that I‚Äôve rarely hesitated to point an accusing finger at air-conditioning. I‚Äôve outlined in many stories and newsletters that AC is a significant contributor to global electricity demand, and it‚Äôs only going to suck up more power as temperatures rise.



But I‚Äôll also be the first to admit that it can be a life-saving technology, one that may become even more necessary as climate change intensifies. And in the wake of Europe‚Äôs recent deadly heat wave, it‚Äôs been oddly villainized.&nbsp;





We should all be aware of the growing electricity toll of air-conditioning, but the AC hate is misplaced. Yes, AC is energy intensive, but so is heating our homes, something that‚Äôs rarely decried in the same way that cooling is. Both are tools for comfort and, more important, for safety. &nbsp;So why is air-conditioning cast as such a villain?



In the last days of June and the first few days of July, temperatures hit record highs across Europe. Over 2,300 deaths during that period were attributed to the heat wave, according to early research from World Weather Attribution, an academic collaboration that studies extreme weather. And human-caused climate change accounted for 1,500 of the deaths, the researchers found. (That is, the number of fatalities would have been under 800 if not for higher temperatures because of climate change.)



We won‚Äôt have the official death toll for months, but these early figures show just how deadly heat waves can be. Europe is especially vulnerable, because in many countries, particularly in the northern part of the continent, air-conditioning is not common.



Popping on a fan, drawing the shades, or opening the windows on the hottest days used to cut it in many European countries. Not anymore. The UK was 1.24 ¬∞C (2.23 ¬∞F) warmer over the past decade than it was between 1961 and 1990, according to the Met Office, the UK‚Äôs national climate and weather service. One recent study found that homes across the country are uncomfortably or dangerously warm much more frequently than they used to be.



The reality is, some parts of the world are seeing an upward shift in temperatures that‚Äôs not just uncomfortable but dangerous. As a result, air-conditioning usage is going up all over the world, including in countries with historically low rates.



The reaction to this long-term trend, especially in the face of the recent heat wave, has been apoplectic. People are decrying AC across social media and opinion pages, arguing that we need to suck it up and deal with being a little bit uncomfortable.



Now, let me preface this by saying that I do live in the US, where roughly 90% of homes are cooled with air-conditioning today. So perhaps I am a little biased in favor of AC. But it baffles me when people talk about air-conditioning this way.





I spent a good amount of my childhood in the southeastern US, where it‚Äôs very obvious that heat can be dangerous. I was used to many days where temperatures were well above 90 ¬∞F (32 ¬∞C), and the humidity was so high your clothes would stick to you as soon as you stepped outdoors.&nbsp;



For some people, being active or working in those conditions can lead to heatstroke. Prolonged exposure, even if it‚Äôs not immediately harmful, can lead to heart and kidney problems. Older people, children, and those with chronic conditions can be more vulnerable.&nbsp;



In other words, air-conditioning is more than a convenience; in certain conditions, it‚Äôs a safety measure. That should be an easy enough concept to grasp. After all, in many parts of the world we expect access to heating in the name of safety. Nobody wants to freeze to death.&nbsp;



And it‚Äôs important to clarify here that while air-conditioning does use a lot of electricity in the US, heating actually has a higher energy footprint.&nbsp;



In the US, about 19% of residential electricity use goes to air-conditioning. That sounds like a lot, and it‚Äôs significantly more than the 12% of electricity that goes to space heating. However, we need to zoom out to get the full picture, because electricity makes up only part of a home‚Äôs total energy demand. A lot of homes in the US use natural gas for heating‚Äîthat‚Äôs not counted in the electricity being used, but it‚Äôs certainly part of the home‚Äôs total energy use.



When we look at the total, space heating accounts for a full 42% of residential energy consumption in the US, while air conditioning accounts for only 9%.



I‚Äôm not letting AC off the hook entirely here. There‚Äôs obviously a difference between running air-conditioning (or other, less energy-intensive technologies) when needed to stay safe and blasting systems at max capacity because you prefer it chilly. And there‚Äôs a lot of grid planning we‚Äôll need to do to make sure we can handle the expected influx of air-conditioning around the globe.&nbsp;



But the world is changing, and temperatures are rising. If you‚Äôre looking for a villain, look beyond the air conditioner and into the atmosphere.



This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.
‚Ä¢ Researchers announce babies born from a trial of three-person IVF
  Eight babies have been born in the UK thanks to a technology that uses DNA from three people: the two biological parents plus a third person who supplies healthy mitochondrial DNA. The babies were born to mothers who carry genes for mitochondrial diseases and risked passing on severe disorders. The eight babies are healthy, say the researchers behind the trial.



‚ÄúMitochondrial disease can have a devastating impact on families,‚Äù Doug Turnbull of Newcastle University, one of the researchers behind the study, said in a statement. ‚ÄúToday‚Äôs news offers fresh hope to many more women at risk of passing on this condition, who now have the chance to have children growing up without this terrible disease.‚Äù





The study, which makes use of a technology called mitochondrial donation, has been described as a ‚Äútour de force‚Äù and ‚Äúa remarkable accomplishment‚Äù by others in the field. In the team‚Äôs approach, patients‚Äô eggs are fertilized with sperm, and the DNA-containing nuclei of those cells are transferred into donated fertilized eggs that have had their own nuclei removed. The new embryos contain the DNA of the intended parents along with a tiny fraction of mitochondrial DNA from the donor, floating in the embryos‚Äô cytoplasm.&nbsp;



‚ÄúThe concept of [mitochondrial donation] has attracted much commentary and occasionally concern and anxiety,‚Äù Stuart Lavery, a consultant in reproductive medicine at University College Hospitals NHS Foundation Trust, said in a statement. ‚ÄúThe Newcastle team have demonstrated that it can be used in a clinically effective and ethically acceptable way to prevent disease and suffering.‚Äù



Not everyone sees the trial as a resounding success. While five of the children were born ‚Äúwith no health problems,‚Äù one developed a fever and a urinary tract infection, and another had muscle jerks. A third was treated for an abnormal heart rhythm. Three of the babies were born with a low level of the very mitochondrial-DNA mutations the treatment was designed to prevent.



Heidi Mertes, a medical ethicist at Ghent University, says she is ‚Äúmoderately optimistic.‚Äù ‚ÄúI‚Äôm happy that it worked,‚Äù she says. ‚ÄúBut at the same time, it‚Äôs concerning ‚Ä¶ it‚Äôs a call for caution and treading carefully.‚Äù



Pavlo Mazur, a former embryologist who has used a similar approach in the conception of 15 babies in Ukraine, believes that trials like this one should be paused until researchers figure out what‚Äôs going on. Others believe that researchers should study the technique in people who don‚Äôt have mitochondrial mutations, to lower the risk of passing any disease-causing mutations to children.



Long time coming



The news of the births has been long awaited by researchers in the field. Mitochondrial donation was first made legal in the UK in 2015. Two years later, the Human Fertility and Embryology Authority (HFEA), which regulates fertility treatment and research in the UK, granted a fertility clinic in Newcastle the sole license to perform the procedure. Newcastle Fertility Centre at Life launched a trial of mitochondrial donation in 2017 with the aim of treating 25 women a year.



That was eight years ago. Since then, the Newcastle team have been extremely tight-lipped about the trial. That‚Äôs despite the fact that other teams elsewhere have used mitochondrial donation to help people achieve pregnancy. A New York‚Äìbased doctor used a type of mitochondrial donation to help a Jordanian couple conceive in Mexico in 2016. Mitochondrial donation has also been trialed by teams in Ukraine and Greece.





But as the only trial overseen by the HFEA, the Newcastle team‚Äôs study was viewed by many as the most ‚Äúofficial.‚Äù Researchers have been itching to hear how the work has been going, given the potential implications for researchers elsewhere (mitochondrial donation was officially made legal in Australia in 2022). ‚ÄúI‚Äôm very glad to see [the results] come out at last,‚Äù says Dagan Wells, a reproductive biologist at the University of Oxford who worked on the Greece trial. ‚ÄúIt would have been nice to have some information out along the way.‚Äù



At the Newcastle clinic, each patient must receive approval from the HFEA to be eligible for mitochondrial donation. Since the trial launched in 2017, 39 patients have won this approval. Twenty-five of them underwent hormonal stimulation to release multiple eggs that could be frozen in storage.



Nineteen of those women went on to have mitochondrial donation. So far, seven of the women have given birth (one had twins), and an eighth is still pregnant. The oldest baby is two years old. The results were published today in the New England Journal of Medicine.



‚ÄúAs parents, all we ever wanted was to give our child a healthy start in life,‚Äù one of the mothers, who is remaining anonymous, said in a statement. ‚ÄúMitochondrial donation IVF made that possible. After years of uncertainty this treatment gave us hope‚Äîand then it gave us our baby ‚Ä¶ Science gave us a chance.‚Äù



When each baby was born, the team collected a blood and urine sample to look at the child‚Äôs mitochondrial DNA. They found that the levels of mutated DNA were far lower than they would have expected without mitochondrial donation. Three of the mothers were ‚Äúhomoplasmic‚Äù‚Äî100% of their mitochondrial DNA carried the mutation. But blood tests showed that in the women‚Äôs four babies (including the twins), 5% or less of the mitochondrial DNA had the mutation, suggesting they won‚Äôt develop disease.



A mixed result



The researchers see this as a positive result. ‚ÄúChildren who would otherwise have inherited very high levels are now inheriting levels that are reduced by 77% to 100%,‚Äù coauthor Mary Herbert, a professor of reproductive biology at Newcastle University and Monash University, told me during a press briefing.



But three of the eight babies had health symptoms. At seven months, one was diagnosed with a rare form of epilepsy, which seemed to resolve within the following three months. Another baby developed a urinary tract infection.





A third baby developed ‚Äúprolonged‚Äù jaundice, high levels of fat in the blood, and a disturbed heart rhythm that required treatment. The baby seemed to have recovered by 18 months, and doctors believe that the symptoms were not related to the mitochondrial mutations, but the team members admit that they can‚Äôt be sure. Given the small sample size, it‚Äôs hard to make comparisons with babies conceived in other ways.&nbsp;



And they acknowledge that a phenomenon called ‚Äúreversal‚Äù is happening in some of the babies. In theory, the children shouldn‚Äôt inherit any ‚Äúbad‚Äù mitochondrial DNA from their mothers. But three of them did. The levels of ‚Äúbad‚Äù mitochondrial DNA in the babies‚Äô blood ranged between 5% and 16%. And they were higher in the babies‚Äô urine‚Äîthe highest figure being 20%.



The researchers don‚Äôt know why this is happening. When an embryologist pulls out the nucleus of a fertilized egg, a bit of mitochondria-containing cytoplasm will inevitably be dragged along with it. But the team didn‚Äôt see any link between the amount of carried-over cytoplasm and the level of ‚Äúbad‚Äù mitochondria. ‚ÄúWe continue to investigate this issue,‚Äù Herbert said.



‚ÄúAs long as they don‚Äôt understand what‚Äôs happening, I would still be worried,‚Äù says Mertes.



Such low levels aren‚Äôt likely to cause mitochondrial diseases, according to experts contacted by MIT Technology Review. But some are concerned that the percentage of mutated DNA could be higher in different tissues, such as the brain or muscle, or that the levels might change with age. ‚ÄúYou never know which tissues [reversal] will show up in,‚Äù says Mazur, who has seen the phenomenon in babies born through mitochondrial donation to parents who didn‚Äôt have mitochondrial mutations. ‚ÄúIt‚Äôs chaotic.‚Äù



The Newcastle team says it hasn‚Äôt looked at other tissues, because it designed the study to be noninvasive.



There has been at least one case in which similar levels of ‚Äúbad‚Äù mitochondria have caused symptoms, says Joanna Poulton, a mitochondrial geneticist at the University of Oxford. She thinks it‚Äôs unlikely that the children in the trial will develop any symptoms but adds that ‚Äúit‚Äôs a bit of a worry.‚Äù



The age of reversal



No one knows exactly when this reversal happens. But Wells and his colleagues have some idea. In their study in Greece, they looked at the mitochondrial DNA of embryos and checked them again during pregnancy and after birth. The trial was designed to study the impact of mitochondrial donation for infertility‚Äînone of the parents involved had genes for mitochondrial disease.



The team has seen mitochondrial reversal in two of the seven babies born in the trial, says Wells. If you put the two sets of results together, mitochondrial donation ‚Äúseems to have this possibility of reversal occurring in maybe about a third of children,‚Äù he says.





In his study, the reversal seemed to occur early on in the embryos‚Äô development, Wells says. Five-day-old embryos ‚Äúlook perfect,‚Äù but mitochondrial mutations start showing up in tests taken at around 15 weeks of pregnancy, he says. After that point, the levels appear to be relatively stable. The Newcastle researchers say they will monitor the children until they are five years old.



People enrolling in future trials might opt for amniocentesis, which involves sampling blood from the fetus‚Äôs amniotic sac at around 15 to 18 weeks, suggests Mertes. That test might reveal the likely level of mitochondrial mutations in the resulting child. ‚ÄúThen the parents could decide what to do,‚Äù says Mertes. ‚ÄúIf you could see there was a 90% mutation load [for a] very serious mitochondrial disease, they would still have an option to cancel the pregnancy,‚Äù she says.



Wells thinks the Newcastle team‚Äôs results are ‚Äúgenerally reassuring.‚Äù He doesn‚Äôt think the trials should be paused. But he wants people to understand that mitochondrial donation is not without risk. ‚ÄúThis can only be viewed as a risk reduction strategy, and not a guarantee of having an unaffected child,‚Äù he says.



And, as Mertes points out, there‚Äôs another option for women who carry mitochondrial DNA mutations: egg donation. Donor eggs fertilized with a partner‚Äôs sperm and transferred to a woman‚Äôs uterus won‚Äôt have her disease-causing mitochondria.&nbsp;



That option won‚Äôt appeal to people who feel strongly about having a genetic link to their children. But Poulton asks: ‚ÄúIf you know whose uterus you came out of, does it matter that the [egg] came from somewhere else?‚Äù
‚Ä¢ These four charts show where AI companies could go next in the US
  A new report by the Brookings Institution attempts to map how embedded AI companies and jobs are in different regions of the United States . The report looked at local talent pool development, innovations in local institutions, and adoption potential among local companies . It found that the vast majority of people working with AI and startups focused on AI are clustered in tech hubs like San Francisco and Boston . There are 14 regions that show promise in AI development and worker engagement with AI .
‚Ä¢ The Download: Veo 3‚Äôs subtitles problem, and the future of our planet‚Äôs resources
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.







Google‚Äôs generative video model Veo 3 has a subtitles problem



As soon as Google launched its latest video-generating AI model at the end of May, creatives rushed to put it through its paces. Released just months after its predecessor, Veo 3 allows users to generate sounds and dialogue for the first time. It sparked a flurry of hyperrealistic eight-second clips stitched together into ads, ASMR videos, imagined film trailers, and humorous street interviews.But others quickly found that in some ways the tool wasn‚Äôt behaving as expected. When it generates clips that include dialogue, Veo 3 often adds nonsensical, garbled subtitles, even when the prompts it‚Äôs been given explicitly ask for no captions or subtitles to be added. And getting rid of them isn‚Äôt straightforward‚Äîor cheap. Read the full story.



‚ÄîRhiannon Williams







MIT Technology Review Narrated: This rare earth metal shows us the future of our planet‚Äôs resources



We‚Äôre in the middle of a potentially transformative moment. The materials we need to power our world are beginning to shift from fossil fuels to energy sources that don‚Äôt produce the greenhouse-gas emissions changing our climate. Metals discovered barely more than a century ago now underpin the technologies we‚Äôre relying on for cleaner energy, and not having enough of them could slow progress.¬†



Take neodymium, for example. Its potential future reveals many of the challenges we‚Äôll likely face across the supply chain for materials in the coming century and beyond.&nbsp;



This is our latest story to be turned into a MIT Technology Review Narrated podcast, which&nbsp; we‚Äôre publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it‚Äôs released.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 OpenAI is developing agents designed specifically for workIn a direct challenge to Microsoft apps like PowerPoint and Excel. (The Information $)+ The whole of OpenAI runs on Slack, apparently. (Insider $)+ Are we ready to hand AI agents the keys? (MIT Technology Review)



2 Congress is poised to reject most of the White House‚Äôs proposed NASA cutsAs well as postponing its plans to cancel the Space Launch System rocket and Orion spacecraft. (Ars Technica)



3 Grok‚Äôs AI companions are already going haywire¬†They‚Äôve no qualms talking about topics like sex or how to bomb a school. (TechCrunch)+ The pair demonstrate Elon Musk‚Äôs willingness to push the boundaries of taste. (NBC News)+ It‚Äôs likely that Grok has been trained on the worst parts of the internet. (CNN)+ Inside the Wild West of AI companionship. (MIT Technology Review)



4 AI could find cures to diseases using drugs we already haveIt may be time to repurpose what we know. (New Yorker $)+ An AI-driven ‚Äúfactory of drugs‚Äù claims to have hit a big milestone. (MIT Technology Review)



5 China is pumping billions into becoming an AI power playerLocal governments are building entire neighborhoods to act as startup incubators. (NYT $)+ Meanwhile, Trump is creating an AI hub in Pennsylvania. (WSJ $)



6 Silicon Valley‚Äôs super-babies are on the wayOne startup claims to be able to sequence an embryo‚Äôs entire genome. (WP $)+ Beyond gene-edited babies: the possible paths for tinkering with human evolution. (MIT Technology Review)



7 How the Earth‚Äôs magnetic crust could improve airplane navigationIt‚Äôs likely to be more reliable than GPS, for one. (WSJ $)



8 We‚Äôre entering the era of hyper-personalized AI slopComing to a Facebook feed near you.(404 Media)



9 You don‚Äôt need to take weight-loss drugs consistentlyPatients who take it sporadically can still lose weight. (New Scientist $)



10 This UK startup wants to give non-alcoholic drinks a buzz It‚Äôs working on a molecule to mimic the high of a few drinks without the hangover. (Bloomberg $)







Quote of the day



‚ÄúI‚Äôm doing the equivalent of vibe coding, except it‚Äôs vibe physics.‚Äù



‚ÄîTravis Kalanick, the founder of Uber, explains how he‚Äôs using xAI‚Äôs Grok to come ‚Äúpretty damn close to some interesting breakthroughs‚Äù in the field of physics, Gizmodo reports.







One more thing







How Indian health-care workers use WhatsApp to save pregnant womenAcross India, an all-women cadre of 1 million community health-care workers are responsible for making public health care accessible to people from remote areas and marginalized communities.These workers counsel pregnant women and ensure they receive proper science-backed health care. Many are turning to WhatsApp as a means to combat the medical misinformation that is rampant across the country and to navigate sensitive medical situations, particularly regarding pregnancy. Their approach has surprisingly good results. Read the full story.



‚ÄîSanket Jain







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Britain‚Äôs greatest export? Possibly its gravy.+ How a luxury condo building in Manhattan ended up sloping sideways (New Yorker $)+ The Emmy nominations are out! But who‚Äôs been snubbed?+ The Tony Hawk‚Äôs Pro Skater 3 + 4 reboots are proving extremely controversial‚Äîafter only 10 songs on their legendary soundtracks made the cut.
‚Ä¢ Finding value with AI automation
  In June 2023, technology leaders and IT services executives had a lightning bolt headed their way when McKinsey published the ‚ÄúThe economic potential of generative AI: The next productivity frontier‚Äù report. It echoed a moment from the 2010s when Amazon Web Services launched an advertising campaign aimed at Main Street‚Äôs C-suite: Why would any fiscally responsible exec allow their IT teams to spend capex for servers and software when AWS only cost 10 cents per virtual machine?&nbsp;







Vendors understand that these kinds of reports and aggressive advertising around competitive risks projected onto an industry sector would drive many calls from boards to their C-suite, rolling from C-suite to their staff all asking, ‚ÄúWhat are we doing with AI?‚Äù When asked to ‚Äúdo something with AI,‚Äù technical leadership and their organizations promptly responded ‚Äî sometimes begrudgingly and sometimes excitedly ‚Äî for work-sanctioned opportunities to get their hands on a new technology. At that point, there was no time to sort between actual business returns from applying AI and ‚ÄúAI novelty‚Äù use cases that were more Rube Goldberg machines than tangible breakthroughs.&nbsp;



Today&#8217;s opportunity: Significant automation gains&nbsp;



When leaders respond to immediate panic, new business risks and mitigations often emerge.&nbsp; Two recent examples highlight the consequences of rushing to implement and publish positive results from AI adoption. The Wall Street Journal reported in April 2025 on companies struggling to realize returns on AI. Just weeks later, it covered MIT‚Äôs retraction of a technical paper about AI where the results that led to its publication could not be substantiated.&nbsp;&nbsp;



While these reports demonstrate the pitfalls of over-reliance on AI without common-sense guardrails, not all is off track in the land of enterprise AI adoption. Incredible results being found from judicious use of AI and related technologies in automating processes across industries. Now that we are through the ‚Äúfear of missing out‚Äù stage and can get down to business, where are the best places to look for value when applying AI to automation of your business?&nbsp;&nbsp;



While chatbots are almost as pervasive as new app downloads for mobile phones, the applications of AI realizing automation and productivity gains line up with the unique purpose and architecture of the underlying AI system they are built on. The dominant patterns where AI gains are realized currently boil down to two things: language (translation and patterns) and data (new format creation and data search).&nbsp;&nbsp;



Example one: Natural language processing &nbsp;



Manufacturing automation challenge: Failure Mode and Effects Analysis (FMEA) is both critical and often labor intensive. It is not always performed prior to a failure in manufacturing equipment, so very often FMEA occurs in a stressful manufacturing lines-down scenario. In Intel‚Äôs case, a global footprint of manufacturing facilities separated by large distances along with time zones and preferred language differences makes this even more difficult to find the root cause of a problem. Weeks of engineering effort are spent per FMEA analysis repeated across large fleets of tools spread between these facilities.&nbsp;&nbsp;



Solution: Leverage already deployed CPU compute servers for natural language processing (NLP) across the manufacturing tool logs, where observations about the tools‚Äô operations are maintained by the local manufacturing technicians. The analysis also applied sentiment analysis to classify words as positive, negative, or neutral. The new system performed FMEA on six months of data in under one minute, saving weeks of engineering time and allowing the manufacturing line to proactively service equipment on a pre-emptive schedule rather than incurring unexpected downtime.&nbsp;&nbsp;



Financial institution challenge: Programming languages commonly used by software engineers have evolved. Mature bellwether institutions were often formed through a series of mergers and acquisitions over the years, and they continue to rely on critical systems that are based on 30-year-old programming languages that current-day software engineers are not familiar with.&nbsp;



Solution: Use NLP to translate between the old and new programming languages, giving software engineers a needed boost to improve the serviceability of critical operational systems. Use the power of AI rather than doing a risky rewrite or massive upgrade.&nbsp;



Example two: Company product specifications and generative AI models&nbsp;



Sales automation challenge: The time it takes to reformat a company‚Äôs product data into a specific customer RFP format has been an ongoing challenge across industries. Teams of sales and technical leads spend weeks of work across different accounts reformatting the same root data between the preferred PowerPoint or Word document formats. The customer response times were measured in weeks, especially if the RFPs required legal reviews.&nbsp;



Solution: By using generative AI combined with a data extraction and prompting technique called retrieval augmented generation (RAG), companies can rapidly reformat product information between different customer required RFP response formats. The time spent moving data between different documents and different document types only to find an unforced error in the move is reduced to hours instead of weeks.&nbsp;&nbsp;



HR policy automation challenge: Navigating internal processes can be time consuming and confusing for both HR and employees. The consequences of misinterpretation, access outages, and personal information or private data being exposed are massively important to the company and the individual.&nbsp;



Solution: Combine generative AI, RAG, and an interactive chatbot that uses employee-assigned assets to determine identity and access rights, provides employees interactive query-based chat formats to answer their questions in real time.&nbsp;



Finding your best use cases for AI&nbsp;



In a world where 80% to 90% of all AI proof of concepts fail to scale, now is the time to develop a framework that is based on caution. Consider starting with a data strategy and governance assessment. Then find opportunities to compare successful AI-based automation efforts at peer companies through peer discussions. Clear, rules-based policies and processes offer the best opportunities to begin a successful AI automation journey in your enterprise. Where you encounter disparate data sources (e.g., unstructured, video, structured databases) or unclear processes, maintain tighter human-in-the-loop decision controls to avoid unexpected data or token exposure and cost overruns.&nbsp;



As the AI hype cycle cools and business pressure mounts, now is the time to become practical. Apply AI to well-defined use cases and begin unlocking the automation benefits that will matter not just in 2025, but for years to come.



This content was produced by Intel. It was not written by MIT Technology Review‚Äôs editorial staff.

üîí Cybersecurity & Privacy
‚Ä¢ DOGE Denizen Marko Elez Leaked API Key for xAI
  Marko Elez, a 25-year-old employee at Elon Musk&#8217;s Department of Government Efficiency (DOGE), has been granted access to sensitive databases at the U.S. Social Security Administration, the Treasury and Justice departments, and the Department of Homeland Security. So it should fill all Americans with a deep sense of confidence to learn that Mr. Elez over the weekend inadvertently published a private key that allowed anyone to interact directly with more than four dozen large language models (LLMs) developed by Musk&#8217;s artificial intelligence company xAI.
Image: Shutterstock, @sdx15.
On July 13, Mr. Elez committed a code script to GitHub called &#8220;agent.py&#8221; that included a private application programming interface (API) key for xAI. The inclusion of the private key was first flagged by GitGuardian, a company that specializes in detecting and remediating exposed secrets in public and proprietary environments. GitGuardian‚Äôs systems constantly scan GitHub and other code repositories for exposed API keys, and fire off automated alerts to affected users.
Philippe Caturegli, ‚Äúchief hacking officer‚Äù at the security consultancy Seralys,¬†said the exposed API key allowed access to at least 52 different LLMs used by xAI. The most recent LLM in the list was called &#8220;grok-4-0709&#8221; and was created on July 9, 2025.
Grok, the generative AI chatbot developed by xAI and integrated into Twitter/X, relies on these and other LLMs (a query to Grok before publication shows Grok currently uses Grok-3, which was launched in Feburary 2025). Earlier today, xAI announced that the Department of Defense will begin using Grok as part of a contract worth up to $200 million. The contract award came less than a week after Grok began spewing antisemitic rants and invoking Adolf Hitler.
Mr. Elez did not respond to a request for comment. The code repository containing the private xAI key was removed shortly after Caturegli notified Elez via email. However, Caturegli said the exposed API key still works and has not yet been revoked.
&#8220;If a developer can&#8217;t keep an API key private, it raises questions about how they&#8217;re handling far more sensitive government information behind closed doors,&#8221; Caturegli told KrebsOnSecurity.
Prior to joining DOGE, Marko Elez worked for a number of Musk&#8217;s companies. His DOGE career began at the Department of the Treasury, and a legal battle over DOGE&#8217;s access to Treasury databases showed Elez was sending unencrypted personal information in violation of the agency&#8217;s policies.
While still at Treasury, Elez resigned after The Wall Street Journal linked him to social media posts that advocated racism and eugenics. When Vice President J.D. Vance lobbied for Elez to be rehired, President Trump agreed and Musk reinstated him.
Since his re-hiring as a DOGE employee, Elez has been granted access to databases at one federal agency after another. TechCrunch reported in February 2025 that he was working at the Social Security Administration. In March, Business Insider found Elez was part of a DOGE detachment assigned to the Department of Labor.
Marko Elez, in a photo from a social media profile.
In April, The New York Times reported that Elez held positions at the U.S. Customs and Border Protection and the Immigration and Customs Enforcement (ICE) bureaus, as well as the Department of Homeland Security. The Washington Post later reported that Elez, while serving as a DOGE advisor at the Department of Justice, had gained access to the Executive Office for Immigration Review&#8217;s Courts and Appeals System (EACS).
Elez is not the first DOGE worker to publish internal API keys for xAI: In May, KrebsOnSecurity detailed how another DOGE employee leaked a private xAI key on GitHub for two months, exposing LLMs that were custom made for working with internal data from Musk&#8217;s companies, including SpaceX, Tesla and Twitter/X.
Caturegli said it&#8217;s difficult to trust someone with access to confidential government systems when they can&#8217;t even manage the basics of operational security.
&#8220;One leak is a mistake,&#8221; he said. &#8220;But when the same type of sensitive key gets exposed again and again, it‚Äôs not just bad luck, it‚Äôs a sign of deeper negligence and a broken security culture.&#8221;

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ CollabLLM: Teaching LLMs to collaborate with users
  Large language models (LLMs) can solve complex puzzles in seconds, yet they sometimes struggle over simple conversations. When these AI tools make assumptions, overlook key details, or neglect to ask clarifying questions, the result can erode trust and derail real-world interactions, where nuance is everything.



A key reason these models behave this way lies in how they‚Äôre trained and evaluated. Most benchmarks use isolated, single-turn prompts with clear instructions. Training methods tend to optimize for the model&#8217;s next response, not its contribution to a successful, multi-turn exchange. But real-world interaction is dynamic and collaborative. It relies on context, clarification, and shared understanding.



User-centric approach to training&nbsp;



To address this, we‚Äôre exploring ways to train LLMs with users in mind. Our approach places models in simulated environments that reflect the back-and-forth nature of real conversations. Through reinforcement learning, these models improve through trial and error, for example, learning when to ask questions and how to adapt tone and communication style to different situations. This user-centric approach helps bridge the gap between how LLMs are typically trained and how people actually use them.¬†¬†



This is the concept behind CollabLLM (opens in new tab), recipient of an ICML (opens in new tab) Outstanding Paper Award (opens in new tab). This training framework helps LLMs improve through simulated multi-turn interactions, as illustrated in Figure 1. The core insight behind CollabLLM is simple: in a constructive collaboration, the value of a response isn‚Äôt just in its immediate usefulness, but in how it contributes to the overall success of the conversation. A clarifying question might seem like a delay but often leads to better outcomes. A quick answer might appear useful but can create confusion or derail the interaction.



Figure 1. Diagram comparing two training approaches for LLMs. (a) The standard method lacks user-agent collaboration and uses single-turn rewards, leading to an inefficient conversation. (b) In contrast, CollabLLM simulates multi-turn user-agent interactions during training, enabling it to learn effective collaboration strategies and produce more efficient dialogues.



CollabLLM puts this collaborative approach into practice with a simulation-based training loop, illustrated in Figure 2. At any point in a conversation, the model generates multiple possible next turns by engaging in a dialogue with a simulated user.



Figure 2: Simulation-based training process used in CollabLLM



The system uses a sampling method to extend conversations turn by turn, choosing likely responses for each participant (the AI agent or the simulated user), while adding some randomness to vary the conversational paths. The goal is to expose the model to a wide variety of conversational scenarios, helping it learn more effective collaboration strategies.



	
		

		
		Spotlight: Microsoft research newsletter
	
	
	
						
				
					
				
			
			
			

									Microsoft Research Newsletter
				
								Stay connected to the research community at Microsoft.
				
								
					
						
							Subscribe today						
					
				
							
	
Opens in a new tab	
	


To each simulated conversation, we applied multiturn-aware reward (MR) functions, which assess how the model‚Äôs response at the given turn influences the entire trajectory of the conversation. We sampled multiple conversational follow-ups from the model, such as statements, suggestions, questions, and used MR to assign a reward to each based on how well the conversation performed in later turns. We based these scores on automated metrics that reflect key factors like goal completion, conversational efficiency, and user engagement.



To score the sampled conversations, we used task-specific metrics and metrics from an LLM-as-a-judge framework, which supports efficient and scalable evaluation. For metrics like engagement, a judge model rates each sampled conversation on a scale from 0 to 1.



The MR of each model response was computed by averaging the scores from the sampled conversations, originating from the model response. Based on the score, the model updates its parameters using established reinforcement learning algorithms like Proximal Policy Optimization (PPO) or Direct Preference Optimization (DPO).



We tested CollabLLM through a combination of automated and human evaluations, detailed in the paper. One highlight is a user study involving 201 participants in a document co-creation task, shown in Figure 3. We compared CollabLLM to a baseline trained with single-turn rewards and to a second, more proactive baseline prompted to ask clarifying questions and take other proactive steps. CollabLLM outperformed both, producing higher-quality documents, better interaction ratings, and faster task completion times.



Figure 3: Results of the user study in a document co-creation task comparing CollabLLM to a baseline trained with single-turn rewards.



Designing for real-world collaboration



Much of today‚Äôs AI research focuses on fully automated tasks, models working without input from or interaction with users. But many real-world applications depend on people in the loop: as users, collaborators, or decision-makers. Designing AI systems that treat user input not as a constraint, but as essential, leads to systems that are more accurate, more helpful, and ultimately more trustworthy.



This work is driven by a core belief: the future of AI depends not just on intelligence, but on the ability to collaborate effectively. And that means confronting the communication breakdowns in today‚Äôs systems.



We see CollabLLM as a step in that direction, training models to engage in meaningful multi-turn interactions, ask clarifying questions, and adapt to context. In doing so, we can build systems designed to work with people‚Äînot around them.
Opens in a new tabThe post CollabLLM: Teaching LLMs to collaborate with users appeared first on Microsoft Research.
‚Ä¢ AI Testing and Evaluation: Learnings from cybersecurity
  Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains‚Äîfrom genome editing to cybersecurity‚Äîto investigate the role of testing and evaluation as a governance tool.&nbsp;AI Testing and Evaluation: Learnings from Science and Industry,&nbsp;hosted by Microsoft Research‚Äôs&nbsp;Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.



In this episode, Sullivan speaks with Professor Ciaran Martin (opens in new tab) of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, Tori Westerhoff (opens in new tab), a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she‚Äôs heard cybersecurity professionals use for their work‚Äîa team sport‚Äîand points to cybersecurity‚Äôs establishment of a shared language and understanding of risk as a model for AI security.








Learn more:




Introducing AI Red Teaming Agent: Accelerate your AI safety and security journey with Azure AI Foundry (opens in new tab)Azure AI Foundry Blog | April 2025



Lessons From Red Teaming 100 Generative AI ProductsPublication | January 2025



Learning from other domains to advance AI evaluation and testingMicrosoft Research Blog | June 2025



Responsible AI: Ethical policies and practices | Microsoft AI



AI and Microsoft Research










	
		
			Subscribe to the Microsoft Research Podcast:		
		
							
					
						  
						Apple Podcasts
					
				
			
							
					
						
						Email
					
				
			
							
					
						
						Android
					
				
			
							
					
						
						Spotify
					
				
			
							
					
						
						RSS Feed
					
				
					
	




	
		
			
				
					

Transcript



[MUSIC]



KATHLEEN SULLIVAN: Welcome to AI Testing and Evaluation: Learnings from Science and Industry. I&#8217;m your host, Kathleen Sullivan.



As generative AI continues to advance, Microsoft has gathered a range of experts‚Äîfrom genome editing to cybersecurity‚Äîto share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.



[MUSIC ENDS]



Today, I&#8217;m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK&#8217;s intelligence, security, and cyber agency.



And after our conversation, we&#8217;ll talk to Microsoft&#8217;s Tori Westerhoff, a principal director on Microsoft‚Äôs AI Red Team, about how we should think about these insights in the context of AI.



Hi, Ciaran. Thank you so much for being here today.



				
				
					



CIARAN MARTIN: Well, thanks so much for inviting me. It‚Äôs great to be here.



SULLIVAN: Ciaran, before we get into some regulatory specifics, it&#8217;d be great to hear a little bit more about your origin story, and just take us to that day‚Äîwho tapped you on the shoulder and said, ‚ÄúCiaran, we need you to run a national cyber center! Do you fancy building one?‚Äù



MARTIN: You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn&#8217;t exist at the time‚ÄîI was invited to join the British government&#8217;s cybersecurity effort in a leadership role‚Äîis now a subset of GCHQ. That&#8217;s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.



I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.



SULLIVAN: I mean, it&#8217;s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?



MARTIN: Well, risk assessment and testing, I think, are two different things. You can&#8217;t defend everything. If you defend everything, you&#8217;re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don&#8217;t want any of them to happen, but you have to have a hierarchy of harm.



SULLIVAN: Yes.



MARTIN: So that&#8217;s your risk assessment.



The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you&#8217;ve got boards and corporate leadership and senior governmental structures, and they say, ‚ÄúLook, how do I run this organization safely and securely?‚Äù And a cybersecurity chief within the organization will say, ‚ÄúWell, we could get this capability in.‚Äù Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what&#8217;s the cost-benefit analysis? And we find that really hard.



So that&#8217;s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we&#8217;re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it&#8217;s meeting those standards? So it&#8217;s a huge issue in cybersecurity and one that we&#8217;re always very conscious of. It‚Äôs really hard.



SULLIVAN: Given the scope of cybersecurity, are there any differences in testing, let&#8217;s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?



MARTIN: There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that&#8217;s well equipped. You have to be realistic.



If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn&#8217;t. So you have to have some differentiation. So again, you&#8217;ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they&#8217;re never going to meet.



SULLIVAN: It&#8217;s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?



MARTIN: I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.



But if you say to them, ‚ÄúLook, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,‚Äù whatever, then you&#8217;ve got a problem. And I think we&#8217;ve wrestled with that, and there&#8217;s no perfect answer. You just have to try and go to ‚Ä¶ find the sweet spot between two ends of a spectrum. And that&#8217;s going to evolve.



The second point, which in some respects if you&#8217;ve got the right capabilities is slightly easier but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ‚Äô90s and the noughties, as we call them over here.



But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that&#8217;s really good because it&#8217;s saying to people that these are the things that are going to matter in the post-quantum age. Here&#8217;s the outline of the standards you&#8217;re going to have to meet; start looking at them. So there&#8217;s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that&#8217;s the era we&#8217;re in now.



SULLIVAN: That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what&#8217;s the real reason they haven&#8217;t?



MARTIN: Well, again, where do you start? I mean, most members of the public quite rightly haven&#8217;t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.



And there&#8217;s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that&#8217;s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.



The third one then is when your perimeter&#8217;s breached, be able to detect it more times than not. And when you can&#8217;t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn&#8217;t eliminate the harm, but you would reduce it quite substantially.



SULLIVAN: Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you‚Äôve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?



MARTIN: I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it&#8217;s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.



We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we&#8217;ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you&#8217;re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules‚Äîand please develop them jointly with us; that&#8217;s the crucial part‚Äîthen that will help because it means that we&#8217;re not going to our boards and saying, or our shareholders, and saying that we should do this, and they&#8217;re saying, ‚ÄúWell, do you have to do it? Are our competitors doing it?‚Äù And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.



The harder nut to crack is the smaller business. And I think there&#8217;s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can&#8217;t throttle small businesses with onerous regulation. At the same time, we&#8217;re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.



There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.



SULLIVAN: Yeah, it&#8217;s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?



MARTIN: I think they&#8217;re crucial, but they have to be practical. I&#8217;ve got a slight, sort of, high horse on this, if you don&#8217;t mind, Kathleen. It&#8217;s sort of ‚Ä¶ [LAUGHS]



SULLIVAN: Of course.



MARTIN: I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn&#8217;t get us very far. There are other types.



We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn&#8217;t provide. So I think it&#8217;s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the ‚Ä¶ not just the problem but the scale of the whole technology is just too big to do that.



So pick a bit of the problem. Find some ways of doing it. Don&#8217;t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. Oh, well, is this our role? You know, should we be doing this, that, and the other? Well, you know, sometimes certainly in this country, you think, well, who&#8217;s actually going to sue you over this, you know? So I wouldn&#8217;t over-programmatize it. Just get stuck practically into solving some problems.



SULLIVAN: I love that. Actually, [it] made me think, are there any surprising allies that you&#8217;ve gained‚Äîyou know, maybe someone who you never expected to be a cybersecurity champion‚Äîthrough your work?



MARTIN: Ooh! That&#8217;s a ‚Ä¶ that&#8217;s a‚Ä¶ what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not immoral, amoral. It just didn&#8217;t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what&#8217;s in it for them?



And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn&#8217;t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it&#8217;s a really positive part of certainly the UK cybersecurity ecosystem.



SULLIVAN: Wonderful. Well, we&#8217;re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?



MARTIN: I think that standards, assurance, and testing really matter, but it&#8217;s a bit like the discussion we&#8217;re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There&#8217;s been some bad regulation under the auspices of standards and assurance. First of all, it‚Äôs, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it&#8217;s not everything.



SULLIVAN: No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.



MARTIN: My pleasure, Kathleen, thank you.



[TRANSITION MUSIC]



SULLIVAN: Now, I&#8217;m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.



So, Tori, welcome!



TORI WESTERHOFF: Thanks. I am so excited to be here.



SULLIVAN: I&#8217;d love to just start a little bit more learning about your background. You&#8217;ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality ‚Ä¶ how do those experiences help shape the way you lead the Microsoft AI Red Team?



WESTERHOFF: I always joke this is the only role I think will always combine the entire patchwork LinkedIn r√©sum√©. [LAUGHS]



I think I use those experiences to help me understand the really broad approach that AI Red Team‚Äîartist also known as AIRT; I&#8217;m sure I&#8217;ll slip into our acronym‚Äîhow we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There&#8217;s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal ‚Äúin‚Äù to getting hooked into AI red teaming generally.



But my experience in national security and I&#8217;d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we&#8217;re thinking about critical industries, how we&#8217;re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that&#8217;s evolving all of the time, that&#8217;s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we&#8217;re shaping up how we approach it.



SULLIVAN: Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?



WESTERHOFF: The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we&#8217;ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.



So if we&#8217;re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that&#8217;s creating mitigations. It&#8217;s platform-security folks who are creating mitigations at scale. And there&#8217;s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it&#8217;s a continuous cycle.



And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research‚Äîwe have a research function within our AI Red Team‚Äîand how we automate and scale. This year, we&#8217;ve pulled a lot of those assets and insights into the Azure [AI] Foundry AI Red Teaming Agent (opens in new tab). And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.



SULLIVAN: You recently‚Äîactually, with your team‚Äîpublished a report that outlined lessons from testing over a hundred generative AI products. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?



WESTERHOFF: I think the most important takeaway from those lessons is that AI security is truly a team sport. You&#8217;ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we&#8217;re going to approach this with intentionality and responsibility.



So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we&#8217;ve done, there&#8217;s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are they using it?



And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation for people, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. 



SULLIVAN: As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?



WESTERHOFF: Yeah, I think it&#8217;s such a broad set of perspectives to bring in, in the AI instance. Something that I&#8217;ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.



So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you&#8217;re working on. It means you all understand, ‚ÄúHey, we are really worried about this fundamental impact.‚Äù And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we&#8217;re trying to really clarify terms and threats.&nbsp;And you see it in updates of those frameworks, as well, that I really love.



So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.



SULLIVAN: Mm-hmm. In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization&#8217;s role and scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&nbsp;



WESTERHOFF: I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we&#8217;re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.



Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which is really fascinating and I love, I still think that our team drives to say, ‚ÄúOK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?‚Äù



So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people&#8217;s trust almost as different variables that could affect the impact, right.



So a good example is if we&#8217;re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it&#8217;s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing empathy.



You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.



SULLIVAN: What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? 



WESTERHOFF: I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It&#8217;s not just saying, ‚ÄúHey, there&#8217;s one test that we want to try,‚Äù but more, ‚ÄúHey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven&#8217;t even thought of, we feel confident that we have the resources and the system?‚Äù



So part of me is really intrigued by the process that we&#8217;re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we&#8217;re really excited about pushing out those insights in an experimental and longer-term way.



I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about are traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I&#8217;m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.



So to me, integration of AI into those frameworks by those same standards means that we&#8217;re evolving security to include AI. We aren&#8217;t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.



I think there&#8217;s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that&#8217;s our job. But the other side of cybersecurity is offense. And I&#8217;m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.



Generally speaking, I think the best practice is to realize that we&#8217;re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.



SULLIVAN: How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I&#8217;d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?



WESTERHOFF: I&#8217;ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I&#8217;m talking to you today is probably evidence that a ton of people are bringing in perspectives that don&#8217;t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we&#8217;re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.



SULLIVAN: No, I think we&#8217;re seeing that across the board. I mean, I&#8217;d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we&#8217;re creating into the hands of our customers and partners and ecosystem is just underscored.



So on the note of speed, let&#8217;s shift gears a little bit to just a quick lightning round. I&#8217;d love to get maybe some quick thoughts from you, just 30-second answers here. I&#8217;ll start with one.



Which headline-grabbing AI threat do you think is mostly hot air?



WESTERHOFF: I think we should pay attention to it all. I&#8217;m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.



SULLIVAN: Is there some sort of maybe new tool that you can&#8217;t wait to sneak into the red team arsenal?



WESTERHOFF: I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we&#8217;re looking at agentic systems. So I would say a method, not a tool.



SULLIVAN: So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?



WESTERHOFF: Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe&#8217;s elote chips. Like the whole bag. [LAUGHTER] It‚Äôs going to get me through. I&#8217;m going to not love that I did it.



[MUSIC]



SULLIVAN: Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.



WESTERHOFF: Thank you so much for having me. This was a joy.



SULLIVAN: And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.



See you next time!‚ÄØ



[MUSIC FADES]

				
			
			
				Show more			
		
	





AI Testing and Evaluation podcast series

Opens in a new tabThe post AI Testing and Evaluation: Learnings from cybersecurity appeared first on Microsoft Research.
‚Ä¢ Accenture scales video analysis with Amazon Nova and Amazon Bedrock Agents
  This post was written with Ilan Geller, Kamal Mannar, Debasmita Ghosh, and Nakul Aggarwal of Accenture. 
Video highlights offer a powerful way to boost audience engagement and extend content value for content publishers. These short, high-impact clips capture key moments that drive viewer retention, amplify reach across social media, reinforce brand identity, and open new avenues for monetization. However, traditional highlight creation workflows are slow and labor-intensive. Editors must manually review footage, identify significant moments, cut clips, and add transitions or narration‚Äîfollowed by manual quality checks and formatting for distribution. Although this provides editorial control, it creates bottlenecks that don‚Äôt scale efficiently. 
This post showcases how Accenture Spotlight delivers a scalable, cost-effective video highlight generation solution using Amazon Nova and Amazon Bedrock Agents. Amazon Nova foundation models (FMs) deliver frontier intelligence and industry-leading price-performance. With Spotlight, content owners can configure AI models and agents to support diverse use cases across the media industry while offering a human-in-the-loop option for quality assurance and collaborative refinement. This maintains accuracy, editorial oversight, and alignment with brand guidelines‚Äîwithout compromising on speed or scalability. 
Real-world use cases 
Spotlight has been applied across a range of industry scenarios, including: 
 
 Personalized short-form video generation ‚Äì Spotlight‚Äôs specialized agents analyze popular short-form content (such as video reels and other social media) to identify patterns of high-performing content. The agents then apply this understanding to long-form video to generate personalized short clips, with built-in checks for brand alignment and content standards. 
 Sports editing and highlights ‚Äì Spotlight automates creation of video highlights for sports like soccer, Formula 1, and rugby, tailoring them to specific user preferences and interests. It also validates each highlight‚Äôs quality and accuracy, streamlining editorial workflows as a result. 
 Content matching for stakeholders ‚Äì Using enriched metadata, Spotlight matches archived or live video content to audience demographics, optimizing distribution strategies and maximizing advertiser value through precise targeting. 
 Real-time retail offer generation ‚Äì In retail environments such as gas stations, Spotlight processes live CCTV footage to infer customer profiles using data (such as vehicle type or transaction history), and then dynamically generates personalized product offers. These offers consider contextual factors such as time of day and weather; and they are delivered with custom visuals in near real time. 
 
Spotlight‚Äôs architecture 
Spotlight‚Äôs architecture addresses the challenge of scalable video processing, efficiently analyzing and generating content while maintaining speed and quality. It incorporates both task-specific models and Amazon Nova FMs that are orchestrated by specialized Amazon Bedrock agents. Key architectural highlights include: 
 
 Task-driven model selection ‚Äì Spotlight dynamically selects between traditional AI models and Amazon Nova FMs based on a given task‚Äôs complexity and latency requirements. This intelligent orchestration enables fast inference for time-sensitive operations while deploying deeper multimodal reasoning where sophisticated analysis is needed‚Äîbalancing speed and intelligence across applications from real-time retail offers to complex video processing. 
 Agent orchestration ‚Äì Specialized agents, each purpose-built for specific analysis tasks, operate across the end-to-end workflow under the direction of a central orchestrator agent. The orchestrator agent manages task breakdown, data flow, and inter-agent communication. 
 Scalable and adaptable ‚Äì By using AWS capabilities, Spotlight‚Äôs architecture is configurable to support different workloads‚Äîfrom high-throughput video highlight generation to low-latency offer personalization at the edge. 
 
Spotlight uses a multi-layered agent workflow to automate video processing and generation while maintaining quality control. For example, to generate dynamic video highlights, Spotlight uses three specialized ‚Äúsuper agents‚Äù that work in coordination under a central orchestrator agent‚Äôs supervision. Each super agent is powered by Amazon Nova models, and is supported by a collection of utility agents (see the following diagram). These agents work together to understand video content, generate high-quality highlights, and maintain alignment with user requirements and brand standards. 
 
The workflow consists of the following super agents and utility agents: 
 
 Video processing agent ‚Äì This agent analyzes long-form video and generates detailed metadata to guide short-form video creation. It uses the following utility agents: 
   
   Research agent ‚Äì Analyzes popular short-form videos to identify key components that create video virality, and creates recipes for successful short-form content. For example, in music videos, it can highlight choreographed dance sequences with the lead performer as essential segments and a recipe based on this insight. 
   Visual analysis agent ‚Äì Applies the research agent‚Äôs findings to new long-form content. It identifies matching segments, tags key individuals, and timestamps relevant moments. It uses traditional AI models (such as person recognition and tracking) to capture fine-grained details for segment identification. 
   Audio analysis agent ‚Äì Performs speech diarization and transcription to support both the research and visual analysis agents with deeper context from the video‚Äôs audio track. 
    
 Short video generation agent ‚Äì This agent orchestrates the actual creation of the short-form video by integrating relevant segments and refining the sequence. Its utility agents include: 
   
   Section of interest (SOI) agent ‚Äì Identifies potential segments based on video genre, target length, featured performers, and JSON metadata from the visual analysis agent. This agent prioritizes logical flow and viewer engagement. 
   Video generation agent ‚Äì Constructs video using segment recommendations and component patterns from the video processing agent. For example, influencer videos might follow a structure of an attention-grabbing hook, key messages, and a call to action. The process will be iteratively improved based on feedback from the reviewer agent. 
   Video postprocessing agent ‚Äì Refines the final output for publishing by performing tasks like cropping to mobile-friendly aspect ratios, or adding subtitles, background music, and brand overlays. 
    
 Reviewer agent ‚Äì This agent works iteratively with the generation agent to maintain video quality and relevance. Its utility agents include: 
   
   Relevance check agent ‚Äì Evaluates alignment with user-defined content guidelines, audience expectations, and desired themes. 
   Abruptness check agent ‚Äì Provides smooth transitions between segments to avoid jarring cuts, enhancing viewer experience and professionalism. 
    
 
See Spotlight in action: 

 
  
 
 
Solution overview 
To interact with Spotlight, users access a frontend UI where they provide natural language input to specify their objective. Spotlight then employs its agentic workflow powered by Amazon Nova to achieve its given task. The following diagram illustrates the solution architecture for video highlight generation. 
 
The workflow consists of the following key components (as numbered in the preceding diagram): 
 
 Frontend UI for user interaction: 
   
   Users interact through a web portal secured by Amazon Cognito authentication and delivered using Amazon CloudFront. 
   Amazon API Gateway serves a restful endpoint for video processing and highlight generation services. 
    
 Live video stream processing: 
   
   AWS Elemental MediaLive processes incoming video stream and triggers AWS Lambda to initiate workflows. (Spotlight also accepts video archive content as media files for processing and highlight generation.) 
    
 Video processing workflow orchestrated with AWS Step Functions: 
   
   Open source models hosted on Amazon SageMaker enable speech analysis and computer vision for person and object detection. 
   The video processing agent powered by Amazon Nova Pro analyzes video and generates fine-grained metadata (for example, identifying patterns from viral videos). 
   The reviewer agent powered by Amazon Nova Premier maintains alignment with brand standards. 
   Open source utility tooling is used for pre-analysis tasks. 
    
 Highlight generation workflow orchestrated with Step Functions: 
   
   Amazon Nova Pro analyzes the user query for clips of interest to understand intent, and reformulates the query for downstream processing. 
   The short video generation agent powered by Amazon Nova Pro constructs a video highlight using segment recommendations. 
   The reviewer agent powered by Amazon Nova Premier makes sure the constructed highlight aligns with quality, brand, and contextual expectations. 
   AWS Elemental Media Convert and open source tooling enable video highlight construction and postprocessing (such as subtitle layover, aspect ratio change, and transitions). 
    
 Storage and monitoring: 
   
   Amazon Simple Storage Service (Amazon S3) stores metadata extracted from processing workflows, reference content (such as scripts and brand guidelines), and generated outputs. 
   Amazon CloudWatch maintains end-to-end system health and monitors performance. 
    
 
Key benefits 
Spotlight‚Äôs approach to video processing and generation creates dynamic value. Additionally, its technical design using Amazon Nova and an integrated agentic workflow helps content owners realize gains in their video processing and editorial operations. Key benefits for Spotlight include: 
 
 Cross-industry application ‚Äì Spotlight‚Äôs modular design allows it to be applied seamlessly across industries‚Äîfrom media and entertainment to retail 
 Real-time processing ‚Äì It supports both live stream feeds and pre-recorded video, with custom highlight generation happening in minutes, reducing from hours or days 
 Cost-efficient deployment ‚Äì It is entirely serverless and on-demand, minimizing idle infrastructure costs and maximizing utilization 
 Efficiency ‚Äì Accenture‚Äôs review of costs using Amazon Nova models showed that Amazon Nova-powered agents deliver over 10 times better cost savings over traditional highlight creation methods 
 
The following table provides is a comparative analysis of Spotlight‚Äôs video processing approach to conventional approaches for video highlight creation. 
 
  
   
   Metric 
   Spotlight Performance 
   Conventional Approach 
   
   
   Video Processing Latency 
   Minutes for 2‚Äì3-hour sessions 
   Hours to days 
   
   
   Highlight Review Cost (3‚Äì5 minutes) 
   10 times lower with Amazon Nova 
   High cost using conventional approaches 
   
   
   Overall Highlight Generation Cost 
   10 times lower using serverless and on-demand LLM deployment 
   Manual workflows with high operational overhead 
   
   
   Deployment Architecture 
   Fully serverless with scalable LLM invocation 
   Typically resource-heavy and statically provisioned 
   
   
   Use Case Flexibility 
   Sports, media editing, retail personalization, and more 
   Often tailored to a single use case 
   
  
 
Conclusion 
Spotlight represents a cutting-edge agentic solution designed to tackle complex media processing and customer personalization challenges using generative AI. With modular, multi-agent workflows built on Amazon Nova, Spotlight seamlessly enables dynamic short-form video generation. The solution‚Äôs core framework is also extensible to diverse industry use cases that require multimodal content analysis at scale. 
As an AWS Premier Tier Services Partner and Managed Services Provider (MSP), Accenture brings deep cloud and industry expertise. Accenture and AWS have worked together for more than a decade to help organizations realize value from their applications and data. Accenture brings its industry understanding and generative AI specialists to build and adapt generative AI solutions to client needs. Together with AWS, through the Accenture AWS Business Group (AABG), we help enterprises unlock business value by rapidly scaling generative AI solutions tailored to their needs‚Äîdriving innovation and transformation in the cloud. 
Try out Spotlight for your own use case, and share your feedback in the comments. 
 
 
About the authors 
Ilan Geller is a Managing Director in the Data and AI practice at Accenture. He is the Global AWS Partner Lead for Data and AI and the Center for Advanced AI. His roles at Accenture have primarily been focused on the design, development, and delivery of complex data, AI/ML, and most recently Generative AI solutions. 
Dr. Kamal Mannar is a Global Computer Vision Lead at Accenture‚Äôs Center for Advanced AI, with over 20 years of experience applying AI across industries like agriculture, healthcare, energy, and telecom. He has led large-scale AI transformations, built scalable GenAI and computer vision solutions, and holds 10+ patents in areas including deep learning, wearable AI, and vision transformers. Previously, he headed AI at Vulcan AI, driving cutting-edge innovation in precision agriculture. Kamal holds a Ph.D. in Industrial &amp; Systems Engineering from the University of Wisconsin‚ÄìMadison. 
Debasmita Ghosh is working as&nbsp;Associate Director&nbsp;in Accenture with&nbsp;21 years&nbsp;of experience in Information Technology (8 years&nbsp;in AI/Gen AI capability), who currently among multiple responsibilities leads&nbsp;Computer Vision practice in India.&nbsp;She has presented her paper on Handwritten Text Recognition in multiple conferences including MCPR 2020, GHCI 2020. She has patent granted on Handwritten Text Recognition solution and received recognition from Accenture under the Accenture Inventor Award Program being named as an inventor on a granted patent. She has multiple papers on Computer Visions solutions like Table Extraction including non-uniform and borderless tables accepted and presented in the ComPE 2021 and CCVPR 2021 international conferences. She has managed projects across multiple technologies (Oracle Apps, SAP). As a programmer, she has worked during various phases of SDLC with experience on Oracle Apps Development across CRM, Procurement, Receivables, SCM, SAP Professional Services, SAP CRM. Debasmita holds&nbsp;M.Sc. in Statistics&nbsp;from Calcutta University. 
Nakul Aggarwal is a Subject Matter Expert in Computer Vision and Generative AI at Accenture, with around 7 years of experience in developing and delivering cutting-edge solutions across computer vision, multimodal AI, and agentic systems. He holds a Master‚Äôs degree from the Indian Institute of Technology (IIT) Delhi and has authored several research papers presented at international conferences. He holds two patents in AI and currently leads multiple projects focused on multimodal and agentic AI. Beyond technical delivery, he plays a key role in mentoring teams and driving innovation by bridging advanced research with real-world enterprise applications. 
Aramide Kehinde is Global Partner Solutions Architect for Amazon Nova at AWS. She works with high growth companies to build and deliver forward thinking technology solutions using AWS Generative AI. Her experience spans multiple industries, including Media &amp; Entertainment, Financial Services, and Healthcare. Aramide enjoys building the intersection of AI and creative arenas and spending time with her family. 
Rajdeep Banerjee is a Senior Partner Solutions Architect at AWS helping strategic partners and clients in the AWS cloud migration and digital transformation journey. Rajdeep focuses on working with partners to provide technical guidance on AWS, collaborate with them to understand their technical requirements, and designing solutions to meet their specific needs. He is a member of Serverless technical field community. Rajdeep is based out of Richmond, Virginia.
‚Ä¢ Deploy conversational agents with Vonage and Amazon Nova Sonic
  This post is co-written with Mark Berkeland, Oscar Rodriguez and Marina Gerzon from Vonage. 
Voice-based technologies are transforming the way businesses engage with customers across customer support, virtual assistants, and intelligent agents. However, creating real-time, expressive, and highly responsive voice interfaces still requires navigating a complex stack of communication protocols, AI models, and media infrastructure. To simplify this process, Vonage has integrated Amazon Nova Sonic, our speech-to-speech foundation model (FM), with the Vonage Voice API, part of their Communications Platform as a Service (CPaaS) offering. 
With this integration, developers can deploy AI voice agents to enable more human-like voice conversations over phone calls, SIP connections, WebRTC, and mobile apps. The solution makes it straightforward to bring intelligent, real-time conversations into workflows for a variety of use cases, such as a small auto repair shop using voice AI to book appointments and track down parts, a global retail brand handling a high volume of customer service calls, or a developer building a scalable voice interface. 
In this post, we explore how developers can integrate Amazon Nova Sonic with the Vonage communications service to build responsive, natural-sounding voice experiences in real time. By combining the Vonage Voice API with the low-latency and expressive speech capabilities of Amazon Nova Sonic, businesses can deploy AI voice agents that deliver more human-like interactions than traditional voice interfaces. These agents can be used as customer support, virtual assistants, and more. 
Amazon Nova Sonic for real-time conversational AI 
Amazon Nova Sonic is a speech-to-speech FM designed to build real-time conversational AI applications in Amazon Bedrock, with industry-leading price-performance and low latency. Its architecture unifies speech understanding and generation into a single model, to enable more human-like voice conversations in AI applications. The model can understand speech in different speaking styles and generate speech in expressive voices, including both masculine-sounding and feminine-sounding voices. Amazon Nova Sonic can adapt the intonation, prosody, and style of the generated speech response to align with the context and content of the speech input and gracefully handle interruptions. Additionally, Amazon Nova Sonic allows for function calling and knowledge grounding with enterprise data using Retrieval Augmented Generation (RAG). 
Vonage Voice APIs, powered by AI 
Vonage, an AWS partner, provides a developer-friendly platform for building voice, messaging, video, and authentication experiences. With its wide-ranging Voice APIs, Vonage offers WebRTC support, multi-channel communication tools, standard phone call integrations, in-app softphones, front-ending contact centers, and voice-over-browser functionality. The software also offers essential building blocks such as inbound and outbound voice call handling, voicemail support, and programmable logic for call routing and queuing. Vonage‚Äôs solution builder and SDKs allow for fast, low-code integration, while its interoperability with business applications and productivity tools enables teams to embed communication directly into their existing workflows. 
Solution overview 
Vonage collaborated with Amazon Nova Sonic to build low-latency, voice-first applications that can understand and respond like a human agent over standard telephony or WebRTC channels. This new tool can connect inbound and outbound Vonage calls directly to Amazon Nova Sonic for conversational AI processing, using expressive, real-time speech synthesis to deliver fluid, natural interactions. Amazon Nova Sonic‚Äôs integration into Vonage Voice API seamlessly manages audio buffering, custom media infrastructure, and protocol translation, so teams can focus on building engaging experiences. 
With built-in conversation control logic and noise cancellation, Vonage‚Äôs integration with Amazon Nova Sonic makes it straightforward for businesses to rapidly build and deploy responsive AI voice agents. These agents can handle real-time voice conversations and scale voice interactions without relying on traditional contact centers. 
Vonage is making this integration available as a GitHub repository for developers to deploy and customize to their needs. 
‚ÄúAs an AWS Amazon Partner Network (APN) member, Vonage has a long history of working closely with the AWS innovation team to create new solutions to benefit enterprise customers,‚Äù said Christophe Van de Weyer, President and Head of Business Unit API for Vonage. ‚ÄúThis latest collaboration with AWS enables organizations to transform how they engage with customers by adopting generative AI solutions that create added value for internal and external communication. By combining Vonage‚Äôs communications APIs with AWS‚Äôs advanced AI, this new voice AI agent technology enables businesses to streamline the adoption of intelligent agents, accelerate the modernization of legacy voice systems, and provide a robust service to deliver exceptional customer experiences with measurable improvements in satisfaction and operational efficiency.‚Äù 
The following video showcases a demo of Diana, an AI voice agent built using Vonage‚Äôs integration with Amazon Nova Sonic. 

 
  
 
 
The following architecture diagram provides an overview of Amazon Nova Sonic deployed as a voice agent in the Vonage Voice API framework on AWS. 
 
The solution routes different types of incoming calls to Amazon Nova Sonic over a WebSocket connection. The architectural components include (left to right): 
 
 Calls ‚Äì Incoming voice connections that can come from global phone numbers, SIP connections with contact centers or business systems, or WebRTC connections from web browsers and mobile apps. 
 Vonage Voice API ‚Äì Provides programmatic control over these types of calls and voice connections, allowing them to be integrated with AI systems, routed elsewhere, or given speech and other treatments. Because Amazon Nova Sonic is a full speech-to-speech AI service, the real-time voice streams are connected directly, unlike other AI integrations that might use text-based integration. 
 Amazon Nova Sonic connector ‚Äì A Vonage integration that connects calls to Amazon Nova Sonic over a WebSocket connection, providing low-latency, real-time, bi-directional voice streaming directly with Amazon Nova Sonic. The connector also manages voice isolation to better handle noisy environments, conversational elements like ‚Äúbarge in‚Äù where the caller interrupts the conversation, and fallback options if needed. 
 Amazon Nova Sonic ‚Äì Part of the Amazon Nova family of FMs available in Amazon Bedrock. Amazon Nova Sonic unifies speech understanding and generation into a single model, streamlining development and reducing complexity when building conversational applications. 
 Retrieval Augmented Generation (RAG) ‚Äì Tools within Amazon Bedrock that optimize the output of an underlying large language model (LLM). Amazon Nova Sonic can reference enterprise-authorized knowledge sources. Attribution and source visibility can be configured based on customer requirements. 
 Customizable prompt ‚Äì Provided to the AI model and allows the voice agent‚Äôs personality and conversational capabilities to be defined and the right knowledge base to be used. 
 User context ‚Äì Maintained by Amazon Nova Sonic throughout interaction sequences to allow a natural continuous conversation. Personally identifiable information (PII) is processed in real time and not retained by Amazon Nova Sonic. AWS safeguards your data through comprehensive security controls, encryption at rest and in transit, and compliance certifications, while also giving you the flexibility to configure additional logging, security, and compliance measures through AWS services. 
 
These components work together to create a flexible, intelligent voice agent service that can dynamically adapt to different communication scenarios and business use cases with different knowledge bases and prompts. 
Example use cases 
The following are just a few of the high-impact ways businesses are already using this integration to transform voice interactions: 
 
 Customer support automation ‚Äì Deploy voice agents that answer inbound customer queries, take appointments, and escalate calls only when necessary. 
 Proactive outbound calling ‚Äì Generate dynamic, expressive outbound messages like reminders, confirmations, or follow-ups with voicemail fallback. 
 Multilingual voice assistants ‚Äì Build voice experiences that seamlessly switch between English and Spanish depending on the caller, enabled by Vonage‚Äôs language detection and multilingual synthesis with Amazon Nova Sonic. 
 
Conclusion 
By combining Amazon Nova Sonic with Vonage‚Äôs flexible communication infrastructure, developers can build intelligent, responsive AI voice agents. With this solution, you can provide proactive voice engagement, create multilingual assistants, handle customer support, and more. This integration makes voice-first AI applications more accessible and scalable than ever. 
To start building with Amazon Nova Sonic, visit the Amazon Bedrock console. For Vonage integration, explore the Vonage API Developer Portal or use the Vonage Solution Builder to configure your voice agent in minutes. 
To learn more about Amazon Nova Sonic, check out the AWS News Blog, Amazon Nova Sonic product page, or Amazon Bedrock User Guide. 
 
About the authors 
 
 Divyesha Malhotra is a Senior Product Manager Technical Intern on the AGI Nova Sonic team. She leads the customer adoption and integrations of cutting-edge speech-to-speech foundation models for next-generation voice-based technologies. 
 Mark Berkeland is a Senior Solutions Engineer in the API Business Unit at Vonage. He designs and implements technical solutions including demos and proofs of concept to help customers bring voice and messaging applications to life. With a professional programming career that began in 1979, his experience ranges from FORTRAN on punched cards to modern cloud-native stacks like React Native, combining deep technical expertise with a passion for making complex ideas accessible. 
 Oscar Rodriguez&nbsp;is Senior Director of Global Partner Solutions in the API Business Unit at Vonage, where he leads strategic initiatives to empower partners through scalable communications solutions. He brings deep technical expertise and a practical understanding of real-world application development with over 20 years experience in web technologies and the last 10 in CPaaS. 
 Marina Gerzon is a Partner Solutions Architect at Vonage with over 20 years of experience in real-time communications, specializing in Video and Voice over IP solutions. Known for her ability to bridge technical depth with business impact, her work spans Telecom, Education, Healthcare, Fintech, and Insurance industries, where she has consistently delivered enterprise-grade SaaS and PaaS architectures tailored to complex business needs.
‚Ä¢ Enabling customers to deliver production-ready AI agents at scale
  AI agents will change how we all work and live. Our AWS CEO, Matt Garman, shared a vision of a technological shift as transformative as the advent of the internet. I‚Äôm energized by this vision because I‚Äôve witnessed firsthand how these intelligent agent systems are already beginning to solve complex problems, automate workflows, and create new possibilities across industries. With agentic AI, AstraZeneca accelerated healthcare insight discovery, Yahoo Finance transformed financial research for millions of investors, and Syngenta revolutionized agriculture with AI-driven precision farming. 
To expand these early successes into widespread adoption, organizations need a practical approach that addresses the inherent complexity of agentic systems. At AWS, we‚Äôre committed to being the best place to build the world‚Äôs most useful AI agents, empowering organizations to deploy reliable and secure agents at scale. 
We‚Äôre focused on making our agentic AI vision accessible to every organization by combining rapid innovation with a strong foundation of security, reliability, and operational excellence. Our approach accelerates progress by building on proven principles while embracing new possibilities‚Äîcreating systems that can adapt as models evolve, new capabilities emerge, and use cases expand across your business. 
Today, I‚Äôm excited to share how we‚Äôre bringing this vision to life with new capabilities that address the fundamental aspects of building and deploying agents at scale. These innovations will help you move beyond experiments to production-ready agent systems that can be trusted with your most critical business processes. 

 
 A comprehensive foundation for building and deploying production-ready agentic AI systems at scale.
 
Guiding principles, evolved for agents 
At AWS, our approach to agentic AI is shaped by our experience building agent systems internally and helping hundreds of thousands of customers accelerate their AI journeys. Four core principles guide everything we do in this space: 
Principle 1: Embrace agility as a competitive edge 
Organizations that thrive won‚Äôt be those who perfectly predict the future, but those who adapt quickly as it unfolds. Staying nimble requires an agentic architecture that embraces flexibility and openness rather than rigid frameworks or singular models. It means building systems that can incorporate new models as they emerge, connect to your proprietary data sources, and seamlessly integrate with your existing tools. 
The dual need for stability and adaptability led us to create Amazon Bedrock AgentCore,&nbsp;a complete set of services for deploying and operating highly capable agents securely at enterprise scale. AgentCore provides a secure, serverless runtime with complete session isolation and the longest running workload available today, tools and capabilities to help agents execute workflows with the right permissions and context, and controls to operate trustworthy agents. Its capabilities can be used together or independently and work with popular open source frameworks such as CrewAI, LangGraph, LlamaIndex, and Strands Agents and with any model including those in (or outside of) Amazon Bedrock, so developers can stay agile as technology shifts. By reducing the undifferentiated heavy lifting, AgentCore helps organizations move beyond experiments to production-ready agent systems that can be trusted with your most critical business processes. 
Customers like Ita√∫ Unibanco, Innovaccer, Boomi, Box, and Epsilon are already experimenting with AgentCore and are excited about how it speeds their deployment of agents to production. These early adopters recognize that AgentCore helps eliminate the trade-off between open source flexibility and enterprise-grade security and reliability, allowing them to focus on creating business value rather than building security and operational foundations from scratch. 
Principle 2: Evolve fundamentals for the agentic era 
While the core principles of enterprise technology haven‚Äôt changed, how we implement them must evolve for the agentic era. These evolved fundamentals create the foundation that makes production-grade agents possible: 
 
 Security and Trust. Agents introduce new security considerations as they cross system boundaries, perform actions on behalf of users or act themselves with pre-authorized user consent. Trust requires transparency, guardrails, and verification. AgentCore Runtime helps address these with dedicated compute environments per session and memory isolation that helps prevent data leaks across agents,&nbsp;building on a decade of AWS Lambda serverless innovation in security and scalability. 
 Reliability and Scalability. Traditional approaches to scaling software fall short with agentic systems as they follow unpredictable execution paths and have variable resource requirements across interactions. AgentCore Runtime&nbsp;is highly reliable with checkpointing and recovery capabilities to help ensure graceful recovery in case of unexpected interruptions and failures, and it can automatically handle scaling from zero to thousands of concurrent sessions, eliminating capacity planning and infrastructure maintenance. 
 Identity. As agents act on behalf of users and systems, traditional identity models must evolve. Managing permissions of both the agent and the user as agents navigate complex workflows spanning multiple systems becomes critical to securing your data. AgentCore Identity delivers secure agent access across AWS services and third-party applications and tools with temporary, fine-grained permissions, and standards-based authentication. It works with leading identity providers such as Amazon Cognito, Microsoft Entra ID, and Okta, as well as popular OAuth providers such as GitHub, Google, Salesforce, and Slack. 
 Observability. Understanding agent decisions requires new approaches to monitoring. Observability becomes essential not just for troubleshooting, but for compliance and continuous improvement, representing a shift from periodic auditing to constant supervision. AgentCore Observability provides real-time visibility through built-in dashboards and standardized telemetry that integrates with your monitoring stack. 
 Data. Your proprietary data is more valuable than ever, enabling agents to understand your specific context. The ability to securely access, process, and learn from this data becomes a critical differentiator for agent performance and relevance. For example, with AgentCore Gateway, you can transform your data sources including Amazon Bedrock Knowledge Bases into agent-compatible tools so agents can access recent and relevant information. 
 Seamless Integration. Agents must work with everything in your environment: your systems, other clouds, SaaS applications, and other agents. AgentCore Gateway makes it possible by transforming APIs and services into agent-compatible tools with minimal code, eliminating months of integration work while enabling agents to discover and interact with your systems. Our open source Strands Agents SDK complements this with flexible orchestration patterns, and support for MCP and A2A to enable seamless coordination between multiple agents and tools across different environments. AWS API MCP Server gives agents a callable interface to AWS services,&nbsp;enabling&nbsp;foundation models to discover available operations, reason over input and output requirements, and generate plans that invoke AWS APIs to explore, configure, or manage resources with&nbsp;real-time AWS capabilities beyond model training cutoff. 
 Tooling and Capabilities. Agents need specialized tools to execute complex tasks and maintain context across interactions. AgentCore Memory makes it easy for developers to build context-aware agents by eliminating complex memory infrastructure management while providing full control over what the AI agent remembers. It provides industry-leading accuracy along with support for both short-term memory for multi-turn conversations and long-term memory that persists across sessions, with the ability to share memory stores across collaborating agents. Built-in tools include AgentCore Browser for web interactions, enabling agents to navigate websites and perform actions on your behalf, and AgentCore Code Interpreter for executing code securely, allowing agents to process data, generate visualizations, and solve complex problems programmatically. These capabilities extend what agents can do while maintaining security and reliability. 
 
 
Together, these evolved fundamentals help organizations build secure, reliable, and scalable agent architectures that deliver consistent results in production environments. With AgentCore, we‚Äôre helping customers focus on creating value rather than reinventing infrastructure. 
Principle 3: Deliver superior outcomes with model choice and data 
At the heart of every effective agent system lies its foundation model, which powers an agent‚Äôs ability to understand, reason, and act. For agents to deliver transformative experiences, carefully selected and potentially tailored models need to interact with rich, context-specific knowledge that determines how effectively the model can make decisions on your behalf. This reality extends to all AI applications, which is why AWS gives customers both the freedom to choose the optimal model for each use case and the tools to enhance those models with their unique data. This approach delivers superior outcomes and the best price-performance for all AI implementations. 
Model requirements vary widely‚Äîsome applications demand sophisticated reasoning, others require fast responses, and many prioritize cost efficiency at scale. No single model excels across all dimensions, which is why we pioneered model choice with Amazon Bedrock in 2023. But the true differentiator is how you combine models with your organization‚Äôs proprietary data, transforming generic AI into systems with deep domain expertise. 
To help you create models with this high level of expertise, today we‚Äôre expanding our model customization capabilities with the launch of Amazon Nova customization in Amazon SageMaker AI. Nova models now offer customers the flexibility to customize the model across the model development life cycle. This includes pre-training and post-training, including both fine-tuning and alignment, with support for parameter efficient fine-tuning (PEFT) and full fine-tuning. With these, Nova now offers the most comprehensive suite of model customization capabilities made available for any proprietary model family. Using techniques including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), reinforcement learning from human feedback using Proximal Policy Optimization (PPO), Continued Pre-Training (CPT), and Knowledge Distillation, customers can create Nova models optimized for their use-case. Once customized, these models can be deployed directly to Amazon Bedrock, allowing you to seamlessly integrate your custom models into your agent systems and other AI applications. 
We are also training our own models optimized for specific agent use cases.&nbsp;Nova Act is an AI model trained to perform actions within a web browser. Customers can get started with building their own browser automation agents with the&nbsp;Nova Act SDK, purpose-built to enable reliable browser agents powered by the Nova Act model. The Nova Act SDK, available in research preview today, uses AgentCore Browser for scalable, cloud-based browser execution. 
Once you have the right model, you need to ensure it can interact with your organization‚Äôs proprietary and current data. Vectors have emerged as the dominant and fastest way AI models can access your data. Until now, the cost of storing vector embeddings‚Äîthe key to enabling this intelligence‚Äîhas forced organizations to limit their AI systems to recent data only, constraining their potential. Today‚Äôs launch of Amazon S3 Vectors, the first cloud object store with native vector support, marks a fundamental change. By reducing vector storage costs by 90% while maintaining sub-second query performance, S3 Vectors enables agents that remember more, reason deeper, and maintain comprehensive context from every customer interaction, document, and business insight. S3 Vectors integrates directly with Amazon Bedrock Knowledge Bases for cost-effective RAG applications and Amazon OpenSearch Service for tiered vector strategies. 
Principle 4: Deploy solutions that transform experiences 
While models and infrastructure change how organizations build, agentic solutions transform how businesses operate. The true power of agentic AI lies in its ability to reshape workflows and human productivity across entire industries. These solutions free people from routine tasks and handle complex information flows, enabling teams to focus on creative thinking and strategic decisions. We‚Äôre making this transformation accessible to more organizations through pre-built agentic solutions. By combining foundational building blocks with pre-built solutions you can move beyond experiments to comprehensive AI strategies that deliver tangible business impact. 
Today, we‚Äôre announcing that you can now buy AI Agents and Tools in AWS Marketplace, with streamlined procurement and multiple deployment options. In today‚Äôs fragmented AI landscape, AWS Marketplace offers a centralized catalog of curated agents, tools, and solutions from AWS Partners. Fast-track automation with pre-built agents from AWS Partners. Our new API-based deployment method helps you to streamline integrations with other agents and tools that support MCP and A2A. And these agents can run on trusted AWS services or in your AWS environment, where you maintain control over security and access. You can deploy select pre-built agents and tools on AgentCore. 
We‚Äôre also continuing to give customers ready-to-deploy agent solutions that enable this transformation. Kiro is an AI IDE that helps developers go from concept to production with spec-driven development. From simple to complex tasks, Kiro works alongside you to turn prompts into detailed specs‚Äîthen into working code, docs, and tests. So, what you build is exactly what you want and ready to share with your team. Kiro‚Äôs agents help you solve challenging problems and automate tasks like generating documentation and unit tests. With Kiro, you can build beyond prototypes while being in the driver‚Äôs seat every step of the way. AWS Transform deploys specialized AI agents to automate complex modernization tasks like code analysis, refactoring, and dependency mapping, dramatically reducing project timelines for enterprise workload migrations. Each solution shows our commitment to flexibility and choice, helping you innovate faster and realize business outcomes sooner. And Amazon Connect, a comprehensive customer experience solution, enables organizations to delight their customers with unlimited AI on every customer interaction across all channels. 
These four principles guide our product strategy and are embedded in every innovation we‚Äôre announcing today: embracing agility, evolving fundamentals, combining model choice with proprietary data, and deploying transformative solutions. Together, they provide a comprehensive framework for successfully implementing agentic AI in your organization. 
The path forward 
The significant potential for our customers and our own diverse businesses has inspired us to focus on building the most trustworthy agentic AI capabilities on the planet. But the most important advice I can offer is simple: start now. 
Don‚Äôt get trapped trying to boil the ocean or waiting for all the answers before you begin. Pick a specific business problem that matters and get building. The organizations seeing the greatest success aren‚Äôt those with the most ambitious plans, they‚Äôre those who have started the learning cycle, gathering real-world feedback that informs each iteration. To help our customers on their AI journey, we‚Äôre investing another 100 million dollars, doubling our investment, in the AWS Generative AI Innovation Center which has helped thousands of customers across industries including NFL, Yahoo Finance, BMW, and AstraZeneca achieve millions of dollars in productivity gains and transform customer experiences. 
AWS set the standard for security, reliability, and data privacy for cloud computing, and we‚Äôre bringing these same principles to agentic AI. No matter your use case or requirements, AWS provides the right foundation to help you succeed. Together, we can reinvent what‚Äôs possible for your business through the power of agentic AI. 
 
About the author 
Swami Sivasubramanian is Vice President for Agentic AI at Amazon Web Services (AWS). At AWS, Swami has led the development and growth of leading AI services like Amazon DynamoDB, Amazon SageMaker, Amazon Bedrock, and Amazon Q. His team‚Äôs mission is to provide the scale, flexibility, and value that customers and partners require to innovate using agentic AI with confidence and build agents that are not only powerful and efficient, but also trustworthy and responsible. Swami also served from May 2022 through May 2025 as a member of the National Artificial Intelligence Advisory Committee, which was tasked with advising the President of the United States and the National AI Initiative Office on topics related to the National AI Initiative.

‚∏ª