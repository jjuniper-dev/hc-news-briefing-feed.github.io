‚úÖ Morning News Briefing ‚Äì October 07, 2025 10:43

üìÖ Date: 2025-10-07 10:43
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ Current Conditions:  17.5¬∞C
  Temperature: 17.5&deg;C Pressure / Tendency: 101.3 kPa falling Humidity: 81 % Dewpoint: 14.2&deg:C Wind: N 5 km/h Air Quality Health Index: n/a . Pembroke 6:00 AM EDT Tuesday 7 October 2025 Temperature: . Temperature: ¬†17.5/deg;
‚Ä¢ Tuesday: A few showers. High 19.
  A few showers beginning early this morning and ending this afternoon . Risk of a thunderstorm this morning . Cloudy. High 19. UV index 2 or low. High 20.50/20/50/50 . Forecast issued 5:00 AM EDT Tuesday 7 October 2025. Forecast: Showery, rainy, thundery, windy, sunny, breezy,
‚Ä¢ Tuesday night: Clearing. Low plus 3.
  Clearing late this evening. Partly cloudy. Clearing later this evening . Low plus 3.50 percent chance of rain in the morning's rainfall . Forecast issued 5:00 AM EDT Tuesday 7 October 2025. Weather forecast: Rainy, cold, cloudy, sunny, breezy, cloudy and breezy . Rainy showers expected to fall through the night, rainy

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ The Nobel Prize for physics is awarded for discoveries in quantum mechanical tunneling
  Nobel committee: Nobel laureates' work provides opportunities to develop "next generation of quantum technology" Committee: Work provides opportunities for quantum cryptography, quantum computers, and quantum sensors . Nobel committee says work could lead to quantum computing, quantum cryptography and quantum computers . Nobel winners' work will be used to develop next generation of technology, committee says . Back to the page you came from. Share
‚Ä¢ With U.S. leadership in doubt, can its allies chart their own course?
  U.S. allies in Europe and the Indo-Pacific are showing willingness to coordinate and cooperate across a wide range of shared interests, from trade to defense and alliance management to China . China is one of the world's most important allies in the Middle East and Asia, according to the U.N. Secretary of State Hillary Clinton . China's influence in the region has grown in recent
‚Ä¢ Why Democrats are casting the government shutdown as a health care showdown
  Democrats are pressuring Republicans to extend billions of dollars in federal tax credits that have dramatically lowered premiums and contributed to record-low rates of uninsured Americans . The tax credits have helped reduce the number of Americans who are uninsured by lowering their premiums and contributing to record low rates . Democrats are pushing to extend the tax credits, which have helped drive down the rate of uninsured in the U.S.
‚Ä¢ The government has long researched high school experiences. Then DOGE cut the effort
  The federal government has long surveyed high schoolers to help track how their academic choices may have influenced the course of their lives . The Trump administration put an end to that effort . The government has been trying to track how academic choices influenced the lives of high school students for more than a decade . The White House says it will no longer be able to survey students about how their choices affect their
‚Ä¢ A tribe in Arizona planned to connect 600 homes to electricity. Then the funding was cut
  Hopi Tribe received a multimillion-dollar federal grant to install solar panels and battery storage systems for hundreds of homes . But the Trump administration has canceled the funding . The Hopi tribe received a multi-million-dollar grant from the federal government to install panels and storage systems . Hopi tribal members say solar panels will be installed on hundreds of Hopi homes in the tribe's homes

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ No account? No Windows 11, Microsoft says as another loophole snaps shut
  Workaround sent to the big OOBE in the sky with latest Insider builds . Microsoft is closing a popular loophole that allowed users to install Windows 11 without a Microsoft account . The loophole was closed by the end of a popular Windows 11 feature that allows you to install the new software without having an account with Microsoft . Microsoft Insider builds are now available in the wild for the first time .
‚Ä¢ Britain eyes satellite laser warning system and carrier-launched jet drones
  Space sensors and UAVs at sea top MoD's list in new wave of cutting-edge projects . UK pressing ahead with research to protect satellites from laser attack . Technology demonstrator for a jet-powered drone to operate from Royal Navy carriers . MoD also developing technology for a technology demonstrator to operate on Royal Navy aircraft carriers . The UK is pressing ahead to develop a technology
‚Ä¢ UK Home Office opens wallet for ¬£60M automated number plate project
  Department eyes new app to tap national ANPR data for live alerts, searches, and integrations . UK's Home Office is inviting tech suppliers to take part in a ¬£60 million "market engagement" for an application that uses data from automated number plate recognition (ANPR) systems . The application will use data from ANPR systems to make live alerts and search alerts available to the public
‚Ä¢ Google DeepMind minds the patch with AI flaw-fixing scheme
  Google says its AI-powered security repair tool CodeMender has been helping secure open source projects through automated patch creation, subject to human approval . The tool has been generating fixes for vulnerabilities in open-source projects . Google says it has been working with the company to identify vulnerabilities in the open source software . It has been creating fixes for flaws in the software that can be fixed without human
‚Ä¢ Cerebras CEO insists dinner-plate-sized chip startup will still go public
  AI chip startup Cerebras Systems pulled its S-1 IPO filing without so much as an explanation . Inference service launched a month before IPO filing turns out to have been a much bigger business than initially thought . AI chip chip startup pulled its $1.1 billion Series G funding round just days after announcing a $1 billion funding round, Cerebrs pulled its IPO filing .

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ A One Health framework for global and local stewardship across the antimicrobial lifecycle
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Volunteer scientists work ‚Äònights and weekends‚Äô to guide vaccine advice in US
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Exploring the role of green space in mitigating childhood opportunity across the U.S
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ The association between preschoolers‚Äô retinal microcirculation and the indoor microbial environment: results of the ENVIRONAGE birth cohort
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Large language models for autism: evaluating theory of mind tasks in a gamified environment
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ The three big unanswered questions about Sora
  Last week OpenAI released Sora, a TikTok-style app that presents an endless feed of exclusively AI-generated videos, each up to 10 seconds long. The app allows you to create a ‚Äúcameo‚Äù of yourself‚Äîa hyperrealistic avatar that mimics your appearance and voice‚Äîand insert other peoples‚Äô cameos into your own videos (depending on what permissions they set).&nbsp;



To some people who believed earnestly in OpenAI‚Äôs promise to build AI that benefits all of humanity, the app is a punchline. A former OpenAI researcher who left to build an AI-for-science startup referred to Sora as an ‚Äúinfinite AI tiktok slop machine.‚Äù&nbsp;



That hasn‚Äôt stopped it from soaring to the top spot on Apple‚Äôs US App Store. After I downloaded the app, I quickly learned what types of videos are, at least currently, performing well: bodycam-style footage of police pulling over pets or various trademarked characters, including SpongeBob and Scooby Doo; deepfake memes of Martin Luther King Jr. talking about Xbox; and endless variations of Jesus Christ navigating our modern world.&nbsp;



Just as quickly, I had a bunch of questions about what‚Äôs coming next for Sora. Here‚Äôs what I‚Äôve learned so far.



Can it last?



OpenAI is betting that a sizable number of people will want to spend time on an app in which you can suspend your concerns about whether what you‚Äôre looking at is fake and indulge in a stream of raw AI. One reviewer put it this way: ‚ÄúIt‚Äôs comforting because you know that everything you‚Äôre scrolling through isn‚Äôt real, where other platforms you sometimes have to guess if it‚Äôs real or fake. Here, there is no guessing, it‚Äôs all AI, all the time.&#8221;



This may sound like hell to some. But judging by Sora‚Äôs popularity, lots of people want it.&nbsp;



So what‚Äôs drawing these people in? There are two explanations. One is that Sora is a flash-in-the-pan gimmick, with people lining up to gawk at what cutting-edge AI can create now (in my experience, this is interesting for about five minutes). The second, which OpenAI is betting on, is that we‚Äôre witnessing a genuine shift in what type of content can draw eyeballs, and that users will stay with Sora because it allows a level of fantastical creativity not possible in any other app.&nbsp;



There are a few decisions down the pike that may shape how many people stick around: how OpenAI decides to implement ads, what limits it sets for copyrighted content (see below), and what algorithms it cooks up to decide who sees what.&nbsp;



Can OpenAI afford it?



OpenAI is not profitable, but that‚Äôs not particularly strange given how Silicon Valley operates. What is peculiar, though, is that the company is investing in a platform for generating video, which is the most energy-intensive (and therefore expensive) form of AI we have. The energy it takes dwarfs the amount required to create images or answer text questions via ChatGPT.



This isn‚Äôt news to OpenAI, which has joined a half-trillion-dollar project to build data centers and new power plants. But Sora‚Äîwhich currently allows you to generate AI videos, for free, without limits‚Äîraises the stakes: How much will it cost the company?&nbsp;





OpenAI is making moves toward monetizing things (you can now buy products directly through ChatGPT, for example). On October 3, its CEO, Sam Altman, wrote in a blog post that ‚Äúwe are going to have to somehow make money for video generation,‚Äù but he didn‚Äôt get into specifics. One can imagine personalized ads and more in-app purchases.&nbsp;



Still, it‚Äôs concerning to imagine the mountain of emissions might result if Sora becomes popular. Altman has accurately described the emissions burden of one query to ChatGPT as impossibly small. What he has not quantified is what that figure is for a 10-second video generated by Sora. It‚Äôs only a matter of time until AI and climate researchers start demanding it.&nbsp;



How many lawsuits are coming?&nbsp;



Sora is awash in copyrighted and trademarked characters. It allows you to easily deepfake deceased celebrities. Its videos use copyrighted music.&nbsp;



Last week, the Wall Street Journal reported that OpenAI has sent letters to copyright holders notifying them that they‚Äôll have to opt out of the Sora platform if they don‚Äôt want their material included, which is not how these things usually work. The law on how AI companies should handle copyrighted material is far from settled, and it‚Äôd be reasonable to expect lawsuits challenging this.&nbsp;



In last week‚Äôs blog post, Altman wrote that OpenAI is ‚Äúhearing from a lot of rightsholders‚Äù who want more control over how their characters are used in Sora. He says that the company plans to give those parties more ‚Äúgranular control‚Äù over their characters. Still, ‚Äúthere may be some edge cases of generations that get through that shouldn‚Äôt,‚Äù he wrote.



But another issue is the ease with which you can use the cameos of real people. People can restrict who can use their cameo, but what limits will there be for what these cameos can be made to do in Sora videos?&nbsp;



This is apparently already an issue OpenAI is being forced to respond to. The head of Sora, Bill Peebles, posted on October 5 that users can now restrict how their cameo can be used‚Äîpreventing it from appearing in political videos or saying certain words, for example. How well will this work? Is it only a matter of time until someone‚Äôs cameo is used for something nefarious, explicit, illegal, or at least creepy, sparking a lawsuit alleging that OpenAI is responsible?¬†



Overall, we haven‚Äôt seen what full-scale Sora looks like yet (OpenAI is still doling out access to the app via invite codes). When we do, I think it will serve as a grim test: Can AI create videos so fine-tuned for endless engagement that they‚Äôll outcompete ‚Äúreal‚Äù videos for our attention? In the end, Sora isn‚Äôt just testing OpenAI‚Äôs technology‚Äîit‚Äôs testing us, and how much of our reality we‚Äôre willing to trade for an infinite scroll of simulation.
‚Ä¢ This company is planning a lithium empire from the shores of the Great Salt Lake
  BOX ELDER COUNTY, Utah ‚Äì On a bright afternoon in August, the shore on the North Arm of the Great Salt Lake looks like something out of a science fiction film set in a scorching alien world. The desert sun is blinding as it reflects off the white salt that gathers and crunches underfoot like snow at the water‚Äôs edge. In a part of the lake too shallow for boats, bacteria have turned the water a Pepto-Bismol pink. The landscape all around is ringed with jagged red mountains and brown brush. The only obvious sign of people is the salt-encrusted hose running from the water‚Äôs edge to a makeshift encampment of shipping containers and trucks a few hundred feet away.&nbsp;



This otherworldly scene is the test site for a company called Lilac Solutions, which is developing a technology it says will shake up the United States‚Äô efforts to pry control over the global supply of lithium, the so-called ‚Äúwhite gold‚Äù needed for electric vehicles and batteries, away from China. Before tearing down its demonstration facility to make way for its first commercial plant, due online next year, the company invited me to be the first journalist to tour its outpost in this remote area, a roughly two-hour drive from Salt Lake City.



The startup is in a race to commercialize a new way to extract lithium from rocks, called direct lithium extraction (DLE). This approach is designed to reduce the environmental damage caused by the two most common traditional methods of mining lithium: hard-rock mining and brining.&nbsp;



Australia, the world‚Äôs top producer of lithium, uses the first approach, scraping rocks laden with lithium out of the earth so they can be chemically processed into industrial-grade versions of the metal. Chile, the second-largest lithium source, uses the second: It floods areas of its sun-soaked Atacama Desert with water. This results in ponds rich in dissolved lithium, which are then allowed to dry off, leaving behind lithium salts that can be harvested and processed elsewhere.&nbsp;



An intake hose, used to pump water to Lilac Solutions‚Äô demonstration site, snakes into the pink-hued Great Salt Lake.ALEXANDER KAUFMAN




The range of methods known as DLE use lithium brine too, but instead of water-intensive evaporation, they all involve advanced chemical or physical filtering processes that selectively separate out lithium ions. While DLE has yet to take off, its reduced need for water and land has made it a prime focus for companies and governments looking to ramp up production to meet the growing demand for lithium as electric vehicles take off and even bigger batteries are increasingly used to back up power grids. China, which processes more than two-thirds of the world‚Äôs mined lithium, is developing its own DLE to increase domestic production of the raw material. New approaches are still being researched, but nearly a dozen companies are actively looking to commercialize DLE technology now, and some industrial giants already offer basic off-the-shelf hardware.&nbsp;



In August, Lilac completed its most advanced test yet of its technology, which the company says doesn‚Äôt just require far less water than traditional lithium extraction‚Äîit uses a fraction of what other DLE approaches demand.&nbsp;





The company uses proprietary beads to draw lithium ions from water and says its process can extract lithium using a tenth as much water as the alumina sorbent technology that dominates the DLE industry. Lilac also highlights its all-American supply chain. Technology originally developed by Koch Industries, for example, uses some Chinese-made components. Lilac‚Äôs beads are manufactured at the company‚Äôs plant in Nevada.&nbsp;



Lilac says the beads are particularly well suited to extracting lithium where concentrations are low. That doesn‚Äôt mean they could be deployed just anywhere‚Äîthere won‚Äôt be lithium extraction on the Hudson River anytime soon. But Lilac‚Äôs tech could offer significant advantages over what‚Äôs currently on the market. And forgoing plans to become a major producer itself could enable the company to seize a decent slice of global production by appealing to lithium miners companies looking for the best equipment, says Milo McBride, a researcher at the Carnegie Endowment for International Peace who authored a recent report on DLE.&nbsp;



If everything pans out, the pilot plant Lilac builds next to prove its technology at commercial scale could significantly increase domestic supply at a moment when the nation‚Äôs largest proposed lithium project, the controversial hard-rock Thacker Pass mine in Nevada, has faced fresh uncertainty. At the beginning of October, the Trump administration renegotiated a federal loan worth more than $2 billion to secure a 5% ownership stake for the US government.&nbsp;



The blue tank on the left filters the brine from the Great Salt Lake to remove large particles before pumping the lithium-rich water into the ion-exchange systems located in the shipping containers.ALEXANDER KAUFMAN




Despite bipartisan government support, the prospect of opening a deep gash in an unspoiled stretch of Nevada landscape has drawn fierce opposition from conservationists and lawsuits from ranchers and Native American tribes who say the Thacker Pass project would destroy the underground freshwater reservoirs on which they depend. Water shortages in the parched West have also made it difficult to plan on using additional evaporation ponds, the other traditional way of extracting lithium.&nbsp;



Lilac is not the only company in the US pushing for DLE. In California‚Äôs Salton Sea, developers such as EnergySource Minerals are looking to build a geothermal power plant to power a DLE facility pulling lithium from the inland desert lake. And energy giants such as Exxon Mobil, Chevron, and Occidental Petroleum are racing to develop an area in southwestern Arkansas called the Smackover region, where researchers with the US Geological Survey have found as much as 19 million metric tons of untapped lithium in salty underground water. In between, both geographically and strategically, is Lilac: It‚Äôs looking to develop new technology like the California companies but sell its hardware to the energy giants in Arkansas.&nbsp;





The Great Salt Lake isn‚Äôt an obvious place to develop a lithium mine. The Salton Sea boasts lithium concentrations of just under 200 parts per million. Argentina, where Lilac has another test facility, has resources of above 700 parts per million.&nbsp;



Here on the Great Salt Lake? ‚ÄúIt‚Äôs 70 parts per million,‚Äù Raef Sully, Lilac‚Äôs Australia-born chief executive, tells me. ‚ÄúSo if you had a football stadium with 45,000 seats, this would be three people.‚Äù



For Lilac, this is actually a feature of the location. ‚ÄúIt‚Äôs a very, very good demonstration of the capability of our technology,‚Äù Sully says. Showing that Lilac‚Äôs hardware can extract lithium at high purity levels from a brine with low concentration, he says, proves its versatility. That wasn‚Äôt the reason Lilac selected the site, though. ‚ÄúUtah is a mining friendly state,‚Äù says Elizabeth Pond, the vice president of communications. And though the lake water has low concentrations of lithium, extracting the brine simply calls for running a hose into the water, whereas other locations would require digging a well at great cost.&nbsp;



When I accompanied Sully to the test site during my tour, our route following unpaved county roads lined with fields of wild sunflowers. The facility itself is little more than an assortment of converted shipping containers and two mobile trailers, one to serve as the main office and the other as a field laboratory to test samples. It‚Äôs off the grid, relying on diesel generators that the company says will be replaced with propane units once this location is converted to a permanent facility but could eventually be swapped for geothermal technology tapping into a hot rock resource located nearby. (Solar panels, Sully clarifies, couldn‚Äôt supply the 24-7 power supply the facility will need.) But it depends on its connection to the Great Salt Lake via that lengthy hose.&nbsp;



Hardened salt and impurities are encrusted on metal mesh that keeps larger materials out of Lilac‚Äôs water intake system.ALEXANDER KAUFMAN




Pumped uphill, the lake water passes through a series of filters to remove solids until it ends up in a vessel filled with the company‚Äôs specially designed ceramic beads, made from a patented material that attracts lithium ions from the water. Once saturated, the beads are put through an acid wash to remove the lithium. The remaining brine is then repeatedly tested and, once deemed safe to release back into the lake, pumped back down to the shore through an outgoing tube in the hose. The lithium solution, meanwhile, is stockpiled in tanks on site before shipping off to a processing plant to be turned into battery-grade lithium carbonate, which is a white powder.&nbsp;



‚ÄúAs a technology provider in the long term, if we‚Äôre going to have decades of lithium demand, they want to position their technology as something that can tap a bunch of markets,‚Äù McBride says. ‚ÄúTo have a technology that can potentially economically recover different types of resources in different types of environments is an enticing proposition.‚Äù&nbsp;



This testing ground won‚Äôt stay this way for long. During my visit, Lilac‚Äôs crew was starting to pack up the location after completing its demonstration testing. The results the company shared exclusively with me suggest a smashing success, particularly for such low-grade brine with numerous impurities: Lilac‚Äôs equipment recovered 87% of the available lithium, on average, with a purity rate of 99.97%.





The next step will be to clear the area to make way for construction of Lilac‚Äôs first permanent commercial facility at the same site. To meet the stipulations of Utah state permits for the new plant, the company had to cease all operations at the demonstration project. If everything goes according to plan, Lilac‚Äôs first US facility will begin commercial production in the second half of 2027. The company has lined up about two-thirds of its funding for the project. That could make the plant the first new commercial source of lithium in the US to come online in years, and the first DLE facility ever.&nbsp;



Once it‚Äôs fully online, the project should produce 5,000 tons per year‚Äîdoubling annual US production of lithium. But a full-scale plant using Lilac‚Äôs technology would produce between three and five times that amount.&nbsp;



There are some potential snags. Utah regulators this year started cracking down on mineral companies pumping water from the Great Salt Lake, which is shrinking amid worsening droughts. (Lilac says it‚Äôs largely immune to the restrictions since it returns the water to the lake.) While the relatively low concentrations of lithium in the water make for a good test case, full-scale commercial production would likely prove far more economical in a place with more of the metal.&nbsp;



Wild sunflowers line the unpaved county roads that cut through ranching land en route to Lilac Solutions‚Äô remote demonstration site.ALEXANDER KAUFMAN




‚ÄúThe Great Salt Lake is probably the worst possible place to be doing this, because there are real challenges around pulling water from the lake,‚Äù says Ashley Zumwalt-Forbes, a mining engineer who previously served as the deputy director of battery minerals at the Department of Energy. ‚ÄúBut if it‚Äôs just being used as a trial for the technology, that makes sense.‚Äù&nbsp;



What makes Lilac stand out among its peers is that it has no plans to design and manufacture its own DLE equipment and produce actual lithium. Lilac wants instead to sell its technology to others. The pilot plant is just intended to test and debut its hardware. Sully tells me it‚Äôs being built under a separate limited-liability corporation to make a potential sale easier if it‚Äôs successful.&nbsp;



It‚Äôs an unusual play in the lithium industry. Once most companies see success with their technology, ‚Äúthey go crazy and think they can vertically integrate and at the same time be a miner and an energy producer,‚Äù Kwasi Ampofo, the head of minerals and metals at the energy consultancy BloombergNEF, tells me.&nbsp;



‚ÄúLilac is trying to be a technology vendor,‚Äù he says. ‚ÄúI wonder why a lot more people aren‚Äôt choosing that route.‚Äù&nbsp;



If things work out the right way, Sully says, Lilac could become the vendor of choice to projects like the oil-backed sites in the Smackover and beyond.&nbsp;



‚ÄúWe think our technology is the next generation,‚Äù he says. ‚ÄúAnd if we end up working with an Exxon or a Chevron or a Rio Tinto, we want to be the DLE technology provider in their lithium project.‚Äù
‚Ä¢ The Download: introducing the 10 climate tech companies to watch for 2025
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



Introducing: 10 climate tech companies to watch



Every year, the MIT Technology Review newsroom produces a list of some of the most promising climate tech firms on the planet. It‚Äôs an exercise that we hope brings positive attention to companies working to decarbonize major sectors of the economy, whether by spinning up new, cleaner sources of energy or reinventing how we produce foods and distribute goods.Though the political and funding landscape has shifted dramatically in the US since last year, nothing has altered the urgency of the climate dangers the world now faces‚Äîwe need to rapidly curb greenhouse gas emissions to avoid the most catastrophic impacts of climate change. This project highlights the firms making progress toward that end.Check out the third annual edition of the list, and learn more about why we selected these companies.







Our best weapon against climate change is ingenuity



‚ÄîBill Gates is a technologist, business leader, and philanthropist.It‚Äôs a foregone conclusion that the world will not meet the goals for limiting emissions and global warming laid out in the 2015 Paris Agreement. Many people want to blame politicians and corporations for this failure, but there‚Äôs an even more fundamental reason: We don‚Äôt have all the technological tools we need to do it, and many of the ones we do have are too expensive.



But I don‚Äôt think this is a reason to be pessimistic. I see it as cause for optimism, because humans are very good at inventing things. In fact, we‚Äôve already created many tools that are reducing emissions. And I am confident that more positive changes are coming. Read the full story.







Another effort to track ICE raids was just taken offline



People over Papers, a crowd-sourcing project that maps sightings of immigration agents, was taken offline yesterday by Padlet, the collaborative bulletin board platform on which it was built.¬†



It‚Äôs just the latest ICE-tracking initiative to be pulled by tech platforms in the past few days, including the ICEBlock app that was removed from app stores last week and the Stop ICE Raids Alert Network. Read the full story.‚ÄîEileen Guo







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 ICE wants to build a social media surveillance squad¬†Contractors will sift through social content searching for information to aid arrests and deportations. (Wired $)+ A US citizen with stage four cancer has been deported. (The Guardian)



2 xAI is building massive data centers in MemphisWhich isn‚Äôt great news for disgruntled locals. (WSJ $)+ Data centers are big business in Europe right now. (Bloomberg $)+ The data center boom in the desert. (MIT Technology Review)



3 Ukraine‚Äôs front lines are fighting deadly infectionsBacteria that are resistant to multiple antibiotics are infiltrating the country. (Knowable Magazine)+ Why tiny viruses could be our best bet against antimicrobial resistance. (MIT Technology Review)



4 A Silicon Valley school asked its students to draft an AI policyMountain View High School thinks involving kids is the best way forward. (WP $)+ Elsewhere, a school in Texas is letting AI guide its entire curriculum. (CBS News)+ AI‚Äôs giants want to take over the classroom. (MIT Technology Review)



5 These countries hope to benefit from the US visa crackdownSkilled engineers from overseas are looking beyond America for new opportunities. (FT $)+ India hopes its skilled workers living abroad will return home. (BBC)



6 How an empty Chinese city became a self-driving testbedOrdos has everything that self-driving cars need‚Äîexcept humans. (Rest of World)+ Why China‚Äôs self-driving industry is pushing into Europe. (Reuters)



7 How to talk to cows A wave of high-tech AI-powered collars is the closest we‚Äôve got. (NYT $)+ Scientists are trying to get cows pregnant with synthetic embryos. (MIT Technology Review)



8 Technology is full of fascinating records Strongest robotic arm, anyone? (IEEE Spectrum)



9 Posting a simple Instagram photo is no longer enoughThe app keeps pushing us to ‚Äòcontentify‚Äô everything. (The Verge)



10 Japanese beer brand Asahi has resumed production¬†After a huge cyber attack forced its breweries offline. (BBC)+ But we don‚Äôt know when its plants will return to full capacity. (Reuters)







Quote of the day



‚ÄúYou‚Äôll never have a human trafficked AI girl.‚Äù



‚ÄîSteve Jones, who runs an AI porn site, explains how he sees the ethics of his endeavor to the Guardian.







One more thing







The race to fix space-weather forecasting before next big solar storm hitsAs the number of satellites in space grows, and as we rely on them for increasing numbers of vital tasks on Earth, the need to better predict stormy space weather is becoming more and more urgent.Scientists have long known that solar activity can change the density of the upper atmosphere. But it‚Äôs incredibly difficult to precisely predict the sorts of density changes that a given amount of solar activity would produce.Now, experts are working on a model of the upper atmosphere to help scientists to improve their models of how solar activity affects the environment in low Earth orbit. If they succeed, they‚Äôll be able to keep satellites safe even amid turbulent space weather, reducing the risk of potentially catastrophic orbital collisions. Read the full story.



‚ÄîTereza Pultarova







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ I love this website showcasing madcap music genres (thanks Rachel!)+ It‚Äôs not just you‚Äîworld records really are getting harder to beat.+ If you‚Äôve ever wanted to play Snake in a url bar, now‚Äôs your chance (warning, it‚Äôs hard!)+ Fall is here, and the photos are already breathtaking ($)
‚Ä¢ 2025 Climate Tech Companies to Watch
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Bill Gates: Our best weapon against climate change is ingenuity
  It‚Äôs a foregone conclusion that the world will not meet the goals for limiting emissions and global warming laid out in the 2015 Paris Agreement. Many people want to blame politicians and corporations for this failure, but there‚Äôs an even more fundamental reason: We don‚Äôt have all the technological tools we need to do it, and many of the ones we do have are too expensive.



For all the progress the world has made on renewable energy sources, electric vehicles, and electricity storage, we need a lot more innovation on every front‚Äîfrom discovery to deployment‚Äîbefore we can hope to reach our ultimate goal of net-zero emissions.&nbsp;



But I don‚Äôt think this is a reason to be pessimistic. I see it as cause for optimism, because humans are very good at inventing things. In fact, we‚Äôve already created many tools that are reducing emissions. In just the past 10 years, energy breakthroughs have lowered the global forecast for emissions in 2040 by 40%. In other words, because of the human capacity to innovate, we are on course to reduce emissions substantially by 2040 even if nothing else changes.



And I am confident that more positive changes are coming. I‚Äôve been learning about global warming and investing in ideas to stop it for the past 20 years. I‚Äôve connected with unbiased scientists and innovators who are committed to preventing a climate disaster. Ten years ago, some of them joined me in creating Breakthrough Energy, an investment group whose sole purpose is to accelerate clean energy innovation. We‚Äôve supported more than 150 companies so far, many of which have blossomed into major businesses such as Fervo Energy and Redwood Materials, two of this year‚Äôs Companies to Watch. [Editor‚Äôs note: Mr. Gates did not participate in the selection process of this year‚Äôs companies and was not aware that two Breakthrough investments had been selected when he agreed to write this essay.]



Yet climate technologies offer more than just a public good. They will remake virtually every aspect of the world‚Äôs economy in the coming years, transforming energy markets, manufacturing, transportation, and many types of industry and food production. Some of these efforts will require long-term commitments, but it‚Äôs important that we act now. And what‚Äôs more, it‚Äôs already clear where the opportunities lie.&nbsp;



In the past decade, an ecosystem of thousands of innovators, investors, and industry leaders has emerged to work on every aspect of the problem. This&nbsp;year‚Äôs list of 10 Climate Tech Companies to Watch shows just a few of the many examples.



Although much of this innovation ecosystem has matured on American shores, it has become a global movement that won‚Äôt be stopped by new obstacles in the US. It‚Äôs unfortunate that governments in the US and other countries have decided to cut funding for climate innovations and reverse some of the policies that help breakthrough ideas get to scale. In this environment, we need to be more rigorous than ever about spending our time, money, and ingenuity on efforts that will have the biggest impact.



How do we figure out which ones those are? First, by understanding which activities are responsible for the most emissions. I group them into five categories: electricity generation, manufacturing, transportation, agriculture, and heating and cooling for buildings.







Of course, the zero-carbon tools we have today aren‚Äôt distributed evenly across these sectors. In some sectors, like electricity, we‚Äôve made a great deal of progress. In others, like agriculture and manufacturing, we‚Äôve made much less. To compare progress across the board, I use what I call the Green Premium, which is the difference in cost between the clean way of doing something and the conventional way that produces emissions.&nbsp;



For example, sustainable aviation fuel now costs more than twice as much as conventional jet fuel, so it has a Green Premium of over 100%. Solar and wind power have grown quickly because in many cases they‚Äôre cheaper than conventional sources of electricity‚Äîthat is, they have a negative Green Premium.&nbsp;



The Green Premium isn‚Äôt purely financial. To be competitive, clean alternatives also need to be as practical as what they‚Äôre replacing. Far more people will buy EVs once you can charge one up as quickly as you can fill your tank with gasoline.







I think the Green Premium is the best way to identify areas of great impact. Where it‚Äôs high, as in the case of jet fuel, we need innovators and investors to jump on the problem. Where it‚Äôs low or even negative, we need to overcome the barriers that are keeping the technologies from reaching a global scale.



A new technology has to overcome a lot of challenges to beat the incumbents, but being able to compete on cost is absolutely essential. So if I could offer one piece of advice to every company working on zero-carbon technologies, it would be to focus on lowering and eliminating the Green Premium in whatever sector you‚Äôve chosen. Think big. If your technology can be competitive enough to eventually eliminate at least 1% of global emissions per year‚Äîthat‚Äôs 0.5 gigatons‚Äîyou‚Äôre on the right track.



I‚Äôd encourage policymakers to bring this sector-by-sector focus on the Green Premium to their work, too. They should also protect funding for clean technologies and the policies that promote them. This is not just a public good: The countries that win the race to develop these breakthroughs will create jobs, hold enormous economic power for decades to come, and become more energy independent.



In addition, young scientists and entrepreneurs should think about how they can put their skills toward these challenges. It‚Äôs an exciting time‚Äîthe people who begin a career in clean technology today will have an enormous impact on human welfare. If you need pointers, the Climate Tech Atlas published last month by Breakthrough Energy and other partners is an excellent guide to the technologies that are essential for decarbonizing the economy and helping people adapt to a warmer climate.



Finally, I‚Äôd encourage investors to put serious money into companies with technologies that can meaningfully reduce the Green Premium. Consider it an investment in what will be the biggest growth industry of the 21st century. Companies have made dramatic progress on better and cleaner solutions in every sector; what many of them need now is private-sector capital and partnerships to help them reach the scale at which they‚Äôll have a real impact on emissions.



So if I could offer one piece of advice to every company working on zero-carbon technologies, it would be to focus on lowering and eliminating the Green Premium in whatever sector you‚Äôve chosen. 



Transforming the entire physical economy is an unprecedented task, and it can only be accomplished through markets‚Äîby supporting companies with breakthrough ideas that beat fossil fuels on cost and practicality. It‚Äôs going to take investors who are both patient and willing to accept the risk that some companies will fail. Of course, governments and nonprofits have a role in the energy transition too, but ultimately, our success will hinge on climate innovators‚Äô ability to build profitable companies.&nbsp;



If we get this right‚Äîand I believe we will‚Äîthen in the next decade, we‚Äôll see fewer news stories about missed emissions targets and more stories about how emissions are dropping fast because the world invented and deployed breakthrough ideas: clean liquid fuels that power passenger jets and cargo ships; neighborhoods built with zero-emissions steel and cement; fusion plants that generate an inexhaustible supply of clean electricity.&nbsp;



Not only will emissions fall faster than most people expect, but hundreds of millions of people will be able to get affordable, reliable clean energy‚Äîwith especially dramatic improvements for low-income countries. More people will have access to air-conditioning for extremely hot days. More children will have lights so they can do their homework at night. More health clinics will be able to keep their vaccines cold so they don‚Äôt spoil. We‚Äôll have built an economy where everyone can prosper.



Of course, climate change will still present many challenges. But the advances we make in the coming years can ensure that everyone gets a chance to live a healthy and productive life no matter where they‚Äôre born, and no matter what kind of climate they‚Äôre born into.



Bill Gates is a technologist, business leader, and philanthropist. In 1975, he cofounded Microsoft with his childhood friend Paul Allen, and today he is chair of the Gates Foundation, a nonprofit fighting poverty, disease, and inequity around the world. Bill is the founder of Breakthrough Energy, an organization focused on advancing clean energy innovation, and TerraPower, a company developing groundbreaking nuclear energy and science technologies. He has three children.

üîí Cybersecurity & Privacy
No updates.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Ideas: More AI-resilient biosecurity with the Paraphrase Project
  Behind every emerging technology is a great idea propelling it forward. In the Microsoft Research Podcast series Ideas, members of the research community at Microsoft discuss the beliefs that animate their research, the experiences and thinkers that inform it, and the positive human impact it targets.



AI has been described as a ‚Äúdual use‚Äù technology: the capabilities that can be leveraged for good can also potentially be used to cause harm. In this episode, Microsoft Chief Scientific Officer Eric Horvitz and his guests‚ÄîBruce Wittmann, a senior applied scientist at Microsoft; Tessa Alexanian (opens in new tab), a technical lead at the International Biosecurity and Biosafety Initiative for Science (IBBIS);&nbsp;and James Diggans (opens in new tab), a vice president at Twist Bioscience‚Äîexplore this idea in the context of AI-powered protein design.



With Horvitz at the lead, Alexanian, Diggans, and Wittmann were part of a cross-sector team that demonstrated toxic protein candidates could be designed with help from AI‚Äîand that they could bypass the systems in place to defend against their creation. The project, known as the Paraphrase Project, culminated in a cybersecurity-style response, a more robust protein screening system, and a modified approach to peer review with implications for how we think about and tackle AI risk more broadly. The work was recently published in Science.








Learn more:




Strengthening nucleic acid biosecurity screening against generative protein design toolsPublication | October 2025



Toward AI-Resilient Screening of Nucleic Acid Synthesis Orders: Process, Results, and RecommendationsPreprint | December 2024



The Paraphrase Project: Designing defense for an era of synthetic biologyMicrosoft Research Blog | October 2025



When AI meets biology: Promise, risk, and responsibilityMicrosoft Research Blog | Eric Horvitz | October 2025



Paraphrase ProjectProject homepage










	
		
			Subscribe to the Microsoft Research Podcast:		
		
							
					
						  
						Apple Podcasts
					
				
			
							
					
						
						Email
					
				
			
							
					
						
						Android
					
				
			
							
					
						
						Spotify
					
				
			
							
					
						
						RSS Feed
					
				
					
	




	
		
			
				
					

Transcript



[MUSIC]



ERIC HORVITZ: You‚Äôre&nbsp;listening to&nbsp;Ideas, a Microsoft Research Podcast that dives deep into the world of technology research and the profound questions behind the code.&nbsp;I‚Äôm&nbsp;Eric Horvitz, Microsoft‚Äôs chief scientific officer, and in this series, we explore the technologies shaping our future and the&nbsp;big ideas&nbsp;that propel them forward.



[MUSIC FADES]



Today,&nbsp;I‚Äôm&nbsp;excited to talk about the Paraphrase Project, an effort I co-led exploring how&nbsp;advances in&nbsp;AI tools&nbsp;for protein design&nbsp;might&nbsp;impact&nbsp;biosecurity. The results were reported in our recent paper,&nbsp;‚ÄúStrengthening nucleic acid biosecurity screening against generative protein design tools,‚Äù (opens in new tab)&nbsp;published in&nbsp;Science&nbsp;on Oct. 2.&nbsp;



Joining me are&nbsp;three&nbsp;of the larger set of&nbsp;coauthors on that paper:&nbsp;Bruce Wittmann, senior applied scientist at Microsoft;&nbsp;James&nbsp;Diggans, vice president at Twist Bioscience and chair of the board for the International Gene Synthesis Consortium;&nbsp;and Tessa Alexanian, technical lead at the International Biosecurity and Biosafety Initiative for Science, also known as IBBIS.&nbsp;



				
				
					



Now, let‚Äôs&nbsp;rewind two years.&nbsp;Almost to&nbsp;the day, Bruce and I uncovered a vulnerability. While preparing a case study for a workshop on AI and biosecurity, we discovered that open-source AI protein design tools could be used to redesign toxic proteins in ways that could bypass biosecurity screening systems, systems set up to&nbsp;identify&nbsp;incoming orders of concern.&nbsp;



Now in that work, we&nbsp;created an AI pipeline from open-source tools that could&nbsp;essentially ‚Äúparaphrase‚Äù the amino acid sequences‚Äîreformulating&nbsp;them while&nbsp;working to&nbsp;preserve&nbsp;their structure and potentially their function.&nbsp;



These paraphrased sequences could evade the screening systems used by major DNA&nbsp;synthesis companies, and these are the systems that scientists rely on to safely produce AI-designed proteins.&nbsp;



Now, experts in the field described this finding as the first ‚Äúzero day‚Äù for AI and biosecurity.&nbsp;And this&nbsp;marked the beginning of a deep, two-year collaborative effort to investigate and address this challenge.&nbsp;



With the help of a&nbsp;strong&nbsp;cross-sector team‚Äîincluding James, Tessa, Bruce, and many others‚Äîwe worked behind the scenes to build AI biosecurity&nbsp;red-teaming approaches,&nbsp;probe for vulnerabilities, and to design practical fixes. These ‚Äúpatches,‚Äù akin to those in cybersecurity,&nbsp;have now been shared with&nbsp;organizations&nbsp;globally to strengthen biosecurity screening.&nbsp;



This has been one of the most fascinating projects&nbsp;I‚Äôve&nbsp;had the privilege to work on, for its technical complexity, its ethical and policy dimensions, and the remarkable collaboration across industry, government, and nonprofit sectors.&nbsp;



The project highlights that the&nbsp;same AI tools capable of&nbsp;incredible&nbsp;good can also be misused, requiring us to be vigilant, thoughtful, and creative so we continue to get the most benefit out of AI tools while working to ensure&nbsp;that&nbsp;we avoid costly misuses.&nbsp;



With that, let me officially welcome our guests.



Bruce, James, Tessa, welcome to the podcast.



BRUCE WITTMANN: Thanks, Eric.



JAMES DIGGANS: Thanks for having us.



HORVITZ: It&#8217;s been such a pleasure working closely with each of you, not only for your expertise but also for your deep commitment and passion about public health and global safety.



Before we dive into the technical side of things, I&#8217;d like to ask each of you, how did you get into this field? What inspired you to become biologists and then pursue the implications of advances in AI for biosecurity? Bruce?



WITTMANN:&nbsp;Well, I&#8217;ve always liked building things. That&#8217;s where I would say I come from. You know, my hobbies when I&#8217;m not working on biology or AI things‚Äîas you know, Eric‚Äîis, like, building things around the house, right. Doing construction. That kind of stuff.



But my broader interests have always been biology, chemistry. So I originally got into organic chemistry. I found that was fascinating. From there, went to synthetic biology, particularly metabolic engineering, because that&#8217;s kind of like organic chemistry, but you&#8217;re wiring together different parts of an organism‚Äôs metabolism rather than different chemical reactions. And while I was working in that space, I, kind of, had the thought of there&#8217;s got to be an easier way to do this [LAUGHS] because it is really difficult to do any type of metabolic engineering. And that&#8217;s how I got into the AI space, trying to solve these very complicated biological problems, trying to build things that we don&#8217;t necessarily even understand using our understanding from data or deriving understanding from data.



So, you know, that&#8217;s the roundabout way of how I got to where I am‚Äîthe abstract way of how I got to where I am.



HORVITZ: And, Tessa, what motivated you to jump into this area and zoom into biology and biosciences and helping us to avoid catastrophic outcomes?



ALEXANIAN: Yeah, I mean, probably the origin of me being really excited about biology is actually a book called [The] Lives of [a] Cell (opens in new tab) by Lewis Thomas, which is an extremely beautiful book of essays that made me be like, Oh, wow, life is just incredible. I think I read it when I was, you know, 12 or 13, and I was like, Life is incredible. I want to work on this. This is the most beautiful science, right. And then I, in university, I was studying engineering, and I heard there was this engineering team for engineering biology‚Äîthis iGEM (opens in new tab) team‚Äîand I joined it, and I thought, Oh, this is so cool. I really got to go work in this field of synthetic biology.



And then I also tried doing the wet lab biology, and I was like, Oh, but I don&#8217;t like this part. I don&#8217;t actually, like, like babysitting microbes. [LAUGHTER] I think there&#8217;s a way ‚Ä¶ some people who are great wet lab biologists are made of really stern stuff. And they really enjoy figuring out how to redesign their negative controls so they can figure out whether it was contamination or whether it was, you know, temperature fluctuation. I&#8217;m not that, apparently.



And so I ended up becoming a lab automation engineer because I could help the science happen, but I ‚Ä¶ but my responsibilities were the robots and the computers rather than the microbes, which I find a little bit intransigent.



HORVITZ: Right. I was thinking of those tough souls; they also used their mouths to do pipetting and so on of these contaminated fluids ‚Ä¶



WITTMANN: Not anymore. ALEXANIAN: It&#8217;s true. [LAUGHTER]



DIGGANS: Not anymore. [LAUGHS]



ALEXANIAN: They used to be tougher. They used to be tougher.



HORVITZ: James.



DIGGANS: So I did my undergrad in computer science and microbiology, mostly because at the time, I couldn&#8217;t pick which of the two I liked more. I liked them both. And by the time I graduated, I was lucky enough that I realized that the intersection of the two could be a thing. And so I did a PhD in computational biology, and then I worked for five years at the MITRE Corporation. It‚Äôs a nonprofit. I got the chance to work with the US biodefense community and just found an incredible group of people working to protect forces and the population at large from biological threats and just learned a ton about both biology and also dual-use risk. And then so when Twist called me and asked if I wanted to join Twist and set up their biosecurity program, I leapt at the chance and have done that for the past 10 years.



HORVITZ: Well, thanks everyone.



I believe that AI-powered protein design in particular is one of the most exciting frontiers of modern science. It holds promise for breakthroughs in medicine, public health, even material science. We&#8217;re already seeing it lead to new vaccines, novel therapeutics, and‚Äîon the scientific front‚Äîpowerful insights into the machinery of life.



So there&#8217;s much more ahead, especially in how AI can help us promote wellness, longevity, and the prevention of disease. But before we get too far ahead, while some of our listeners work in bioscience, many may not have a good understanding of some of the foundations.



So, Bruce, can you just give us a high-level overview of proteins? What are they? Why are they important? How do they figure into human-designed applications?



WITTMANN: Sure. Yeah. Fortunately, I used to TA a class on AI for protein design, so it‚Äôs right in my wheelhouse. [LAUGHS]



HORVITZ: Perfect, perfect background. [LAUGHS]



WITTMANN:&nbsp;It&#8217;s perfect. Yeah. I got to go back to all of that. Yeah, so from the very basic level, proteins are the workhorses of life.



Every chemical reaction that happens in our body‚Äîwell, nearly every chemical reaction that happens in our body‚Äîmost of the structure of our cells, you name it. Any life process, proteins are central to it.



Now proteins are encoded by what are known as ‚Ä¶ well, I shouldn&#8217;t say encoded. They are constructed from what are called amino acids‚Äîthere are 20 of them‚Äîand depending on the combination and order in which you string these amino acids together, you get a different protein sequence. So that&#8217;s what we mean when we say protein sequence.



The sequence of a protein then determines what shape that protein folds into in a cell, and that shape determines what the protein does. So we will often say sequence determines structure, which determines function.



Now the challenge that we face in engineering proteins is just how many possibilities there are. For all practical purposes, it&#8217;s infinite. So we have 20 building blocks. There are on average around 300 amino acids in a protein. So that&#8217;s 20 to the power of 300 possible combinations. And a common reference point is that it&#8217;s estimated there are around 10 to the 80 particles in the observable universe. So beyond astronomical numbers of possible combinations that we could have, and the job of a protein engineer is to find that one or a few of the proteins within that space that do what we want it to do.



So when a human has an idea of, OK, here&#8217;s what I want a protein to do, we have various techniques of finding that desired protein, one of which is using artificial intelligence and trying to either sift through that milieu of potential proteins or, as we&#8217;ll talk about more in this podcast, physically generating them. So creating them in a way, sampling them out of some distribution of reasonable proteins.



HORVITZ: Great. So I wanted to throw it to James now to talk about how protein design goes from computer to reality‚Äîfrom in silico to test tubes. What role does Twist Bioscience (opens in new tab) play in transforming digital protein designs into synthesized proteins? And maybe we can talk also about what safeguards are in place at your company and why do we need them.



DIGGANS: So all of these proteins that Bruce has described are encoded in DNA. So the language that our cells use to kind of store the information about how to make these proteins is all encoded in DNA. And so if you as an engineer have designed a protein and you want to test it to see if it does what you think it does, the first step is to have the DNA that encodes that protein manufactured, and companies like Twist carry out that role.



So we are cognizant also, however, that these are what are called dual-use technologies. So you can use DNA and proteins for an incredible variety of amazing applications. So drug development, agricultural improvements, bioindustrial manufacturing, all manner of incredible applications. But you could also potentially use those to cause harm so toxins or other, you know, sort of biological misuse.



And so the industry has since at least 2010 recognized that they have a responsibility to make sure that when we&#8217;re asked to make some sequence of DNA that we understand what that thing is encoding and who we&#8217;re giving it for. So we&#8217;re screening both the customer that&#8217;s coming to us and we&#8217;re screening the sequence that they&#8217;re requesting.



And so Twist has long invested in a very, sort of, complicated system for essentially reverse engineering the constructs that we&#8217;re asked to make so that we understand what they are. And then a system where we engage with our customers and make sure that they&#8217;re going to use those for legitimate purpose and responsibly.



HORVITZ: And how do the emergence of these new generative AI tools influence how you think about risk?



DIGGANS: A lot of the power of these AI tools is they allow us to make proteins or design proteins that have never existed before in nature to carry out functions that don&#8217;t exist in the natural world. That&#8217;s an extremely powerful capability.



But the existing defensive tools that we use at DNA synthesis companies generally rely on what&#8217;s called homology, similarity to known naturally occurring sequences, to determine whether something might pose risk. And so AI tools kind of break the link between those two things.



HORVITZ: Now you also serve as chair of the International Gene Synthesis Consortium (opens in new tab). Can you tell us a little bit more about the IGSC, its mission, how it supports global biosecurity?



DIGGANS: Certainly. So the IGSC was founded in 2010[1] and right now has grown to more than 40 companies and organizations across 10 countries. And the IGSC is essentially a place where companies who might be diehard competitors in the market around nucleic acid synthesis come together and design and develop best practices around biosecurity screening to, kind of, support the shared interest we all have in making sure that these technologies are not subject to misuse.



HORVITZ: Thanks, James. Now, Tessa, your organization, IBBIS (opens in new tab) is focused‚Äîit&#8217;s a beautiful mission‚Äîon advancing science while minimizing catastrophic risk, likelihood of catastrophic risk. When we say catastrophic risk, what do we really mean, Tessa, in the context of biology and AI? And how is that ‚Ä¶ do you view that risk landscape as evolving as AI capabilities are growing?



ALEXANIAN: I think the ‚Ä¶ to be honest, as a person who&#8217;s been in biosecurity for a while, I&#8217;ve been surprised by how much of the conversation about the risks from advances in artificial intelligence has centered on the risk of engineered biological weapons and engineered pandemics.



Even recently, there was a new discussion on introducing redlines for AI that came up at the UN General Assembly. And the very first item they list in their list of risks, if I&#8217;m not mistaken, was engineered pandemics, which is exactly the sort of thing that people fear could be done, could be done with these biological AI tools.



Now, I think that when we talk about catastrophic risk, we talk about, you know, something that has an impact on a large percentage of humanity. And I think the reason that we think that biotechnologies pose a catastrophic risk is that we believe there, as we&#8217;ve seen with many historical pandemics, there&#8217;s a possibility for something to emerge or be created that is beyond our society&#8217;s ability to control.



You know, there were a few countries in COVID that managed to more or less successfully do a zero-COVID policy, but that was not, that was not most countries. That was not any of the countries that I lived in. And, you know, we saw millions of people die. And I think we believe that with something like the 1918 influenza, which had a much higher case fatality rate, you could have far more people die.



Now, why we think about this in the context of AI and where this connects to DNA synthesis is that, you know, there is a ‚Ä¶ these risks of both, sort of, public health risks, pandemic risks, and misuse risks‚Äîpeople deliberately trying to do harm with biology, as we&#8217;ve seen from the long history of biological weapons programs‚Äîyou know, we think that those might be accelerated in a few different ways by AI technology, both the potential ‚Ä¶ and I say potential here because as everyone who has worked in a wet lab‚Äîwhich I think is everyone on this call‚Äîknows, engineering biology is really difficult. So there&#8217;s maybe a potential for it to become easier to develop biological technology for the purposes of doing harm, and there&#8217;s maybe also the potential to create novel threats.



And so I think people talk about both of those, and people have been looking hard for possible safeguards. And I think one safeguard that exists in this biosecurity world that, for example, doesn&#8217;t exist as cleanly in the cybersecurity world is that none of these biological threats can do harm until they are realized in physical reality, until you actually produce the protein or produce the virus or the microorganism that could do harm. And so I think at this point of production, both in DNA synthesis and elsewhere, we have a chance to introduce safeguards that can have a really large impact on the amount of risk that we&#8217;re facing‚Äîas long as we develop those safeguards in a way that keeps pace with AI.



HORVITZ: Well, thanks, Tessa. So, Bruce, our project began when I posed a challenge to you of the form: could current open-source AI tools be tasked with rewriting toxic protein sequences in a way that preserves their native structure, and might they evade today&#8217;s screening systems?



And I was preparing for a global workshop on AI and biosecurity that I&#8217;d been organizing with Frances Arnold, David Baker, and Lynda Stuart, and I wanted a concrete case study to challenge attendees. And what we found was interesting and deeply concerning.



So I wanted to dive in with you, Bruce, on the technical side. Can you describe some about the generative pipeline and how it works and what you did to build what we might call an AI and biosecurity red-teaming pipeline for testing and securing biosecurity screening tools?



WITTMANN: Sure. Yeah. I think the best place to start with this is really by analogy.



An analogy I often use in this case is the type of image generation AI tools we&#8217;re all familiar with now where I can tell the AI model, &#8220;Hey, give me a cartoonish picture of a dog playing fetch.&#8221; And it&#8217;ll do that, and it&#8217;ll give us back something that is likely never been seen before, right. That exact image is new, but the theme is still there. The theme is this dog.



And that&#8217;s kind of the same technology that we&#8217;re using in this red-teaming pipeline. Only rather than using plain language, English, we&#8217;re passing in what we would call conditioning information that is relevant to a protein.



So our AI models aren&#8217;t at the point yet where I can say, &#8220;Give me a protein that does x.&#8221; That would be the dream. We&#8217;re a long way from that. But what instead we do is we pass in things that match that theme that we&#8217;re interested in. So rather than saying, &#8220;Hey, give me back the theme on a dog,&#8221; we pass in information that we know will cause or at least push this generative model to create a protein that has the characteristics that we want.



So in the case of that example you just mentioned, Eric, it would be the protein structure. Like I mentioned earlier, we usually say structure determines function. There&#8217;s obviously a lot of nuance to that, but we can, at a first approximation, say structure determines function. So if I ask an AI model, ‚ÄùHey, here&#8217;s this structure; give me a protein sequence that folds to this structure,‚Äù just like with that analogy with the dog, it&#8217;s going to give me something that matches that structure but that is likely still never been seen before. It&#8217;s going to be a new sequence.



So you can imagine taking this one step further. In the red-teaming pipeline, what we would do is take a protein that should normally be captured by DNA synthesis screening‚Äîthat would be captured by DNA synthesis screening‚Äîfind its structure, pass it through one of these models, and get variants on the theme of that structure so these new sequences, these synthetic homologs that you mentioned, paraphrased, reformulated, whatever phrase we want to use to describe them.



And they have a chance or a greater chance than not of maintaining the structure and so maintaining the function while being sufficiently different that they&#8217;re not detected by these tools anymore.



So that&#8217;s the nuts and bolts of how the red-teaming pipeline comes together. We use more tools than just structure. I think structure is the easiest one to understand. But we have a suite of tools in there, each pass different conditioning information that causes the model to generate sequences that are paraphrased versions of potential proteins of concern.



HORVITZ: But to get down to brass tacks, what Bruce did for the framing study was ‚Ä¶ we took the toxic, well-known toxic protein ricin, as we described in a framing paper that&#8217;s actually part of the appendix now to the Science publication, and we generated through this pipeline, composed of open-source tools, thousands of AI-rewritten versions of ricin.



And this brings us to the next step of our project, way back when, at the early ‚Ä¶ in the early days of this effort, where Twist Bioscience was one of the companies we approached with what must have seemed like an unusual question to your CEO, in fact, James: would you be open to testing whether current screening systems could detect thousands of AI-rewritten versions of ricin, a well-known toxic protein?



And your CEO quickly connected me with you, James. So, James, what were your first thoughts on hearing about this project, and how did you respond to our initial framing study?



DIGGANS: I think my first response was gratitude and excitement. So it was fantastic that Microsoft had really leaned forward on this set of ideas and had produced this dataset. But to have it, you know, show up on our doorstep in a very concrete way with a partner that was ready to, sort of, help us try and address that, I think was a really ‚Ä¶ a valuable opportunity. And so we really leapt at that.



HORVITZ: And the results were that both for you and another company, major producer IDT [Integrated DNA Technologies], those thousands of variants flew through ‚Ä¶ flew under the radar of the biosecurity screening software as we covered in that framing paper.



Now, after our initial findings on this, we quietly shared the paper with a few trusted contacts, including some in government. Through my work with the White House Office of Science and Technology Policy, or OSTP, we connected up with biosecurity leads there, and it was an OSTP biosecurity lead who described our results as the first zero day in AI and biosecurity. And now in cybersecurity, a zero day is a vulnerability unknown to defenders generally, meaning there&#8217;s no time to respond before it could be exploited should it be known.



In that vein, we took a cybersecurity approach. We stood up a CERT‚ÄîC-E-R-T‚Äîa cybersecurity [computer] emergency response team approach used in responding to cybersecurity vulnerabilities, and we implemented this process to address what we saw as a vulnerability with AI-enabled challenges to biosecurity.



At one point down the line, it was so rewarding to hear you say, James, ‚ÄúI&#8217;m really glad Microsoft got here first.‚Äù I&#8217;m curious how you think about this kind of AI-enabled vulnerability compared to other ones, biosecurity threats, you&#8217;ve encountered, and I&#8217;d love to hear your perspective on how we handled the situation from the early discovery to the coordination and outreach.



DIGGANS: Yeah, I think in terms of comparison known threats, the challenge here is really there is no good basis on which we can just, sort of, say, Oh, I&#8217;ll build a new tool to detect this concrete universe of things, right. This was more a pattern of I&#8217;m going to use tools‚Äîand I love the name ‚ÄúParaphrase‚Äù; it&#8217;s a fantastic name‚ÄîI can paraphrase anything that I would normally think of as biological ‚Ä¶ as posing biological risk, and now that thing is harder to detect for existing tools. And so that really was a very eye-opening experience, and I think the practice of forming this CERT response, putting together a group of people who were well versed not just in the threat landscape but also in the defensive technologies, and then figuring out how to mitigate that risk and broaden that study, I think, was a really incredibly valuable response to the entire synthesis industry.



HORVITZ: Yeah, and, Bruce, can you describe a little bit about the process by which we expanded the effort beyond our initial framing study to more toxins and then to a larger challenge set and then the results that we pursued and achieved?



WITTMANN:&nbsp;Yeah, of course. So, you know, using machine learning lingo, you don&#8217;t want to overfit to a single example. So early on with this, as part of the framing study, we were able to show or I should say James and coworkers across the screening field were able to show that this could be patched, right. We needed to just make some changes to the tools,&nbsp;and we could at the very least detect ricin or reformulated versions of ricin.



So the next step of course was then, OK, how generalizable are these patches? Can they detect other reformulated sequences, as well? So we had to expand the set of proteins that we had reformulated. We couldn&#8217;t just do 10s of thousands of ricins. We had to do 10s of thousands of name your other potentially hazardous ‚Ä¶



HORVITZ: I think we had 72, was it?



WITTMANN:&nbsp;It was 72 in the end that we ended up at. I believe, James, it was you and maybe Jake, another one of the authors on the list ‚Ä¶ on the paper, who primarily put that list together &#8230;



HORVITZ: This is Jacob Beal ‚Ä¶ Jacob Beal at Raytheon BBN.



WITTMANN: I think James actually might be the better one to answer how this list was expanded.



DIGGANS:&nbsp;Initially the focus [was] on ricin as a toxin so that list expanded to 62 sort of commonly controlled toxins that are subject to an export control restriction or other concern. And then on top of that, we added 10 viral proteins. So we didn&#8217;t really just want to look at toxins. We also wanted to look at viral proteins, largely because those proteins tend to have multiple functions. They have highly constrained structures. And so if we could work in a toxin context, could Paraphrase also do the same for viral proteins, as well.



HORVITZ: And, Bruce, can you describe some about how we characterize the updates and the, we&#8217;ll say, the boost in capabilities of the patched screening tools?



WITTMANN: So we had, like you said, Eric, 72 base proteins or template proteins. And for each of those, we had generated a few 100 to a couple thousand reformulated variants of them. The only way to really get any sense of validity of those sequences was to predict their structures. So we predicted protein structures for I think it was 70ish thousand protein structures in the end that we had to predict and score them using in silico metrics. So things like, how similar is this to that template, wild-type protein structure that we used as our conditioning information?



We put them on a big grid. So we have two axes. We have on the x-axis‚Äîand this is a figure in our paper‚Äîthe quality of the prediction. It&#8217;s essentially a confidence metric: how realistic is this protein sequence? And on the other axis is, how similar is the predicted structure of this variant to the original? And ultimately, what we were wanting to see was the proteins that scored well in both of those metrics, so that showed up in the top right of that diagram, were caught primarily, because these are again the ones that are most likely, having to say most likely, to retain function of the original.



So when you compare the original tools‚ÄîTool Series A, right, the unpatched tools‚Äîwhat you&#8217;ll find is varying degrees of success in the top right. It varied by tool. But in some cases, barely anything being flagged as potentially hazardous. And so improvement is then in the next series‚ÄîSeries B, the patched version of tools‚Äîwe have more flagged in that upper-right corner.



HORVITZ: And we felt confident that we had a more AI-resilient screening solution across the companies, and, James, at this point, the whole team decided it was time to disclose the vulnerability as well as the patch details and pointers to where to go for the updated screening software and to communicate this to synthesis companies worldwide via the IGSC. This was probably July, I think, of 2024. What was that process like, and how did members respond?



DIGGANS: I think members were really grateful and excited. To present to that group, to say, hey, this activity (a) has gone on, (b) was successful, and (c) was kept close hold until we knew how to mitigate this, I think everyone was really gratified by that and comforted by the fact that now they had kind of off-the-shelf solutions that they could use to improve their resilience against any incoming heavily engineered protein designs.



HORVITZ: Thanks, James.



Now, I know that we all understand this particular effort to be important but a piece of the biosecurity and AI problem. I&#8217;m just curious to ‚Ä¶ I‚Äôll ask all three of you to just share some brief reflections.



I know, Bruce, you&#8217;ve been on ‚Ä¶ you‚Äôve stayed on this, and we‚Äôve‚Äîall of us on the original team‚Äîhave other projects going on that are pushing on the frontiers ahead of where we were with this paper when we published it.



Let me start with Tessa in terms of, like, what new risks do you see emerging as AI accelerates and maybe couple that with thoughts about how do we proactively get ahead of them.



ALEXANIAN: Yeah, I think with the Paraphrase‚Äôs work, as Bruce explained so well, you know, I sometimes use the metaphor of the previous response that the IGSC had to do, the synthesis screening community, where it used to be you could look for similarities to DNA sequences, and then everyone started doing synthetic biology where they were doing codon optimization so that proteins could express more efficiently in different host organisms, and now all of a sudden, well, you&#8217;ve scrambled your DNA sequence and it doesn&#8217;t look very similar even though your protein sequence actually still looks, you know, very similar or often the same once it&#8217;s been translated from DNA to protein, and so that was a, you know, many, many in the industry were already screening both DNA and protein, but they had to start screening ‚Ä¶ everybody had to start screening protein sequences even just to do the similarity testing as these codon optimization tools became universal.



I feel like we&#8217;re, kind of, in a similar transition phase with protein-design, protein-rephrasing, tools where, you know, these tools are still in many cases drawing from the natural distribution of proteins. You know, I think some of the work we saw in, you know, designing novel CRISPR enzymes, you go, OK, yeah, it is novel; it&#8217;s very unlike any one CRISPR enzyme. But if you do a massive multiple sequence alignment of every CRISPR enzyme that we know about, you&#8217;re like, OK, this fits in the distribution of those enzymes. And so, you know, I think we&#8217;re not ‚Ä¶ we&#8217;re having to do a more flexible form of screening, where we look for things that are kind of within distribution of natural proteins.



But I feel like broadly, all of the screening tools were able to respond by doing something like that. And I think &#8230; I still feel like the clock is ticking down on that and that as the AI tools get better at predicting function and designing, sort of, novel sequences to pursue a particular function, you know‚Äîyou have tools now that can go from Gene Ontology terms to a potential structure or potential sequence that may again be much farther out of the distribution of natural protein‚ÄîI think all of us on the screening side are going to have to be responding to that, as well.



So I think I see this as a necessary ongoing engagement between people at the frontier of designing novel biology and people at the frontier of producing all of the materials that allow that novel biology to be tested in the lab. You know, I think this feels like the first, you know, detailed, comprehensive zero day disclosure and response. But I think that&#8217;s ‚Ä¶ I think we&#8217;re going to see more of those. And I think what I&#8217;m excited about doing at IBBIS is trying to encourage and set up more infrastructure so that you can, as an AI developer, disclose these new discoveries to the people who need to respond before the publication comes out.



HORVITZ: Thank you, Tessa.



The, the ‚Ä¶ Bruce, I mean, you and I are working on all sorts of dimensions. You&#8217;re leading up some efforts at Microsoft, for example, on the foundation model front and so on, among other directions. We&#8217;ve talked about new kinds of embedding models that might go beyond sequence and structure. Can you talk a little bit about just a few of the directions that just paint the larger constellation of the kinds of things that we talk about when we put our worry hats on?



WITTMANN:&nbsp;I feel like that could have its own dedicated podcast, as well. There&#8217;s a lot ‚Ä¶ [LAUGHTER] there&#8217;s a lot to talk about.



HORVITZ: Yeah. We want to make sure that we don&#8217;t tell the world that the whole problem is solved here.



WITTMANN:&nbsp;Right, right, right. I think Tessa said it really, really well in that most of what we&#8217;re doing right now, it&#8217;s a variant on a known theme. I have to know the structure that does something bad to be able to pass it in as context. I have to know some existing sequence that does something bad to pass it in.



And obviously the goal is to move away from that in benign applications, where when I&#8217;m designing something, I often want to design it because nothing exists [LAUGHS] that already does it. So we are going to be heading to this space where we don&#8217;t know what this protein does. It&#8217;s kind of a circular problem, right, where we&#8217;re going to need to be able to predict what some obscure protein sequence does in order to be able to still do our screening.



Now, the way that I think about this, I often think about it beyond just DNA synthesis screening. It&#8217;s one line of defense, and there needs to be many lines of defense that come into play here that go beyond just relying on this one roadblock. It&#8217;s a very powerful roadblock. It&#8217;s a very powerful barrier. But we need to be proactively thinking about how we broaden the scope of defenses. And there are lots of conversations that are ongoing. I won&#8217;t go into the details of them. Again, that would be its own podcast.



But primarily my big push‚Äîand I think this is emerging consensus in the field, though I don&#8217;t want to speak for everybody‚Äîis it needs to ‚Ä¶ any interventions we have need to come more at the systems level and less at the model level, primarily because this is such dual-use technology. If it can be used for good biological design, it can be used for bad biological design. Biology has no sense of morality. There is no bad protein. It&#8217;s just a protein.



So we need to think about this differently than how we would maybe think about looking at the outputs of that image generator model that I spoke about earlier, where I can physically look at an image and say, don&#8217;t want my model producing that, do want my model producing that. I don&#8217;t have that luxury in this space. So it&#8217;s a totally different problem. It&#8217;s an evolving problem. Conversations are happening about it, but the work is very much not done.



HORVITZ: And, James, I want to give you the same open question, but I&#8217;d like to apply what Bruce just said on system level and so on and in the spirit of the kind of things that you&#8217;re very much involved with internationally to also add to it, just get some comments on programs and policies that move beyond technical solutions for governance mechanisms‚Äîlogging, auditing nucleic acid orders, transparency, various kinds‚Äîthat might complement technical approaches like Paraphrase and their status today.



DIGGANS: Yeah, I&#8217;m very gratified that Bruce said that we, the synthesis industry, should not be the sole bulwark against misuse. That is very comforting and correct.



Yeah, so the US government published a guidance document in 2023 that essentially said you, the entire biotech supply chain, have a responsibility to make sure that you&#8217;re evaluating your customers. You should know your customer; you know that they&#8217;re legitimate. I think that&#8217;s an important practice.



Export controls are designed to minimize the movement of equipment and materials that can be used in support of these kinds of misuse activities. And then governments have really been quite active in trying to incentivize, you know, sort of what we would think of as positive behavior, so screening, for example, in DNA synthesis companies. The US government created a framework in 2024, and it&#8217;s under a rewrite now to basically say US research dollars will only go to companies who make nucleic acid who do these good things. And so that is using, kind of, the government-funding carrot to, kind of, continue to build these layers of defense against potential misuse.



HORVITZ: Thanks. Now, discussing risk, especially when it involves AI and biosecurity, isn&#8217;t always easy. As we&#8217;ve all been suggesting, some worry about alarming the public or arming bad actors. Others advocate for openness as a principle of doing science with integrity.



A phase of our work as we prepared our paper was giving serious thought to both the benefits and the risks of transparency about what it was that we were doing. Some experts encouraged full disclosure as important for enhancing the science of biosecurity. Other experts, all experts, cautioned against what are called information hazards, the risk of sharing the details to enable malevolent actions with our findings or our approach.



So we faced a real question: how can we support open science while minimizing the risk of misuse? And we took all the input we got, even if it was contradictory, very seriously. We carefully deliberated about a good balance, and even then, once we chose our balance and submitted our manuscript to Science, the peer reviewers came back and said they wanted some of the more sensitive details that we withheld with explanations as to why.



So this provoked some thinking out of the box about a novel approach, and we came up with a perpetual gatekeeping strategy where requests for access to sensitive methods and data and even the software across different risk categories would be carefully reviewed by a committee and a process for access that would continue in perpetuity.



Now, we brought the proposal to Tessa and her team at IBBIS‚Äîthis is a great nonprofit group; look at their mission‚Äîand we worked with Tessa and her colleagues to refine a workable solution that was accepted by Science magazine as a new approach to handling information hazards as first demonstrated by our paper.



So, Tessa, thank you again for helping us to navigate such a complex challenge. Can you share your perspective on information hazards? And then walk us through how our proposed system ensures responsible data and software sharing.



ALEXANIAN: Yeah. And thanks, Eric.



It&#8217;s all of the long discussions we had among the group of people on this podcast and the other authors on the paper and many people we engaged, you know, technical experts, people in various governments, you know, we heard a lot of contradictory advice.



And I think it showed us that there isn&#8217;t a consensus right now on how to handle information hazards in biotechnology. You know, I think ‚Ä¶ I don&#8217;t want to overstate how much of a consensus there is in cybersecurity either. If you go to DEF CON, you&#8217;ll hear people about how they&#8217;ve been mistreated in their attempts to do responsible disclosure for pacemakers and whatnot. But I think we&#8217;re ‚Ä¶ we have even less of a consensus when it comes to handling biological information.



You know, you have some people who say, oh, because the size of the consequences could be so catastrophic if someone, you know, releases an engineered flu or something, you know, we should just never share information about this. And then you have other people who say there&#8217;s no possibility of building defenses unless we share information about this. And we heard very strong voices with both of those perspectives in the process of conducting this study.



And I think what we landed on that I&#8217;m really excited about and really excited to get feedback on now that the paper is out, you know, if you go and compare our preprint, which came out in December of 2024, and this paper in October 2025, you&#8217;ll see a lot of information got added back in.



And I&#8217;m excited to see people&#8217;s reaction to that because even back in January 2025, talking with people who were signatories to the responsible biodesign commitments, they were really excited that this was such an empirically concrete paper because they&#8217;d maybe read a number of papers talking about biosecurity risks from AI that didn&#8217;t include a whole lot of data, you know, often, I think, because of concerns about information hazards. And they found the arguments in this paper are much more convincing because we are able to share data.



So the process we underwent that I felt good about was trying to really clearly articulate, when we talk about an information hazard, what are we worried about being done with this data? And if we put this data in public, completely open source, does it shift the risk at all? You know, I think doing that kind of marginal contribution comparison is really important because it also let us make more things available publicly.



But there were a few tiers of data that after a lot of discussion amongst the authors of the paper, we thought, OK, potentially someone who wanted to do harm, if they got access to this data, it might make it easier for them. Again, not necessarily saying it, you know, it opens the floodgates, but it might make it easier for them. And when we thought about that, we thought, OK, you know, giving all of those paraphrased protein sequences, maybe, maybe that, you know, compared to having to set up the whole pipeline with the open-source tools yourself, just giving you those protein sequences, maybe that makes your life a bit easier if you&#8217;re trying to do harm.



And then we thought, OK, giving you those protein sequences plus whether or not they were successfully flagged, maybe that makes your life, you know, quite a bit easier. And then finally, we thought, OK, the code that we want to share with some people who might try to reproduce these results or might try to build new screening systems that are more robust, we want to share the code with them. But again, if you have that whole code pipeline just prepared for you, it might really help make your life easier if you&#8217;re trying to do harm.



And so we, sort of, sorted the data into these three tiers and then went through a process actually very inspired by the existing customer screening processes in nucleic acid synthesis about how to determine, you know, we tried to take an approach not of what gets you in but what gets you out. You know, for the most part, we think it should be possible to access this data.



You know, if you have an affiliation with a recognizable institution or some good explanation of why you don&#8217;t have one right now, you know, if you have a reason for accessing this data, it shouldn&#8217;t be too hard to meet those requirements, but we wanted to have some in place. And we wanted it to be possible to rule out some people from getting access to this data. And so we&#8217;ve tried to be extremely transparent about what those are. If you go through our data access process and for some reason you get rejected, you&#8217;ll get a list of, &#8220;Here&#8217;s the reasons we rejected you. If you don&#8217;t think that&#8217;s right, get back to us.&#8221;



So I&#8217;m really excited to pilot this in part because I think, you know, we&#8217;re already in conversations with some other people handling potential bio-AI information hazard about doing a similar process for their data of, you know, tiering it, determining which gates to put in which tiers, but I really hope a number of people do get access through the process or if they try and they fail, they tell us why. Because I think as we move toward this world of potentially, you know, biology that is much easier to engineer, partly due to dual-use tools, you know, my dream is it&#8217;s, like, still hard to engineer harm with biology, even if it&#8217;s really easy to engineer biology. And I think these, kind of, new processes for managing access to things, this sort of like, you know, open but not completely public, I think those can be a big part of that layered defense.



HORVITZ: Thanks, Tessa. So we&#8217;re getting close to closing, and I just thought I would ask each of you to just share some reflections on what we&#8217;ve learned, the process we&#8217;ve demonstrated, the tools, the policy work that we did, this idea of facing the dual-use dilemma with ‚Ä¶ even at the information hazard level, with sharing information versus withholding it. What do you think about how our whole end to end of the study, now reaching the two-year point, can help other fields facing dual-use dilemmas?



Tessa, Bruce, James ‚Ä¶ James, have you ever thought about that? And we&#8217;ll go to Bruce and then Tessa.



DIGGANS:&nbsp;Yeah, I think it was an excellent model. I would like to see a study like this repeated on a schedule, you know, every six months because from where I sit, you know, the tools that we used for this project are now two years old. And so capabilities have moved on. Is the picture the same in terms of defensive capability? And so using that model over time, I think, would be incredibly valuable. And then using the findings to chart, you know, how much should we be investing in alternative strategies for this kind of risk mitigation for AI tool ‚Ä¶ the products of AI tools?



HORVITZ: Bruce.



WITTMANN:&nbsp;Yeah, I think I would extend on what James said. The anecdote I like to point out about this project is, kind of, our schedule. We found the vulnerability and it was patched within a week, two weeks, on all major synthesis screening platforms. We wrote the paper within a month. We expanded on the paper within two months, and then we spent a year and a half to nearly two years [LAUGHS] trying to figure out what goes into the paper; how do we release this information; you know, how do we do this responsibly?



And my hope is similar to what James said. We&#8217;ve made it easier for others to do this type of work. Not this exact work; it doesn&#8217;t have to necessarily do with proteins. But to do this type of work where you are dealing with potential hazards but there is also value in sharing and that hopefully that year and a half we spent figuring out how to appropriately share and what to share will not be a year and a half for other teams because these systems are in place or at least there is an example to follow up from. So that&#8217;s my takeaway.



HORVITZ: Tessa, bring us home‚Äîbring us home! [LAUGHS]



ALEXANIAN: Bring us home! Let&#8217;s do it faster next time. [LAUGHTER] Come talk to any of us if you&#8217;re dealing with this kind of stuff. You know, I think IBBIS, especially, we want to be a partner for building those layers of defense and, you know, having ripped out our hair as a collective over the past year and a half about the right process to follow here, I think we all really hope it&#8217;ll be faster next time.



And I think, you know, the other thing I would encourage is if you&#8217;re an AI developer, I would encourage you to think about how your tool can strengthen screening and strengthen recognition of threats.



I know James and I have talked before about how, you know, our Google search alerts each week send us dozens of cool AI bio papers, and it&#8217;s more like once a year or maybe once every six months, if we&#8217;re lucky, that we get something that&#8217;s like applying AI bio to biosecurity. So, you know, if you&#8217;re interested in these threats, I think we&#8217;d love to see more work that&#8217;s directly applied to facing these threats using the most modern technology.



HORVITZ: Well said.



Well, Bruce, James, Tessa, thank you so much for joining me today and for representing the many collaborators, both coauthors and beyond, who made this project possible.



It&#8217;s been a true pleasure to work with you. I&#8217;m so excited about what we&#8217;ve accomplished, the processes and the models that we&#8217;re now sharing with the world. And I&#8217;m deeply grateful for the collective intelligence and dedication that really powered the effort from the very beginning. So thanks again.



[MUSIC]



WITTMANN: Thanks, Eric.



DIGGANS: Thank you.



ALEXANIAN: Thank you.



[MUSIC FADES]

				
			
			
				Show more			
		
	








[1] The original organization was founded in 2009 and became the International Gene Synthesis Consortium in 2010.
Opens in a new tabThe post Ideas: More AI-resilient biosecurity with the Paraphrase Project appeared first on Microsoft Research.
‚Ä¢ When AI Meets Biology: Promise, Risk, and Responsibility
  Advances in AI are opening extraordinary frontiers in biology. AI-assisted protein engineering holds the promise of new medicines, materials, and breakthroughs in scientific understandings. Yet these same technologies also introduce biosecurity risks and may lower barriers to designing harmful toxins or pathogens. This ‚Äúdual-use‚Äù potential, where the same knowledge can be harnessed for good or misuse to cause harm, poses a critical dilemma for modern science.



Great Promise‚Äîand Potential Threat



I‚Äôm excited about the potential for AI-assisted protein design to drive breakthroughs in biology and medicine. At the same time, I‚Äôve also studied how these tools could be misused. In computer-based studies, we found that AI protein design (AIPD) tools could generate modified versions of proteins of concern, such as ricin. Alarmingly, these reformulated proteins were able to evade the biosecurity screening systems used by DNA synthesis companies, which scientists rely on to synthesize AI-generated sequences for experimental use. 



In our paper published in Science on October 2, ‚ÄúStrengthening nucleic acid biosecurity screening against generative protein design tools (opens in new tab),‚Äù we describe a two-year confidential project we began in late 2023 while preparing a case study for a workshop on AI and biosecurity.



We worked confidentially with partners across organizations and sectors for 10 months to develop AI biosecurity ‚Äúred-teaming‚Äù methods that allowed us to better understand vulnerabilities and craft practical solutions‚Äî&#8221;patches‚Äù that have now been adopted globally, making screening systems significantly more AI-resilient.



Summary of AIPD red-teaming workflow.



For structuring, methods, and process in our study, we took inspiration from the cybersecurity community, where ‚Äúzero-day‚Äù vulnerabilities are kept confidential until a protective patch is developed and deployed. Following the acknowledgment by a small group of workshop attendees of a zero-day for AI in biology, we worked closely with stakeholders‚Äîincluding synthesis companies, biosecurity organizations, and policymakers‚Äîto rapidly create and distribute patches that improved detection of AI-redesigned protein sequences. We delayed public disclosure until protective measures were in place and widely adopted.



Dilemma of Disclosure



The dual use dilemma also complicates how we share information about vulnerabilities and safeguards. Across AI and other fields, researchers face a core question: 




How can scientists share potentially risk-revealing methods and results in ways that enable progress without offering a roadmap for misuse?




We recognized that our work itself‚Äîdetailing methods and failure modes‚Äîcould be exploited by malicious actors if published openly. To guide decisions about what to share, we held a multi-stakeholder deliberation involving government agencies, international biosecurity organizations, and policy experts. Opinions varied: some urged full transparency to maximize reproducibility‚Äîand to help others to build on our work; others stressed restraint to minimize risk. It was clear that a new model of scientific communication was needed, one that could balance openness and security.



The Novel Framework



The risk of sharing dangerous information through biological research has become a growing concern. We have participated in community-wide discussion on the challenges, including a recent National Academies of Science, Engineering, and Medicine workshop and study.&nbsp;



In preparing our manuscript for publication, we worked on designing a process to limit the spread of dangerous information while still enabling scientific progress.&nbsp;



To address the dual challenges, we devised a tiered access system for data and methods, implemented in partnership with the International Biosecurity and Biosafety Initiative for Science (IBBIS) (opens in new tab), a nonprofit dedicated to advancing science while reducing catastrophic risks. The system works as follows:




Controlled access: Researchers can request access through IBBIS, providing their identity, affiliation, and intended use. Requests are reviewed by an expert biosecurity committee, ensuring that only legitimate scientists conducting relevant research gain access.



Stratified tiers of information: Data and code are classified into several tiers according to their potential hazard, from low-risk summaries through sensitive technical data to critical software pipelines.



Safeguards and agreements: Approved users sign tailored usage agreements, including non-disclosure terms, before receiving data.



Resilience and longevity: Provisions are built in for declassification when risks subside, and for succession of stewardship to trusted organizations should IBBIS be unable to continue its operation.




This framework allows replication and extension of our work while guarding against misuse. Rather than relying on secrecy, it provides a durable system of responsible access.



To ensure continued funding for the storage and responsible distribution of sensitive data and software, and for the operation of the sharing program, we provided an endowment to IBBIS to support the program in perpetuity. This approach was modeled after the One Hundred Year Study on AI at Stanford, which is endowed to continue for the life of the university.



An Important Step in Scientific Publishing



We are pleased that the leadership at Science accepted our approach to handling information hazards. To our knowledge, this is the first time a leading scientific journal has formally endorsed a tiered-access approach to manage an information hazard. This recognition validates the idea that rigorous science and responsible risk management can coexist‚Äîand that journals, too, can play a role in shaping how sensitive knowledge is shared. We acknowledge the visionary leadership at Science, including editors, Michael Funk and Valda Vinson, and Editor-in-Chief, Holden Thorp.



Beyond Biology: A Model for Sensitive Research



While developed for AI-powered protein design, our approach offers a generalizable model for dual-use research of concern (DURC) across disciplines. Whether in biology, chemistry, or emerging technologies, scientists will increasingly confront situations where openness and security pull in opposite directions. Our experience shows that these values can be balanced: with creativity, coordination, and new institutional mechanisms, science can uphold both reproducibility and responsibility.



We hope this framework becomes a template for future projects, offering a way forward for researchers who wish to share their insights without amplifying risks. By embedding resilience into how knowledge is communicated‚Äînot just what is communicated‚Äîwe can ensure that scientific progress continues to serve humanity safely.



The responsible management of information hazards is no longer a peripheral concern: it is central to how science will advance in the age of powerful technologies like AI. This approach to managing information hazards demonstrates a path forward, where novel frameworks for access and stewardship allow sensitive but vital research to be shared, scrutinized, and extended responsibly. Approaches like this will be critical to ensuring that scientific openness and societal safety advance hand-in-hand.







Additional reading



Strengthening nucleic acid biosecurity screening against generative protein design tools.



The Age of AI in the Life Sciences: Benefits and Biosecurity Considerations, National Academies of Science, Engineering, and Medicine, 2025. (opens in new tab)



Disseminating In Silico and Computational Biological Research: Navigating Benefits and Risks: Proceedings of a Workshop, National Academies of Science, Engineering, and Medicine, 2025. (opens in new tab)



Protecting scientific integrity in an age of generative AI, Proceedings of the National Academy of Science, 2024. (opens in new tab)
Opens in a new tabThe post When AI Meets Biology: Promise, Risk, and Responsibility appeared first on Microsoft Research.
‚Ä¢ Responsible AI: How PowerSchool safeguards millions of students with AI-powered content filtering using Amazon SageMaker AI
  This post is cowritten with Gayathri Rengarajan and Harshit Kumar Nyati from PowerSchool. 
PowerSchool is a leading provider of cloud-based software for K-12 education, serving over 60 million students in more than 90 countries and over 18,000 customers, including more than 90 of the top 100 districts by student enrollment in the United States. When we launched PowerBuddy, our AI assistant integrated across our multiple educational platforms, we faced a critical challenge: implementing content filtering sophisticated enough to distinguish between legitimate academic discussions and harmful content in educational contexts. 
In this post, we demonstrate how we built and deployed a custom content filtering solution using Amazon SageMaker AI that achieved better accuracy while maintaining low false positive rates. We walk through our technical approach to fine tuning Llama 3.1 8B, our deployment architecture, and the performance results from internal validations. 
PowerSchool‚Äôs PowerBuddy 
PowerBuddy is an AI assistant that provides personalized insights, fosters engagement, and provides support throughout the educational journey. Educational leaders benefit from PowerBuddy being brought to their data and their users‚Äô most common workflows within the PowerSchool ecosystem ‚Äì such as Schoology Learning, Naviance CCLR, PowerSchool SIS, Performance Matters, and more ‚Äì to ensure a consistent experience for students and their network of support providers at school and at home. 
The PowerBuddy suite includes several AI solutions: PowerBuddy for Learning functions as a virtual tutor; PowerBuddy for College and Career provides insights for career exploration; PowerBuddy for Community simplifies access to district and school information, and others. The solution includes built-in accessibility features such as speech-to-text and text-to-speech functionality. 
Content filtering for PowerBuddy 
As an education technology provider serving millions of students‚Äîmany of whom are minors‚Äîstudent safety is our highest priority. National data shows that approximately 20% of students ages 12‚Äì17 experience bullying, and 16% of high school students have reported seriously considering suicide. With PowerBuddy‚Äôs widespread adoption across K-12 schools, we needed robust guardrails specifically calibrated for educational environments. 
The out-of-the-box content filtering and safety guardrails solutions available on the market didn‚Äôt fully meet PowerBuddy‚Äôs requirements, primarily because of the need for domain-specific awareness and fine-tuning within the education context. For example, when a high school student is learning about sensitive historical topics such as World War II or the Holocaust, it‚Äôs important that educational discussions aren‚Äôt mistakenly flagged for violent content. At the same time, the system must be able to detect and immediately alert school administrators to indications of potential harm or threats. Achieving this nuanced balance requires deep contextual understanding, which can only be enabled through targeted fine-tuning. 
We needed to implement a sophisticated content filtering system that could intelligently differentiate between legitimate academic inquiries and truly harmful content‚Äîdetecting and blocking prompts indicating bullying, self-harm, hate speech, inappropriate sexual content, violence, or harmful material not suitable for educational settings. Our challenge was finding a cloud solution to train and host a custom model that could reliably protect students while maintaining the educational functionality of PowerBuddy. 
After evaluating multiple AI providers and cloud services that allow model customization and fine-tuning, we selected Amazon SageMaker AI as the most suitable platform based on these critical requirements: 
 
 Platform stability: As a mission-critical service supporting millions of students daily, we require an enterprise-grade infrastructure with high availability and reliability. 
 Autoscaling capabilities: Student usage patterns in education are highly cyclical, with significant traffic spikes during school hours. Our solution needed to handle these fluctuations without degrading performance. 
 Control of model weights after fine-tuning: We needed control over our fine-tuned models to enable continuous refinement of our safety guardrails, enabling us to quickly respond to new types of harmful content that might emerge in educational settings. 
 Incremental training capability: The ability to continually improve our content filtering model with new examples of problematic content was essential. 
 Cost-effectiveness: We needed a solution that would allow us to protect students without creating prohibitive costs that would limit schools‚Äô access to our educational tools. 
 Granular control and transparency: Student safety demands visibility into how our filtering decisions are made, requiring a solution that isn‚Äôt a black box but provides transparency into model behavior and performance. 
 Mature managed service: Our team needed to focus on educational applications rather than infrastructure management, making a comprehensive managed service with production-ready capabilities essential. 
 
Solution overview 
 
Our content filtering system architecture, shown in the preceding figure, consists of several key components: 
 
 Data preparation pipeline: 
   
   Curated datasets of safe and unsafe content examples specific to educational contexts 
   Data preprocessing and augmentation to ensure robust model training 
   Secure storage in Amazon S3 buckets with appropriate encryption and access controls Note: All training data was fully anonymized and did not include personally identifiable student information 
    
 
 
 Model training infrastructure: 
   
   SageMaker training jobs for fine-tuning Llama 3.1 8B 
    
 
 
 Inference architecture: 
   
   Deployment on SageMaker managed endpoints with auto-scaling configured 
   Integration with PowerBuddy through Amazon API Gateway for real-time content filtering 
   Monitoring and logging through Amazon CloudWatch for continuous quality assessment 
    
 
 
 Continuous improvement loop: 
   
   Feedback collection mechanism for false positives/negatives 
   Scheduled retraining cycles to incorporate new data and improve performance 
   A/B testing framework to evaluate model improvements before full deployment 
    
 
Development process 
After exploring multiple approaches to content filtering, we decided to fine-tune Llama 3.1 8B using Amazon SageMaker JumpStart. This decision followed our initial attempts to develop a content filtering model from scratch, which proved challenging to optimize for consistency across various types of harmful content. 
SageMaker JumpStart significantly accelerated our development process by providing pre-configured environments and optimized hyperparameters for fine-tuning foundation models. The platform‚Äôs streamlined workflow allowed our team to focus on curating high-quality training data specific to educational safety concerns rather than spending time on infrastructure setup and hyperparameter tuning. 
We fine-tuned Llama 3.1 8B model using Low Rank Adaptation (LoRA) technique on Amazon SageMaker AI training jobs, which allowed us to maintain full control over the training process. 
After the fine-tuning was done, we deployed the model on SageMaker AI managed endpoint and integrated it as a critical safety component within our PowerBuddy architecture. 
For our production deployment, we selected NVIDIA A10G GPUs available through ml.g5.12xlarge instances, which offered the ideal balance of performance and cost-effectiveness for our model size. The AWS team provided crucial guidance on selecting optimal model serving configuration for our use case. This advice helped us optimize both performance and cost by ensuring we weren‚Äôt over-provisioning resources. 
Technical implementation 
Below is the code snippet to fine-tune the model on the pre-processed dataset. Instruction tuning dataset is first converted into domain adaptation dataset format and scripts utilize Fully Sharded Data Parallel (FSDP) as well as Low Rank Adaptation (LoRA) method for fine-tuning the model. 
We define an estimator object first. By default, these models train via domain adaptation, so you must indicate instruction tuning by setting the instruction_tuned hyperparameter to True. 
 
 estimator = JumpStartEstimator(
    model_id=model_id,
    environment={"accept_eula": "true"},  
    disable_output_compression=True,
    hyperparameters={
        "instruction_tuned": "True",
        "epoch": "5",
        "max_input_length": "1024",
        "chat_dataset": "False"
    },
    sagemaker_session=session,
    base_job_name = "CF-M-0219251"
) 
 
After we define the estimator, we are ready to start training: 
estimator.fit({"training": train_data_location}) 
After training, we created a model using the artifacts stored in S3 and deployed the model to a real-time endpoint for evaluation. We tested the model using our test dataset that covers key scenarios to validate performance and behavior. We calculated recall, F1, confusion matrix and inspected misclassifications. If needed, adjust hyperparameters/prompt template and retrain; otherwise proceed with production deployment. 
You can also check out the sample notebook for fine tuning Llama 3 models on SageMaker JumpStart in SageMaker examples. 
We used the Faster autoscaling on Amazon SageMaker realtime endpoints notebook to set up autoscaling on SageMaker AI endpoints. 
Validation of solution 
To validate our content filtering solution, we conducted extensive testing across multiple dimensions: 
 
 Accuracy testing: In our internal validation testing, the model achieved ~93% accuracy in identifying harmful content across a diverse test set representing various forms of inappropriate material. 
 False positive analysis: We worked to minimize instances where legitimate educational content was incorrectly flagged as harmful, achieving a false positive rate of less than 3.75% in test environments; results may vary by school context. 
 Performance testing: Our solution maintained response times averaging 1.5 seconds. Even during peak usage periods simulating real classroom environments, the system consistently delivered seamless user experience with no failed transactions. 
 Scalability and reliability validation: 
   
   Comprehensive load testing achieved 100% transaction success rate with consistent performance distribution, validating system reliability under sustained educational workload conditions. 
   Transactions completed successfully without degradation in performance or accuracy, demonstrating the system‚Äôs ability to scale effectively for classroom-sized concurrent usage scenarios. 
    
 Production deployment: Initial rollout to a select group of schools showed consistent performance in real-world educational environments. 
 Student safety outcomes: Schools reported a significant reduction in reported incidents of AI-enabled bullying or inappropriate content generation compared to other AI systems without specialized content filtering. 
 
Fine-tuned model metrics compared to out-of-the-box content filtering solutions 
The fine-tuned content filtering model demonstrated higher performance than generic, out-of-the-box filtering solutions in key safety metrics. It achieved a higher accuracy (0.93 compared to 0.89), and better F1-scores for both the safe (0.95 compared to 0.91) and unsafe (0.90 compared to 0.87) classes. The fine-tuned model also demonstrated a more balanced trade-off between precision and recall, indicating more consistent performance across classes. Importantly, it makes fewer false positive errors by misclassifying only 6 safe cases as unsafe, compared to 19 original responses in a test set of 160‚Äî a significant advantage in safety-sensitive applications. Overall, our fine-tuned content filtering model proved to be more reliable and effective. 
Future plans 
As the PowerBuddy suite evolves and is integrated into other PowerSchool products and agent flows, the content filter model will be continuously adapted and improved with fine tuning for other products with specific needs. 
We plan to implement additional specialized adapters using the SageMaker AI multi-adapter inference feature alongside our content filtering model subject to feasibility and compliance consideration. The idea is to deploy fine-tuned small language models (SLMs) for specific problem solving in cases where large language models (LLMs) are huge and generic and don‚Äôt meet the need for narrower problem domains. For example: 
 
 Decision making agents specific to the Education domain 
 Data domain identification in cases of text to SQL queries 
 
This approach will deliver significant cost savings by eliminating the need for separate model deployments while maintaining the specialized performance of each adapter. 
The goal is to create an AI learning environment that is not only safe but also inclusive and responsive to diverse student needs across our global implementations, ultimately empowering students to learn effectively while being protected from harmful content. 
Conclusion 
The implementation of our specialized content filtering system on Amazon SageMaker AI has been transformative for PowerSchool‚Äôs ability to deliver safe AI experiences in educational settings. By building robust guardrails, we‚Äôve addressed one of the primary concerns educators and parents have about introducing AI into classrooms‚Äîhelping to ensure student safety. 
As Shivani Stumpf, our Chief Product Officer, explains: ‚ÄúWe‚Äôre now tracking around 500 school districts who‚Äôve either purchased PowerBuddy or activated included features, reaching over 4.2 million students approximately. Our content filtering technology ensures students can benefit from AI-powered learning support without exposure to harmful content, creating a safe space for academic growth and exploration.‚Äù 
The impact extends beyond just blocking harmful content. By establishing trust in our AI systems, we‚Äôve enabled schools to embrace PowerBuddy as a valuable educational tool. Teachers report spending less time monitoring student interactions with technology and more time on personalized instruction. Students benefit from 24/7 learning support without the risks that might otherwise come with AI access. 
For organizations requiring domain-specific safety guardrails, consider how the fine-tuning capabilities and managed endpoints of SageMaker AI can be adapted to your use case. 
As we continue to expand PowerBuddy‚Äôs capabilities with the multi-adapter inference of SageMaker, we remain committed to maintaining the perfect balance between educational innovation and student safety‚Äîhelping to ensure that AI becomes a positive force in education that parents, teachers, and students can trust. 
 
About the authors 
Gayathri Rengarajan is the Associate Director of Data Science at PowerSchool, leading the PowerBuddy initiative. Known for bridging deep technical expertise with strategic business needs, Gayathri has a proven track record of delivering enterprise-grade generative AI solutions from concept to production. 
 Harshit Kumar Nyati is a Lead Software Engineer at PowerSchool with 10+ years of experience in software engineering and analytics. He specializes in building enterprise-grade Generative AI applications using Amazon SageMaker AI, Amazon Bedrock, and other cloud services. His expertise includes fine-tuning LLMs, training ML models, hosting them in production, and designing MLOps pipelines to support the full lifecycle of AI applications. 
Anjali Vijayakumar is a Senior Solutions Architect at AWS with over 9 years of experience helping customers build reliable and scalable cloud solutions. Based in Seattle, she specializes in architectural guidance for EdTech solutions, working closely with Education Technology companies to transform learning experiences through cloud innovation. Outside of work, Anjali enjoys exploring the Pacific Northwest through hiking. 
Dmitry Soldatkin&nbsp;is a Senior AI/ML Solutions Architect at Amazon Web Services (AWS), helping customers design and build AI/ML solutions. Dmitry‚Äôs work covers a wide range of ML use cases, with a primary interest in Generative AI, deep learning, and scaling ML across the enterprise. He has helped companies in many industries, including insurance, financial services, utilities, and telecommunications. You can connect with Dmitry on&nbsp;LinkedIn. 
Karan Jain is a Senior Machine Learning Specialist at AWS, where he leads the worldwide Go-To-Market strategy for Amazon SageMaker Inference. He helps customers accelerate their generative AI and ML journey on AWS by providing guidance on deployment, cost-optimization, and GTM strategy. He has led product, marketing, and business development efforts across industries for over 10 years, and is passionate about mapping complex service features to customer solutions.
‚Ä¢ Unlock global AI inference scalability using new global cross-Region inference on Amazon Bedrock  with Anthropic‚Äôs Claude Sonnet 4.5
  Organizations are increasingly integrating generative AI capabilities into their applications to enhance customer experiences, streamline operations, and drive innovation. As generative AI workloads continue to grow in scale and importance, organizations face new challenges in maintaining consistent performance, reliability, and availability of their AI-powered applications. Customers are looking to scale their AI inference workloads across multiple AWS Regions to support consistent performance and reliability. 
To address this need, we introduced cross-Region inference (CRIS) for Amazon Bedrock. This managed capability automatically routes inference requests across multiple Regions, enabling applications to handle traffic bursts seamlessly and achieve higher throughput without requiring developers to predict demand fluctuations or implement complex load-balancing mechanisms. CRIS works through inference profiles, which define a foundation model (FM) and the Regions to which requests can be routed. 
We are excited to announce availability of global cross-Region inference with Anthropic‚Äôs Claude Sonnet 4.5 on Amazon Bedrock. Now, with cross-Region inference, you can choose either a geography-specific inference profile or a global inference profile. This evolution from geography-specific routing provides greater flexibility for organizations because Amazon Bedrock automatically selects the optimal commercial Region within that geography to process your inference request. Global CRIS further enhances cross-Region inference by enabling the routing of inference requests to supported commercial Regions worldwide, optimizing available resources and enabling higher model throughput. This helps support consistent performance and higher throughput, particularly during unplanned peak usage times. Additionally, global CRIS supports key Amazon Bedrock features, including prompt caching, batch inference, Amazon Bedrock Guardrails, Amazon Bedrock Knowledge Bases, and more. 
In this post, we explore how global cross-Region inference works, the benefits it offers compared to Regional profiles, and how you can implement it in your own applications with Anthropic‚Äôs Claude Sonnet 4.5 to improve your AI applications‚Äô performance and reliability. 
Core functionality of global cross-Region inference 
Global cross-Region inference helps organizations manage unplanned traffic bursts by using compute resources across different Regions. This section explores how this feature works and the technical mechanisms that power its functionality. 
Understanding inference profiles 
An inference profile in Amazon Bedrock defines an FM and one or more Regions to which it can route model invocation requests. The global cross-Region inference profile for Anthropic‚Äôs Claude Sonnet 4.5 extends this concept beyond geographic boundaries, allowing requests to be routed to one of the supported Amazon Bedrock commercial Regions globally, so you can prepare for unplanned traffic bursts by distributing traffic across multiple Regions. 
Inference profiles operate on two key concepts: 
 
 Source Region ‚Äì The Region from which the API request is made 
 Destination Region ‚Äì A Region to which Amazon Bedrock can route the request for inference 
 
At the time of writing, global CRIS supports over 20 source Regions, and the destination Region is a supported commercial Region dynamically chosen by Amazon Bedrock. 
Intelligent request routing 
Global cross-Region inference uses an intelligent request routing mechanism that considers multiple factors, including model availability, capacity, and latency, to route requests to the optimal Region. The system automatically selects the optimal available Region for your request without requiring manual configuration: 
 
 Regional capacity ‚Äì The system considers the current load and available capacity in each potential destination Region. 
 Latency considerations ‚Äì Although the system prioritizes availability, it also takes latency into account. By default, the service attempts to fulfill requests from the source Region when possible, but it can seamlessly route requests to other Regions as needed. 
 Availability metrics ‚Äì The system continuously monitors the availability of FMs across Regions to support optimal routing decisions. 
 
This intelligent routing system enables Amazon Bedrock to distribute traffic dynamically across the AWS global infrastructure, facilitating optimal availability for each request and smoother performance during high-usage periods. 
Monitoring and logging 
When using global cross-Region inference, Amazon CloudWatch and AWS CloudTrail continue to record log entries only in the source Region where the request originated. This simplifies monitoring and logging by maintaining all records in a single Region regardless of where the inference request is ultimately processed. To track which Region processed a request, CloudTrail events include an additionalEventData field with an inferenceRegion key that specifies the destination Region. Organizations can monitor and analyze the distribution of their inference requests across the AWS global infrastructure. 
Data security and compliance 
Global cross-Region inference maintains high standards for data security. Data transmitted during cross-Region inference is encrypted and remains within the secure AWS network. Sensitive information remains protected throughout the inference process, regardless of which Region processes the request. Because security and compliance is a shared responsibility, you must also consider legal or compliance requirements that come with processing inference request in a different geographic location. Because global cross-Region inference allows requests to be routed globally, organizations with specific data residency or compliance requirements can elect, based on their compliance needs, to use geography-specific inference profiles to make sure data remains within certain Regions. This flexibility helps businesses balance redundancy and compliance needs based on their specific requirements. 
Implement global cross-Region inference 
To use global cross-Region inference with Anthropic‚Äôs Claude Sonnet 4.5, developers must complete the following key steps: 
 
 Use the global inference profile ID ‚Äì When making API calls to Amazon Bedrock, specify the global Anthropic‚Äôs Claude Sonnet 4.5 inference profile ID (global.anthropic.claude-sonnet-4-5-20250929-v1:0) instead of a Region-specific model ID. This works with both InvokeModel and Converse APIs. 
 Configure IAM permissions ‚Äì Grant appropriate AWS Identity and Access Management (IAM) permissions to access the inference profile and FMs in potential destination Regions. In the next section, we provide more details. You can also read more about prerequisites for inference profiles. 
 
Implementing global cross-Region inference with Anthropic‚Äôs Claude Sonnet 4.5 is straightforward, requiring only a few changes to your existing application code. The following is an example of how to update your code in Python: 
 
 import boto3
import json
bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')


model_id = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"&nbsp;&nbsp;



response = bedrock.converse(
&nbsp; &nbsp;&nbsp;messages=[{"role": "user", "content": [{"text": "Explain cloud computing in 2 sentences."}]}],
&nbsp;&nbsp; &nbsp;modelId=model_id,
)

print("Response:", response['output']['message']['content'][0]['text'])
print("Tokens used:", result.get('usage', {})) 
 
If you‚Äôre using the Amazon Bedrock InvokeModel API, you can quickly switch to a different model by changing the model ID, as shown in Invoke model code examples. 
IAM policy requirements for global CRIS 
In this section, we discuss the IAM policy requirements for global CRIS. 
Enable global CRIS 
To enable global CRIS for your users, you must apply a three-part IAM policy to the role. The following is an example IAM policy to provide granular control. You can replace &lt;REQUESTING REGION&gt; in the example policy with the Region you are operating in. 
 
 {
&nbsp;&nbsp; &nbsp;"Version": "2012-10-17",
&nbsp;&nbsp; &nbsp;"Statement": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Sid": "GrantGlobalCrisInferenceProfileRegionAccess",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Effect": "Allow",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Action": "bedrock:InvokeModel",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Resource": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"arn:aws:bedrock:&lt;REQUESTING REGION&gt;:&lt;ACCOUNT&gt;:inference-profile/global.&lt;MODEL NAME&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Condition": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"StringEquals": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"aws:RequestedRegion": "&lt;REQUESTING REGION&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Sid": "GrantGlobalCrisInferenceProfileInRegionModelAccess",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Effect": "Allow",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Action": "bedrock:InvokeModel",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Resource": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"arn:aws:bedrock:&lt;REQUESTING REGION&gt;::foundation-model/&lt;MODEL NAME&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Condition": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"StringEquals": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"aws:RequestedRegion": "&lt;REQUESTING REGION&gt;",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock:InferenceProfileArn": "arn:aws:bedrock:&lt;REQUESTING REGION&gt;:&lt;ACCOUNT&gt;:inference-profile/global.&lt;MODEL NAME&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Sid": "GrantGlobalCrisInferenceProfileGlobalModelAccess",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Effect": "Allow",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Action": "bedrock:InvokeModel",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Resource": [
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"arn:aws:bedrock:::foundation-model/&lt;MODEL NAME&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;],
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"Condition": {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"StringEquals": {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "aws:RequestedRegion":&nbsp;"unspecified",
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"bedrock:InferenceProfileArn": "arn:aws:bedrock:&lt;REQUESTING REGION&gt;:&lt;ACCOUNT&gt;:inference-profile/global.&lt;MODEL NAME&gt;"
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;]
} 
 
The first part of the policy grants access to the Regional inference profile in your requesting Region. This policy allows users to invoke the specified global CRIS inference profile from their requesting Region. The second part of the policy provides access to the Regional FM resource, which is necessary for the service to understand which model is being requested within the Regional context. The third part of the policy grants access to the global FM resource, which enables the cross-Region routing capability that makes global CRIS function. When implementing these policies, make sure all three resource Amazon Resource Names (ARNs) are included in your IAM statements: 
 
 The Regional inference profile ARN follows the pattern arn:aws:bedrock:REGION:ACCOUNT:inference-profile/global.MODEL-NAME. This is used to give access to the global inference profile in the source Region. 
 The Regional FM uses arn:aws:bedrock:REGION::foundation-model/MODEL-NAME. This is used to give access to the FM in the source Region. 
 The global FM requires arn:aws:bedrock:::foundation-model/MODEL-NAME. This is used to give access to the FM in different global Regions. 
 
The global FM ARN has no Region or account specified, which is intentional and required for the cross-Region functionality. 
To simplify onboarding, global CRIS doesn‚Äôt require complex changes to an organization‚Äôs existing Service Control Policies (SCPs) that might deny access to services in certain Regions. When you opt in to global CRIS using this three-part policy structure, Amazon Bedrock will process inference requests across commercial Regions without validating against Regions denied in other parts of SCPs. This prevents workload failures that could occur when global CRIS routes inference requests to new or previously unused Regions that might be blocked in your organization‚Äôs SCPs. However, if you have data residency requirements, you should carefully evaluate your use cases before implementing global CRIS, because requests might be processed in any supported commercial Region. 
Disable global CRIS 
You can choose from two primary approaches to implement deny policies to global CRIS for specific IAM roles, each with different use cases and implications: 
 
 Remove an IAM policy ‚Äì The first method involves removing one or more of the three required IAM policies from user permissions. Because global CRIS requires all three policies to function, removing a policy will result in denied access. 
 Implement a deny policy ‚Äì The second approach is to implement an explicit deny policy that specifically targets global CRIS inference profiles. This method provides clear documentation of your security intent and makes sure that even if someone accidentally adds the required allow policies later, the explicit deny will take precedence. The deny policy should use a StringEquals condition matching the pattern "aws:RequestedRegion": "unspecified". This pattern specifically targets inference profiles with the global prefix. 
 
When implementing deny policies, it‚Äôs crucial to understand that global CRIS changes how the aws:RequestedRegion field behaves. Traditional Region-based deny policies that use StringEquals conditions with specific Region names such as "aws:RequestedRegion": "us-west-2" will not work as expected with global CRIS because the service sets this field to global rather than the actual destination Region. However, as mentioned earlier, "aws:RequestedRegion": "unspecified" will result in the deny effect. 
Note: To simplify customer onboarding, global CRIS has been designed to work without requiring complex changes to an organization‚Äôs existing SCPs that may deny access to services in certain Regions. When customers opt in to global CRIS using the three-part policy structure described above, Amazon Bedrock will process inference requests across supported AWS commercial Regions without validating against regions denied in any other parts of SCPs. This prevents workload failures that could occur when global CRIS routes inference requests to new or previously unused Regions that might be blocked in your organization‚Äôs SCPs. However, customers with data residency requirements should evaluate their use cases before implementing global CRIS, because requests may be processed in any supported commercial Regions. As a best practice, organizations who use geographic CRIS but want to opt out from global CRIS should implement the second approach. 
Request limit increases for global CRIS with Anthropic‚Äôs Claude Sonnet 4.5 
When using global CRIS inference profiles, it‚Äôs important to understand that service quota management is centralized in the US East (N. Virginia) Region. However, you can use global CRIS from over 20 supported source Regions. Because this will be a global limit, requests to view, manage, or increase quotas for global cross-Region inference profiles must be made through the Service Quotas console or AWS Command Line Interface (AWS CLI) specifically in the US East (N. Virginia) Region. Quotas for global CRIS inference profiles will not appear on the Service Quotas console or AWS CLI for other source Regions, even when they support global CRIS usage. This centralized quota management approach makes it possible to access your limits globally without estimating usage in individual Regions. If you don‚Äôt have access to US East (N. Virginia), reach out to your account teams or AWS support. 
Complete the following steps to request a limit increase: 
 
 Sign in to the Service Quotas console in your AWS account.  
 Make sure your selected Region is US East (N. Virginia). 
 In the navigation pane, choose AWS services. 
 From the list of services, find and choose Amazon Bedrock. 
 In the list of quotas for Amazon Bedrock, use the search filter to find the specific global CRIS quotas. For example: 
   
   Global cross-Region model inference tokens per day for Anthropic Claude Sonnet 4.5 V1 
   Global cross-Region model inference tokens per minute for Anthropic Claude Sonnet 4.5 V1 
    
 Select the quota you want to increase. 
 Choose Request increase at account level.  
 Enter your desired new quota value. 
 Choose Request to submit your request. 
 
Use global cross-Region inference with Anthropic‚Äôs Claude Sonnet 4.5 
Claude Sonnet 4.5 is Anthropic‚Äôs most intelligent model (at the time of writing), and is best for coding and complex agents. Anthropic‚Äôs Claude Sonnet 4.5 demonstrates advancements in agent capabilities, with enhanced performance in tool handling, memory management, and context processing. The model shows marked improvements in code generation and analysis, including identifying optimal improvements and exercising stronger judgment in refactoring decisions. It particularly excels at autonomous long-horizon coding tasks, where it can effectively plan and execute complex software projects spanning hours or days while maintaining consistent performance and reliability throughout the development cycle. 
Global cross-Region inference for Anthropic‚Äôs Claude Sonnet 4.5 delivers multiple advantages over traditional geographic cross-Region inference profiles: 
 
 Enhanced throughput during peak demand ‚Äì Global cross-Region inference provides improved resilience during periods of peak demand by automatically routing requests to Regions with available capacity. This dynamic routing happens seamlessly without additional configuration or intervention from developers. Unlike traditional approaches that might require complex client-side load balancing between Regions, global cross-Region inference handles traffic spikes automatically. This is particularly important for business-critical applications where downtime or degraded performance can have significant financial or reputational impacts. 
 Cost-efficiency ‚Äì Global cross-Region inference for Anthropic‚Äôs Claude Sonnet 4.5 offers approximately 10% savings on both input and output token pricing compared to geographic cross-Region inference. The price is calculated based on the Region from which the request is made (source Region). This means organizations can benefit from improved resilience with even lower costs. This pricing model makes global cross-Region inference a cost-effective solution for organizations looking to optimize their generative AI deployments. By improving resource utilization and enabling higher throughput without additional costs, it helps organizations maximize the value of their investment in Amazon Bedrock. 
 Streamlined monitoring ‚Äì When using global cross-Region inference, CloudWatch and CloudTrail continue to record log entries in your source Region, simplifying observability and management. Even though your requests are processed across different Regions worldwide, you maintain a centralized view of your application‚Äôs performance and usage patterns through your familiar AWS monitoring tools. 
 On-demand quota flexibility ‚Äì With global cross-Region inference, your workloads are no longer limited by individual Regional capacity. Instead of being restricted to the capacity available in a specific Region, your requests can be dynamically routed across the AWS global infrastructure. This provides access to a much larger pool of resources, making it less complicated to handle high-volume workloads and sudden traffic spikes. 
 
If you‚Äôre currently using Anthropic‚Äôs Sonnet models on Amazon Bedrock, upgrading to Claude Sonnet 4.5 is a great opportunity to enhance your AI capabilities. It offers a significant leap in intelligence and capability, offered as a straightforward, drop-in replacement at a comparable price point as Sonnet 4. The primary reason to switch is Sonnet 4.5‚Äôs superior performance across critical, high-value domains. It is Anthropic‚Äôs most powerful model so far for building complex agents, demonstrating state-of-the-art performance in coding, reasoning, and computer use. Furthermore, its advanced agentic capabilities, such as extended autonomous operation and more effective use of parallel tool calls, enable the creation of more sophisticated AI workflows. 
Conclusion 
Amazon Bedrock global cross-Region inference for Anthropic‚Äôs Claude Sonnet 4.5 marks a significant evolution in AWS generative AI capabilities, enabling global routing of inference requests across the AWS worldwide infrastructure. With straightforward implementation and comprehensive monitoring through CloudTrail and CloudWatch, organizations can quickly use this powerful capability for their AI applications, high-volume workloads, and disaster recovery scenarios.We encourage you to try global cross-Region inference with Anthropic‚Äôs Claude Sonnet 4.5 in your own applications and experience the benefits firsthand. Start by updating your code to use the global inference profile ID, configure appropriate IAM permissions, and monitor your application‚Äôs performance as it uses the AWS global infrastructure to deliver enhanced resilience. 
For more information about global cross-Region inference for Anthropic‚Äôs Claude Sonnet 4.5 in Amazon Bedrock, refer to Increase throughput with cross-Region inference, Supported Regions and models for inference profiles, and Use an inference profile in model invocation. 
 
About the authors 
Melanie Li, PhD, is a Senior Generative AI Specialist Solutions Architect at AWS based in Sydney, Australia, where her focus is on working with customers to build solutions using state-of-the-art AI/ML tools. She has been actively involved in multiple generative AI initiatives across APJ, harnessing the power of LLMs. Prior to joining AWS, Dr. Li held data science roles in the financial and retail industries. 
Saurabh Trikande&nbsp;is a Senior Product Manager for Amazon Bedrock and Amazon SageMaker Inference. He is passionate about working with customers and partners, motivated by the goal of democratizing AI. He focuses on core challenges related to deploying complex AI applications, inference with multi-tenant models, cost optimizations, and making the deployment of generative AI models more accessible. In his spare time, Saurabh enjoys hiking, learning about innovative technologies, following TechCrunch, and spending time with his family. 
Derrick Choo&nbsp;is a Senior Solutions Architect at AWS who accelerates enterprise digital transformation through cloud adoption, AI/ML, and generative AI solutions. He specializes in full-stack development and ML, designing end-to-end solutions spanning frontend interfaces, IoT applications, data integrations, and ML models, with a particular focus on computer vision and multi-modal systems. 
Satveer Khurpa&nbsp;is a Sr. WW Specialist Solutions Architect, Amazon Bedrock at Amazon Web Services. In this role, he uses his expertise in cloud-based architectures to develop innovative generative AI solutions for clients across diverse industries. Satveer‚Äôs deep understanding of generative AI technologies allows him to design scalable, secure, and responsible applications that unlock new business opportunities and drive tangible value. 
Jared Dean is a Principal AI/ML Solutions Architect at AWS. Jared works with customers across industries to develop machine learning applications that improve efficiency. He is interested in all things AI, technology, and BBQ. 
Jan Catarata is a software engineer working on Amazon Bedrock, where he focuses on designing robust distributed systems. When he‚Äôs not building scalable AI solutions, you can find him strategizing his next move with friends and family at game night.
‚Ä¢ Secure ingress connectivity to Amazon Bedrock AgentCore Gateway using interface VPC endpoints
  Agentic AI applications represent a significant development in enterprise automation, where intelligent agents autonomously execute complex workflows, access sensitive datasets, and make real-time decisions across your organization‚Äôs infrastructure. Amazon Bedrock AgentCore accelerates enterprise AI transformation by providing fully managed services that remove infrastructure complexity, maintain session isolation, and enable seamless integration with enterprise tools so organizations can deploy trustworthy AI agents at scale. AgentCore Gateway, a modular service under AgentCore, simplifies integration by securely transforming APIs, AWS Lambda functions, and services into Model Context Protocol (MCP)-compatible tools and making them available to agents through a unified endpoint, with built-in authentication and serverless infrastructure that minimizes operational overhead. 
In production environments, AI agents are typically deployed within virtual private clouds (VPCs) to maintain secure, isolated network access and to meet enterprise security and compliance requirements. Amazon Web Services (AWS) interface VPC endpoints can enhance agentic AI security by creating private connections between VPC-hosted agents and AgentCore Gateway, keeping sensitive communications within the secure infrastructure of AWS. These endpoints use dedicated network interfaces with private IP addresses to deliver reduced latency and superior performance through direct connectivity. Additionally, VPC interface endpoints offer granular access control through endpoint policies, streamline operations by avoiding proxy server management, reduce data transfer costs, and establish the secure foundation that autonomous AI systems require when processing confidential data in regulated environments at enterprise scale. 
In this post, we demonstrate how to access AgentCore Gateway through a VPC interface endpoint from an Amazon Elastic Compute Cloud (Amazon EC2) instance in a VPC. We also show how to configure your VPC endpoint policy to provide secure access to the AgentCore Gateway while maintaining the principle of least privilege access. 
Architecture overview 
This architecture diagram illustrates a user accessing an application supported by backend agents deployed across various AWS compute services, including EC2 instances, Lambda functions, Amazon Elastic Kubernetes Service (Amazon EKS), or Amazon Elastic Container Service (Amazon ECS), all operating within a VPC environment. These agents communicate with AgentCore Gateway to discover, access, and invoke external tools and services that have been transformed into agent-compatible resources, such as enterprise APIs and Lambda functions. In the standard configuration, agent requests to AgentCore Gateway traverse the public internet. By implementing interface VPC endpoints, organizations can route these communications through the AWS secure internal network backbone instead, delivering significant benefits that can include enhanced security, reduced latency, and improved compliance alignment for regulated workloads that require strict network isolation and data protection standards. The solution follows this workflow: 
 
 AI agent interaction ‚Äì An agent running within the VPC obtains the required inbound authorization from identity providers, authenticates with Gateway, and sends a tool-use request (invokes the MCP tool) to the gateway through the interface VPC endpoint. 
 Gateway processing: Gateway manages OAuth authorization to make sure only valid users and agents can access tools and resources. The inbound request is authorized by Gateway. Converts agent requests using protocols like Model Context Protocol (MCP) into API requests and Lambda invocations 
 Secure access: The gateway handles credential injection for each tool, enabling agents to use tools with different authentication requirements seamlessly. It uses AgentCore Identity to securely access backend resources (the targets) on behalf of the agent. 
 Target execution: The gateway data plane invokes the target, which can be a Lambda function, an OpenAPI specification, or a Smithy model. 
 Monitoring: AgentCore Gateway provides built-in observability and auditing. Additionally, AWS PrivateLink publishes metrics to Amazon CloudWatch for monitoring interface endpoints. You can optionally enable VPC Flow Logs for logging IP traffic to AgentCore Gateway. 
 
 
Be aware of the following key considerations: 
 
 Private and public network communication ‚Äì The interface VPC endpoint enables secure communication for inbound traffic from agents to AgentCore Gateway through AWS PrivateLink, making sure this traffic remains within the private network. However, authentication workflows‚Äîincluding OAuth access token retrieval and credential exchange processes between agents and external Identity Provider systems for both inbound and outbound flows‚Äîand outbound access from the gateway to MCP tools continue to require internet connectivity for establishing secure sessions with identity systems and external resources hosted outside the AWS environment. 
 Data plane scope ‚Äì It‚Äôs important to understand that, currently, the interface VPC endpoint support is applicable only to the data plane endpoints of your gateway‚Äîthe runtime endpoints where your applications interact with agent tools. To clarify the distinction: although you can now access your gateway‚Äôs runtime endpoint through the interface VPC endpoint, the control plane operations, such as creating gateways, managing tools, and configuring security settings, must still be performed through the standard public AgentCore control plane endpoint (for example, bedrock-agentcore-control.&lt;region&gt;.amazonaws.com) 
 
Prerequisites 
To perform the solution, you need the following prerequisites: 
 
 An AWS account with appropriate AWS Identity and Access Management (IAM) permissions for VPC and Amazon Elastic Compute Cloud (Amazon EC2) management 
 Existing VPC setup with subnet configuration and route tables 
 AgentCore Gateway already provisioned and configured in your AWS account 
 Basic understanding of VPC networking concepts and security group configurations 
 
Solution walkthrough 
In the following sections, we demonstrate how to configure the interface VPC endpoint using the AWS Management Console and establish secure connectivity from a test EC2 instance within the VPC to AgentCore Gateway. 
Create a security group for the EC2 instance 
To create a security group for the EC2 instance, follow these steps, as shown in the following screenshot: 
 
 Navigate to the Amazon EC2 console in your preferred AWS Region and choose Security Groups in the navigation pane under Network &amp; Security. 
 Choose Create security group. 
 For Security group name, enter a descriptive name such as ec2-agent-sg. 
 For Description, enter a meaningful description such as Security group for EC2 instances running AI agents. 
 For VPC, choose your target VPC. 
 Add relevant Inbound rules for the EC2 instance management such as SSH (port 22) from your management network or bastion host. 
 Leave Outbound rules as default (allows all outbound traffic) to make sure agents can communicate with necessary services. 
 Choose Create security group. 
 
 
Create a security group for the interface VPC endpoint 
To create a security group for the interface VPC endpoint, follow these steps: 
Create a second security group named vpce-agentcore-sg that will be attached to the AgentCore Gateway interface VPC endpoint using similar steps to the preceding instructions and selecting the same VPC. For this security group, configure the following rules to enable secure and restricted access: 
 
 Inbound rules ‚Äì Allow HTTPS (port 443) for secure communication to the AgentCore Gateway 
 Source ‚Äì Select the EC2 security group (ec2-agent-sg) you created in the preceding section to allow traffic only from authorized agent instances 
 Outbound rules ‚Äì Leave as default (all traffic allowed) to support response traffic 
 
This security group configuration implements the principle of least privilege by making sure only EC2 instances with the agent security group can access the VPC endpoint while blocking unauthorized access from other resources in the VPC. These steps are illustrated by the following screenshot. 
 
Provision an EC2 instance within the VPC 
Provision an EC2 instance in the same VPC and select an appropriate Availability Zone for your workload requirements. Configure the instance with the network settings shown in the following list, making sure you select the same VPC and note the chosen subnet for VPC endpoint configuration: 
 
 VPC ‚Äì Select your target VPC 
 Subnet ‚Äì Choose a private subnet for enhanced security (note this subnet for VPC endpoint configuration) 
 Security group ‚Äì Attach the EC2 security group (ec2-agent-sg) you created in the previous steps 
 IAM role ‚Äì Configure an IAM role with necessary permissions for Amazon Bedrock and AgentCore Gateway access 
 Instance type ‚Äì Choose an appropriate instance type based on your agent workload requirements 
 
Remember the chosen subnet because you‚Äôll need to configure the VPC endpoint in the same subnet to facilitate optimal network routing and minimal latency. These configurations are shown in the following screenshot. 
 
Create an interface VPC endpoint 
Create an interface VPC endpoint using Amazon Virtual Private Cloud (Amazon VPC) that automatically uses AWS PrivateLink technology, enabling secure communication from your EC2 instance to AgentCore Gateway without traversing the public internet. Follow these steps: 
 
 Navigate to the Amazon VPC console and choose Endpoints in the navigation pane under the PrivateLink and Lattice section. 
 Choose Create endpoint. 
 For Name tag, enter a descriptive name (for example, vpce-agentcore-gateway). 
 For Service category, choose AWS services. 
 For Services, search for and choose com.amazonaws.&lt;region&gt;.bedrock-agentcore.gateway (replace &lt;region&gt; with your actual AWS Region). 
 
These settings are shown in the following screenshot. 
 
 
 Set the VPC to the same VPC you‚Äôve been working with throughout this setup. 
 Select Enable DNS name to allow access to the AgentCore Gateway using its default domain name, which simplifies application configuration and maintains compatibility with existing code. 
 Specify the subnet where the EC2 instance is running to maintain optimal network routing and minimal latency, as shown in the following screenshot. 
 
 
 
 Set the security group to the VPC endpoint security group (vpce-agentcore-sg) you created earlier to control access to the endpoint. 
 For initial testing, leave the policy set to Full access to allow agents within your VPC to communicate with AgentCore Gateway in your AWS account. In production environments, implement more restrictive policies based on the principle of least privilege. 
 
 
After you create the endpoint, it will take approximately 2‚Äì5 minutes to become available. You can monitor the status on the Amazon VPC console, and when it shows as Available, you can proceed with testing the connection. 
Test the connection 
Log in to the EC2 instance to perform following the tests. 
Check traffic flow over an interface VPC endpoint 
To confirm the traffic flow through the Amazon Bedrock AgentCore Gateway endpoint, check the IP address of the source resource that connects to the AgentCore Gateway endpoint. When you set up an interface VPC endpoint, AWS deploys an elastic network interface with a private IP address in the subnet. This deployment allows communication with AgentCore Gateway from resources within the Amazon VPC and on-premises resources that connect to the interface VPC endpoint through AWS Direct Connect or AWS Site-to-Site VPN. It also allows communication with resources in other Amazon VPC endpoints when you use centralized interface VPC endpoint architecture patterns. 
Check whether you turned on private DNS for the AgentCore Gateway endpoint. If you turn on private DNS, then AgentCore Gateway endpoints resolve to the private endpoint IP addresses. For AgentCore Gateway, enabling private DNS means your agents can continue using the standard gateway endpoint URL while benefiting from private network routing through the VPC endpoint. 
Before VPC interface endpoint, as shown in the following example, the DNS resolves to a public IP address for AgentCore Gateway endpoint: 
 
 nslookup gateway.bedrock-agentcoreamazonaws.com

Non-authoritative answer:
Name: gateway.bedrock-agentcore..amazonaws.com
Address: 52.86.152.150 
 
After VPC interface endpoint creation with private DNS resolution, as shown in the following example, the DNS resolves to private IP address from the CIDR range of the subnet of the VPC in which the VPC endpoint was created. 
 
 nslookup .gateway.bedrock-agentcore..amazonaws.com

Non-authoritative answer:
Name: .gateway.bedrock-agentcore..amazonaws.com
Address: 172.31.91.174 
 
When you select Enable DNS name for AgentCore Gateway VPC interface endpoints, by default AWS turns on the Enable private DNS only for inbound endpoints option. 
Private DNS enabled (cURL) (recommended) 
When private DNS is enabled, your applications can seamlessly use the standard gateway URL endpoint in the format https://{gateway-id}.gateway.bedrock-agentcore.{region}.amazonaws.com while traffic automatically routes through the VPC endpoint. 
The following is a sample cURL request to be executed from a resource within the VPC. The command sends a JSON-RPC POST request to retrieve available tools from the AgentCore Gateway: 
 
 curl -sS -i -X POST https://&lt;gatewayid&gt;.gateway.bedrock-agentcore.&lt;region&gt;.amazonaws.com/mcp \
--header 'Content-Type: application/json' \ 
--header "Authorization: Bearer $TOKEN" \ 
--data '{
"jsonrpc": "2.0",
"id": "'"$UNIQUE_ID"'",
"method": "tools/list",
"params": {}
}' 

 
 
This cURL command sends a JSON-RPC 2.0 POST request to the AgentCore Gateway MCP endpoint to retrieve a list of available tools. It uses bearer token authentication and includes response headers in the output, calling the tools/list method to discover what tools are accessible through the gateway. 
Private DNS disabled (Python) 
When Private DNS is disabled, you can‚Äôt access the gateway directly through the standard AgentCore Gateway endpoint. Instead, you must route traffic through the VPC DNS name shown in the following screenshot and include the original gateway domain name in the Host header. 
 
 
 curl -sS -i -X POST https://&lt;vpce-dns-name&gt;/mcp \
  --header 'Host: &lt;gatewayid&gt;.gateway.bedrock-agentcore.&lt;region&gt;.amazonaws.com \
  --header 'Content-Type: application/json' \
  --header "Authorization: Bearer $TOKEN" \
  --data '{
    "jsonrpc": "2.0",
    "id": "'$UNIQUE_ID'",
    "method": "tools/list",
    "params": {}
  }'
 
 
The following steps below walk through executing a Python script that uses the Host header: 
 
 Access your EC2 instance. Log in to your EC2 instance that has access to the VPC endpoint. 
 Configure the required environment variables for the connection: 
 GATEWAY_URL ‚Äì The VPC endpoint URL used to access the AgentCore Gateway through your private network connection 
 TOKEN ‚Äì Your authentication bearer token for accessing the gateway 
 GATEWAY_HOST ‚Äì The original AgentCore Gateway domain name that must be included in the Host header when Private DNS is disabled 
 
For example: 
 
 export GATEWAY_URL=https://&lt;vpce_id&gt;.gateway.bedrock-agentcore.ap-southeast-2.vpce.amazonaws.com/mcp
export TOKEN=&lt;your-token-here&gt;
export GATEWAY_HOST=&lt;gateway_id&gt;.gateway.bedrock-agentcore.ap-southeast-2.amazonaws.com
 
 
 
 Create and execute the test script. 
   
   Copy the following Python code into a file named agent.py. This code tests the AgentCore Gateway workflow by discovering available tools, creating a Strands Agent with the tools, and then testing both conversational interactions (tool listing and weather queries) and direct MCP tool calls. Copy the code: 
    
 
 
 from strands.models import BedrockModel
from mcp.client.streamable_http import streamablehttp_client
from strands.tools.mcp.mcp_client import MCPClient
from strands import Agent
import logging
import os

# Read authentication token and gateway URL from environment variables
token = os.getenv('TOKEN')
gatewayURL = os.getenv('GATEWAY_URL')  #vpc endpoint url
gatewayHost = os.getenv('GATEWAY_HOST') #domain name of the agentcore gateway

def create_streamable_http_transport():
    """Create HTTP transport with proper authentication headers"""
    return streamablehttp_client(
        gatewayURL, 
        headers={
            "Authorization": f"Bearer {token}",
            "Host":gatewayHost
        }
    )
# Initialize MCP client with the transport
client = MCPClient(create_streamable_http_transport)

# Configure Bedrock model - ensure IAM credentials in ~/.aws/credentials have Bedrock access
yourmodel = BedrockModel(
    model_id="amazon.nova-pro-v1:0",
    temperature=0.7,
)

# Configure logging for debugging and monitoring
logging.getLogger("strands").setLevel(logging.INFO)
logging.basicConfig(
    format="%(levelname)s | %(name)s | %(message)s",
    handlers=[logging.StreamHandler()]
)

# Test the complete agent workflow
with client:
    targetname = 'TestGatewayTarget36cb2ebf'
    
    # List available tools from the MCP server
    tools = client.list_tools_sync()
    
    # Create an Agent with the model and available tools
    agent = Agent(model=yourmodel, tools=tools)
    print(f"Tools loaded in the agent: {agent.tool_names}")
    
    # Test agent with a simple query to list available tools
    response1 = agent("Hi, can you list all tools available to you?")
    print(f"Agent response for tool listing: {response1}")
    
    # Test agent with a tool invocation request
    response2 = agent("Get the current weather for Seattle and show me the exact response from the tool")
    print(f"Agent response for weather query: {response2}")
    
    # Direct MCP tool invocation for validation
    result = client.call_tool_sync(
        tool_use_id="get-weather-seattle-call-1",  # Unique identifier for this call
        name=f"{targetname}___get_weather",  # Tool name format for Lambda targets
        arguments={"location": "Seattle"}
    )
    print(f"Direct MCP tool response: {result}") 
 
 
 Invoke the script using the following command: 
 
python3 agent.py 
Advanced configuration: VPC endpoint access policies 
A VPC endpoint policy is a resource-based policy that controls access to AWS services through the endpoint. Unlike identity-based policies, endpoint policies provide an additional layer of access control at the network level. You can configure access policies for AgentCore Gateway VPC endpoints with specific considerations.When creating endpoint policies for AgentCore Gateway, consider these key elements: 
 
 Principal configuration ‚Äì The Principal field can‚Äôt be modified because AgentCore Gateway doesn‚Äôt use IAM for authentication. Authentication is handled through bearer tokens rather than IAM principals. 
 Resource specification ‚Äì Clearly define the Resource field if you want to restrict access to specific gateway endpoints. Use the full Amazon Resource Name (ARN) format to target particular gateways within your account as shown in the following sample policy structure. 
 Action permissions ‚Äì For the Action field, avoid specifying control plane operations. Use a wildcard (*) to allow the necessary data plane operations for gateway functionality. 
 
Here is a sample policy structure: 
 
 {
"Version": "2012-10-17",
"Statement": [
{
"Principal": "*",
"Effect": "Allow",
"Action": "*",
"Resource": "arn:aws:bedrock-agentcore:&lt;region&gt;:&lt;AWS_Account_ID&gt;:gateway/&lt;gateway_id&gt;"
}
]
}
 
 
When the VPC endpoint policy blocks a request, you will see error responses such as: 
 
 {"jsonrpc":"2.0","id":2,"error":{"code":-32002,"message":"Authorization error - Insufficient permissions"}} 
 
Policy caching behavior 
AgentCore Gateway implements a caching mechanism for access policies that introduces a delay of up to 15 minutes before policy changes take effect. Although this caching significantly improves gateway performance, it means that policy modifications might not be immediately reflected in access controls. To work effectively with this behavior, you should allow at least 15 minutes for policy changes to fully propagate throughout the system after making updates. When possible, schedule policy modifications during planned maintenance windows to minimize operational impact. Always test policy changes in nonproduction environments before applying them to production gateways and factor in the caching delay when diagnosing access-related issues to avoid premature troubleshooting efforts. 
Advanced patterns 
In a shared gateway, multiple agents pattern, multiple agents from different services access a single centralized gateway through a shared VPC endpoint, simplifying network architecture while maintaining security through token-based authentication. This pattern is illustrated in the following diagram. 
 
In a multi-gateway, multi-agent pattern, which is shown in the following diagram, multiple agents across different applications access multiple specialized gateways through dedicated VPC endpoints, providing maximum security isolation with access control per gateway. 
 
In a cross-VPC gateway access pattern, shown in the following diagram, agents in multiple VPCs can access AgentCore Gateway through VPC peering or AWS Transit Gateway connections, allowing centralized gateway access across network boundaries while maintaining isolation. 
 
In a hybrid cloud gateway pattern, on-premises agents can access cloud-based gateways through VPC endpoints with private DNS disabled, enabling hybrid cloud deployments through Direct Connect or VPN connections. The following diagram illustrates this pattern. 
 
Clean up 
To avoid ongoing charges and maintain good resource hygiene, clean up your resources by completing the following steps in order:Delete the EC2 instance: 
 
 Navigate to the Amazon EC2 console and select your test instance 
 Choose Instance state and Stop instance, then wait for it to stop 
 Choose Instance state and Terminate instance to permanently delete the instance 
 
Delete the VPC endpoint: 
 
 Navigate to the Amazon VPC console and choose Endpoints 
 Select the VPC endpoint (vpce-agentcore-gateway) you created 
 Choose Actions and Delete VPC endpoints 
 Confirm the deletion 
 
Delete the security groups: 
 
 Navigate to the Amazon EC2 console and choose Security groups 
 Select the EC2 security group (ec2-agent-sg) you created 
 Choose Actions and Delete security groups 
 Repeat for the VPC endpoint security group (vpce-agentcore-sg) 
 
Conclusion 
In this post, we demonstrated how to establish secure, private connectivity between VPC-hosted resources and Amazon Bedrock AgentCore Gateway using VPC interface endpoints and AWS PrivateLink. This architecture delivers comprehensive benefits for enterprise agentic AI deployments by implementing networks that are isolated from the internet, providing enhanced security through dedicated private network paths. The solution implements a robust data perimeter through VPC endpoint policies, which create granular access controls that establish strict data boundaries around your AI resources. Additionally, the architecture enables private connectivity to Gateway endpoints for on-premises environments, supporting distributed AI architectures that span cloud and on-premises infrastructure. For organizations deploying autonomous AI systems at scale, implementing VPC interface endpoints creates the secure networking foundation necessary for efficient agent operations while delivering reduced latency through optimized network paths. This enterprise-grade approach helps enable your agentic AI applications to achieve improved performance and reduced response times while meeting security and compliance requirements. 
To learn more about implementing these patterns and best practices, visit the Amazon Bedrock documentation and AWS PrivateLink documentation for comprehensive guidance on AI deployments. 
 
About the authors 
Dhawal Patel is a Principal Machine Learning Architect at Amazon Web Services (AWS). He has worked with organizations ranging from large enterprises to midsized startups on problems related to distributed computing and AI. He focuses on deep learning, including natural language processing (NLP) and computer vision domains. He helps customers achieve high-performance model inference on Amazon SageMaker. 
Sindhura Palakodety is a Senior Solutions Architect at Amazon Web Services (AWS) and Single-Threaded Leader (STL) for ISV Generative AI, where she is dedicated to empowering customers in developing enterprise-scale, Well-Architected solutions. She specializes in generative AI and data analytics domains, enabling organizations to leverage innovative technologies for transformative business outcomes. 
Thomas Mathew Veppumthara is a Sr. Software Engineer at Amazon Web Services (AWS) with Amazon Bedrock AgentCore. He has previous generative AI leadership experience in Amazon Bedrock Agents and nearly a decade of distributed systems expertise across Amazon eCommerce Services and Amazon Elastic Block Store (Amazon EBS). He holds multiple patents in distributed systems, storage, and generative AI technologies. 
June Won is a Principal Product Manager with Amazon SageMaker JumpStart. He focuses on making foundation models (FMs) easily discoverable and usable to help customers build generative AI applications. His experience at Amazon also includes mobile shopping applications and last-mile delivery.

‚∏ª