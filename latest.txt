‚úÖ Morning News Briefing ‚Äì September 19, 2025 10:43

üìÖ Date: 2025-09-19 10:43
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ Current Conditions: Fog Patches, 6.0¬∞C
  Temperature: 6.0&deg;C Pressure: 102.0 kPa Visibility: 11 km Visibility : 11 km . Humidity: 95 % Dewpoint: 5.2&deg:C Wind: W 5 km/h Air Quality Health Index: n/a . Air Quality: "N/A" Air Quality health index: "Health Index" "Health
‚Ä¢ Friday: Mainly sunny. High 17.
  A mix of sun and cloud this morning, becoming sunny this morning . Wind becoming northwest 20 km/h late this morning. High 17. UV index 6 or high, with a high of 6 or very high UV index of 6 in the morning's UVB (high or medium) UVB is 6 or medium . Forecast issued 5:00 AM EDT Friday 19 September 2025 .
‚Ä¢ Friday night: Clear. Low plus 1 with frost.
  Clear. Clear. Low plus 1 with frost. Clear . Clear. Forecast issued 5:00 AM EDT Friday 19 September 2025 . Forecast forecast: Clear, low-freezing conditions. Clear and frosty weather. Clear skies. Clear weather. Low-freeze conditions. Cold temperatures: Clear and low lows: Clear . Frosty conditions: Clear. Frosty weather .

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Grocery prices have jumped up, and there's no relief in sight
  Groceries saw their biggest jump in nearly three years last month, a worrisome sign for inflation-weary shoppers . Tariffs are contributing to higher prices for imported staples like bananas and coffee . Grocery prices have risen in the past three years, according to a recent survey of grocery stores in the U.S. and elsewhere in the world . Inflation is a concern for
‚Ä¢ Who offered Trump an exceedingly rare second state visit? Find out in the quiz
  This week's quiz also features late-night hosts, Emmy losers, the pope, geometry and bears . It also features the pope and the pope as well as the pope . Check out the latest round of our weekly quiz to test your knowledge of the latest news from iReport.com . Back to the page you came from, comment on the latest episode of this week's Daily Mail
‚Ä¢ Six-man football is more than touchdowns and wins in Texas: 'It's like an identity'
  In the state's rural pockets, schools with fewer than 105 students can opt to play six-man football . The game is a version of the game that takes fewer players and has its own special set of rules . In rural areas, schools can play six man football, which takes less than 105 players and takes fewer than a quarter of the players . Six man football is a special version
‚Ä¢ 20 years later, Israelis ask if the Gaza exit backfired ‚Äî and if it's time to go back
  Israel dismantled its settlements and withdrew from the Gaza Strip 20 years ago . Now, Israelis ask if it helped pave the way for the Oct. 7 attack . Some Israelis want to resettle there, and some want to move there . Israel dismantled settlements in Gaza in 1994, but some say it paved way for terror attacks in Gaza . Israel has been accused of inciting violence in Gaza since then
‚Ä¢ Lawsuit aims to force Trump administration to stop delaying student loan forgiveness
  The American Federation of Teachers is seeking a preliminary injunction that would force the department to resume student loan forgiveness . The union is seeking an injunction to stop the program from being reinstated . The department has been criticized by the union for not allowing student loans to be paid off for more than a quarter of their loans . The lawsuit seeks an injunction from the Department of Education that would halt the program .

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ OpenAI plugs ShadowLeak bug in ChatGPT that let miscreants raid inboxes
  Radware says flaw enabled hidden email prompts to trick Deep Research agent into exfiltrating sensitive data . ChatGPT's research assistant sprung a leak ‚Äì since patched ‚Äì that let attackers steal Gmail secrets with just a single carefully crafted email . Radware: The flaw has since been patched and has been fixed . The vulnerability was fixed by Radware's software company, Radware, which
‚Ä¢ Charities warn Ofcom too soft on Online Safety Act violators
  Charity chief raises concerns over robustness of Ofcom's enforcement of the legislation . Another blow for the legislation as Parliament continues to hear stakeholder views . UK ministers continue to quiz stakeholders over the effectiveness of the Online Safety Act . Ofcom has been criticised for not enforcing the controversial legislation in the past . The charity chief raised concerns over Ofcom enforcing the law, raising questions about Ofcom
‚Ä¢ British spreadsheet wizard will take mad skillz to Vegas after taking national Excel crown
  The inaugural finals of the UK Excel Championship have come and gone, and there is now one spreadsheet wrangler to rule them all, at least in the United Kingdom . The first finals were held in London on Monday, January 1st, 1900, when Excel was introduced to the world on January 1, 1900 . The event took place in London, London and London, with a total of
‚Ä¢ Word to the wise: Don't tell your IT manager they're not in Excel
  The Register's Friday frolic through your tales of delightful tech support encounters . Contractor sneakily fired after pointing out odious ignorance . On Call is a weekly feature of our tech support columnists on CNN Tech's tech-savvy Friday at 10 a.m. ET . Back to Mail Online home . Back To The Register home .Back to the page you came from . Back
‚Ä¢ MI6 reveals 'Silent Courier' dark web portal upgrade it hopes will help it recruit new spies
  The UK's Secret Intelligence Service, aka MI6, has created a dark web portal called ‚ÄúSilent Courier‚Äù that it hopes would-be foreign informants will find a suitably secure means of sharing secrets . The UK‚Äôs Secret . Intelligence Service hopes to find a suitable secure means to share secrets with spooks over Tor or VPN without blowing your cover . The ÔøΩ

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Sleep and circadian rhythms in cardiovascular resilience: mechanisms, implications, and a Roadmap for research and interventions
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Comparison of Three Anonymization Tools for a Health Fitness Study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ My career switch from psychologist to open-science advocate
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ A national cohort study of long-term opioid prescription and sociodemographic and health care-related risk factors
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Prevalence and risk factors of viral hepatitis and HIV among people experiencing homelessness in Germany based on a nationwide study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ A pivotal meeting on vaccine guidance is underway‚Äîand former CDC leaders are alarmed
  This week has been an eventful one for America‚Äôs public health agency. Two former leaders of the US Centers for Disease Control and Prevention explained the reasons for their sudden departures from the agency in a Senate hearing. And they described how CDC employees are being instructed to turn their backs on scientific evidence.



The CDC‚Äôs former director Susan Monarez and former chief medical officer Debra Houry took questions from a Senate committee on Wednesday. They painted a picture of a health agency in turmoil‚Äîand at risk of harming the people it is meant to serve.





On Thursday, an advisory CDC panel that develops vaccine guidance met for a two-day discussion on multiple childhood vaccines. During the meeting, which was underway as The Checkup went to press, members of the panel were set to discuss those vaccines and propose recommendations on their use.



Monarez worries that access to childhood vaccines is under threat‚Äîand that the public health consequences could be dire. ‚ÄúIf vaccine protections are weakened, preventable diseases will return,‚Äù she said.



As the current secretary of health and human services, Robert F. Kennedy Jr. oversees federal health and science agencies that include the CDC, which monitors and responds to threats to public health. Part of that role involves developing vaccine recommendations.



As we‚Äôve noted before, RFK Jr. has long been a prominent critic of vaccines. He has incorrectly linked commonly used ingredients to autism and made other incorrect statements about risks associated with various vaccines.



Still, he oversaw the recruitment of Monarez‚Äîwho does not share those beliefs‚Äîto lead the agency. When she was sworn in on July 31, Monarez, who is a microbiologist and immunologist, had already been serving as acting director of the agency. She had held prominent positions at other federal agencies and departments too, including the Advanced Research Projects Agency for Health (ARPA-H) and the Biomedical Advanced Research and Development Authority (BARDA). Kennedy¬†described her as ‚Äúa public health expert with unimpeachable scientific credentials.‚Äù



His opinion seems to have changed somewhat since then. Just 29 days after Monarez took on her position, she was turfed out of the agency. And in yesterday‚Äôs hearing, she explained why.



On August 25, Kennedy asked Monarez to do two things, she said. First, he wanted her to commit to firing scientists at the agency. And second, he wanted her to ‚Äúpre-commit‚Äù to approve vaccine recommendations made by the agency‚Äôs Advisory Committee on Immunization Practices (ACIP), regardless of whether there was any scientific evidence to support those recommendations, she said. ‚ÄúHe just wanted blanket approval,‚Äù she said during her testimony.¬†



She refused both requests.



Monarez testified that she didn‚Äôt want to get rid of hardworking scientists who played an important role in keeping Americans safe. And she said she could not commit to approving vaccine recommendations without reviewing the scientific evidence behind them and maintain her integrity. She was sacked.





Those vaccine recommendations are currently under discussion, and scientists like Monarez are worried about how they might change. Kennedy fired all 17 members of the previous committee in June. (Monarez said she was not consulted on the firings and found out about them through media reports.)



‚ÄúA clean sweep is needed to reestablish public confidence in vaccine science,‚Äù Kennedy wrote in¬†a piece for the Wall Street Journal at the time. He went on to replace those individuals with eight new members, some of whom have been prominent vaccine critics and¬†have spread misinformation about vaccines. One later withdrew.



That new panel met two weeks later. The¬†meeting included a presentation about thimerosal‚Äîa chemical that Kennedy has incorrectly linked to autism, and which is no longer included in vaccines in the US‚Äîand a proposal to recommend that the MMRV vaccine (for measles, mumps, rubella, and varicella) not be offered to children under the age of four.



Earlier this week,¬†five new committee members were named. They include¬†individuals who have advocated against vaccine mandates and who have argued that mRNA-based covid vaccines should be removed from the market.



All 12 members are convening for a meeting that runs today and tomorrow. At that meeting, members will propose recommendations for the MMRV vaccine and vaccines for covid-19 and hepatitis B, according to an agenda published on the CDC website.



Those are the recommendations for which Monarez says she was asked to provide ‚Äúblanket approval.‚Äù ‚ÄúMy worst fear is that I would then be in a position of approving something that reduces access [to] lifesaving vaccines to children and others who need them,‚Äù she said.



That job now goes to Jim O‚ÄôNeill, the deputy health secretary and acting CDC director (also a longevity enthusiast), who now holds the authority to approve those recommendations.



We don‚Äôt yet know what those recommendations will be. But if they are approved, they could reshape access to vaccines for children and vulnerable people in the US. As¬†six former chairs of the committee wrote for STAT: ‚ÄúACIP is directly linked to the Vaccines for Children program, which provides vaccines without cost to approximately 50% of children in the US, and the Affordable Care Act that requires insurance coverage for ACIP-recommended vaccines to approximately 150 million people in the US.‚Äù



Drops in vaccine uptake have already contributed to this year‚Äôs measles outbreak in the US, which is the biggest in decades. Two children have died. We are already seeing the impact of undermined trust in childhood vaccines. As Monarez put it: ‚ÄúThe stakes are not theoretical.‚Äù



This article first appeared in The Checkup,¬†MIT Technology Review‚Äôs¬†weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,¬†sign up here.
‚Ä¢ The Download: AI-designed viruses, and bad news for the hydrogen industry
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



AI-designed viruses are here and already killing bacteria



Artificial intelligence can draw cat pictures and write emails. Now the same technology can compose a working genome.A research team in California says it used AI to propose new genetic codes for viruses‚Äîand managed to get several of them to replicate and kill bacteria.The work, described in a preprint paper, has the potential to create new treatments and accelerate research into artificially engineered cells. But experts believe it is also an ‚Äúimpressive first step‚Äù toward AI-designed life forms. Read the full story.



‚ÄîAntonio Regalado







Clean hydrogen is facing a big reality check



Hydrogen is sometimes held up as a master key for the energy transition. It can be made using several low-emissions methods and could play a role in cleaning up industries ranging from agriculture to aviation to shipping.



This moment is a complicated one for the green fuel, though, as a new report from the International Energy Agency lays out. A number of major projects face cancellations and delays. The US in particular is seeing a slowdown after changes to key tax credits and cuts in support for renewable energy.Still, there are bright spots for the industry, including in China, and new markets could soon become crucial for growth. Here are three things to know about the state of hydrogen in 2025.



‚ÄîCasey Crownhart



This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 Meta‚Äôs new smart glasses have a tiny screenWelcome back, Google Glass. (NYT $)+ Mark Zuckerberg says the devices are our best bet at unlocking ‚Äúsuperintelligence.‚Äù (FT $)+ He‚Äôs also refusing to let his metaverse dream die. (WP $)+ What‚Äôs next for smart glasses. (MIT Technology Review)



2 DeepSeek writes flawed code for groups China disfavorsResearchers found that it produced code with major security weaknesses when told it was for the banned spiritual movement Falun Gong. (WP $)



3 The CDC is a messIts advice can no longer be trusted. Here‚Äôs where to turn instead. (The Atlantic $)+ Its ousted director claims RFK Jr pressured her to approve vaccine changes. (Wired $)+ Why childhood vaccines are a public health success story. (MIT Technology Review)



4 Google‚Äôs gen-AI image model Nano Banana is a global smash hitParticularly in India. (TechCrunch)+ Nvidia‚Äôs Jensen Huang really loves it, too. (Wired $)



5 OpenAI has found a way to reduce its models‚Äô schemingBut they weren‚Äôt able to eradicate it completely. (ZDNET)+ AI systems are getting better at tricking us. (MIT Technology Review)



6 Inside Texas‚Äô efforts to keep vector-borne diseases at bayThe Arbovirus-Entomology Laboratory analyzes mosquitos, but resources are drying up. (Vox)+ Brazil is fighting dengue with bacteria-infected mosquitos. (MIT Technology Review)



7 Financial AI advisors are comingBut companies are still cautious about rolling them out at scale. (WSJ $)+ Warning: ChatGPT‚Äôs advice may not necessarily be financially sound. (NYT $)+ Your most important customer may be AI. (MIT Technology Review)



8 China‚Äôs flying car market is raring to take offHovering taxis above the city of Guangzhou could soon become commonplace. (FT $)+ Eek‚Äîa pair of flying cars collided during an airshow earlier this week. (CNN)+ These aircraft could change how we fly. (MIT Technology Review)



9 Samsung‚Äôs US fridges will soon display adsWow, that‚Äôs not depressing at all. (The Verge)10 Online dating is getting even worse And AI is to blame. (NY Mag $)







Quote of the day



‚ÄúHow do educators have any real choice here about intentional use of AI when it is just being injected into educational environments without warning, without testing and without consultation?‚Äù



‚ÄîEamon Costello, an associate professor at Dublin City University, tells the Washington Post why he‚Äôs against Google adding a ‚Äòhomework help‚Äô button to its Chrome browser.







One more thing







Your boss is watchingWorking today‚Äîwhether in an office, a warehouse, or your car‚Äîcan mean constant electronic surveillance with little transparency, and potentially with livelihood-¬≠ending consequences if your productivity flags.But what matters even more than the effects of this ubiquitous monitoring on privacy may be how all that data is shifting the relationships between workers and managers, companies and their workforce. It‚Äôs a huge power shift that may require new policies and protections. Read the full story.



‚ÄîRebecca Ackermann







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)+ Find yourself feeling sleepy every afternoon? Here‚Äôs how to fight the post-lunch slump.+ Life lessons from a London graffiti artist.+ If you‚Äôre in need of a laugh, a good comedy is a great place to start.+ Yellowstone‚Äôs famous hot springs are under attack‚Äîfrom tourists‚Äô hats.
‚Ä¢ Clean hydrogen is facing a big reality check
  Hydrogen is sometimes held up as a master key for the energy transition . It can be made using several low-emissions methods and could play a role in cleaning up industries ranging from agriculture and chemicals to aviation and long-distance shipping . A number of major projects face cancellations and delays, especially in the US and Europe . Still, there are bright spots for the industry, including in China, and new markets could soon become crucial for growth .
‚Ä¢ AI-designed viruses are here and already killing bacteria
  Artificial intelligence can draw cat pictures and write emails. Now the same technology can compose a working genome.



A research team in California says it used AI to propose new genetic codes for viruses‚Äîand managed to get several of these viruses to replicate and kill bacteria.



The scientists, based at Stanford University and the nonprofit Arc Institute, both in Palo Alto, say the germs with AI-written DNA represent the ‚Äúthe first generative design of complete genomes.‚Äù



The work, described in a preprint paper, has the potential to create new treatments and accelerate research into artificially engineered cells. It is also an ‚Äúimpressive first step‚Äù toward AI-designed life forms, says Jef Boeke, a biologist at NYU Langone Health, who was provided an advance copy of the paper by MIT Technology Review.¬†¬†



Boeke says the AI‚Äôs performance was surprisingly good and that its ideas were unexpected. ‚ÄúThey saw viruses with new genes, with truncated genes, and even different gene orders and arrangements,‚Äù he says.



This is not yet AI-designed life, however. That‚Äôs because viruses are not alive. They‚Äôre more like renegade bits of genetic code with relatively puny, simple genomes.¬†





In the new work, researchers at the Arc Institute sought to develop variants of a bacteriophage‚Äîa virus that infects bacteria‚Äîcalled phiX174, which has only 11 genes and about 5,000 DNA letters.



To do so, they used two versions of an AI called Evo, which works on the same principles as large language models like ChatGPT. Instead of feeding them textbooks and blog posts to learn from, the scientists trained the models on the genomes of about 2 million other bacteriophage viruses.



But would the genomes proposed by the AI make any sense? To find out, the California researchers chemically printed 302 of the genome designs as DNA strands and then mixed those with E. coli bacteria.



That led to a profound ‚ÄúAI is here‚Äù moment when, one night, the scientists saw plaques of dead bacteria in their petri dishes. They later took microscope pictures of the tiny viral particles, which look like fuzzy dots.



‚ÄúThat was pretty striking, just actually seeing, like, this AI-generated sphere,‚Äù says Brian Hie, who leads the lab at the Arc Institute where the work was carried out.



Overall, 16 of the 302 designs ended up working‚Äîthat is, the computer-designed phage started to replicate, eventually bursting through the bacteria and killing them.



J. Craig Venter, who created some of the first organisms with lab-made DNA nearly two decades ago, says the AI methods look to him like ‚Äújust a faster version of trial-and-error experiments.‚Äù



For instance, when a team he led managed to create a bacterium with a lab-printed genome in 2008, it was after a long hit-or-miss process of testing out different genes. ‚ÄúWe did the manual AI version‚Äîcombing through the literature, taking what was known,‚Äù he says.¬†



But speed is exactly why people are betting AI will transform biology. The new methods already claimed a Nobel Prize in 2024 for predicting protein shapes. And investors are staking billions that AI can find new drugs. This week a Boston company, Lila, raised $235 million to build automated labs run by artificial intelligence.



Computer-designed viruses could also find commercial uses. For instance, doctors have sometimes tried ‚Äúphage therapy‚Äù to treat patients with serious bacterial infections. Similar tests are underway to cure cabbage of black rot, also caused by bacteria.



‚ÄúThere is definitely a lot of potential for this technology,‚Äù says Samuel King, the student who spearheaded the project in Hei‚Äôs lab. He notes that most gene therapy uses viruses to shuttle genes into patients‚Äô bodies, and AI might develop more effective ones.



The Stanford researchers say they purposely haven‚Äôt taught their AI about viruses that can infect people. But this type of technology does create the risk that other scientists‚Äîout of curiosity, good intentions, or malice‚Äîcould turn the methods on human pathogens, exploring new dimensions of lethality.



‚ÄúOne area where I urge extreme caution is any viral enhancement research, especially when it‚Äôs random so you don‚Äôt know what you are getting,‚Äù says Venter. ‚ÄúIf someone did this with smallpox or anthrax, I would have grave concerns.‚Äù



Whether an AI can generate a bona fide genome for a larger organism remains an open question. For instance, E. coli has about a thousand times more DNA code than phiX174 does.¬†‚ÄúThe complexity would rocket from staggering to ‚Ä¶ way way more than the number of subatomic particles in the universe,‚Äù says Boeke.



Also, there‚Äôs still no easy way to test AI designs for larger genomes. While some viruses can ‚Äúboot up‚Äù from just a DNA strand, that‚Äôs not the case with a bacterium, a mammoth, or a human. Scientists would instead have to gradually change an existing cell with genetic engineering‚Äîa still laborious process.



Despite that, Jason Kelly, the CEO of Ginkgo Bioworks, a cell-engineering company in Boston, says exactly such an effort is needed. He believes it could be carried out in ‚Äúautomated‚Äù laboratories where genomes get proposed and tested and the results are fed back to AI for further improvement.



¬†‚ÄúThis would be a nation-scale scientific milestone, as cells are the building blocks of all life,‚Äù says Kelly. ‚ÄúThe US should make sure we get to it first.‚Äù
‚Ä¢ The Download: measuring returns on R&D, and AI‚Äôs creative potential
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



How to measure the returns on R&amp;D spending



Given the draconian cuts to US federal funding for science, it‚Äôs worth asking some hard-nosed money questions: How much should we be spending on R&amp;D? How much value do we get out of such investments, anyway?&nbsp;



To answer that, in several recent papers, economists have approached this issue in clever new ways.&nbsp; And, though they ask slightly different questions, their conclusions share a bottom line: R&amp;D is, in fact, one of the better long-term investments that the government can make. Read the full story.



‚ÄîDavid Rotman



This article is part of MIT Technology Review Explains, our series untangling the complex, messy world of technology to help you understand what‚Äôs coming next. You can read more from the series here.



If you‚Äôre interested in reading more about America‚Äôs economic situation, check out:



+ Sweeping tariffs could threaten the US manufacturing rebound‚Äîand they could stunt its ability to make tomorrow&#8217;s breakthroughs. Read the full story.+ The surprising barrier that keeps us from building the housing we need. Read the full story.+ How to fine-tune AI for prosperity.+ People are worried that AI will take everyone‚Äôs jobs. We‚Äôve been here before.







MIT Technology Review Narrated: How AI can help supercharge creativity



Forget one-click creativity. Artists and musicians are finding new ways to make art using AI, by injecting friction, challenge, and serendipity into the process.



This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we‚Äôre publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it‚Äôs released.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 TikTok‚Äôs buyers may include Oracle, Silver Lake and Andreessen Horowitz¬†They would control around 80% of the business, with Chinese shareholders holding the rest. (WSJ $)+ We still have plenty of unanswered questions about the deal. (Bloomberg $)+ It was brokered in Madrid. (The Guardian)



2 OpenAI is working on a version of ChatGPT for teenagersAnd it‚Äôll use age-prediction tech to bar them from the standard version. (Axios)+ The move comes as the US Senate is hearing evidence about chatbot harms. (404 Media)+ The looming crackdown on AI companionship. (MIT Technology Review)3 China has banned tech firms from buying Nvidia‚Äôs chipsIn an effort to boost its own companies. (FT $)+ Alibaba and ByteDance have been instructed to terminate orders. (Bloomberg $)



4 Anthropic refuses to let US law enforcement use its modelsMuch to the White House‚Äôs chagrin. (Semafor)5 Tesla‚Äôs doors may trap passengers inside its carsVehicle safety regulators are investigating after people reported being forced to break windows to retrieve children. (NYT $)¬†¬†



6 How AI companies train their models to do white-collar jobs¬†¬†After hitting a wall, they‚Äôre throwing money at the problem. (The Information $)+ New training ‚Äòenvironments‚Äô are a hot AI topic right now.¬† (TechCrunch)+ How AI is shaking up corporate hierarchies. (WSJ $)



7 Inside Damascus‚Äô bid to become a tech hubThe city‚Äôs tech industry has been embraced by its new government. (Rest of World)



8 A supply shipment to the ISS has been delayedNASA is blaming engine trouble. (Ars Technica)+ The great commercial takeover of low Earth orbit. (MIT Technology Review)



9 Our darkest nights are getting lighterArtificial light is ruining our chances of seeing starry skies. (IEEE Spectrum)+ Bright LEDs could spell the end of dark skies. (MIT Technology Review)



10 You can now book a safari through Uber Expedition into Nairobi National Park, anyone? (Bloomberg $)







Quote of the day



‚ÄúWhat began as a homework helper gradually turned itself into a confidant and then a suicide coach.‚Äù



‚ÄîMatthew Raine, whose 16-year old son Adam died by suicide after repeatedly sharing his intentions with ChatGPT, gives evidence to a Senate Judiciary subcommittee investigating chatbot dangers, the Washington Post reports.







One more thing







AI is coming for music, tooWhile large language models that generate text have exploded in the last three years, a different type of AI, based on what are called diffusion models, is having an unprecedented impact on creative domains.By transforming random noise into coherent patterns, diffusion models can generate new images, videos, or speech, guided by text prompts or other input data. The best ones can create outputs indistinguishable from the work of peopleNow these models are marching into a creative field that is arguably more vulnerable to disruption than any other: music. Read the full story.



‚ÄîJames O&#8217;Donnell







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Food, in all shapes and forms, is bigger than ever. So why aren‚Äôt we watching cooking shows any more?+ Kate Bush‚Äôs Hounds of Love turns 40 this year, but still sounds as fresh as ever.+ Here‚Äôs how to maximize your chances of booking a bargain flight.+ Robert Redford, you were one of a kind.

üîí Cybersecurity & Privacy
‚Ä¢ Self-Replicating Worm Hits 180+ Software Packages
  At least 187 code packages made available through the JavaScript repository NPM have been infected with a self-replicating worm that steals credentials from developers and publishes those secrets on GitHub, experts warn.¬†The malware, which briefly infected multiple code packages from the security vendor CrowdStrike, steals and publishes even more credentials every time an infected package is installed.
Image: https://en.wikipedia.org/wiki/Sandworm_(Dune)
The novel malware strain is being dubbed Shai-Hulud &#8212; after the name for the giant sandworms in Frank Herbert&#8217;s Dune novel series &#8212; because it publishes any stolen credentials in a new public GitHub repository that includes the name &#8220;Shai-Hulud.&#8221;
&#8220;When a developer installs a compromised package, the malware will look for a npm token in the environment,&#8221; said Charlie Eriksen, a researcher for the Belgian security firm Aikido. &#8220;If it finds it, it will modify the 20 most popular packages that the npm token has access to, copying itself into the package, and publishing a new version.&#8221;
At the center of this developing maelstrom are code libraries available on NPM (short for ‚ÄúNode Package Manager‚Äù), which acts as a central hub for JavaScript development and provides the latest updates to widely-used JavaScript components.
The Shai-Hulud worm emerged just days after unknown attackers launched a broad phishing campaign that spoofed NPM and asked developers to &#8220;update&#8221; their multi-factor authentication login options. That attack led to malware being inserted into at least two-dozen NPM code packages, but the outbreak was quickly contained and was narrowly focused on siphoning cryptocurrency payments.
Image: aikido.dev
In late August, another compromise of an NPM developer resulted in malware being added to &#8220;nx,&#8221; an open-source code development toolkit with as many as six million weekly downloads. In the nx compromise, the attackers introduced code that scoured the user‚Äôs device for authentication tokens from programmer destinations like GitHub and NPM, as well as SSH and API keys. But instead of sending those stolen credentials to a central server controlled by the attackers, the malicious nx code created a new public repository in the victim‚Äôs GitHub account, and published the stolen data there for all the world to see and download.
Last month&#8217;s attack on nx did not self-propagate like a worm, but this Shai-Hulud malware does and bundles reconnaissance tools to assist in its spread. Namely, it uses the open-source tool TruffleHog to search for exposed credentials and access tokens on the developer&#8217;s machine. It then attempts to create new GitHub actions and publish any stolen secrets.
&#8220;Once the first person got compromised, there was no stopping it,&#8221; Aikido&#8217;s Eriksen told KrebsOnSecurity. He said the first NPM package compromised by this worm appears to have been altered on Sept. 14, around 17:58 UTC.
The security-focused code development platform socket.dev reports the Shai-Halud attack briefly compromised at least 25 NPM code packages managed by CrowdStrike. Socket.dev said the affected packages were quickly removed by the NPM registry.
In a written statement shared with KrebsOnSecurity, CrowdStrike said that after detecting several malicious packages in the public NPM registry, the company swiftly removed them and rotated its keys in public registries.
&#8220;These packages are not used in the Falcon sensor, the platform is not impacted and customers remain protected,&#8221; the statement reads, referring to the company&#8217;s widely-used endpoint threat detection service. &#8220;We are working with NPM and conducting a thorough investigation.&#8221;
A writeup on the attack from StepSecurity found that for cloud-specific operations, the malware enumerates AWS, Azure and Google Cloud Platform secrets. It also found the entire attack design assumes the victim is working in a Linux or macOS environment, and that it deliberately skips Windows systems.
StepSecurity said Shai-Hulud spreads by using stolen NPM authentication tokens, adding its code to the top 20 packages in the victim&#8217;s account.
&#8220;This creates a cascading effect where an infected package leads to compromised maintainer credentials, which in turn infects all other packages maintained by that user,&#8221; StepSecurity&#8217;s Ashish Kurmi wrote.
Eriksen said Shai-Hulud is still propagating, although its spread seems to have waned in recent hours.
&#8220;I still see package versions popping up once in a while, but no new packages have been compromised in the last ~6 hours,&#8221; Eriksen said. &#8220;But that could change now as the east coast starts working. I would think of this attack as a &#8216;living&#8217; thing almost, like a virus. Because it can lay dormant for a while, and if just one person is suddenly infected by accident, they could restart the spread. Especially if there&#8217;s a super-spreader attack.&#8221;
For now, it appears that the web address the attackers were using to exfiltrate collected data was disabled due to rate limits, Eriksen said.
Nicholas Weaver is a researcher with the International Computer Science Institute, a nonprofit in Berkeley, Calif. Weaver called the Shai-Hulud worm &#8220;a supply chain attack that conducts a supply chain attack.&#8221; Weaver said NPM (and all other similar package repositories) need to immediately switch to a publication model that requires explicit human consent for every publication request using a phish-proof 2FA method.
&#8220;Anything less means attacks like this are going to continue and become far more common, but switching to a 2FA method would effectively throttle these attacks before they can spread,&#8221; Weaver said. &#8220;Allowing purely automated processes to update the published packages is now a proven recipe for disaster.&#8221;

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ Scale visual production using Stability AI Image Services in Amazon Bedrock
  This post was written with Alex Gnibus of Stability AI. 
Stability AI Image Services are now available in Amazon Bedrock, offering ready-to-use media editing capabilities delivered through the Amazon Bedrock API. These image editing tools expand on the capabilities of Stability AI‚Äôs Stable Diffusion 3.5 models (SD3.5) and Stable Image Core and Ultra models, which are already available in Amazon Bedrock and have set new standards in image generation. 
The professional creative production process consists of multiple editing steps to get the exact output needed. With Stability AI Image Services in Amazon Bedrock, you can modify, enhance, and transform existing images without jumping between multiple systems or sending files to external services. Everything runs through the same Amazon Bedrock experience you‚Äôre already using. The business impact can be immediate for teams that produce visual content at scale. 
In this post, we explore examples of how these tools enable precise creative control to accelerate professional-grade visual content. 
Editing tools now available in Amazon Bedrock 
Stability AI Image Services span&nbsp;9 tools across two categories: Edit and Control. Each tool handles specific editing tasks that typically require specialized software or manual intervention. 
Edit: Advanced capabilities for granular editing steps 
The tools in the Edit category make complex editing tasks more accessible and efficient. 
The suite begins with fundamental yet powerful retouching tools. The Erase Object tool, for example, removes unwanted elements from images while intelligently maintaining background consistency. The following animation showcases the Erase Object tool removing a mannequin from a product shot while preserving the background. The tool can transform a source image based on a mask image or derive the mask from the source image‚Äôs alpha channel. 
 
The Remove Background tool automatically isolates subjects with precision. This enables the creation of clean, professional product listings with consistent backgrounds or a variety of lifestyle settings, which is a game changer for ecommerce. 
The following example illustrates the removal of an image background, while preserving details of a furniture product in the foreground. 
 
The Search and Recolor and Search and Replace tools target specific elements within images for modification. Search and Recolor changes object colors; for example, showing different colorways of a dress without new photoshoots. In the following illustration, Search and Recolor changes the color swatch on furniture. 
 
Search and Replace can swap objects entirely, which is useful for updating seasonal elements in marketing materials or replacing products. The following is an application of Search and Replace for virtual try-on experiences. 
 
The Inpaint tool intelligently modifies images by filling in or replacing specified areas with new content based on the content of a mask image. 
Control: Structural and stylistic precision 
This category of tools provides precise manipulation of image structure and style through three specialized tools. 
The Sketch tool transforms sketch-style renderings into photorealistic concepts. Architecture firms might use this to convert conceptual drawings into realistic visualizations, and apparel brands to turn design sketches into product mockups. The tool helps accelerate the creative production process from initial concepts to final visual execution. 
In this example, the Sketch tool transforms a building architecture drawing to help real estate developers visualize the concept against a cityscape. 
 
In another example, the Sketch tool transforms a mannequin drawing into a photorealistic model shot. 
 
The Structure tool maintains the structural elements of input images while allowing content modification. This tool helps preserve layouts, compositions, and spatial relationships while changing subjects or styles. Creative teams can use the Structure tool to recreate scenes with different subjects or render new characters while maintaining consistent framing. 
The following example demonstrates the Structure tool transforming a workshop scene into a new scene while preserving the composition and spatial relationships. 
 
The Style Guide and Style Transfer tools help marketing teams produce new images that align with brand style and guidelines. The Style Guide tool takes artistic styles and colors from a reference style image and generates new images based on text prompts. 
In the following example, the Style Guide tool takes clues from a brand‚Äôs color palette and textures and generates new images matching brand identity. 
 
The Style Transfer tool uses visual characteristics from reference images to transform existing images, while preserving the original composition. For example, a home decor retailer can transform product imagery from modern minimalist to traditional styles without new photography. Marketing teams could create seasonal variations by applying different visual styles to existing product catalogs. 
Solution overview 
To demonstrate Stability AI Image Services in Amazon Bedrock, let‚Äôs walk through an example using a Jupyter notebook found in the GitHub repo. 
Prerequisites 
To follow along, you must have the following prerequisites: 
 
 An AWS account. 
 AWS credentials configured for creating and accessing Amazon Bedrock and Amazon SageMaker AI resources. 
 An AWS Identity and Access Management (IAM) execution role for SageMaker AI, which has the AmazonSageMakerFullAccess and AmazonBedrockLimitedAccess AWS managed policies attached. For more details, see How to use SageMaker AI execution roles. 
 A SageMaker notebook instance. 
 Stability AI Image Services model access, which you can request through the Amazon Bedrock console. Refer to Access Amazon Bedrock foundation models for more details. 
 
Create a SageMaker AI notebook instance 
Complete the following steps to create a SageMaker AI notebook instance, which can be used to run the sample notebook: 
 
 On the SageMaker AI console, in the navigation pane, under Applications and IDEs, choose Notebooks. 
 Choose Create notebook instance. 
 For Notebook instance name, enter a name for your notebook instance (for example, ai-images-notebook-instance). 
 For Notebook Instance type, choose ml.t2.medium. 
 For Platform identifier, choose Amazon Linux 2. 
 For IAM role, choose either an existing IAM role, which has the AmazonSageMakerFullAccess and AmazonBedrockLimitedAccess policies attached, or choose Create a new role. 
 Note the name of the IAM role that you chose. 
 Leave other settings as default and choose Create notebook instance. 
 
After a few minutes, SageMaker AI creates a notebook instance, and its status changes from Pending to InService. 
Confirm the IAM role for the notebook instance has the necessary permissions 
Complete the following steps to verify that the SageMaker AI execution role that you assigned to the notebook instance has the correct permissions: 
 
 On the IAM console, in the navigation pane, under Access management, choose Roles. 
 In the Roles search bar, enter the name of the SageMaker AI execution role that you used when creating the notebook instance. 
 Choose the IAM role. 
 Under Permissions policies, verify that the AWS managed policies AmazonSageMakerFullAccess and AmazonBedrockLimitedAccess are present. 
 (Optional) If either policy is missing, choose Add permissions, then choose Attach policies to attach the missing policy. 
   
   In the Other permissions policies search bar, enter the policy name. 
   Select the policy, then chose Add permissions. 
    
 
Run the notebook 
Complete the following steps to run the notebook: 
 
 On the SageMaker AI console, in the navigation pane, under Applications and IDEs, choose Notebooks. 
 Choose the newly created ai-images-notebook-instance notebook instance. 
 Wait for the notebook to be in InService status. 
 Choose the Open JupyterLab link to launch JupyterLab in a new browser tab. 
 On the Git menu, choose Clone a Repository. 
 Enter the URI https://github.com/aws-samples/stabilityai-sample-notebooks.git and select Include submodules and Download the repository. 
 Choose Clone. 
 On the File menu, choose Open from path. 
 Enter the following: stabilityai-sample-notebooks/stability-ai-image-services/stability-ai-image-services-sample-notebook.ipynb 
 Choose Open. 
 When prompted, choose the kernel conda_python3, then choose Select. 
 Run through each notebook cell to experience Stability AI Image Services in Amazon Bedrock. 
 
Clean up 
To avoid ongoing charges, stop the ai-images-notebook-instance SageMaker AI notebook instance that you created in this walkthrough: 
 
 On the SageMaker AI console, in the navigation pane, under Applications and IDEs, choose Notebooks. 
 Choose the ai-images-notebook-instance SageMaker AI notebook instance that you created. 
 Choose Actions, then choose Stop. 
 
After a few minutes, the notebook instance transitions from Stopping to Stopped status. 
 
 Choose Actions, then Delete. 
 
After a few seconds, SageMaker AI deletes the notebook instance. 
For more details, refer to Clean up Amazon SageMaker notebook instance resources. 
Conclusion 
The availability of Stability AI Image Services in Amazon Bedrock is an exciting step forward for visual content creation and manipulation, with particularly time-saving implications for professional creative teams at enterprises. 
For example, in media and entertainment, creators can rapidly enhance scenes and create special effects, and marketing teams can generate multiple campaign variations effortlessly. Retail and ecommerce businesses can streamline product photography and digital catalog creation, and gaming developers can prototype environments more efficiently. Architecture firms can visualize design concepts instantly, and educational institutions can create more engaging visual content. 
With these tools, businesses of different sizes can produce professional-grade, highly engaging visual content with efficiency and creativity. These tools can streamline operations, reduce costs, and open new creative possibilities, helping brands tell their stories more effectively and engage customers in more compelling ways. 
To get started, check out Stability AI models in Amazon Bedrock and the AWS Samples GitHub repo. 
 
About the authors 
Alex Gnibus is a Product Marketing Manager at Stability AI, connecting the dots between cutting-edge research breakthroughs and practical use cases. With experience spanning from creative agencies to deep enterprise tech, Alex brings both technical expertise and an understanding of the challenges that professional creative teams can solve with generative AI. 
Isha Dua is a Senior Solutions Architect based in the San Francisco Bay Area. She helps AWS Enterprise customers grow by understanding their goals and challenges and guiding them on how they can architect their applications in a cloud-based manner while making sure they are resilient and scalable. She‚Äôs passionate about machine learning technologies and environmental sustainability. 
Fabio Branco is a Senior Customer Solutions Manager at Amazon Web Services (AWS) and strategic advisor helping customers achieve business transformation, drive innovation through generative AI and data solutions, and successfully navigate their cloud journeys. Prior to AWS, he held Product Management, Engineering, Consulting, and Technology Delivery roles across multiple Fortune 500 companies in industries, including retail and consumer goods, oil and gas, financial services, insurance, and aerospace and defense. 
Suleman Patel is a Senior Solutions Architect at Amazon Web Services (AWS), with a special focus on machine learning and modernization. With expertise in both business and technology, Suleman helps customers design and build solutions that tackle real-world business problems. When he‚Äôs not immersed in his work, Suleman loves exploring the outdoors, taking road trips, and cooking up delicious dishes in the kitchen.
‚Ä¢ Prompting for precision with Stability AI Image Services in Amazon Bedrock
  Amazon Bedrock now offers Stability AI Image Services: 9 tools that improve how businesses create and modify images. The technology extends Stable Diffusion and Stable Image models to give you precise control over image creation and editing. Clear prompts are critical‚Äîthey provide art direction to the AI system. Strong prompts control specific elements like tone, texture, lighting, and composition to create the desired visual outcomes. This capability serves professional needs across product photography, concept, and marketing campaigns. 
In this post, we expand on the post Understanding prompt engineering: Unlock the creative potential of Stability AI models on AWS. We show how to effectively use advanced prompting techniques to maximize image generation quality and precision for enterprise application using Stability AI Image Services in Amazon Bedrock. 
Solution overview 
Stability AI Image Services are available as APIs in Amazon Bedrock, featuring capabilities such as, in-painting, style transfer, recoloring, background removal, object removal, style guide, and much more. 
In the following sections, we first discuss prompt structure for maximum control of image generation, then we provide advanced techniques of prompting for stylistic guidance. Code samples can be found in the following GitHub repository. 
Prerequisites 
To get started with Stability AI Image Services in Amazon Bedrock, follow the instructions in Getting started with the API to complete the following prerequisites: 
 
 Set up your AWS account. 
 Acquire credentials to grant programmatic access. 
 Attach the Amazon Bedrock permission to an AWS Identity and Access Management (IAM) user or role. 
 Request access to the Amazon Bedrock models. 
 
Structure prompts that maximize control 
To maximize the granular capabilities of Stability AI Image Services in Amazon Bedrock, you must construct prompts that enable fine-grained control. 
This section outlines best practices for building effective prompts that produce the desired output. We demonstrate how prompt structure affects results and why more structured prompts typically yield more consistent and controllable outcomes. 
Choose the right prompt type for your use case 
Selecting the right prompt format helps the model better understand your intent. Three primary prompt formats deliver different levels of control and readability: 
 
 Natural language maximizes readability and is best for general usage 
 Tag-based formats enable precise structural control and are ideal for technical application 
 Hybrid formats combine natural language and the structural elements of tags to provide even more control 
 
The following table provides examples of these three common ways to phrase your prompts. Each prompt format has its strengths depending on your goal or the interface you‚Äôre using. 
 
  
   
   Prompt type  
   Prompt example  
   Generated image using Stable Image Ultra in Amazon Bedrock 
   Description and use case 
   
   
   Basic Prompt (Natural Language) 
   ‚ÄúA clean product photo of a perfume bottle on a marble countertop‚Äù 
    
   This is readable and intuitive. Great for exploration, conversational tools, and some model types. Stable Diffusion 3.5 responds best to this style. 
   
   
   Tag-Based Prompt 
   ‚Äúperfume bottle, marble surface, soft light, high quality, product photo‚Äù 
    
   Used in many generation UIs or with models trained on datasets like LAION or Danbooru. Compact and good for stacking details. 
   
   
   Hybrid Prompt 
   ‚Äúperfume bottle on marble counter, soft studio lighting, sharp focus, f/2.8lens‚Äù 
    
   Best of both worlds. Add emphasis with weighting syntax to influence the model‚Äôs priorities. 
   
  
 
Build modular prompts 
Modular prompting enhances AI image generation effectiveness. This approach divides prompts into distinct components, each specifying what to draw and how it should appear. Modular structures provide several benefits: they help prevent conflicting or confusing instructions, allow for precise output control, and simplify prompt debugging. By isolating individual elements, you can quickly identify and adjust effective or ineffective parts of your prompts. This method ultimately leads to more refined and targeted AI-generated images. 
The following table provides examples of modular prompt modules. Experiment with different prompt sequences for your desired outcome; for example, placing the style before the subject will give it a more visual weight. 
 
  
   
   Module 
   Example 
   Description 
   
   
   Prefix 
   ‚Äúfashion editorial portrait of‚Äù 
   Sets the tone and intent for a high-fashion styled portrait 
   
   
   Subject 
   ‚Äúa woman with medium-brown skin and short coiled hair‚Äù 
   Gives the model‚Äôs look and surface detail to help guide facial features 
   
   
   Modifiers 
   ‚Äúwearing an asymmetrical black mesh top, metallic jewelry‚Äù 
   Adds stylized clothing and accessories for visual interest 
   
   
   Action 
   ‚Äúseated with her shoulders angled, eyes locked on camera, one arm lifted‚Äù 
   Describes body language and pose to give dynamic composition 
   
   
   Environment 
   ‚Äúbathed in intersecting beams of hard directional light through window slats‚Äù 
   Adds context for dramatic light play and atmosphere 
   
   
   Style 
   ‚Äúhigh-contrast chiaroscuro lighting, sculptural and abstract‚Äù 
   Informs the aesthetic and mood (shadow-driven, moody, architectural) 
   
   
   Camera/Lighting 
   ‚Äúshot on 85mm, studio setup, layered shadows and light falling across face and body‚Äù 
   Adds technical precision and helps control realism and fidelity 
   
  
 
The following example illustrates how to use a modular prompt to generate the desired output. 
 
  
   
   Modular Prompt 
   Generated Image Using Stable Image Ultra in Amazon Bedrock 
   
   
   ‚Äúfashion editorial portrait of a woman with medium-brown skin and short coiled hair, wearing an asymmetrical black mesh top and metallic jewelry, seated with shoulders angled and one arm lifted, eyes locked on camera, bathed in intersecting beams of hard directional light through window slats, layered shadows and highlights sculpting her face and body, high-contrast chiaroscuro lighting, abstract and bold, shot on 85mm in studio‚Äù 
    
   
  
 
Use negative prompts for polished output 
Negative prompts improve AI output quality by removing specific visual elements. Explicitly defining what not to include in the prompt guides the model‚Äôs output, typically leading to professional outputs. Negative prompts act like a retoucher‚Äôs checklist used to address aspects of an image to enhance quality and appeal. For example, ‚ÄúNo weird hands. No blurry corners. No cartoon filters. Definitely no watermarks.‚Äù Negative prompts result in clean, confident, compositions, free of distracting element and distortions. 
The following table provides examples of additional tokens that can be used in negative prompts. 
 
  
   
   Artifact Type 
   Tokens to Use 
   
   
   Low quality or noise 
   blurry, lowres, jpeg artifacts, noisy 
   
   
   Anatomy or model issues 
   deformed, extra limbs, bad hands, missing fingers 
   
   
   Style clashes 
   cartoon, illustration, anime, painting 
   
   
   Technical errors 
   watermark, text, signature, overexposed 
   
   
   General cleanup 
   ugly, poorly drawn, distortion, worst quality 
   
  
 
The following example illustrates how a well-structured negative prompt can enhance photorealism. 
 
  
   
   Without Negative Prompt 
    Prompt ‚Äú(medium full shot) of (charming office cubicle) made of glass material, multiple colors, modern style, space-saving, upholstered seat, patina, gold trim, located in a modern garden, with sleek furniture, stylish decor, bright lighting, comfortable seating, Masterpiece, best quality, raw photo, realistic, very aesthetic, dark ‚Äú 
    
   
   
   With Negative Prompt 
    Prompt ‚Äú(medium full shot) of (charming office cubicle) made of glass material, multiple colors, modern style, space-saving, upholstered seat, patina, gold trim, located in a modern garden, with sleek furniture, stylish decor, bright lighting, comfortable seating, Masterpiece, best quality, raw photo, realistic, very aesthetic, dark‚Äù Negative Prompt ‚Äúcartoon, 3d render, cgi, oversaturated, smooth plastic textures, unreal lighting, artificial, matte surface, painterly, dreamy, glossy finish, digital art, low detail background‚Äù 
    
   
  
 
Emphasize or suppress elements with prompt weighting 
Prompt weighting controls the influence of individual elements in AI image generation. These numerical weights prioritize specific prompt components over others. For example, to emphasize the character over the background, you can apply a 1.8 weight to ‚Äúcharacter‚Äù (character: 1.8) and 1.1 to ‚Äúbackground‚Äù (background: 1.1), which makes sure the model prioritizes character detail while maintaining environmental context. This targeted emphasis produces more precise outputs by minimizing competition between prompt elements and clarifying the model‚Äôs priorities. 
The syntax for prompt weights is (&lt;term&gt;:&lt;weight&gt;). You can also use a shorthand such as ((&lt;term&gt;)), where the number of parentheses represent the weight. Values between 0.0‚Äì1.0 deemphasize the term, and values between 1.1‚Äì2.0 emphasize the term.For example: 
 
 (term:1.2): Emphasize 
 (term:0.8): Deemphasize 
 ((term)): Shorthand for (term:1.2) 
 (((((((((term)))))))): Shorthand for (term:1.8) 
 
The following example shows how prompt weights contribute to the generated output. 
 
  
   
    Prompt with weights ‚Äúeditorial product photo of (a translucent gel moisturizer jar:1.4) placed on a (frosted glass pedestal:1.2), surrounded by (dewy pink flower petals:1.1), with soft (diffused lighting:1.3), subtle water droplets, shallow depth of field‚Äù 
    
   
   
    Prompt without weights ‚Äúeditorial product photo of a translucent gel moisturizer jar placed on a frosted glass pedestal, surrounded by dewy pink flower petals, with soft, subtle water droplets, shallow depth of field‚Äù 
    
   
  
 
You can also use weights in negative prompts to reduce how strongly the model avoids something. For example, ‚Äú(text:0.5), (blurry:0.2), (lowres:0.1).‚Äù This tells the model to be especially sure to avoid generating blurry text or low-resolution content. 
Giving specific stylistic guidance 
Effective prompt writing when using Stability AI Image Services such as Style Transfer and Style Guide requires a good understanding of style matching and reference-driven prompting. These techniques help provide clear stylistic direction for both text-to-image and image-to-image creation. 
Image-to-image style transfer extracts stylistic elements from an input image (control image) and uses it to guide the creation of an output image based on the prompt. Approach writing the prompt as if you‚Äôre directing a professional photographer or stylist. Focus on materials, lighting quality, and artistic intention‚Äînot just objects. For example, a well-structured prompt might read: ‚ÄúClose-up editorial photo of a translucent green lip gloss tube on crushed iridescent plastic, diffused colored lighting, shallow DOF, high fashion product styling.‚Äù 
Style tag layering: Known aesthetic labels that align with brand identity 
The art of crafting effective prompts often relies on incorporating established style tags that resonate with familiar visual languages and datasets. By strategically blending terms from recognized aesthetic categories (ranging from editorial photography and analog film to anime, cyberpunk cityscapes, and brutalist structures), creators can guide the AI toward specific visual outcomes that align with their brand identity. These style descriptors serve as powerful anchors in the prompt engineering process. The versatility of these tags extends further through their ability to be combined and weighted, allowing for nuanced control over the final aesthetic. For instance, a skincare brand might blend the clean lines of product photography with dreamy, surreal elements, whereas a tech company could merge brutalist structure with cyberpunk elements for a distinctive visual identity. This approach to style mixing helps creators improve their outputs while maintaining clear ties to recognizable visual genres that resonate with their target audience. The key is understanding how these style tags interact and using their combinations to create unique, yet culturally relevant, visual expressions that serve specific creative or commercial objectives. The following table provides examples of prompts for a desired aesthetic. 
 
  
   
   Desired aesthetic 
   Prompt phrases 
   Example use case 
   
   
   Retro / Y2K 
   2000s nostalgia, flash photography, candy tones, harsh lighting 
   Metallic textures, thin fonts, early digital feel. 
   
   
   Clean modern 
   neutral tones, soft gradients, minimalist styling, editorial layout 
   Great for wellness or skincare products. 
   
   
   Bold streetwear 
   urban background, oversized fit, strong pose, midday shadow 
   Fashion photography and lifestyle ads. Prioritize outfit structure and location cues. 
   
   
   Hyperreal surrealism 
   dreamcore lighting, glossy textures, cinematic DOF, surreal shadows 
   Plays well in music, fashion, or alt-culture campaigns. 
   
  
 
Invoke a named style as a reference 
Some prompt structures benefit from invoking a named visual signature from a specific artist, especially when combined with your own stylistic phrasing or workflows, as shown in the following example. 
 
  
   
    Prompt ‚Äúeditorial studio portrait of a woman with glowing skin in minimalist glam makeup, high-contrast lighting, clean background, (depiction of Van Gogh style:1.3)‚Äù 
    
   
  
 
The following is a more conceptual example. 
 
  
   
    Prompt ‚Äúproduct shot of a silver hair oil bottle with soft reflections on curved chrome, (depiction of Wes Anderson style:1.2), under cold studio lighting‚Äù 
    
   
  
 
These phrases function like calling on a genre; they imply choices around materials, lighting, layout, and color tonality. 
Use reference images to guide style 
Another useful technique is using a reference image to guide the pose, color, or composition of the output. For use cases like matching a pose from a lookbook image, transferring a color palette from a campaign still, or copying shadowplay from a photo shoot, you can extract and apply structure or style from reference images. 
Stability AI Image Services support a variety of image-to-image workflows where you can use a reference image (control image) to guide the output, such as Structure, Sketch, and Style. Tools like ControlNet (a neural network architecture developed by Stability AI that enhances control), IP-Adapter (an image prompt adapter), or clip-based captioning also enable further control when paired with Stability AI models. 
We will discuss ControlNet, IP-Adapter, and clip-based captioning in a subsequent post. 
The following is an example of an image-to-image workflow: 
 
 Find a high-quality editorial reference. 
 Use it with a depth, canny, or seg ControlNet to lock a pose. 
 Style with a prompt. 
 
 
  
   
    Prompt ‚Äúfashion editorial of a model in layered knitwear, dramatic colored lighting, strong shadows, high ISO texture‚Äù 
    
   
  
 
Create the right mood with lighting control 
In a prompt, lighting sets tone, adds dimensionality, and mimics the language of photography. It shouldn‚Äôt just be ‚Äúbright vs. dark.‚Äù Lighting is often the style itself, especially for audiences like Gen Z, for instance TikTok, early-aughts flash, harsh backlight, and color gels. The following table provides some useful lighting style prompt terms. 
 
  
   
   Lighting style 
   Prompt terms 
   Example use case 
   
   
   High-contrast studio 
   hard directional light, deep shadows, controlled highlights 
   Beauty, tech, fashion with punchy visuals 
   
   
   Soft editorial 
   diffused light, soft shadows, ambient glow, overcast 
   Skincare, fashion, wellness 
   
   
   Colored gel lighting 
   blue and pink gel lighting, dramatic color shadows, rim lighting 
   Nightlife, music-adjacent fashion, youth-forward styling 
   
   
   Natural bounce 
   golden hour, soft natural light, sun flare, warm tones 
   Outdoors, lifestyle, brand-friendly minimalism 
   
  
 
Build intent with posing and framing terms 
Good posing helps products feel aspirational and digital models more dynamic. With AI, you must be intentional. Framing and pose cues help avoid stiffness, anatomical errors, and randomness. The following table provides some useful posing and framing prompt terms. 
 
  
   
   Prompt cue 
   Description 
   Tip 
   
   
   looking off camera 
   Creates candid or editorial energy 
   Useful for lookbooks or ad pages 
   
   
   hands in motion 
   Adds realism and fluidity 
   Avoids awkward, static body posture 
   
   
   seated with body turned 
   Adds depth and twist to the torso 
   Reduces symmetry, feels natural 
   
   
   shot from low angle 
   Power or status cue 
   Works well for stylized streetwear or product hero shots 
   
  
 
Example: Putting it all together 
The following example puts together what we‚Äôve discussed in this post. 
 
  
   
    Prompt ‚Äústudio portrait of a model with platinum hair in metallic cargo pants and a cropped mesh hoodie, seated with legs wide on (acrylic stairs:1.6), magenta and teal gel lighting from left and behind, dramatic contrast, shot on 50mm, streetwear editorial for Gen Z campaign‚Äù Negative prompt ‚Äúblurry, extra limbs, watermark, cartoon, distorted face missing fingers, bad anatomy‚Äù 
    
   
  
 
Let‚Äôs break down the preceding prompt. We direct the look of the subject (platinum hair, metallic clothes), specify their pose (seated wide-legged, confident, unposed), define the environment (acrylic stairs and studio setup, controlled, modern), state the lighting (mixed gel sources, bold stylization), designate the lens (50mm, portrait realism), and lastly detail the purpose (for Gen Z campaign, sets visual and cultural tone). Together, the prompt produces the desired result. 
Best practices and troubleshooting 
Prompting is rarely a one-and-done task, especially for creative use cases. Most great images come from refining an idea over multiple attempts. Consider the following methodology to iterate over your prompts: 
 
 Keep a prompt log 
 Change one variable at a time 
 Save seeds and base images 
 Use comparison grids 
 
Sometimes things go wrong‚Äîmaybe the model ignores your prompt, or the image looks messy. These issues are common and often quick to fix, and you can get sharper, cleaner, and more intentional outputs with every adjustment. The following table provides useful tips for troubleshooting your prompts. 
 
  
   
   Problem 
   Cause of issue 
   How to fix it 
   
   
   Style feels random 
   Model is confused or terms are vague 
   Clarify style, add weight, remove conflicts 
   
   
   Face gets warped 
   Over-styled or lacks facial cues 
   Add portrait of, headshot, or adjust pose or lighting 
   
   
   Image is too dark 
   Lighting not defined 
   Add softbox from left, natural light, or time of day 
   
   
   Repetitive poses 
   Same seed or static structure 
   Switch seed or change camera angle or subject action 
   
   
   Lacks realism or feels ‚ÄúAI-ish‚Äù 
   Wrong tone or artifacts 
   Add negatives like cartoon, digital texture, distorted 
   
  
 
Conclusion 
Mastering advanced prompting techniques can turn basic image generation into professional creative outputs. Stability AI Image Services in Amazon Bedrock provide precise control over visual creation and editing, helping businesses convert concepts into production-ready assets. The combination of technical expertise and creative intent can help creators achieve the precision and consistency required in professional settings. This control proves valuable across multiple applications, such as marketing campaigns, brand consistency, and product visualizations. This post demonstrated how to optimize Stability AI Image Services in Amazon Bedrock to produce high-quality imagery that aligns with your creative goals. 
To implement these techniques, access Stability AI Image Services through Amazon Bedrock or explore Stability AI‚Äôs foundation models available in Amazon SageMaker JumpStart. You can also find practical code examples in our GitHub repository. 
 
About the authors 
Maxfield Hulker is the VP of Community and Business Development at Stability AI. He is a longtime leader in the generative AI space. He has helped build creator-focused platforms like Civitai and Dream Studio. Maxfield regularly publishes guides and tutorials to make advanced AI techniques more accessible. 
Suleman Patel is a Senior Solutions Architect at Amazon Web Services (AWS), with a special focus on machine learning and modernization. Leveraging his expertise in both business and technology, Suleman helps customers design and build solutions that tackle real-world business problems. When he‚Äôs not immersed in his work, Suleman loves exploring the outdoors, taking road trips, and cooking up delicious dishes in the kitchen. 
Isha Dua is a Senior Solutions Architect based in the San Francisco Bay Area working with generative AI model providers and helping customer optimize their generative AI workloads on AWS. She helps enterprise customers grow by understanding their goals and challenges, and guides them on how they can architect their applications in a cloud-based manner while supporting resilience and scalability. She‚Äôs passionate about machine learning technologies and environmental sustainability. 
Fabio Branco is a Senior Customer Solutions Manager at Amazon Web Services (AWS) and a strategic advisor, helping customers achieve business transformation, drive innovation through generative AI and data solutions, and successfully navigate their cloud journeys. Prior to AWS, he held Product Management, Engineering, Consulting, and Technology Delivery roles across multiple Fortune 500 companies in industries, including retail and consumer goods, oil and gas, financial services, insurance, and aerospace and defense.
‚Ä¢ Monitor Amazon Bedrock batch inference using Amazon CloudWatch metrics
  As organizations scale their use of generative AI, many workloads require cost-efficient, bulk processing rather than real-time responses. Amazon Bedrock batch inference addresses this need by enabling large datasets to be processed in bulk with predictable performance‚Äîat 50% lower cost than on-demand inference. This makes it ideal for tasks such as historical data analysis, large-scale text summarization, and background processing workloads. 
In this post, we explore how to monitor and manage Amazon Bedrock batch inference jobs using Amazon CloudWatch metrics, alarms, and dashboards to optimize performance, cost, and operational efficiency. 
New features in Amazon Bedrock batch inference 
Batch inference in Amazon Bedrock is constantly evolving, and recent updates bring significant enhancements to performance, flexibility, and cost transparency: 
 
 Expanded model support ‚Äì Batch inference now supports additional model families, including Anthropic‚Äôs Claude Sonnet 4 and OpenAI OSS models. For the most up-to-date list, refer to Supported Regions and models for batch inference. 
 Performance enhancements ‚Äì Batch inference optimizations on newer Anthropic Claude and OpenAI GPT OSS models now deliver higher batch throughput as compared to previous models, helping you process large workloads more quickly. 
 Job monitoring capabilities ‚Äì You can now track how your submitted batch jobs are progressing directly in CloudWatch, without the heavy lifting of building custom monitoring solutions. This capability provides AWS account-level visibility into job progress, making it straightforward to manage large-scale workloads. 
 
Use cases for batch inference 
AWS recommends using batch inference in the following use cases: 
 
 Jobs are not time-sensitive and can tolerate minutes to hours of delay 
 Processing is periodic, such as daily or weekly summarization of large datasets (news, reports, transcripts) 
 Bulk or historical data needs to be analyzed, such as archives of call center transcripts, emails, or chat logs 
 Knowledge bases need enrichment, including generating embeddings, summaries, tags, or translations at scale 
 Content requires large-scale transformation, such as classification, sentiment analysis, or converting unstructured text into structured outputs 
 Experimentation or evaluation is needed, for example testing prompt variations or generating synthetic datasets 
 Compliance and risk checks must be run on historical content for sensitive data detection or governance 
 
Launch an Amazon Bedrock batch inference job 
You can start a batch inference job in Amazon Bedrock using the AWS Management Console, AWS SDKs, or AWS Command Line Interface (AWS CLI). For detailed instructions, see Create a batch inference job. 
To use the console, complete the following steps: 
 
 On the Amazon Bedrock console, choose Batch inference under Infer in the navigation pane. 
 Choose Create batch inference job. 
 For Job name, enter a name for your job. 
 For Model, choose the model to use. 
 For Input data, enter the location of the Amazon Simple Storage Service (Amazon S3) input bucket (JSONL format). 
 For Output data, enter the S3 location of the output bucket. 
 For Service access, select your method to authorize Amazon Bedrock. 
 Choose Create batch inference job. 
 
 
Monitor batch inference with CloudWatch metrics 
Amazon Bedrock now automatically publishes metrics for batch inference jobs under the AWS/Bedrock/Batch namespace. You can track batch workload progress at the AWS account level with the following CloudWatch metrics. For current Amazon Bedrock models, these metrics include records pending processing, input and output tokens processed per minute, and for Anthropic Claude models, they also include tokens pending processing. 
The following metrics can be monitored by modelId: 
 
 NumberOfTokensPendingProcessing ‚Äì Shows how many tokens are still waiting to be processed, helping you gauge backlog size 
 NumberOfRecordsPendingProcessing ‚Äì Tracks how many inference requests remain in the queue, giving visibility into job progress 
 NumberOfInputTokensProcessedPerMinute ‚Äì Measures how quickly input tokens are being consumed, indicating overall processing throughput 
 NumberOfOutputTokensProcessedPerMinute ‚Äì Measures generation speed 
 
To view these metrics using the CloudWatch console, complete the following steps: 
 
 On the CloudWatch console, choose Metrics in the navigation pane. 
 Filter metrics by AWS/Bedrock/Batch. 
 Select your modelId to view detailed metrics for your batch job. 
 
 
To learn more about how to use CloudWatch to monitor metrics, refer to Query your CloudWatch metrics with CloudWatch Metrics Insights. 
Best practices for monitoring and managing batch inference 
Consider the following best practices for monitoring and managing your batch inference jobs: 
 
 Cost monitoring and optimization ‚Äì By monitoring token throughput metrics (NumberOfInputTokensProcessedPerMinute and NumberOfOutputTokensProcessedPerMinute) alongside your batch job schedules, you can estimate inference costs using information on the Amazon Bedrock pricing page. This helps you understand how fast tokens are being processed, what that means for cost, and how to adjust job size or scheduling to stay within budget while still meeting throughput needs. 
 SLA and performance tracking ‚Äì The NumberOfTokensPendingProcessing metric is useful for understanding your batch backlog size and tracking overall job progress, but it should not be relied on to predict job completion times because they might vary depending on overall inference traffic to Amazon Bedrock. To understand batch processing speed, we recommend monitoring throughput metrics (NumberOfInputTokensProcessedPerMinute and NumberOfOutputTokensProcessedPerMinute) instead. If these throughput rates fall significantly below your expected baseline, you can configure automated alerts to trigger remediation steps‚Äîfor example, shifting some jobs to on-demand processing to meet your expected timelines. 
 Job completion tracking ‚Äì When the metric NumberOfRecordsPendingProcessing reaches zero, it indicates that all running batch inference jobs are complete. You can use this signal to trigger stakeholder notifications or start downstream workflows. 
 
Example of CloudWatch metrics 
In this section, we demonstrate how you can use CloudWatch metrics to set up proactive alerts and automation. 
For example, you can create a CloudWatch alarm that sends an Amazon Simple Notification Service (Amazon SNS) notification when the average NumberOfInputTokensProcessedPerMinute exceeds 1 million within a 6-hour period. This alert could prompt an Ops team review or trigger downstream data pipelines. 
 
The following screenshot shows that the alert has In alarm status because the batch inference job met the threshold. The alarm will trigger the target action, in our case an SNS notification email to the Ops team. 
 
The following screenshot shows an example of the email the Ops team received, notifying them that the number of processed tokens exceeded their threshold. 
 
You can also build a CloudWatch dashboard displaying the relevant metrics. This is ideal for centralized operational monitoring and troubleshooting. 
 
Conclusion 
Amazon Bedrock batch inference now offers expanded model support, improved performance, deeper visibility into the progress of your batch workloads, and enhanced cost monitoring. 
Get started today by launching an Amazon Bedrock batch inference job, setting up CloudWatch alarms, and building a monitoring dashboard, so you can maximize efficiency and value from your generative AI workloads. 
 
About the authors 
Vamsi Thilak Gudi&nbsp;is a Solutions Architect at Amazon Web Services (AWS) in Austin, Texas, helping Public Sector customers build effective cloud solutions. He brings diverse technical experience to show customers what‚Äôs possible with AWS technologies. He actively contributes to the AWS Technical Field Community for Generative AI. 
Yanyan Zhang&nbsp;is a Senior Generative AI Data Scientist at Amazon Web Services, where she has been working on cutting-edge AI/ML technologies as a Generative AI Specialist, helping customers use generative AI to achieve their desired outcomes. Yanyan graduated from Texas A&amp;M University with a PhD in Electrical Engineering. Outside of work, she loves traveling, working out, and exploring new things. 
Avish Khosla&nbsp;is a software developer on Bedrock‚Äôs Batch Inference team, where the team build reliable, scalable systems to run large-scale inference workloads on generative AI models. he care about clean architecture and great docs. When he is not shipping code, he is on a badminton court or glued to a good cricket match. 
Chintan Vyas serves as a Principal Product Manager‚ÄìTechnical at Amazon Web Services (AWS), where he focuses on Amazon Bedrock services. With over a decade of experience in Software Engineering and Product Management, he specializes in building and scaling large-scale, secure, and high-performance Generative AI services. In his current role, he leads the enhancement of programmatic interfaces for Amazon Bedrock. Throughout his tenure at AWS, he has successfully driven Product Management initiatives across multiple strategic services, including Service Quotas, Resource Management, Tagging, Amazon Personalize, Amazon Bedrock, and more. Outside of work, Chintan is passionate about mentoring emerging Product Managers and enjoys exploring the scenic mountain ranges of the Pacific Northwest. 
Mayank Parashar&nbsp;is a Software Development Manager for Amazon Bedrock services.
‚Ä¢ Use AWS Deep Learning Containers with Amazon SageMaker AI managed MLflow
  Organizations building custom machine learning (ML) models often have specialized requirements that standard platforms can‚Äôt accommodate. For example, healthcare companies need specific environments to protect patient data while meeting HIPAA compliance, financial institutions require specific hardware configurations to optimize proprietary trading algorithms, and research teams need flexibility to experiment with cutting-edge techniques using custom frameworks. These specialized needs drive organizations to build custom training environments that give them control over hardware selection, software versions, and security configurations. 
These custom environments provide the necessary flexibility, but they create significant challenges for ML lifecycle management. Organizations typically try to solve these problems by building additional custom tools, and some teams piece together various open source solutions. These approaches further increase operational costs and require engineering resources that could be better used elsewhere. 
AWS Deep Learning Containers (DLCs) and managed MLflow on Amazon SageMaker AI offer a powerful solution that addresses both needs. DLCs provide preconfigured Docker containers with frameworks like TensorFlow and PyTorch, including NVIDIA CUDA drivers for GPU support. DLCs are optimized for performance on AWS, regularly maintained to include the latest framework versions and patches, and designed to integrate seamlessly with AWS services for training and inference. AWS Deep Learning AMIs (DLAMIs) are preconfigured Amazon Machine Images (AMIs) for Amazon Elastic Compute Cloud (Amazon EC2) instances. DLAMIs come with popular deep learning frameworks like PyTorch and TensorFlow, and are available for CPU-based instances and high-powered GPU-accelerated instances. They include NVIDIA CUDA, cuDNN, and other necessary tools, with AWS managing the updates of DLAMIs. Together, DLAMIs and DLCs provide ML practitioners with the infrastructure and tools to accelerate deep learning in the cloud at scale. 
SageMaker managed MLflow delivers comprehensive lifecycle management with one-line automatic logging, enhanced comparison capabilities, and complete lineage tracking. As a fully managed service on SageMaker AI, it alleviates the operational burden of maintaining tracking infrastructure. 
In this post, we show how to integrate AWS DLCs with MLflow to create a solution that balances infrastructure control with robust ML governance. We walk through a functional setup that your team can use to meet your specialized requirements while significantly reducing the time and resources needed for ML lifecycle management. 
Solution overview 
In this section, we describe the architecture and AWS services used to integrate AWS DLCs with SageMaker managed MLflow to implement the solution.The solution uses several AWS services together to create a scalable environment for ML development: 
 
 AWS DLCs provide preconfigured Docker images with optimized ML frameworks 
 SageMaker managed MLflow introduces enhanced model registry capabilities with fine-grained access controls and adds generative AI support through specialized tracking for LLM experiments and prompt management 
 Amazon Elastic Container Registry (Amazon ECR) stores and manages container images 
 Amazon Simple Storage Service (Amazon S3) stores input and output artifacts 
 Amazon EC2 runs the AWS DLCs 
 
For this use case, you will develop a TensorFlow neural network model for abalone age prediction with integrated SageMaker managed MLflow tracking code. Next, you will pull an optimized TensorFlow training container from the AWS public ECR repository and configure an EC2 instance with access to the MLflow tracking server. You will then execute the training process within the DLC while storing model artifacts in Amazon S3 and logging experiment results to MLflow. Finally, you will view and compare experiment results in the MLflow UI to evaluate model performance. 
The following diagram that shows the interaction between various AWS services, AWS DLCs, and SageMaker managed MLflow for the solution. 
 
The workflow consists of the following steps: 
 
 Develop a TensorFlow neural network model for abalone age prediction. Integrate SageMaker managed MLflow tracking within the model code to log parameters, metrics, and artifacts. 
 Pull an optimized TensorFlow training container from the AWS public ECR repository. Configure Amazon EC2 and DLAMI with access to the MLflow tracking server using an AWS Identity and Access Management (IAM) role for EC2. 
 Execute the training process within the DLC running on Amazon EC2, store model artifacts in Amazon S3, and log all experiment results and register model in MLflow. 
 Compare experiment results through the MLflow UI. 
 
Prerequisites 
To follow along with this walkthrough, make sure you have the following prerequisites: 
 
 An AWS account with billing enabled. 
 An EC2 instance (t3.large or larger) running Ubuntu 20.4 or later with at least 20 GB of available disk space for Docker images and containers. 
 Docker (latest) installed on the EC2 instance. 
 The AWS Command Line Interface (AWS CLI) version 2.0 or later. 
 An IAM role with permissions for the following: 
   
   Amazon EC2 to talk to SageMaker managed MLflow. 
   Amazon ECR to pull the TensorFlow container. 
   SageMaker managed MLflow to track experiments and register models. 
    
 An Amazon SageMaker Studio domain. To create a domain, refer to Guide to getting set up with Amazon SageMaker AI. Add the sagemaker-mlflow:AccessUI permission to the SageMaker execution role created. This permission makes it possible to navigate to MLflow from the SageMaker Studio console. 
 A SageMaker managed MLflow tracking server set up in SageMaker AI. 
 Internet access from the EC2 instance to download the abalone dataset. 
 The GitHub repository cloned to your EC2 instance. 
 
Deploy the solution 
Detailed step-by-step instructions are available in the accompanying GitHub repository‚Äôs README file. The walkthrough covers the entire workflow‚Äîfrom provisioning infrastructure and setting up permissions to executing your first training job with comprehensive experiment tracking. 
Analyze experiment results 
After you‚Äôve implemented the solution following the steps in the README file, you can access and analyze your experiment results. The following screenshots demonstrate how SageMaker managed MLflow provides comprehensive experiment tracking, model governance, and auditability for your deep learning workloads. When training is complete, all experiment metrics, parameters, and artifacts are automatically captured in MLflow, providing a central location to track and compare your model development journey. The following screenshot shows the experiment abalone-tensorflow-experiment with a run named unique-cod-104. This dashboard gives you a complete overview of all experiment runs, so you can compare different approaches and model iterations at a glance. 
 
The following screenshot shows the detailed information for run unique-cod-104, including the registered model abalone-tensorflow-custom-callback-model (version v2). This view provides critical information about model provenance, showing exactly which experiment run produced which model version, which is a key component of model governance. 
 
The following visualization tracks the training loss across epochs, captured using a custom callback. Such metrics help you understand model convergence patterns and evaluate training performance, giving insights into potential optimization opportunities. 
 
The registered models view illustrated in the following screenshot shows how abalone-tensorflow-custom-callback-model is tracked in the model registry. This integration enables versioning, model lifecycle management, and deployment tracking. 
 
The following screenshot illustrates one of the solution‚Äôs most powerful governance features. When logging a model with mlflow.tensorflow.log_model() using the registered_model_name parameter, the model is automatically registered in the Amazon SageMaker Model Registry. This creates full traceability from experiment to deployed model, establishing an audit trail that connects your training runs directly to production models. 
 
This seamless integration between your custom training environments and SageMaker governance tools helps you maintain visibility and compliance throughout your ML lifecycle. 
The model artifacts are automatically uploaded to Amazon S3 after training completion, as illustrated in the following screenshot. This organized storage structure makes sure all model components including weights, configurations, and associated metadata are securely preserved and accessible through a standardized path. 
 
Cost implications 
The following resources incur costs. Refer to the respective pricing page to estimate costs. 
 
 Amazon EC2 On-Demand ‚Äì Refer to the instance size and AWS Region where it has been provisioned. Storage using Amazon Elastic Block Store (Amazon EBS) is additional. 
 SageMaker managed MLflow ‚Äì You can find the details under On-demand pricing for SageMaker MLflow for tracking and storage. 
 Amazon S3 ‚Äì Refer to pricing for storage and requests. 
 SageMaker Studio ‚Äì There is no additional charges for using the SageMaker Studio UI. However, any EFS or EBS volumes attached, jobs or resources launched from SageMaker Studio applications, or JupyterLab applications will incur costs. 
 
Clean up 
Complete the following steps to clean up your resources: 
 
 Delete the MLflow tracking server, because it continues to incur costs as long as it‚Äôs running: 
 
 
 aws sagemaker delete-mlflow-tracking-server \ 
   --tracking-server-name &lt;your-tracking-server-name&gt; 
 
 
 Stop the EC2 instance to avoid incurring additional costs: 
 
 
 aws ec2 stop-instances --instance-ids &lt;your-instance-id&gt; 
 
 
 Remove training data, model artifacts, and MLflow experiment data from S3 buckets: 
 
 
 aws s3 rm s3://&lt;your-bucket&gt;/&lt;your-MLflow-folder&gt; ‚Äìrecursive 
 
 
 Review and clean up any temporary IAM roles created for the EC2 instnce. 
 Delete your SageMaker Studio domain. 
 
Conclusion 
AWS DLCs and SageMaker managed MLflow provide ML teams a solution that balances the trade-off between governance and flexibility. This integration helps data scientists seamlessly track experiments and deploy models for inference, and helps administrators establish secure, scalable SageMaker managed MLflow environments. Organizations can now standardize their ML workflows using either AWS DLCs or DLAMIs while accommodating specialized requirements, ultimately accelerating the journey from model experimentation to business impact with greater control and efficiency. 
In this post, we explored how to integrate custom training environments with SageMaker managed MLflow to gain comprehensive experiment tracking and model governance. This approach maintains the flexibility of your preferred development environment while benefiting from centralized tracking, model registration, and lineage tracking. The integration provides a perfect balance between customization and standardization, so teams can innovate while maintaining governance best practices. 
Now that you understand how to track training in DLCs with SageMaker managed MLflow, you can implement this solution in your own environment. All code examples and implementation details from this post are available in our GitHub repository. 
For more information, refer to the following resources: 
 
 AWS Deep Learning AMIs Developer Guide 
 AWS Deep Learning Containers Developer Guide 
 Amazon SageMaker AI Developer Guide 
 Accelerate generative AI development using managed MLflow on Amazon SageMaker AI 
 
 
 
About the authors 
Gunjan Jain, an AWS Solutions Architect based in Southern California, specializes in guiding large financial services companies through their cloud transformation journeys. He expertly facilitates cloud adoption, optimization, and implementation of Well-Architected best practices. Gunjan‚Äôs professional focus extends to machine learning and cloud resilience, areas where he demonstrates particular enthusiasm. Outside of his professional commitments, he finds balance by spending time in nature. 
Rahul Easwar is a Senior Product Manager at AWS, leading managed MLflow and Partner AI Apps within the SageMaker AIOps team. With over 15 years of experience spanning startups to enterprise technology, he leverages his entrepreneurial background and MBA from Chicago Booth to build scalable ML platforms that simplify AI adoption for organizations worldwide. Connect with Rahul on&nbsp;LinkedIn to learn more about his work in ML platforms and enterprise AI solutions.
‚Ä¢ Supercharge your organization‚Äôs productivity with the Amazon Q Business browser extension
  Generative AI solutions like Amazon Q Business are transforming the way employees work. Organizations in every industry are embracing these tools to help their workforce extract valuable insights from increasingly fragmented data to accelerate decision-making processes. However, the adoption of generative AI tools hasn‚Äôt been without its challenges. 
Two hurdles have emerged in the implementation of generative AI solutions. First, users often find themselves compelled to abandon familiar workflows, manually transferring data to an AI assistant for analysis. This creates unnecessary friction and increases the time to value. Second, the absence of generative AI tools in commonly used software makes it difficult for employees to identify opportunities where AI can significantly boost their productivity. 
Enter Amazon Q Business, a generative AI-powered assistant tailored for the modern workplace, so you can engage in conversations, solve complex problems, and take action by seamlessly connecting to company data and enterprise systems. Amazon Q Business provides employees with instant access to relevant information and advice, streamlining tasks, accelerating decision-making, and fostering creativity and innovation in the workplace. We recently launched the Amazon Q Business browser extension in Amazon Q Business, and it is now available to Amazon Q Business subscribers (Lite and Pro). The Amazon Q Business browser extension brings the power of Amazon Q Business directly into your browsers, so you can receive context-aware, generative AI assistance and get on-the-go help for daily tasks. 
In this post, we show how to implement this solution for your own enterprise, giving your team seamless access to AI-driven insights and assistance. 
Use cases for the Amazon Q Business browser extension 
The Amazon Q Business browser extension is deployed to all Amazonians, making tens of thousands of users more productive every day. In this section, we highlight some of the most impactful use cases for which Amazonians use the Amazon Q Business browser extension to boost their productivity. 
Analyze web content 
Business and technical teams need to analyze and synthesize information across various reports, competitive analyses, and industry documents found outside the company‚Äôs data to develop insights and strategy. They must make sure their strategic recommendations are based on verified data sources and trustworthy industry information. Additionally, identifying patterns across multiple sources is time-consuming and complex. With the Amazon Q Business browser extension, strategists can quickly generate industry insights and identify trends across trusted internal and external data sources in seconds, while maintaining the human element in strategic thinking. 
Check out the following demo video: 

 
  
 
 
Improve content quality 
The Amazon Q Business browser extension brings the unique ability to incorporate context that might not be readily available to your generative AI assistant. You can use the Amazon Q Business browser extension for content creation and content quality improvements by including multiple disparate sources in your queries that typically aren‚Äôt available to generative AI assistants. You can use it to perform real-time validation of content from various sources and incorporate web-based style guides and best practices to accelerate content creation. 
Check out the following demo video: 

 
  
 
 
Solution overview 
In the following sections, we walk through how to get started with the Amazon Q Business browser extension if you have already enabled Amazon Q Business for your organization. To learn more, see Configuring the Amazon Q Business browser extension for use. 
Prerequisites 
Complete the prerequisite steps in this section before deploying the browser extension. 
Create an Amazon Q Business application and subscribe your users 
The Amazon Q Business browser extension is a feature of Amazon Q Business and requires customers to first create an Amazon Q Business application and subscribe their users before the browser extension can be enabled. To learn more about how you can get started with Amazon Q Business, see Getting started with Amazon Q Business. 
Set up the Amazon Q Business web experience 
The browser extension uses the Amazon Q Business web experience client as the mechanism to authenticate users and offer Amazon Q Business features. The first step to enabling the browser extension is to create an Amazon Q Business web experience. If you have already created a web experience for your users, you can skip this step. However, if you have developed a custom web experience using the Amazon Q Business APIs, complete the following steps to create an Amazon Q Business web experience: 
 
 On the Amazon Q Business console, go to your Amazon Q Business application. 
 
The Web experience settings section shows if you already have a web experience deployed. If you don‚Äôt have a web experience deployed, this section will be empty, with the message ‚ÄúA web experience needs to be created before deploying.‚Äù 
 
 
 At the top of your application details page, choose Edit. 
 
 
 
 For Outcome, select Web experience. 
 Choose Update. 
 
This step might take a few minutes to complete. 
 
After your web experience is deployed, you will find a URL where your web experience is hosted on your Amazon Q Business application details page. Save this URL for later. 
 
Grant users access to send queries directly to the large language model 
The Amazon Q Business browser extension can include your users‚Äô web page context in queries by passing the web page content as file attachments alongside a user‚Äôs prompt. Because the file attachment feature is available only for General knowledge mode, the browser extension requires Amazon Q Business admins to grant users access to send queries directly to the large language model (LLM) to take advantage of the full feature set of the browser extension. Without this prerequisite, users can only access their company knowledge through the browser extension and can‚Äôt ask Amazon Q Business questions about their web page content. 
Amazon Q Business does not store user conversation data and does not use queries or conversations for training its LLMs. Conversations are only stored within the application for 30 days. You can delete these conversations by accessing the Amazon Q Business web experience and choosing Chat in the navigation pane, as shown in the following screenshot. 
 
To grant users access to send queries directly to the Amazon Q LLM, complete the following steps: 
 
 On the Amazon Q Business console, go to your application. 
 Choose Admin controls and guardrails in the navigation pane. 
 
 
 
 In the Global controls section, choose Edit. 
 
 
 
 Select Allow end users to send queries directly to the LLM. 
 Choose Save. 
 
 
You are now ready to enable the browser extension for your users. 
Configure the Amazon Q Business browser extension 
Now that you have completed the prerequisites for the browser extension, complete the following steps to enable the browser extension for your users: 
 
 On the Amazon Q Business console, go to your application. 
 Under Enhancements in the navigation pane, choose Integrations. 
 In the Browser extensions section, choose Edit. 
 
 
 
 Select the check boxes for the browser extensions you want to enable: 
   
   The Chromium check box enables the Chrome store extension, which supports Google Chrome and Microsoft Edge browsers. 
   The Firefox check box enables the Firefox Browser add-on for Firefox browsers. 
    
 
You can also view the Chrome or Firefox store pages for the extension using the links in the respective Learn more sections. 
 
 Choose Save. 
 
 
Your users will now see instructions to install the Amazon Q Business browser extension the next time they log in to the Amazon Q Business web experience. If you have not yet done so, share the web experience URL you obtained in the earlier steps with your users so they can follow the steps to install the browser extension. 
Activate the browser extension if you are using IAM federation authentication for Amazon Q Business 
If you‚Äôre using an external identity provider (IdP) for your Amazon Q Business application, you must allow-list the browser extension with the external provider before your users can start using the browser extension. You can allow-list the following URLs with your IdP to activate the browser extension: 
 
 For the Chromium browser extension (suitable for Google Chrome and Microsoft Edge), use https://feihpdljijcgnokhfoibicengfiellbp.chromiumapp.org/ 
 For the Mozilla Firefox browser extension, https://ba6e8e6e4fa44c1057cf5f26fba9b2e788dfc34f.extensions.allizom.org/ 
 
You don‚Äôt need to take the aforementioned steps if you‚Äôre using AWS IAM Identity Center as the authentication solution for your Amazon Q Business application. 
Get started with the browser extension 
After you share the web experience URL with your users, they can use it to find the browser extension store page and install the browser extension. Users can complete the following steps: 
 
 Log in to the Amazon Q Business web experience provided by your admin. 
 
You will notice a banner letting you know that your admin has enabled the browser extension for you. 
 
 Choose Install extension. 
 
 
The link will take you to the appropriate Amazon Q Business browser extension store page based on the browser you‚Äôre using. 
 
 Choose Add to Chrome or the appropriate installation option for your browser. 
 
 
Upon installing the extension, you will find it in your browser‚Äôs tool bar under Extensions. You can choose the pin icon to pin the browser extension. 
 
After you open your browser extension, you will see a side pane as shown in the following screenshot. It will automatically detect the correct web experience URL from your open tabs to help you sign in. If it doesn‚Äôt, enter the web experience URL provided by your admin in the Amazon Q URL section and choose Sign in. 
 
Upon sign in, you‚Äôre ready to go! Refer to the earlier section discussing Amazon‚Äôs use cases for inspiration on how you can use the extension to boost your productivity. 
 
Deploy the Amazon Q Business browser extension on behalf of your users 
Some admins might choose to directly deploy the Amazon Q Business browser extension on their users‚Äô browsers to streamline and accelerate adoption. 
Enterprises use varying mobile device management software and have differing requirements for their browser policies. To deploy the Amazon Q Business browser extension, refer to the following resources: 
 
 Mozilla Firefox policy settings 
 Google Chrome policy settings 
 Microsoft Edge: 
   
   Policy settings 
   Reference guide 
    
 
Customize the Amazon Q Business browser extension for your enterprise 
Some admins might choose to customize the look and feel of the Amazon Q Business browser extension to fit their enterprise‚Äôs needs. This section outlines the extension‚Äôs supported customization functionality and the corresponding browser extension policy values to configure on your users‚Äô browsers. 
Remove the Amazon Q Business URL input from the browser extension login page 
If you don‚Äôt want to require an Amazon Q Business web experience URL from your users at sign-in, you can set a default URL on their behalf by setting the Q_BIZ_BROWSER_EXTENSION_URL policy to the appropriate Amazon Q Business web experience URL for your users. 
 
Replace the browser extension‚Äôs toolbar icon 
You can modify the toolbar icon of your browser extension by setting the value of one or more of the following browser policy keys to the URL of your PNG or SVG image or a valid datauri for your users: 
 
 Q_BIZ_BROWSER_EXTENSION_ICON_128 (mandatory) 
 Q_BIZ_BROWSER_EXTENSION_ICON_16 (optional) 
 Q_BIZ_BROWSER_EXTENSION_ICON_32 (optional) 
 Q_BIZ_BROWSER_EXTENSION_ICON_48 (optional) 
 
 
Replace the logo or icon in the browser extension window 
To change the logo or icon in your browser extension window, set the value of the Q_BIZ_BROWSER_EXTENSION_LOGO policy key with a URL to your PNG or SVG image or a valid datauri for your users. 
 
Modify the name of the browser extension shown in the browser extension window 
To replace references to ‚ÄúAmazon Q,‚Äù ‚ÄúAmazon Q Business,‚Äù ‚ÄúAWS,‚Äù and ‚ÄúAmazon Web Services‚Äù with a name of your choice inside the browser extension window, set the value of the Q_BIZ_BROWSER_EXTENSION_ENTERPRISE_NAME policy key with the new name for your users. 
 
Modify the title of your browser extension in hover text 
To change the title of your browser extension as it shows in the text when hovering over your extension (‚ÄúAmazon Q Business has access to this site,‚Äù as seen in the prior screenshot), set the Q_BIZ_BROWSER_EXTENSION_TITLE_NAME policy to the appropriate string for your users. 
 
Replace the AI policy link in the browser extension footer with your own link 
To replace the link text in the footer of your browser extension, set Q_BIZ_BROWSER_EXTENSION_FOOTER_POLICY_NAME to the appropriate string for your users. 
To replace the URL in the footer of your browser extension, set Q_BIZ_BROWSER_EXTENSION_FOOTER_POLICY_URL to the appropriate URL for your users. 
 
Congratulations! You and your organization are ready to receive generative assistance for your browser-based tasks. 
Clean up 
This section outlines the steps to disable or remove the browser extension or revert deployments and customization for your users. 
Disable the Amazon Q Business browser extension through the Amazon Q Business console 
You can disable the Amazon Q Business browser extension from the Amazon Q Business console whenever you choose, even before removing the browser extension from your users‚Äô browsers. To do so, complete the following steps: 
 
 On the Amazon Q Business console, go to your application. 
 Under Enhancements in the navigation pane, choose Integrations. 
 In the Browser extensions section, choose Edit. 
 
 
 
 Deselect the check boxes for the browser extensions you want to disable: 
   
   The Chromium check box disables the Chrome store extension, which supports Google Chrome and Microsoft Edge browsers. 
   The Firefox check box disables the Firefox Browser add-on for Firefox browsers. 
    
 Choose Save. 
 
 
Revert the deployment of the Amazon Q Business browser extension on behalf of your users 
Enterprises use varying mobile device management software and have differing requirements for their browser policies. If you deployed the browser extension by updating your browser policy settings, you should remove those policies by following the guidance in the policy settings documentation for the respective browsers: 
 
 Mozilla Firefox policy settings 
 Google Chrome policy settings 
 Microsoft Edge: 
   
   Policy settings 
   Reference guide 
    
 
Revert the deployment of the Amazon Q Business browser extension on behalf of your users 
If you customized the Amazon Q Business browser extension by modifying browser policies as detailed earlier in this post, you can revert those customizations by simply removing the corresponding policy entry in your browser policy settings. 
Conclusion 
In this post, we showed how to use the Amazon Q Business browser extension to give your team seamless access to AI-driven insights and assistance. The browser extension is now available in US East (N. Virginia) and US West (Oregon) AWS Regions for Mozilla, Google Chrome, and Microsoft Edge as part of the Lite Subscription. There is no additional cost to use the browser extension. 
To get started, log in to the Amazon Q Business console and setup the browser extension for your Amazon Q Business application. To learn more, see Configuring the Amazon Q Business browser extension for use. 
 
About the authors 
Firaz Akmal is a Sr. Product Manager for Amazon Q Business and has been at AWS for 8+ years. He is a customer advocate, helping customers transform their search and generative AI use-cases on AWS. Outside of work Firaz enjoys spending time in the mountains of the PNW or experiencing the world through his daughter‚Äôs perspective. 
Abhinand Sukumar is a Senior Product Manager at Amazon Web Services for Amazon Q Business, where he drives the product vision and roadmap for innovative generative AI solutions. Abhinand works closely with customers and engineering to deliver successful integrations, including the browser extension. His expertise spans generative AI experiences and AI/ML educational devices, with a deep passion for education, artificial intelligence, and design thinking. Prior to joining AWS, Abhinand worked as an embedded software engineer in the networking industry. With 5-6 years of experience in technology,

‚∏ª