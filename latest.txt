‚úÖ Morning News Briefing ‚Äì November 13, 2025 10:47

üìÖ Date: 2025-11-13 10:47
üè∑Ô∏è Tags: #briefing #ai #publichealth #digitalgov

‚∏ª

üßæ Weather
‚Ä¢ No watches or warnings in effect, Pembroke
  No watches or warnings in effect. No warnings or watches or watches in effect . Watch or warnings are no longer in effect in the U.S. No watches, warnings are in effect for the rest of the day . No watches and warnings are still in effect, but no watches are in place for the day's events . The weather is not expected to be affected by the weather .
‚Ä¢ Current Conditions:  0.5¬∞C
  Temperature: 0.5&deg;C Pressure / Tendency: 100.6 kPa rising Humidity: 89 % Dewpoint: -1.0&deg:C Wind: W 4 km/h Air Quality Health Index: n/a . Pembroke 5:00 AM EST Thursday 13 November 2025 Temperature: -0.5¬∞C Pressure/ Tendency
‚Ä¢ Thursday: Chance of flurries or rain showers. High plus 4. POP 40%
  Mainly cloudy with 40 percent chance of rain showers or flurries near noon . Wind becoming northwest 20 km/h gusting to 40 this morning . Wind chill chill minus 6 this morning. UV index 1 or low. High plus 4.50¬∞C . Wind chiller minus 6¬∞C. Wind chill minus 4¬∞F. Wind chills minus 6 ¬∞F . Wind

üåç International News
No updates.

üçÅ Canadian News
No updates.

üá∫üá∏ U.S. Top Stories
‚Ä¢ Why home insurance is unaffordable, even in places without wildfires or hurricanes
  Some of the country's highest home insurance prices are in the central U.S., a region generally considered to be protected from climate-driven disasters such as wildfires and hurricanes . The central part of the nation is considered protected by climate-related disasters like hurricanes and wildfires, such as wildfire and hurricanes, but is not protected from these types of disasters . The region is considered more likely to
‚Ä¢ SNAP funding pause to soon end, but anxiety and anger may linger
  The first ever disruption to the nation's largest anti-hunger program came as a shock . It's shaken trust in the program for some and stoked concern that it could happen again . The program is the largest in the country's largest and largest program in terms of food and sheltering people in need of sheltering animals . It is hoped the disruption will lead to an increase in hunger
‚Ä¢ Israel deported Palestinian prisoners to Egypt. Some Israelis question the practice
  Israel deported more than 150 freed Palestinian prisoners last month . Some experts in Israel warn it could have long-term consequences for Israeli security . Israel deported over 150 freed prisoners from Palestinian prisons last month. Some experts warn it may have long term consequences for Israel security. Israel deported some 150 freed Palestinians from Palestinian jails last month; some experts say it could be dangerous to Israel's security forces .
‚Ä¢ California plans to revoke 17,000 commercial driver's licenses given to immigrants
  The announcement follows harsh criticism from the Trump administration about California and other states granting licenses to people in the country illegally . California has been criticized for giving licenses to illegal immigrants in the U.S. illegally . The announcement comes after harsh criticism about the state's treatment of illegal immigrants from illegal immigrants . The state has also been criticized by the federal government for allowing illegal immigrants to obtain licenses .
‚Ä¢ The longest government shutdown in U.S. history comes to a close
  President Trump signed a bill to fund the government through the end of January, ending the shutdown that has dragged on for six weeks . The shutdown has been the longest in the history of the U.S. Congress . The bill was signed by President Trump on Thursday night, ending a six-week shutdown that began on January 1 . The government will be funded through the rest of January .

üß† Artificial Intelligence
No updates.

üíª Digital Strategy
‚Ä¢ To 'Infinity' ... and beyond: MX Linux 25 has arrived
  MX Linux 25 "Infinity" is now available, with things that used to be boot-time choices now more loaded pre-install decisions . Systemd-free option still available if you choose that download that download . New version has some significant differences from the 2023 release, with the new version having some significant changes from that release of 2023 .‚Ä¶‚Ä¶‚Ä¶ and things that
‚Ä¢ Networking students need an explanation of the internet that can fit in their heads
  Networks have changed profoundly, except for the parts that haven‚Äôt, says co-author Bruce Davie . He asks: How should we think about educating the next generation of students about networking, given how different and more complex the internet is today? How should students think about how to learn about networking? Systems Approach is the best way to teach students about networks, says Davie
‚Ä¢ Russia‚Äôs first autonomous humanoid robot staggers and falls on debut
  Semi-autonomous humanoid robot said to be Russia‚Äôs first such machine fell over within seconds of facing the public for the first time . Go home, comrade clanker, you look drunk ‚Äì and worryingly angry ‚Äì and look drunk .‚Ä¶‚Ä¶‚Ä¶...‚Ä¶ Go home. Go home,. you looked drunk and look angry, and you look like you're going mad .
‚Ä¢ Google to allow Android users with high pain tolerance to sideload unverified apps
  Google has decided to loosen some of its recently introduced rules regarding registration of Android developers and their apps . Promises some easing of rules that knobble indie devs, but isn't rushing to deliver the modest changes it plans . Google isn‚Äôt rushing to give the modest change it plans to deliver, but says it‚Äôs not rushing to get it right now, but itÔøΩ
‚Ä¢ Atlassian twice shunned AWS Graviton CPUs, but now runs Jira and Confluence on them
  Atlassian twice marked Amazon Web Services‚Äô Graviton CPUs off-limits for production purposes, but recently relented and now uses them to power thousands of server instances that run its Jira and Confluence products . Bills fell 10 percent after granular tests suggested JVM tweaks that improved performance improved performance . So what changed?‚Ä¶ What changed? Read the rest of this week's blog

üè• Public Health
No updates.

üî¨ Science
‚Ä¢ Correction: Quality of life improvements associated with weight loss using a novel shape-shifting hydrogel capsule: RESET study results
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ How much protein do you really need? What the science says
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Extreme rainfall poses the biggest risk to Mumbai‚Äôs most vulnerable people
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ The evolving landscape of cardiovascular health in Africa: insights from WHO AFRO
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations
‚Ä¢ Evaluation of the clinical frailty scale for predicting mortality or functional dependence at ICU discharge: A cohort study
  CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery . Please submit your best shots of our featured destinations for next week . Visit CNN iReport.com/Travel next Wednesday for a new gallery of snapshots . Visit www.dailyimpact.com for a gallery next week for snapshots of places to go next week in the gallery . Submit photos of your favorite destinations

üßæ Government & Policy
No updates.

üèõÔ∏è Enterprise Architecture & IT Governance
No updates.

ü§ñ AI & Emerging Tech
‚Ä¢ The Download: how to survive a conspiracy theory, and moldy cities
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



What it‚Äôs like to be in the middle of a conspiracy theory (according to a conspiracy theory expert)



‚ÄîMike Rothschild is a journalist and an expert on the growth and impact of conspiracy theories and disinformation.It‚Äôs something of a familiar cycle by now: Tragedy hits; rampant misinformation and conspiracy theories follow. It‚Äôs often even more acute in the case of a natural disaster, when conspiracy theories about what ‚Äúreally‚Äù caused the calamity run right into culture-war-driven climate change denialism. Put together, these theories obscure real causes while elevating fake ones.I‚Äôve studied these ideas extensively, having spent the last 10 years writing about conspiracy theories and disinformation as a journalist and researcher. I‚Äôve covered everything from the rise of QAnon to whether Donald Trump faked his assassination attempt. I‚Äôve written three books, testified to Congress, and even written a report for the January 6th Committee.&nbsp;



Still, I‚Äôd never lived it. Not until my house in Altadena, California, burned down. Read the full story.



This story is part of MIT Technology Review‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology. Check out the rest of the series here. It‚Äôs also featured in this week‚Äôs MIT Technology Review Narrated podcast, which we publish each week on Spotify and Apple Podcasts.&nbsp;



If you‚Äôd like to hear more from Mike, he‚Äôll be joining our features editor Amanda Silverman and executive editor Niall Firth for a subscriber-exclusive Roundtable conversation exploring how we can survive in the age of conspiracies. It‚Äôs at 1pm ET on Thursday November 20‚Äîregister now to join us!







This startup thinks slime mold can help us design better cities



It is a yellow blob with no brain, yet some researchers believe a curious organism known as slime mold could help us build more resilient cities.Humans have been building cities for 6,000 years, but slime mold has been around for 600 million. The team behind a new startup called Mireta wants to translate the organism‚Äôs biological superpowers into algorithms that might help improve transit times, alleviate congestion, and minimize climate-related disruptions in cities worldwide. Read the full story.



‚ÄîElissaveta M. Brandon



This story is from the latest print issue of MIT Technology Review magazine, which is full of fascinating stories about our bodies. If you haven‚Äôt already, subscribe now to receive future issues once they land.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 US government officials are skipping COP30And American corporate executives are following their lead. (NYT $)+ Protestors stormed the climate talks in Brazil. (The Guardian)+ Gavin Newsom took aim at Donald Trump‚Äôs climate policies onstage. (FT $)



2 The UK may assess AI models for their ability to generate CSAMIts government has suggested amending a legal bill to enable the tests. (BBC)+ US investigators are using AI to detect child abuse images made by AI. (MIT Technology Review)



3 Google is suing a group of Chinese hackersIt claims they‚Äôre selling software to enable criminal scams. (FT $)+ The group allegedly sends colossal text message phishing attacks. (CBS News)4 A major ‚Äòcryptoqueen‚Äô criminal has been jailedQian Zhimin used money stolen from Chinese pensioners to buy cryptocurrency now worth billions. (BBC)+ She defrauded her victims through an elaborate ponzi scheme. (CNN)



5 Carbon capture‚Äôs creators fear it‚Äôs being misusedOverreliance on the method could breed overconfidence and cause countries to delay reducing emissions. (Bloomberg $)+ Big Tech‚Äôs big bet on a controversial carbon removal tactic. (MIT Technology Review)



6 The UK will use AI to phase out animal testing3D bioprinted human tissues could also help to speed up the process. (The Guardian)+ But the AI boom is looking increasingly precarious. (WSJ $)



7 Louisiana is dealing with a whooping cough outbreakTwo infants have died to date from the wholly preventative disease. (Undark)



8 Here‚Äôs how ordinary people use ChatGPTEmotional support and discussions crop up regularly.(WP $)+ It‚Äôs surprisingly easy to stumble into a relationship with an AI chatbot. (MIT Technology Review)



9 Inside the search for lost continentsA newly-discovered mechanism is shedding light on why they may have vanished. (404 Media)+ How environmental DNA is giving scientists a new way to understand our world. (MIT Technology Review)



10 AI is taking Gen Z‚Äôs entry-level jobsEspecially in traditionally graduate-friendly consultancies. (NY Mag $)+ What the Industrial Revolution can teach us about how to handle AI. (Knowable Magazine)+ America‚Äôs corporate boards are stumbling in the dark. (WSJ $)







Quote of the day



&#8220;We can‚Äôt eat money.‚Äù



‚ÄîNato, an Indigenous leader from the Tupinamba community, tells Reuters why they are protesting at the COP30 climate summit in Brazil against any potential sale of their land.







One more thing







How K-pop fans are shaping elections around the globeBack in the early ‚Äò90s, Korean pop music, known as K-pop, was largely conserved to its native South Korea. It‚Äôs since exploded around the globe into an international phenomenon, emphasizing choreography and elaborate performance.It‚Äôs made bands like Girls Generation, EXO, BTS, and Blackpink into household names, and inspired a special brand of particularly fierce devotion in their fans.Now, those same fandoms have learned how to use their digital skills to advocate for social change and pursue political goals‚Äîorganizing acts of civil resistance, donating generously to charity, and even foiling white supremacist attempts to spread hate speech. Read the full story.‚ÄîSoo Youn







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ These sucker fish are having the time of their lives hitching a ride on a whale.+ Next time you fly, ditch the WiFi. I know I will.+ I love this colossal interactive gif.+ The hottest scent in perfumery right now? Smelling like a robot, apparently.
‚Ä¢ Improving VMware migration workflows with agentic AI
  CNCF‚Äôs 2024 Annual Survey, 89% of organizations have already adopted at least some cloud-native techniques . Share of companies reporting nearly all development and deployment as cloud native grew sharply from 2023 to 2024 (20% to 24%) Market research firm IDC reports that cloud providers have become top strategic partners for generative AI initiatives . As enterprises prepare for that inevitability, they are facing compute demands that are difficult, if not prohibitively expensive, to maintain exclusively on-premises .
‚Ä¢ The Download: surviving extreme temperatures, and the big whale-wind turbine conspiracy
  This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.



The quest to find out how our bodies react to extreme temperatures



Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. That‚Äôs heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.While we broadly know how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. Researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and cold‚Äîand how to survive in a new world. Read the full story.



‚ÄîMax G.Levy



This story is from the latest print issue of MIT Technology Review magazine, which is full of fascinating stories about the body. If you haven‚Äôt already, subscribe now to receive future issues once they land.







Whales are dying. Don‚Äôt blame wind turbines.



Whale deaths have become a political flashpoint. There are currently three active mortality events for whales in the Atlantic, meaning clusters of deaths that experts consider unusual. And Republican lawmakers, conservative think tanks, and‚Äîmost notably‚ÄîPresident Donald Trump (a longtime enemy of wind power) are making dubious claims that offshore wind farms are responsible.But any finger-pointing at wind turbines for whale deaths ignores the fact that whales have been washing up on beaches since long before the giant machines were rooted in the ocean floor. This is something that has always happened. And the scientific consensus is clear: There‚Äôs no evidence that wind farms are the cause of recent increases in whale deaths. Read the full story.



‚ÄîCasey Crownhart



This story is part of MIT Technology Review‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology. Check out the rest of the series here.







The State of AI: Energy is king, and the US is falling behind



In the age of AI, the biggest barrier to progress isn‚Äôt money but energy. That should be particularly worrying in the US, where massive data centers are waiting to come online. It doesn‚Äôt look as if the country will build the steady power supply or infrastructure needed to serve them all.It wasn‚Äôt always like this. For about a decade before 2020, data centers were able to offset increased demand with efficiency improvements. Now, though, electricity demand is ticking up in the US, with billions of queries to popular AI models each day‚Äîand efficiency gains aren‚Äôt keeping pace.If we want AI to have the chance to deliver on big promises without driving electricity prices sky-high for the rest of us, the US needs to learn some lessons from the rest of the world on energy abundance. Just look at China. Read the full story.



‚ÄîCasey Crownhart &amp; Pilita Clark



This is from The State of AI, our subscriber-only collaboration between the Financial Times &amp; MIT Technology Review examining the ways in which AI is reshaping global power.Every Monday for the next four weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. While subscribers to The Algorithm, our weekly AI newsletter, get access to an extended excerpt, subscribers to the magazine are able to read the whole thing. Sign up here to receive future editions every Monday.







The must-reads



I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.



1 How China narrowed its AI divide with the USAmerica still has a clear lead‚Äîbut for how long? (WSJ $)+ The AI boom won‚Äôt offset tariffs and America‚Äôs immigration crackdown forever. (FT $)+ How quickly is AI likely to progress really? (Economist $)+ Is China about to win the AI race? (MIT Technology Review)



2 Anthropic is due to turn a profit much faster than OpenAIThe two companies are taking very different approaches to making money. (WSJ $)+ OpenAI has lured Intel‚Äôs AI chief away. (Bloomberg $)



3 The EU is setting up a new intelligence sharing unitIt‚Äôs a bid to shore up intel in the wake of Donald Trump‚Äôs plans to reduce security support for Europe. (FT $)



4 Trump officials are poised to suggest oil drilling off the coast of CaliforniaThat&#8217;s likely to rile the state‚Äôs politicians and leaders. (WP $)+ What role should oil and gas companies play in climate tech? (MIT Technology Review)



5 America‚Äôs cyber defenses are poorRepeated cuts and mass layoffs are making it harder to protect the nation. (The Verge)



6 China is on track to hit its peak CO2 emissions target earlyAlthough it‚Äôs likely to miss its goal for cutting carbon intensity. (The Guardian)+ World leaders are heading to COP30 in Brazil this week. (New Yorker $)



7 OpenAI cannot use song lyrics without a licenseThat‚Äôs what a German court has decided, after siding with a music rights society. (Reuters)+ OpenAI is no stranger to legal proceedings. (The Atlantic $)+ AI is coming for music. (MIT Technology Review)



8 A small Michigan town is fighting a proposed AI data centerThe planned center is part of a collaboration between the University of Michigan and nuclear weapons scientists. (404 Media)+ Here‚Äôs where America‚Äôs data centers should be built instead. (Wired $)+ Communities in Latin America are pushing back, too. (The Guardian)+ Should we be moving data centers to space? (MIT Technology Review)9 AI models can‚Äôt tell the time Analog clocks leave them completely stumped. (IEEE Spectrum)



10 ChatGPT is giving daters the ickThese refuseniks don‚Äôt want anything to do with AI, or love interests who use it. (The Guardian)







Quote of the day



‚ÄúI never imagined that making a cup of tea or obtaining water, antibiotics, or painkillers would require such tremendous effort.‚Äù



‚ÄîAn anonymous member of startup accelerator Gaza Sky Geeks tells Rest of World about the impact the war has had on them.







One more thing







How Rust went from a side project to the world‚Äôs most-loved programming languageMany software projects emerge because‚Äîsomewhere out there‚Äîa programmer had a personal problem to solve.That‚Äôs more or less what happened to Graydon Hoare. In 2006, Hoare was a 29-year-old computer programmer working for Mozilla. After a software crash broke the elevator in his building, he set about designing a new computer language; one that he hoped would make it possible to write small, fast code without memory bugs.That language developed into Rust, one of the hottest new languages on the planet. But while it isn‚Äôt unusual for someone to make a new computer language, it‚Äôs incredibly rare for one to take hold and become part of the programming pantheon. How did Rust do it? Read the full story.¬†



‚ÄîClive Thompson







We can still have nice things



A place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet &#8217;em at me.)



+ Having a bit of a rubbish day so far? Here‚Äôs how to make it better.+ A Hungarian man played Dance Dance Revolution for 144 hours non-stop, because he knows how to have a seriously good time.+ A new book is celebrating cats, as it should (thanks Jess!)+ How a poem from a medieval trickster sowed the seed for hundreds of years of bubonic plague misinformation
‚Ä¢ The State of AI: Energy is king, and the US is falling behind
  Welcome back to&nbsp;The State of AI, a new collaboration between the Financial Times and MIT Technology Review. Every Monday, writers from both publications debate one aspect of the generative AI revolution and how it is reshaping global power.



This week, Casey Crownhart, senior reporter for energy at MIT Technology Review and Pilita Clark, FT&#8217;s columnist, consider how China&#8217;s rapid renewables buildout could help it leapfrog on AI progress.







Casey Crownhart writes:



In the age of AI, the biggest barrier to progress isn‚Äôt money but energy. That should be particularly worrying here in the US, where massive data centers are waiting to come online, and it doesn‚Äôt look as if the country will build the steady power supply or infrastructure needed to serve them all.



It wasn‚Äôt always like this. For about a decade before 2020, data centers were able to offset increased demand with efficiency improvements. Now, though, electricity demand is ticking up in the US, with billions of queries to popular AI models each day‚Äîand efficiency gains aren‚Äôt keeping pace. With too little new power capacity coming online, the strain is starting to show: Electricity bills are ballooning for people who live in places where data centers place a growing load on the grid.



If we want AI to have the chance to deliver on big promises without driving electricity prices sky-high for the rest of us, the US needs to learn some lessons from the rest of the world on energy abundance. Just look at China.



China installed 429 GW of new power generation capacity in 2024, more than six times the net capacity added in the US during that time.



China still generates much of its electricity with coal, but that makes up a declining share of the mix. Rather, the country is focused on installing solar, wind, nuclear, and gas at record rates.



The US, meanwhile, is focused on reviving its ailing coal industry. Coal-fired power plants are polluting and, crucially, expensive to run. Aging plants in the US are also less reliable than they used to be, generating electricity just 42% of the time, compared with a 61% capacity factor in 2014.



It‚Äôs not a great situation. And unless the US changes something, we risk becoming consumers as opposed to innovators in both energy and AI tech. Already, China earns more from exporting renewables than the US does from oil and gas exports.&nbsp;



Building and permitting new renewable power plants would certainly help, since they‚Äôre currently the cheapest and fastest to bring online. But wind and solar are politically unpopular with the current administration. Natural gas is an obvious candidate, though there are concerns about delays with key equipment.



One quick fix would be for data centers to be more flexible. If they agreed not to suck electricity from the grid during times of stress, new AI infrastructure might be able to come online without any new energy infrastructure.





One study from Duke University found that if data centers agree to curtail their consumption just 0.25% of the time (roughly 22 hours over the course of the year), the grid could provide power for about 76 GW of new demand. That‚Äôs like adding about 5% of the entire grid‚Äôs capacity without needing to build anything new.



But flexibility wouldn‚Äôt be enough to truly meet the swell in AI electricity demand. What do you think, Pilita? What would get the US out of these energy constraints? Is there anything else we should be thinking about when it comes to AI and its energy use?&nbsp;



Pilita Clark responds:



I agree. Data centers that can cut their power use at times of grid stress should be the norm, not the exception. Likewise, we need more deals like those giving cheaper electricity to data centers that let power utilities access their backup generators. Both reduce the need to build more power plants, which makes sense regardless of how much electricity AI ends up using.



This is a critical point for countries across the world, because we still don‚Äôt know exactly how much power AI is going to consume.&nbsp;



Forecasts for what data centers will need in as little as five years‚Äô time vary wildly, from less than twice today‚Äôs rates to four times as much.



This is partly because there‚Äôs a lack of public data about AI systems‚Äô energy needs. It‚Äôs also because we don‚Äôt know how much more efficient these systems will become. The US chip designer Nvidia said last year that its specialized chips had become 45,000 times more energy efficient over the previous eight years.&nbsp;



Moreover, we have been very wrong about tech energy needs before. At the height of the dot-com boom in 1999, it was erroneously claimed that the internet would need half the US‚Äôs electricity within a decade‚Äînecessitating a lot more coal power.



Still, some countries are clearly feeling the pressure already. In Ireland, data centers chew up so much power that new connections have been restricted around Dublin to avoid straining the grid.



Some regulators are eyeing new rules forcing tech companies to provide enough power generation to match their demand. I hope such efforts grow. I also hope AI itself helps boost power abundance and, crucially, accelerates the global energy transition needed to combat climate change. OpenAI‚Äôs Sam Altman said in 2023 that ‚Äúonce we have a really powerful super intelligence, addressing climate change will not be particularly difficult.‚Äù&nbsp;



The evidence so far is not promising, especially in the US, where renewable projects are being axed. Still, the US may end up being an outlier in a world where ever cheaper renewables made up more than 90% of new power capacity added globally last year.&nbsp;



Europe is aiming to power one of its biggest data centers predominantly with renewables and batteries. But the country leading the green energy expansion is clearly China.



The 20th century was dominated by countries rich in the fossil fuels whose reign the US now wants to prolong. China, in contrast, may become the world‚Äôs first green electrostate. If it does this in a way that helps it win an AI race the US has so far controlled, it will mark a striking chapter in economic, technological, and geopolitical history.



Casey Crownhart replies:



I share your skepticism of tech executives‚Äô claims that AI will be a groundbreaking help in the race to address climate change. To be fair, AI is progressing rapidly. But we don‚Äôt have time to wait for technologies standing on big claims with nothing to back them up.&nbsp;



When it comes to the grid, for example, experts say there‚Äôs potential for AI to help with planning and even operating, but these efforts are still experimental.&nbsp;&nbsp;



Meanwhile, much of the world is making measurable progress on transitioning to newer, greener forms of energy. How that will affect the AI boom remains to be seen. What is clear is that AI is changing our grid and our world, and we need to be clear-eyed about the consequences.&nbsp;



Further reading&nbsp;



MIT Technology Review reporters did the math on the energy needs of an AI query.



There are still a few reasons to be optimistic about AI‚Äôs energy demands.&nbsp;&nbsp;



The FT‚Äôs visual data team take a look inside the relentless race for AI capacity.



And global FT reporters ask whether data centers can ever truly be green.



This article first appeared in our weekly AI newsletter, The Algorithm. Sign up here to get next week&#8217;s installment early.
‚Ä¢ Reimagining cybersecurity in the era of AI and quantum
  AI and quantum technologies are dramatically reconfiguring how cybersecurity functions, redefining the speed and scale with which digital defenders and their adversaries can operate.







The weaponization of AI tools for cyberattacks is already proving a worthy opponent to current defenses. From reconnaissance to ransomware, cybercriminals can automate attacks faster than ever before with AI. This includes using generative AI to create social engineering attacks at scale, churning out tens of thousands of tailored phishing emails in seconds, or accessing widely available voice cloning software capable of bypassing security defenses for as little as a few dollars. And now, agentic AI raises the stakes by introducing autonomous systems that can reason, act, and adapt like human adversaries.



But AI isn‚Äôt the only force shaping the threat landscape. Quantum computing has the potential to seriously undermine current encryption standards if developed unchecked. Quantum algorithms can solve the mathematical problems underlying most modern cryptography, particularly public-key systems like RSA and Elliptic Curve, widely used for secure online communication, digital signatures, and cryptocurrency.



‚ÄúWe know quantum is coming. Once it does, it will force a change in how we secure data across everything, including governments, telecoms, and financial systems,‚Äù says Peter Bailey, senior vice president and general manager of Cisco‚Äôs security business.



‚ÄúMost organizations are understandably focused on the immediacy of AI threats,&#8221; says Bailey. ‚ÄúQuantum might sound like science fiction, but those scenarios are coming faster than many realize. It‚Äôs critical to start investing now in defenses that can withstand both AI and quantum attacks.‚Äù



Critical to this defense is a zero trust approach to cybersecurity, which assumes no user or device can be inherently trusted. By enforcing continuous verification, zero trust enables constant monitoring and ensures that any attempts to exploit vulnerabilities are quickly detected and addressed in real time. This approach is technology-agnostic and creates a resilient framework even in the face of an ever-changing threat landscape.



Putting up AI defenses&nbsp;



AI is lowering the barrier to entry for cyberattacks, enabling hackers even with limited skills or resources to infiltrate, manipulate, and exploit the slightest digital vulnerability.



Nearly three-quarters (74%) of cybersecurity professionals say AI-enabled threats are already having a significant impact on their organization, and 90% anticipate such threats in the next one to two years.&nbsp;



‚ÄúAI-powered adversaries have advanced techniques and operate at machine speed,‚Äù says Bailey. ‚ÄúThe only way to keep pace is to use AI to automate response and defend at machine speed.‚Äù



To do this, Bailey says, organizations must modernize systems, platforms, and security operations to automate threat detection and response‚Äîprocesses that have previously relied on human rule-writing and reaction times. These systems must adapt dynamically as environments evolve and criminal tactics change.



At the same time, companies must strengthen the security of their AI models and data to reduce exposure to manipulation from AI-enabled malware. Such risks could include, for instance, prompt injections, where a malicious user crafts a prompt to manipulate an AI model into performing unintended actions, bypassing its original instructions and safeguards.



Agentic AI further ups the ante, with hackers able to use AI agents to automate attacks and make tactical decisions without constant human oversight. ‚ÄúAgentic AI has the potential to collapse the cost of the kill chain,‚Äù says Bailey. ‚ÄúThat means everyday cybercriminals could start executing campaigns that today only well-funded espionage operations can afford.‚Äù



Organizations, in turn, are exploring how AI agents can help them stay ahead. Nearly 40% of companies expect agentic AI to augment or assist teams over the next 12 months, especially in cybersecurity, according to Cisco‚Äôs 2025 AI Readiness Index. Use cases include AI agents trained on telemetry, which can identify anomalies or signals from machine data too disparate and unstructured to be deciphered by humans.&nbsp;



Calculating the quantum threat



As many cybersecurity teams focus on the very real AI-driven threat, quantum is waiting on the sidelines. Almost three-quarters (73%) of US organizations surveyed by KPMG say they believe it is only a matter of time before cybercriminals are using quantum to decrypt and disrupt today‚Äôs cybersecurity protocols. And yet, the majority (81%) also admit they could do more to ensure that their data remains secure.



Companies are right to be concerned. Threat actors are already carrying out harvest now, decrypt later attacks, stockpiling sensitive encrypted data to crack once quantum technology matures. Examples include state-sponsored actors intercepting government communications and cybercriminal networks storing encrypted internet traffic or financial records.&nbsp;



Large technology companies are among the first to roll out quantum defenses. For example, Apple is using cryptography protocol PQ3 to defend against harvest now, decrypt later attacks on its iMessage platform. Google is testing post-quantum cryptography (PQC)‚Äîwhich is resistant to attacks from both quantum and classical computers‚Äîin its Chrome browser. And Cisco ‚Äúhas made significant investments in quantum-proofing our software and infrastructure,‚Äù says Bailey. ‚ÄúYou‚Äôll see more enterprises and governments taking similar steps over the next 18 to 24 months,‚Äù he adds.&nbsp;



As regulations like the US Quantum Computing Cybersecurity Preparedness Act lay out requirements for mitigating against quantum threats, including standardized PQC algorithms by the National Institute of Standards and Technology, a wider range of organizations will start preparing their own quantum defenses.&nbsp;



For organizations beginning that journey, Bailey outlines two key actions. First, establish visibility. ‚ÄúUnderstand what data you have and where it lives,‚Äù he says. ‚ÄúTake inventory, assess sensitivity, and review your encryption keys, rotating out any that are weak or outdated.‚Äù



Second, plan for migration. ‚ÄúNext, assess what it will take to support post-quantum algorithms across your infrastructure. That means addressing not just the technology, but also the process and people implications,‚Äù Bailey says.



Adopting proactive defense&nbsp;



Ultimately, the foundation for building resilience against both AI and quantum is a zero trust approach, says Bailey. By embedding zero trust access controls across users, devices, business applications, networks, and clouds, this approach grants only the minimum access required to complete a task and enables continuous monitoring. It can also minimize the attack surface by confining a potential threat to an isolated zone, preventing it from accessing other critical systems.



Into this zero trust architecture, organizations can integrate specific measures to defend against AI and quantum risks. For instance, quantum-immune cryptography and AI-powered analytics and security tools can be used to identify complex attack patterns and automate real-time responses.&nbsp;



‚ÄúZero trust slows down attacks and builds resilience,‚Äù Bailey says. ‚ÄúIt ensures that even if a breach occurs, the crown jewels stay protected and operations can recover quickly.‚Äù



Ultimately, companies should not wait for threats to emerge and evolve. They must get ahead now. ‚ÄúThis isn‚Äôt a what-if scenario; it‚Äôs a when,‚Äù says Bailey. ‚ÄúOrganizations that invest early will be the ones setting the pace, not scrambling to catch up.‚Äù



This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.

üîí Cybersecurity & Privacy
‚Ä¢ Drilling Down on Uncle Sam‚Äôs Proposed TP-Link Ban
  The U.S. government is reportedly preparing to ban the sale of wireless routers and other networking gear from TP-Link Systems, a tech company that currently enjoys an estimated 50% market share among home users and small businesses. Experts say while the proposed ban may have more to do with TP-Link&#8217;s ties to China than any specific technical threats, much of the rest of the industry serving this market also sources hardware from China and ships products that are insecure fresh out of the box.
A TP-Link WiFi 6 AX1800 Smart WiFi Router (Archer AX20).
The Washington Post recently reported that more than a half-dozen federal departments and agencies were backing a proposed ban on future sales of TP-Link devices in the United States. The story said U.S. Department of Commerce officials concluded TP-Link Systems products pose a risk because the U.S.-based company‚Äôs products handle sensitive American data and because the officials believe it remains subject to jurisdiction or influence by the Chinese government.
TP-Link Systems denies that, saying that it fully split from the Chinese TP-Link Technologies over the past three years, and that its critics have vastly overstated the company&#8217;s market share (TP-Link puts it at around 30 percent). TP-Link says it has headquarters in California, with a branch in Singapore, and that it manufactures in Vietnam. The company says it researches, designs, develops and manufactures everything except its chipsets in-house.
TP-Link Systems told The Post it has sole ownership of some engineering, design and manufacturing capabilities in China that were once part of China-based TP-Link Technologies, and that it operates them without Chinese government supervision.
&#8220;TP-Link vigorously disputes any allegation that its products present national security risks to the United States,&#8221; Ricca Silverio, a spokeswoman for TP-Link Systems, said in a statement. &#8220;TP-Link is a U.S. company committed to supplying high-quality and secure products to the U.S. market and beyond.&#8221;
Cost is a big reason TP-Link devices are so prevalent in the consumer and small business market: As this February 2025 story from Wired observed regarding the proposed ban, TP-Link has long had a reputation for flooding the market with devices that are considerably cheaper than comparable models from other vendors. That price point (and consistently excellent performance ratings) has made TP-Link a favorite among Internet service providers (ISPs) that provide routers to their customers.
In August 2024, the chairman and the ranking member of the House Select Committee on the Strategic Competition Between the United States and the Chinese Communist Party called for an investigation into TP-Link devices, which they said were found on U.S. military bases and for sale at exchanges that sell them to members of the military and their families.
‚ÄúTP-Link‚Äôs unusual degree of vulnerabilities and required compliance with PRC law are in and of themselves disconcerting,&#8221; the House lawmakers warned in a letter (PDF) to the director of the Commerce Department. &#8220;When combined with the PRC government‚Äôs common use of SOHO [small office/home office] routers like TP-Link to perpetrate extensive cyberattacks in the United States, it becomes significantly alarming.‚Äù
The letter cited a May 2023 blog post by Check Point Research about a Chinese state-sponsored hacking group dubbed &#8220;Camaro Dragon&#8221; that used a malicious firmware implant for some TP-Link routers to carry out a sequence of targeted cyberattacks against European foreign affairs entities. Check Point said while it only found the malicious firmware on TP-Link devices, &#8220;the firmware-agnostic nature of the implanted components indicates that a wide range of devices and vendors may be at risk.&#8221;
In a report published in October 2024, Microsoft said it was tracking a network of compromised TP-Link small office and home office routers that has been abused by multiple distinct Chinese state-sponsored hacking groups since 2021. Microsoft found the hacker groups were leveraging the compromised TP-Link systems to conduct &#8220;password spraying&#8221; attacks against Microsoft accounts. Password spraying involves rapidly attempting to access a large number of accounts (usernames/email addresses) with a relatively small number of commonly used passwords.
TP-Link rightly points out that most of its competitors likewise source components from China. The company also correctly notes that advanced persistent threat (APT) groups from China and other nations have leveraged vulnerabilities in products from their competitors, such as Cisco and Netgear.
But that may be cold comfort for TP-Link customers who are now wondering if it&#8217;s smart to continue using these products, or whether it makes sense to buy more costly networking gear that might only be marginally less vulnerable to compromise.
Almost without exception, the hardware and software that ships with most consumer-grade routers includes a number of default settings that need to be changed before the devices can be safely connected to the Internet. For example, bring a new router online without changing the default username and password and chances are it will only take a few minutes before it is probed and possibly compromised by some type of Internet-of-Things botnet. Also, it is incredibly common for the firmware in a brand new router to be dangerously out of date by the time it is purchased and unboxed.
Until quite recently, the idea that router manufacturers should make it easier for their customers to use these products safely was something of an anathema to this industry. Consumers were largely left to figure that out on their own, with predictably disastrous results.
But over the past few years, many manufacturers of popular consumer routers have begun forcing users to perform basic hygiene &#8212; such as changing the default password and updating the internal firmware &#8212; before the devices can be used as a router. For example, most brands of &#8220;mesh&#8221; wireless routers &#8212; like Amazon&#8217;s Eero, Netgear&#8217;s Orbi series, or Asus&#8217;s ZenWifi &#8212; require online registration that automates these critical steps going forward (or at least through their stated support lifecycle).
For better or worse, less expensive, traditional consumer routers like those from Belkin and Linksys also now automate this setup by heavily steering customers toward installing a mobile app to complete the installation (this often comes as a shock to people more accustomed to manually configuring a router). Still, these products tend to put the onus on users to check for and install available updates periodically. Also, they&#8217;re often powered by underwhelming or else bloated firmware, and a dearth of configurable options.
Of course, not everyone wants to fiddle with mobile apps or is comfortable with registering their router so that it can be managed or monitored remotely in the cloud. For those hands-on folks &#8212; and for power users seeking more advanced router features like VPNs, ad blockers and network monitoring &#8212; the best advice is to check if your router&#8217;s stock firmware can be replaced with open-source alternatives, such as OpenWrt¬†or DD-WRT.
These open-source firmware options are compatible with a wide range of devices, and they generally offer more features and configurability. Open-source firmware can even help extend the life of routers years after the vendor stops supporting the underlying hardware, but it still requires users to manually check for and install any available updates.
Happily, TP-Link users spooked by the proposed ban may have an alternative to outright junking these devices, as many TP-Link routers also support open-source firmware options like OpenWRT. While this approach may not eliminate any potential hardware-specific security flaws, it could serve as an effective hedge against more common vendor-specific vulnerabilities, such as undocumented user accounts, hard-coded credentials, and weaknesses that allow attackers to bypass authentication.
Regardless of the brand, if your router is more than four or five years old it may be worth upgrading for performance reasons alone &#8212; particularly if your home or office is primarily accessing the Internet through WiFi.
NB: The Post&#8217;s story notes that a substantial portion of TP-Link routers and those of its competitors are purchased or leased through ISPs. In these cases, the devices are typically managed and updated remotely by your ISP, and equipped with custom profiles responsible for authenticating your device to the ISP&#8217;s network. If this describes your setup, please do not attempt to modify or replace these devices without first consulting with your Internet provider.

üéì University AI
No updates.

üè¢ Corporate AI
‚Ä¢ MMCTAgent: Enabling multimodal reasoning over large video and image collections
  Modern multimodal AI models can recognize objects, describe scenes, and answer questions about images and short video clips, but they struggle with long-form and large-scale visual data, where real-world reasoning requires moving beyond object recognition and short-clip analysis.



Real-world reasoning increasingly involves analyzing long-form video content, where context spans minutes or hours, far beyond the context limits of most models.‚ÄØIt also entails querying across massive multimodal libraries of videos, images, and transcripts, where finding and integrating relevant evidence requires more than retrieval‚Äîit requires strategic reasoning. Existing models typically perform single-pass inference, producing one-shot answers. This limits their ability to handle tasks that require temporal reasoning, cross-modal grounding, and iterative refinement.



MMCTAgent



To meet these challenges, we developed the Multi-modal Critical Thinking Agent, or MMCTAgent, for structured reasoning over long-form video and image data, available on GitHub (opens in new tab) and featured on Azure AI Foundry Labs (opens in new tab).



Built on AutoGen, Microsoft‚Äôs open-source multi-agent system, MMCTAgent provides multimodal question-answering with a Planner‚ÄìCritic architecture. This design enables planning, reflection, and tool-based reasoning, bridging perception and deliberation in multimodal tasks. It links language, vision, and temporal understanding, transforming static multimodal tasks into dynamic reasoning workflows.&nbsp;&nbsp;



Unlike conventional models that produce one-shot answers, MMCTAgent has modality-specific agents, including ImageAgent and VideoAgent, which include tools like get_relevant_query_frames() or object_detection-tool(). These agents perform&nbsp;deliberate, iterative reasoning‚Äîselecting the right tools for each modality, evaluating intermediate results, and refining conclusions through a Critic loop. This enables MMCTAgent to analyze complex queries across long videos and large image libraries with explainability, extensibility, and scalability.




MMCTAgent on Azure AI Foundry Labs




	
		

		
		Spotlight: Microsoft research newsletter
	
	
	
						
				
					
				
			
			
			

									Microsoft Research Newsletter
				
								Stay connected to the research community at Microsoft.
				
								
					
						
							Subscribe today						
					
				
							
	
Opens in a new tab	
	


How MMCTAgent works



MMCTAgent integrates two coordinated agents, Planner and Critic, orchestrated through AutoGen. The Planner agent decomposes a user query, identifies the appropriate reasoning tools, performs multimodal operations, and drafts a preliminary answer. The Critic agent reviews the Planner‚Äôs reasoning chain, validates evidence alignment, and refines or revises the response for factual accuracy and consistency.



This iterative reasoning loop enables MMCTAgent to improve its answers through structured self-evaluation‚Äîbringing reflection into AI reasoning. A key strength of MMCTAgent lies in its modular extensibility. Developers can easily integrate new, domain-specific tools‚Äîsuch as medical image analyzers, industrial inspection models, or specialized retrieval modules‚Äîby adding them to ImageQnATools or VideoQnATools. This design makes MMCTAgent adaptable across domains.



VideoAgent: From ingestion to long-form multimodal reasoning



Figure 1. MMCTAgent‚Äôs Planner‚ÄìCritic architecture enables multimodal reasoning over long-form video through structured ingestion, retrieval, and iterative feedback



The VideoAgent extends this architecture to long-form video reasoning. It operates in two connected phases: library creation (ingestion) and query-time reasoning.







Phase 1 ‚Äì Video ingestion and library creation



Before reasoning, long-form videos undergo an ingestion pipeline that aligns multimodal information for retrieval and understanding:




Transcription and translation: Converts audio to text and, if multilingual, translates transcripts into a consistent language&nbsp;



Key-frame identification: Extracts representative frames marking major visual or scene changes



Semantic chunking and chapter generation: Combines transcript segments and visual summaries into coherent, semantically segmented chapters with associated key frames. Inspired by Microsoft‚Äôs Deep Video Discovery agentic search tool, this step also extracts detailed descriptions of objects, on-screen text, and characters present within each video segment, integrating these insights directly into the corresponding chapters.&nbsp;



Multimodal embedding creation: Generates image embeddings for key frames, linking them to their corresponding transcript and chapter data




All structured metadata, including transcripts, visual summaries, chapters, and embeddings, is indexed in the Multimodal Knowledgebase using Azure AI Search (opens in new tab), which forms the foundation for scalable semantic retrieval and downstream reasoning.







Phase 2 ‚Äì Video question answering and reasoning



When a user submits a query, the VideoAgent retrieves, analyzes, and reasons across the indexed video content using specialized planner and critic tools.



Planner tools




get_video_analysis: Finds the most relevant video, provides a summary, and lists detected objects&nbsp;



get_context: Retrieves contextual information and relevant chapters from the Azure AI Search index



get_relevant_frames: Selects key frames most relevant to the user query



query_frame: Performs detailed visual and textual reasoning over selected frames



get_context and get_relevant_frames work in tandem to ensure that reasoning begins from the most semantically relevant evidence




Critic tool




critic_tool: Evaluates the reasoning output for temporal alignment, factual accuracy, and coherence between visual and textual modalities




This two-phase design, which involves&nbsp;structured ingestion followed by agentic reasoning, enables MMCTAgent to deliver accurate, interpretable insights for long information-dense videos.&nbsp;



ImageAgent: Structured reasoning for static visuals



While the VideoAgent handles temporal reasoning across long-form videos, the ImageAgent applies the same Planner‚ÄìCritic paradigm to static visual analysis. It performs modular, tool-based reasoning over images, combining perception tools for recognition, detection, and optical character recognition with language-based reasoning for interpretation and explanation.



Planner tools




vit_tool: Leverages Vision Transformer (ViT) or Vision Languague Model (VLM) for high-level visual understanding and description&nbsp;



recog_tool: Performs scene, face, and object recognition



object_detection_tool: Localizes and labels entities within an image



ocr_tool: Extracts embedded text from visual elements




Critic tool




critic_tool: Validates the Planner‚Äôs conclusions for factual alignment and consistency, refining the final response&nbsp;




This lightweight ImageAgent provides fine-grained, explainable reasoning over image collections‚Äîsupporting visual question answering, content inspection, and multimodal retrieval‚Äîwhile maintaining architectural symmetry with the VideoAgent.



Evaluation Results&nbsp;



To assess the effectiveness of MMCTAgent, we evaluated both the ImageAgent and VideoAgent with multiple base LLM models and a range of benchmark datasets and real-world scenarios. Some key results are presented here.&nbsp;



Image DatasetsGPT-4VMMCT with GPT-4VGPT4oMMCT with GPT-4oGPT-5MMCT with GPT-5MM-Vet [1]60.2074.2477.9879.3680.5181.65MMMU [2]56.8063.5769.1073.0084.2085.44



Video DatasetsGPT4oMMCT with GPT-4oVideoMME [3]72.1076.70



MMCTAgent enhances base model performance by augmenting their capabilities with appropriate tools such as object detection and optical character recognition (OCR) for weaker models, or domain-specific tools for stronger models, thereby leading to substantial improvements. For example, integrating these tools raised GPT-4V‚Äôs accuracy from 60.20% to 74.24% on MM-Vet dataset. Additionally, the configurable Critic agent provides additional validation, which is especially valuable in critical domains. The additional evaluation results are available here (opens in new tab).



Takeaways and next steps



MMCTAgent demonstrates a scalable agentic approach to multimodal reasoning with a Planner‚ÄìCritic architecture. Its unified multimodal design supports both image and video pipelines, while the extensible toolchain enables rapid integration of domain-specific tools and capabilities. It provides Azure-native deployment and supports configurability within the broader open-source ecosystem.



Looking ahead, we aim to improve efficiency and adaptability in retrieval and reasoning workflows, and to extend MMCTAgent‚Äôs applications beyond current agricultural evaluations, exploring new real-world domains through initiatives like Project Gecko to advance the creation of accessible, innovative multimodal applications for people around the globe.&nbsp;



Acknowledgements



We would like to thank our team members for their valuable contributions to this work: Aman Patkar, Ogbemi Ekwejunor-Etchie, Somnath Kumar, Soumya De, and Yash Gadhia.‚ÄØ



References&nbsp;



[1] W.‚ÄØYu, Z.‚ÄØYang, L.‚ÄØLi, J.‚ÄØWang, K.‚ÄØLin, Z.‚ÄØLiu, X.‚ÄØWang, and L.‚ÄØWang. ‚ÄúMM-VET: Evaluating large multimodal models for integrated capabilities‚Äù, 2023.&nbsp;



[2] X.‚ÄØYue, Y.‚ÄØNi, K.‚ÄØZhang, T.‚ÄØZheng, R.‚ÄØLiu, G.‚ÄØZhang, S.‚ÄØStevens, D.‚ÄØJiang, W.‚ÄØRen, Y.‚ÄØSun, C.‚ÄØWei, B.‚ÄØYu, R.‚ÄØYuan, R.‚ÄØSun, M.‚ÄØYin, B.‚ÄØZheng, Z.‚ÄØYang, Y.‚ÄØLiu, W.‚ÄØHuang, H.‚ÄØSun, Y.‚ÄØSu, and W.‚ÄØChen. ‚ÄúMMMU: A massive multi-discipline multimodal understanding and reasoning benchmark for expert AGI‚Äù, 2023.&nbsp;



[3] Chaoyou Fu, Yuhan Dai, Yondong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou, Yunhang Shen, Mengdan Zhang, et‚ÄØal. ‚ÄúVideo-MME: The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis‚Äù, 2024.&nbsp;
Opens in a new tabThe post MMCTAgent: Enabling multimodal reasoning over large video and image collections appeared first on Microsoft Research.
‚Ä¢ BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI
  Introduction



Large&nbsp;language&nbsp;models&nbsp;(LLMs)&nbsp;are now widely used for automated code generation across software engineering tasks. However, this powerful capability in code generation also introduces security concerns. Code generation systems could be misused for harmful purposes, such as generating malicious code.&nbsp;It&nbsp;could also&nbsp;produce&nbsp;bias-filled&nbsp;code reflecting&nbsp;underlying logic that is&nbsp;discriminatory&nbsp;or unethical. Additionally, even when completing benign tasks, LLMs may inadvertently produce vulnerable code that&nbsp;contains&nbsp;security flaws (e.g., injection risks, unsafe input handling). These unsafe outcomes undermine the trustworthiness of code generation models and pose threats to the broader software ecosystem, where safety and reliability are critical.



Many&nbsp;studies have explored red teaming code LLMs, testing whether the models can reject unsafe requests and whether their generated code&nbsp;exhibits&nbsp;insecure patterns. For more details, see our earlier MSR blog post on&nbsp;RedCodeAgent. While red teaming has significantly improved our understanding of model failure modes, progress on blue teaming‚Äîi.e., developing effective defensive mechanisms to detect and prevent such failures‚Äîremains&nbsp;relatively limited. Current blue teaming approaches face several challenges: (1)&nbsp;Poor alignment with security concepts:&nbsp;additional&nbsp;safety&nbsp;prompts&nbsp;struggle to help models&nbsp;understand high-level notions,&nbsp;such as what constitutes a malicious or bias instruction, and typically lack actionable principles to guide safe decision-making. A case study is shown in Figure 1.&nbsp;(2)&nbsp;Over-conservatism:&nbsp;especially in the domain of vulnerable code detection, models tend to misclassify safe code as unsafe, leading to more false positives and reduced developer trust.&nbsp;(3)&nbsp;Incomplete risk coverage: without a strong knowledge foundation, models perform poorly when dealing with subtle or previously unseen risks.&nbsp;&nbsp;&nbsp;



To address these challenges, researchers from the University of Chicago, University of California, Santa Barbara, University of Illinois Urbana‚ÄìChampaign, VirtueAI, and Microsoft Research recently released a paper: BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI. This work makes the following key contributions:&nbsp;




Diverse red-teaming pipeline: The authors design a comprehensive red-teaming process that integrates multiple strategies to synthesize diverse red-teaming data for effective knowledge accumulation.



Knowledge-enhanced blue teaming: Building on the foundation of red-teaming knowledge, BlueCodeAgent significantly improves blue-teaming performance by leveraging constitutions derived from knowledge and dynamic testing.&nbsp;



Principled-Level Defense and Nuanced-Level analysis: The authors propose two complementary strategies‚ÄîPrincipled-Level Defense (via constitutions) and Nuanced-Level Analysis (via dynamic testing)‚Äîand demonstrate their synergistic effects in vulnerable code detection tasks.&nbsp;



Generalization to seen and unseen risks: Empowered by comprehensive red-teaming knowledge, BlueCodeAgent generalizes effectively to unseen risks. Overall, BlueCodeAgent achieves an average 12.7% improvement in F1 score across four datasets and three tasks, attributed to its ability to distill actionable constitutions that enhance context-aware risk detection.&nbsp;




Figure 1. A case study of BlueCodeAgent on the bias instruction detection task. Even when concepts such as ‚Äúbiased‚Äù are explicitly included in additional safety prompts, models often fail to recognize biased requests (left). BlueCodeAgent (right) addresses this gap by summarizing constitutions from knowledge and applying concrete, actionable constraints benefited from red teaming to improve the defense. 



A blue teaming agent enabled by red teaming



Figure 2: Overview of BlueCodeAgent, an end-to-end blue teaming framework powered by automated red teaming for code security. By integrating knowledge derived from diverse red teaming and conducting dynamic sandbox-based testing, BlueCodeAgent substantially strengthens the defensive capabilities beyond static LLM analysis. 



Figure 2 presents an overview of the pipeline. The framework unifies both sides of the process: red teaming generates diverse risky cases and behaviors, which are then distilled into actionable constitutions that encode safety rules on the blue-teaming side. These constitutions guide BlueCodeAgent to more effectively detect unsafe textual inputs and code outputs, mitigating limitations such as poor alignment with abstract security concepts.&nbsp;



This work targets three major risk categories, covering both input/textual-level risks‚Äîincluding biased and malicious instructions‚Äîand output/code-level risks, where models may generate vulnerable code. These categories represent risks that have been widely studied in prior research.&nbsp;



Diverse red-teaming process for knowledge accumulation&nbsp;



Since different tasks require distinct attack strategies, the&nbsp;red-teaming&nbsp;employs multiple attack methods to generate realistic and diverse data. Specifically, the red-teaming process is divided into three categories:




Policy-based instance generation: To synthesize policy-grounded red-teaming data, diverse security and ethical policies are first collected. These high-level principles are then used to prompt an uncensored model to generate instances that intentionally violate the specified policies.



Seed-based adversarial prompt optimization: Existing adversarial instructions are often overly simplistic and easily rejected by models. To overcome this limitation, an adaptive red-teaming agent invokes various jailbreak tools to iteratively refine initial seed prompts until the prompts achieve high attack success rates.



Knowledge-driven vulnerability generation: To synthesize both vulnerable and safe code samples under realistic programming scenarios, domain knowledge of common software weaknesses (CWE) is leveraged to generate diverse code examples.




Knowledge-enhanced blue teaming agent&nbsp;



After accumulating red-teaming knowledge data, BlueCodeAgent set up Principled-Level Defense via Constitution Construction and Nuanced-Level Analysis via Dynamic Testing.




Principled-Level Defense via Constitution Construction&nbsp;Based on the most relevant knowledge data, BlueCodeAgent summarizes red-teamed knowledge into actionable constitutions‚Äîexplicit rules and principles distilled from prior attack data. These constitutions serve as normative guidelines, enabling the model to stay aligned with ethical and security principles even when confronted with novel or unseen adversarial inputs.&nbsp;



Nuanced-Level Analysis via Dynamic Testing&nbsp;In vulnerable code detection, BlueCodeAgent augments static reasoning with dynamic sandbox-based analysis, executing generated code within isolated Docker environments to verify whether the model-reported vulnerabilities manifest as actual unsafe behaviors. This dynamic validation effectively mitigates the model‚Äôs tendency toward over-conservatism, where benign code is mistakenly flagged as vulnerable.&nbsp;




	
		

		
		PODCAST SERIES
	
	
	
						
				
					
				
			
			
			

									The AI Revolution in Medicine, Revisited
				
								Join Microsoft‚Äôs Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.
				
								
					
						
							Listen now						
					
				
							
	
Opens in a new tab	
	


Insights from BlueCodeAgent&nbsp;



BlueCodeAgent outperforms prompting baselines&nbsp;



As shown in Figure 3, BlueCodeAgent significantly outperforms other baselines. Several findings are highlighted.&nbsp;



(1) Even when test categories differ from knowledge categories to simulate unseen scenarios, BlueCodeAgent effectively leverages previously seen risks to handle unseen ones, benefiting from its knowledge-enhanced safety reasoning.&nbsp;



(2) BlueCodeAgent is model-agnostic, working consistently across diverse base LLMs, including both open-source and commercial models. Its F1 scores for bias and malicious instruction detection approach 1.0, highlighting strong effectiveness.&nbsp;



(3) BlueCodeAgent achieves a strong balance between safety and usability. It accurately identifies unsafe inputs while maintaining a reasonable false-positive rate on benign ones, resulting in a consistently high F1 score.&nbsp;



(4) By contrast, prompting with general or fine-grained safety reminders remains insufficient for effective blue teaming, as models struggle to internalize abstract safety concepts and apply them to unseen risky scenarios. BlueCodeAgent bridges this gap by distilling actionable constitutions from knowledge, using concrete and interpretable safety constraints to enhance model alignment.&nbsp;



Figure 3:¬†F1 scores on bias instruction detection task (BlueCodeEval-Bias) in the first row and on malicious instruction detection task (BlueCodeEval-Mal) in the second row.¬†



Complementary effects of constitutions and dynamic testing&nbsp;



In vulnerability detection tasks, models tend to behave conservatively‚Äîan effect also noted in prior research. They are often more likely to flag code as unsafe rather than safe. This bias is understandable: confirming that code is completely free from vulnerabilities is generally harder than spotting a potential issue.&nbsp;



To mitigate this over-conservatism, BlueCodeAgent integrates dynamic testing into its analysis pipeline. When BlueCodeAgent identifies a potential vulnerability, it triggers a reliable model (Claude-3.7-Sonnet-20250219) to generate test cases and corresponding executable code that embeds the suspicious snippet. These test cases are then run in a controlled environment to verify whether the vulnerability actually manifests. The final judgment combines the LLM‚Äôs analysis of the static code, the generated test code, run-time execution results, and constitutions derived from knowledge.&nbsp;



Researchers find the two components‚Äîconstitutions and dynamic testing‚Äîplay complementary roles. Constitutions expand the model‚Äôs understanding of risk, increasing true positives (TP) and reducing false negatives (FN). Dynamic testing, on the other hand, focuses on reducing false positives (FP) by validating whether predicted vulnerabilities can truly be triggered at run-time. Together, they make BlueCodeAgent both more accurate and more reliable in blue-teaming scenarios.&nbsp;



Summary&nbsp;



BlueCodeAgent introduces an end-to-end blue-teaming framework designed to address risks in code generation. The key insight behind BlueCodeAgent is that comprehensive red-teaming can greatly strengthen blue-teaming defenses. Based on this idea, the framework first builds a red-teaming process with diverse strategies for generating red-teaming data. It then constructs a blue-teaming agent that retrieves relevant examples from the red-teaming knowledge base and summarizes safety constitutions to guide LLMs in making accurate defensive decisions. A dynamic testing component is further added to reduce false positives in vulnerability detection.&nbsp;



Looking ahead, several directions hold promise.&nbsp;&nbsp;



First, it is valuable to explore the generalization of BlueCodeAgent to other categories of code-generation risks beyond bias, malicious code, and vulnerable code. This may require designing and integrating novel red-teaming strategies into BlueCodeAgent and creating corresponding benchmarks for new risks.&nbsp;&nbsp;



Second, scaling BlueCodeAgent to the file and repository levels could further enhance its real-world utility, which requires equipping agents with more advanced context retrieval tools and memory components.&nbsp;&nbsp;



Finally, beyond code generation, it is also important to extend BlueCodeAgent to mitigate risks in other modalities, including text, image, video, and audio, as well as in multimodal applications.&nbsp;
Opens in a new tabThe post BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI appeared first on Microsoft Research.
‚Ä¢ Introducing agent-to-agent protocol support in Amazon Bedrock AgentCore Runtime
  We recently announced the support for Agent-to-Agent (A2A) protocol on Amazon Bedrock AgentCore Runtime. With this addition, agents can discover peers, share capabilities, and coordinate actions across platforms using standardized communication. 
Amazon Bedrock AgentCore Runtime provides a secure, serverless environment designed for deploying AI agents and tools. It works with any framework and model, supports real-time and long-running workloads, and supports session isolation with built-in authentication. With support for MCP, and now the&nbsp;A2A protocol, Bedrock AgentCore Runtime enables seamless communication between agents. Agents built using different frameworks, Strands Agents, OpenAI Agents SDK, LangGraph, Google ADK, or Claude Agents SDK, can share context, capabilities, and reasoning in a common, verifiable format. 
In this post, we demonstrate how you can use the A2A protocol for AI agents built with different frameworks to collaborate seamlessly. You‚Äôll learn how to deploy A2A servers on AgentCore Runtime, configure agent discovery and authentication, and build a real-world multi-agent system for incident response. We‚Äôll cover the complete A2A request lifecycle, from agent card discovery to task delegation, showing how standardized protocols eliminate the complexity of multi-agent coordination. 
Understanding multi-agent systems 
Building effective agentic systems requires several foundational components. These include memory, both short-term for maintaining conversation context and long-term for retaining insights across sessions; tools that agents can access either natively or through MCP servers; identity for more secure authentication and permission management, allowing agents to act on behalf of users or autonomously access resources; and guardrails to detect harmful content, help prevent hallucinations, and make sure responses align with policies and factual accuracy. 
 
While MCP connects a single agent to its tools and data, A2A lets multiple agents coordinate with one another. For example, a retail inventory agent might use MCP to query product databases, then use A2A to communicate with external supplier agents to place orders. 
The A2A protocol brings benefits to multi-agent systems through seamless interoperability across diverse boundaries. Agents built with different frameworks like Strands or OpenAI, powered by various LLMs such as Anthropic Claude, GPT-4, or Llama, and hosted on different systems including AWS or edge devices can communicate and coordinate effortlessly without requiring complex translation layers. This interoperability is complemented by loose coupling and modularity, where each agent operates as an independent unit that can be developed, tested, deployed, and even upgraded without disrupting the entire system. New specialized agents can join the environment seamlessly, and the failure of one agent remains isolated due to well-defined interaction boundaries, helping prevent cascading failures across the system. The protocol also supports dynamic agent discovery and orchestration. Agents advertise their capabilities through standardized schemas while orchestrator agents can discover and invoke specialized agents based on real-time task requirements. 
A2A request lifecycle on Amazon Bedrock AgentCore Runtime 
The A2A protocol defines a structured request lifecycle with specific components that work together to coordinate multi-agent communication.&nbsp;Here are the key elements: 
 
 User: Initiates requests through the Client Agent, either as a human operator or automated service defining goals that require multi-agent assistance. 
 A2A Client (Client Agent): Acts on behalf of the user, initiating communication using the A2A protocol to discover and request tasks from remote agents. 
 A2A Server (Remote Agent): Exposes HTTP endpoints implementing the A2A protocol to receive requests, process tasks, and return results. Different agents can serve this role, handling both synchronous and asynchronous interactions using JSON-RPC 2.0 over HTTP/S or Server-Sent Events. 
 Agent Card: A JSON metadata file that each agent publishes to advertise its identity, capabilities, endpoints, and authentication requirements. This enables the dynamic discovery feature, where agents query what their peer agents can do before delegating tasks. 
 Task Object: Represents each unit of work flowing through the system with a unique ID and lifecycle. As agents coordinate, tasks may be long-running, involve multiple turns, and span several agents working together. 
 Artifact: The output produced when a task completes, which can include structured text, JSON, images, audio, or other multimodal content. Agents exchange these artifacts as they collaborate to fulfill the user‚Äôs original request. 
 
Multi-agent use case: Monitoring and incident response 
To demonstrate the power of multi-agent systems using A2A on Amazon Bedrock AgentCore Runtime, we‚Äôll walk through an enterprise monitoring and incident response solution. This real-world use-case showcases how specialized agents built with different frameworks coordinate seamlessly to handle complex operational challenges through the A2A protocol. 
The monitoring and incident response solution implements a hub-and-spoke architecture with three specialized agents, each using Amazon Bedrock AgentCore features ‚Äì modular building blocks that provide core capabilities like AgentCore Memory for context-aware responses, AgentCore Identity using Amazon Cognito for more secure authentication for agents and what action each agent can perform, AgentCore Gateway for more secure and centralized access to tools, and observability to trace, debug, and monitor AI agents‚Äô performance. View the architecture and demonstration video below for reference: 
 
The multi-agent system contains the following components: 
 
 Host agent&nbsp;(Google ADK):&nbsp;Acts as the intelligent routing layer and coordination hub for the agent interactions. Demonstrates the cross-system interoperability using A2A. This agent runs on Amazon Bedrock AgentCore Runtime using Google‚Äôs Agent Development Kit, yet communicates seamlessly with agents hosted on AWS through the standardized A2A protocol. Key responsibilities of the host agent include: 
   
   Dynamic agent discovery: Fetches Identity Provider (IDP) configuration from AWS Systems Manager Parameter Store for each remote agent, enabling more secure authentication across the multi-agent system 
   Capability awareness: Retrieves agent cards from each A2A server to understand available skills and endpoints 
   Intelligent routing: Analyzes user queries and routes them to the appropriate specialist agent based on capabilities 
   Multi-agent coordination: Orchestrates complex workflows requiring multiple agents 
    
 Monitoring agent (Strands Agents SDK): Serves as the operational intelligence layer, continuously analyzing CloudWatch logs, metrics, dashboards, and alarms across AWS services. This agent specializes in identifying anomalies, tracking error patterns, and surfacing actionable insights from vast amounts of telemetry data. When unusual patterns emerge, the monitoring Agent initiates conversations with other specialized agents to coordinate response actions.Key responsibilities of the monitoring agent include: 
   
   CloudWatch integration: 
     
     Lists and analyzes CloudWatch dashboards 
     Fetches logs for specific AWS services (Lambda, ECS, EC2) 
     Monitors alarms and alert states 
     Analyzes log groups for patterns and errors 
      
   Cross-account access: Supports monitoring across multiple AWS accounts 
    
 Operational agent (OpenAI SDK): Provides remediation strategies and external knowledge integration. When the monitoring agent detects a critical issue, it communicates directly with the operational agent through A2A, providing context about the problem and requesting specific remediation actions. Key responsibilities&nbsp;of the operational agent include: 
   
   Web search: Uses Tavily API to search for AWS best practices, troubleshooting guides, and solutions 
   Remediation strategies: Proposes solutions based on detected issues 
    
 
 
Implementing the multi-agent monitoring solution 
Now that we‚Äôve explored how these three specialized agents collaborate to handle AWS incidents, let‚Äôs walk through how to build and deploy this multi-agent system using Amazon Bedrock AgentCore Runtime. 
The implementation follows a progressive approach: 
 
 Start with the foundation ‚Äì We‚Äôll deploy a simple A2A server to understand the core mechanics of agent deployment, authentication, and invocation on AgentCore Runtime 
 Build the monitoring system ‚Äì Using the same deployment patterns, we‚Äôll construct each specialized agent (Monitoring, Operational, and Host) with their specific tools and capabilities 
 Connect the agents ‚Äì Configure A2A communication channels between agents, enabling them to discover and invoke each other through standardized protocols 
 Observe the system in action ‚Äì Watch the demo video showing real-time incident detection, cross-agent coordination, and automated response 
 
All code examples, complete agent implementations, and deployment scripts for this multi-agent monitoring system are available in our GitHub repository. 
Getting started with A2A on AgentCore Runtime 
To understand the fundamentals of deploying A2A servers on Amazon Bedrock AgentCore Runtime, including step-by-step instructions for creating, testing, deploying, and invoking agents, refer to the A2A Protocol Support documentation. This guide covers: 
 
 Creating and configuring A2A servers with any framework (Strands, OpenAI SDK, LangGraph) 
 Local testing and validation 
 Deployment using the AgentCore CLI 
 Authentication setup (OAuth 2.0 and AWS IAM) 
 Agent Card retrieval and discovery 
 Client implementation for invoking deployed agents 
 
Once you‚Äôre familiar with these fundamentals, you can apply the same patterns to build each component of the multi-agent monitoring system. 
View the full example in this GitHub sample. For this post, we will focus on this use case implementation. 
Prerequisites 
To deploy the multi-agent monitoring system implementation, follow the prerequisite steps: 
 
 AWS account: You need an active AWS account with appropriate permissions 
   
   Create an AWS account 
   AWS Management Console access 
    
 AWS CLI: Install and configure AWS CLI with your credentials 
   
   Install AWS CLI 
   Configure AWS CLI 
    
 Install uv. 
 Supported Regions: This solution is currently tested and supported in the following AWS Regions. 
 
Note: To deploy in other Regions, you‚Äôll need to update the DynamoDB prefix list mappings in cloudformation/vpc-stack.yaml. See the VPC Stack documentation for details. 
Deployment steps 
This guide walks you through deploying a multi-agent system on AWS using infrastructure-as-code.&nbsp;The easiest way to deploy this solution is using our automated deployment script: 
Step 1: Clone the repository 
 
 git clone https://github.com/awslabs/amazon-bedrock-agentcore-samples.git
cd 02-use-cases/A2A-multi-agent-incident-response 
 
Step 2: Run the deployment script 
This deployment script will verify that the AWS CLI is installed and configured, check if the AWS credentials are valid, confirm that the Region is set to us-west-2, interactively collect the required parameters, generate unique S3 bucket names and automatically deploy all stacks in the correct order. The approximate deployment time is 10-15 minutes. 
 
 uv run deploy.py 
 
Step 3: Provide the runtime CLI parameters 
Next, provide the parameters used at deployment.&nbsp;Press enter for each of the options to use the default Amazon Bedrock model ID and the CloudFormation stack names for each of the agents. 
API keys: You‚Äôll need the following API keys (the deployment script will prompt for these): 
 
 OpenAI API key: Get it from OpenAI Platform 
 Tavily API key: Get it from Tavily 
 Google API key: Get it from Google AI Studio 
 
Once you have configured the information, start the deployment process and track it below in the AWS Console and terminal respectively. 
Step 4: Provide the runtime CLI parameters 
Run the frontend using following commands.&nbsp;This sets up and runs the React frontend UI that allows users to interact with the multi-agent incident response system for monitoring AWS infrastructure, querying CloudWatch metrics and logs, and searching for remediation strategies through&nbsp;the coordinated A2A agents. 
 
 cd frontend
npm install

chmod +x ./setup-env.sh
./setup-env.sh

npm run dev 
 
This deployment creates a multi-agent A2A system with three specialized AI agents running on Amazon Bedrock AgentCore Runtime and orchestrated using the A2A protocol. The Cognito stack provisions OAuth 2.0-based machine-to-machine authentication by creating a Cognito user pool with four distinct client applications (WebSearch, Monitoring, Gateway, and Host Agent clients). 
The monitoring agent (built with the Strands SDK) connects to CloudWatch metrics and logs through an AgentCore Gateway using a Smithy model definition, with custom semantic memory strategies for incident tracking. 
The operations agent (built with OpenAI Agents SDK) interfaces with Tavily API for remediation research and the host agent (built with Google ADK) acts as the coordinator using HTTP protocol to delegate tasks to the two specialized A2A agents. 
End-to-end incident response workflow 
In this section, we will walk through an end-to-end workflow where the host agent manages conversations, gets the requirements from the user, and selects the best agent to route the request to (monitoring or operations agent). The monitoring and operations agent expose their agent cards that is used by the host agent for orchestration. In this example, we will test with simple error analysis from various log groups and search for remediation strategies. 
 
The workflow includes the following steps: 
 
 Initial greeting: The user sends a greeting message asking ‚ÄúHi! How are you?‚Äù to the host agent. The host agent processes the request. The host agent responds back to the user with a friendly greeting saying ‚ÄúI‚Äôm doing well, thank you!‚Äù 
 Capabilities query: The user asks the host agent ‚ÄúWhat are your capabilities?‚Äù to understand what the agent can do. The host agent explains to the user that it is an orchestration agent designed for AWS monitoring and operations based on the remote agent connections that it has access to. 
 List log groups and dashboards: The user requests the host agent to list the log groups and dashboards in their AWS account. The host agent recognizes this is a monitoring task and executes the transfer_to_agent tool to delegate the work. The request is transferred from the host agent to the monitoring agent for specialized handling. The&nbsp;monitoring agent uses the Agent-to-Agent (A2A) Json RPC Transport protocol to communicate. The&nbsp;monitoring agent retrieves the information and returns results showing 0 dashboards and 153 log groups found in the account. The host agent receives the results from the&nbsp;monitoring agent and displays the dashboards and log groups information to the user. 
 Analyze specific log group: The user requests the host agent to look for errors in a specific log group at path /aws/bedrock-agentcore/runtimes/hostadk-&lt;runtimeId&gt;-DEFAULT. The host agent determines this requires monitoring expertise and executes the transfer_to_agent tool. The request is transferred to the&nbsp;monitoring agent with instructions to analyze the specified log group for errors. The&nbsp;monitoring agent analyzes the log group and discovers 9 errors and 18 warnings, specifically identifying OTLP Export Failures. The host agent receives the analysis results and displays a detailed error analysis report to the user. 
 Debug and fix recommendations: The user asks the host agent to debug the errors and provide a report on the fixes needed. The request is transferred to the operations agent to search for solutions related to OTLP export failures. The operations agent uses A2A JsonRPC Transport to attempt the search and performs web search to provide a solution. 
 
Security with A2A on Amazon Bedrock AgentCore Runtime 
Amazon Bedrock AgentCore Runtime supports two authentication methods for securing A2A communication: 
OAuth 2.0 authentication: The A2A client authenticates with an external authorization server to obtain a JSON Web Token (JWT), which is then included with all requests to the A2A server. This token-based approach enables secure, standardized authentication using either machine-to-machine (M2M) credentials or user federation, allowing the A2A server to verify the client‚Äôs identity and enforce access controls based on the token‚Äôs claims. 
AWS IAM authentication: The A2A client assumes an IAM role with permissions to invoke the A2A server‚Äôs agent. This approach leverages AWS SigV4 request signing and IAM policies to control access, alleviating the need for external token management while providing fine-grained permissions. 
What is supported in Amazon Bedrock AgentCore Runtime with A2A 
Amazon Bedrock AgentCore Runtime provides comprehensive support for A2A communication. View some of the capabilities supported: 
 
 Stateless server: Amazon Bedrock AgentCore Runtime can host A2A servers that expose an HTTP interface, running a stateless HTTP server on port 9000 and supporting JSON-RPC messaging. The runtime acts as a transparent proxy, passing JSON-RPC requests and responses unchanged to preserve protocol fidelity. 
 Authenticated agent cards: Supports authenticated agent card at&nbsp;/.well-known/agent-card.json containing its capabilities &amp; skills allowing other agents to discover it automatically. 
 Authentication&nbsp;with secure inbound auth: Amazon Bedrock AgentCore Runtime supports secure authentication via AWS SigV4 and OAuth 2.0, making sure the agent-to-agent communication is authorized and secure. The A2A server authenticates every incoming request using the credentials provided in the HTTP headers, leveraging Amazon Bedrock AgentCore Identity. 
 Authorization with secure outbound auth:&nbsp;Amazon Bedrock AgentCore Runtime enables secure outbound authorization through both IAM execution roles and AgentCore Identity. Each agent assumes a defined IAM execution role, granting it the necessary permissions to access AWS resources more securely. For interactions with external services, agents can use Amazon Bedrock AgentCore Identity, which provides managed OAuth 2.0 support for third-party identity providers such as Google, GitHub, Slack, and more. 
 VPC connectivity:&nbsp;You can configure Amazon Bedrock AgentCore Runtime to connect to resources in your Amazon Virtual Private Cloud (VPC). By configuring VPC connectivity, you enable secure access to private resources such as databases, internal APIs, and services within your VPC. 
 Leverage AWS PrivateLink:&nbsp;Amazon Bedrock AgentCore enables secure, private connections between your Virtual Private Cloud (VPC) and AgentCore services using AWS PrivateLink. By creating interface VPC endpoints, you can keep A2A server communication within your VPC without traversing the public internet. 
 Lifecycle management:&nbsp;Amazon Bedrock AgentCore Runtime lets you configure lifecycle rules to manage resource usage with idleRuntimeSessionTimeout and maxLifetime. Idle or long-running sessions are automatically terminated for efficient resource utilization and to maintain system performance. 
 
Conclusion 
The Agent-to-Agent protocol support in Amazon Bedrock AgentCore Runtime provides the support for building scalable, interoperable multi-agent systems. By providing standardized communication between AI agents, regardless of their underlying framework, model, or hosting infrastructure, organizations can compose sophisticated agentic solutions with the A2A protocol. The AWS monitoring and incident response example demonstrates the practical power of this approach: a Google ADK-based orchestrator coordinating with Strands and OpenAI SDK agents, all deployed on AgentCore Runtime, working together to detect issues, search for solutions, and recommend fixes. This level of interoperability would traditionally require extensive custom integration work, but A2A makes it straightforward through standardized protocols.As AI systems continue to evolve from single-purpose tools to collaborative environments, protocols like A2A and MCP become essential building blocks. They create a future where agents can be discovered, composed, and orchestrated dynamically, enabling organizations to build once and integrate anywhere. 
 
About the authors 
Madhur Prashant is an Applied Generative AI Architect at Amazon Web Services. He is passionate about the intersection of human thinking and Agentic AI. His interests lie in generative AI, cognitive science and specifically building solutions that are helpful and harmless, and most of all optimal for customers. Outside of work, he loves doing yoga, hiking, spending time with his twin and playing the guitar. 
Eashan Kaushik is a Specialist Solutions Architect AI/ML at Amazon Web Services. He is driven by creating cutting-edge generative AI solutions while prioritizing a customer-centric approach to his work. Before this role, he obtained an MS in Computer Science from NYU Tandon School of Engineering. Outside of work, he enjoys sports, lifting, and running marathons. 
Sriharsha M S is a Principal Gen AI specialist solution architect in the Strategic Specialist team at Amazon Web Services. He works with strategic AWS customers who are taking advantage of AI/ML to solve complex business problems. He provides technical guidance and design advice to foundational model science and agentic AI applications at scale. His expertise spans application hardware accelerators, architecture, big data, analytics and machine learning. 
Jeffrey Burke is an Applied Generative AI Solutions Architect at Amazon Web Services (AWS), where he specializes in designing and implementing cutting-edge generative AI solutions for enterprise customers. With a passion for teaching complex technologies, he focuses on translating sophisticated AI concepts into practical, scalable solutions that drive business value. He has a MS in Data Science and BS in Chemical Engineering. 
Shreyas Subramanian is a Principal Data Scientist and helps customers by using Generative AI to solve their business challenges using the AWS platform. Shreyas has a background in large scale optimization and Deep Learning, and he is a researcher studying the use of Machine Learning and Reinforcement Learning for accelerating learning and optimization tasks. Shreyas is also an Amazon best-selling book author with several research papers and patents to his name. 
Andy Palmer is a Director of Technology for AWS Strategic Accounts. His teams provide Specialist Solutions Architecture skills across a number of speciality domain areas, including AIML, generative AI, data and analytics, security, network, and open source software. Andy and his team have been at the forefront of guiding our most advanced customers through their generative AI journeys and helping to find ways to apply these new tools to both existing problem spaces and net new innovations and product experiences. 
Sayee Kulkarni is a Software Development Engineer on the AWS Bedrock AgentCore service. Her team is responsible for building and maintaining the AgentCore Runtime platform, a foundational component that enables customers to leverage agentic AI capabilities. She is driven by delivering tangible customer value, and this customer-centric focus motivates her work. Sayee played a key role in designing and launching Agent-to-Agent (A2A) capabilities for AgentCore, empowering customers to build sophisticated multi-agent systems that autonomously collaborate to solve complex business challenges.
‚Ä¢ Powering enterprise search with the Cohere Embed 4 multimodal embeddings model in Amazon Bedrock
  The Cohere Embed 4 multimodal embeddings model is now available as a fully managed, serverless option in&nbsp;Amazon Bedrock. Users can choose between cross-Region inference (CRIS) or Global cross-Region inference to manage unplanned traffic bursts by utilizing compute resources across different AWS Regions. Real-time information requests and time zone concentrations are example events that can cause inference demand to exceed anticipated traffic. 
The new Embed 4 model on Amazon Bedrock is purpose-built for analyzing business documents. The model delivers leading multilingual capabilities and shows notable improvements over Embed 3 across the key benchmarks, making it ideal for use cases such as enterprise search. 
In this post, we dive into the benefits and unique capabilities of Embed 4 for enterprise search use cases. We‚Äôll show you how to quickly get started using Embed 4 on Amazon Bedrock, taking advantage of integrations with Strands Agents, S3 Vectors,&nbsp;and Amazon Bedrock AgentCore to build powerful agentic retrieval-augmented generation (RAG) workflows. 
Embed 4 advances multimodal embedding capabilities by natively supporting complex business documents that combine text, images, and interleaved text and images into a unified vector representation. Embed 4 handles up to 128,000 tokens, minimizing the need for tedious document splitting and preprocessing pipelines. Embed 4 also offers configurable compressed embeddings that reduce vector storage costs by up to 83% (Introducing Embed 4: Multimodal search for business). Together with multilingual understanding across over 100 languages, enterprises in regulated industries such as finance, healthcare, and manufacturing can efficiently process unstructured documents, accelerating insight extraction for optimized RAG systems. Read about Embed 4 in this launch blog from July 2025 to explore how to deploy on&nbsp;Amazon SageMaker JumpStart. 
Embed 4 can be integrated into your applications using the&nbsp;InvokeModel API, and here‚Äôs an example of how to use the&nbsp;AWS SDK for Python (Boto3)&nbsp;with Embed 4: 
For the text only input: 
 
 import boto3
import json

# Initialize Bedrock Runtime client
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')

# Request body
body = json.dumps({
"texts": [
text1,
          text2],
     "input_type":"search_document",
     "embedding_types": ["float"]
})

# Invoke the model
model_id = 'cohere.embed-v4:0'

response = bedrock_runtime.invoke_model(
    modelId=model_id,
    body=json.dumps(body),
    accept= '*/*',
    contentType='application/json'
)

# Parse response
result = json.loads(response['body'].read()) 
 
For the mixed modalities input: 
 
 import base64

# Initialize Bedrock Runtime client
bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')

# Request body
body = json.dumps({
"inputs": [
{
"content": [
{ "type": "text", "text": text },
{ "type": "image_url", {"image_url":image_base64_uri}}
]
}
],
     "input_type":"search_document",
     "embedding_types": ["int8","float"]
})

# Invoke the model
model_id = 'cohere.embed-v4:0'

response = bedrock_runtime.invoke_model(
    modelId=model_id,
    body=json.dumps(body),
    accept= '*/*',
    contentType='application/json'
)

# Parse response
result = json.loads(response['body'].read()) 
 
For more details, you can check Amazon Bedrock User Guide for Cohere Embed 4. 
Enterprise search use case 
In this section, we focus on using Embed 4 for an enterprise search use case in the finance industry. Embed 4 unlocks a range of capabilities for enterprises seeking to: 
 
 Streamline information discovery 
 Enhance generative AI workflows 
 Optimize storage efficiency 
 
Using foundation models in Amazon Bedrock is a fully serverless environment which removes infrastructure management and simplifies integration with other Amazon Bedrock capabilities. See more details for other possible use cases with Embed 4. 
Solution overview 
With the serverless experience available in Amazon Bedrock, you can get started quickly without spending too much effort on infrastructure management. In the following sections, we show how to get started with Cohere Embed 4. Embed 4 is already designed with storage efficiency in mind. 
We choose Amazon S3 vectors for storage because it is a cost-optimized, AI-ready storage with native support for storing and querying vectors at scale. S3 vectors can store billions of vector embeddings with sub-second query latency, reducing total costs by up to 90% compared to traditional vector databases. We leverage the extensible Strands Agent SDK to simplify agent development and take advantage of model choice flexibility. We also use Bedrock AgentCore because it provides a fully managed, serverless runtime specifically built to handle dynamic, long-running agentic workloads with industry-leading session isolation, security, and real-time monitoring. 
 
Prerequisites 
To get started with Embed 4, verify you have the following prerequisites in place: 
 
 IAM permissions: Configure your IAM role with necessary Amazon Bedrock permissions, or generate API keys through the console or SDK for testing. For more information, see Amazon Bedrock API keys. 
 Strands SDK installation: Install the required SDK for your development environment. For more information, see the Strands quickstart guide. 
 S3 Vectors configuration: Create an S3 vector bucket and vector index for storing and querying vector data. For more information, see the getting started with S3 Vectors tutorial. 
 
Initialize Strands agents 
The Strands Agents SDK offers an open source, modular framework that streamlines the development, integration, and orchestration of AI agents. With the flexible architecture developers can build reusable agent components and create custom tools with ease. The system supports multiple models, giving users freedom to select optimal solutions for their specific use cases. Models can be hosted on Amazon Bedrock, Amazon SageMaker, or elsewhere. 
For example, Cohere Command A is a generative model with 111B parameters and a 256K context length. The model excels at tool use which can extend baseline functionality while avoiding unnecessary tool calls. The model is also suitable for multilingual tasks and RAG tasks such as manipulating numerical information in financial settings. When paired with Embed 4, which is purpose-built for highly regulated sectors like financial services, this combination delivers substantial competitive benefits through its adaptability. 
We begin by defining a tool that a Strands agent can use. The tool searches for documents stored in S3 using semantic similarity. It first converts the user‚Äôs query into vectors with Cohere Embed 4. It then returns the most relevant documents by querying the embeddings stored in the S3 vector bucket. The code below shows only the inference portion. Embeddings created from the financial documents were stored in a S3 vector bucket before querying. 
 
 # S3 Vector search function for financial documents
@tool
def search(query_text: str, bucket_name: str = "my-s3-vector-bucket", 
           index_name: str = "my-s3-vector-index-1536", top_k: int = 3, 
           category_filter: str = None) -&gt; str:
    """Search financial documents using semantic vector search"""
    
    bedrock = boto3.client("bedrock-runtime", region_name="us-east-1")
    s3vectors = boto3.client("s3vectors", region_name="us-east-1")
    
    # Generate embedding using Cohere Embed v4
    response = bedrock.invoke_model(
        modelId="cohere.embed-v4:0",
        body=json.dumps({
            "texts": [query_text],
            "input_type": "search_query",
            "embedding_types": ["float"]
        }),
        accept='*/*',
        contentType='application/json'
    )
    
    response_body = json.loads(response["body"].read())
    embedding = response_body["embeddings"]["float"][0]
    
    # Query vectors
    query_params = {
        "vectorBucketName": bucket_name,
        "indexName": index_name,
        "queryVector": {"float32": embedding},
        "topK": top_k,
        "returnDistance": True,
        "returnMetadata": True
    }
    
    if category_filter:
        query_params["filter"] = {"category": category_filter}
    
    response = s3vectors.query_vectors(**query_params)
    return json.dumps(response["vectors"], indent=2) 
 
We then define a financial research agent that can use the tool to search financial documents. As your use case becomes more complex, more agents can be added for specialized tasks. 
 
 # Create financial research agent using Strands
agent = Agent(
    name="FinancialResearchAgent",
    system_prompt="You are a financial research assistant that can search through financial documents, earnings reports, regulatory filings, and market analysis. Use the search tool to find relevant financial information and provide helpful analysis.",
    tools=[search]) 
 
Simply using the tool returns the following results. Multilingual financial documents are ranked by semantic similarity to the query about comparing earnings growth rates. An agent can use this information to generate useful insights. 
 
 result = search(‚ÄúCompare earnings growth rates mentioned in the documents‚Äù) 
print(result)
 {
    "key": "doc_0_en",
    "metadata": {
      "language": "en",
      "source_text": "Q3 2024 earnings report shows revenue growth of 15% year-over-year driven by strong performance in cloud services and AI products",
      "doc_id": 0
    },
    "distance": 0.7292724251747131
  },
  {
    "key": "doc_18_zh",
    "metadata": {
      "source_text": "2024Âπ¥‰∏äÂçäÂπ¥Ë¥¢Âä°Êä•ÂëäÊòæÁ§∫ÂáÄÂà©Ê∂¶Â¢ûÈïø20%Ôºå‰∏ªË¶ÅÂèóÁõä‰∫éÈáëËûçÁßëÊäÄÂíåÊï∞Â≠óÊîØ‰ªò‰∏öÂä°ÁöÑÂø´ÈÄüÂèëÂ±ï",
      "language": "zh",
      "doc_id": 18
    },
    "distance": 0.7704182863235474
  },
  {
    "key": "doc_12_de",
    "metadata": {
      "language": "de",
      "doc_id": 12,
      "source_text": "Halbjahresbericht 2024 verzeichnet 12% Gewinnsteigerung durch erfolgreiche Digitalisierung und Automatisierungsl\u00f6sungen"
    },
    "distance": 0.7738275527954102
  }
] 
 
The example above relies on the QueryVectors API operation for S3 Vectors, which can work well for small documents. This approach can be improved to handle large and complex enterprise documents using sophisticated chunking and reranking techniques. Sentence boundaries can be used to create document chunks to preserve semantic coherence. The document chunks are then used to generate embeddings. The following API call passes the same query to the Strands agent: 
 
 response = agent("Compare earnings growth rates mentioned in the documents")  
 
The Strands agent uses the search tool we defined to generate an answer for the query about comparing earnings growth rates. The final answer considers the results returned from the search tool: 
 
 Agent Query:
I'll search for information about earnings growth rates in the financial documents to help you compare them.
Tool #1: search
Let me search for more specific earnings growth information and financial performance metrics.
Tool #2: search
Let me search for more comprehensive financial performance data and specific earnings metrics.
Tool #3: search
Based on the financial documents I've searched through, here's a comparison of the earnings growth rates mentioned:
‚Ä¶
## Key Insights:

1. **Growth Range:** The earnings growth rates span from 12% to 20%, indicating generally healthy performance 
across different markets and sectors.

2. **Technology Focus:** All companies showing strong growth are heavily invested in technology sectors 
(fintech, AI, cloud services, cybersecurity, automation).

3. **Geographic Diversity:** The strong performers represent different regions (Asia, Europe, North America), 
suggesting broad-based growth in tech-enabled services.

4. **Growth Sustainability:** The Chinese fintech company leads with 20% net profit growth, while the others 
show strong revenue growth in the 12-18% range.

The data suggests that companies with strong technology components, particularly in emerging areas like AI, 
fintech, and cybersecurity, are experiencing the most robust earnings growth rates in 2024.Based on the 
financial documents I've searched through, here's a comparison of the earnings growth rates mentioned:
## Earnings Growth Rate Comparison

The data suggests that companies with strong technology components, particularly in emerging areas like AI, 
fintech, and cybersecurity, are experiencing the most robust earnings growth rates in 2024.
 
 
A custom tool like the S3 Vector search function used in this example is just one of many possibilities. With Strands it is straightforward to develop and orchestrate autonomous agents while Bedrock AgentCore serves as the managed deployment system to host and scale these Strands agents in production. 
Deploy to Amazon Bedrock AgentCore 
Once an agent is built and tested, it is ready to be deployed. AgentCore Runtime is a secure and serverless runtime purpose-built for deploying and scaling dynamic AI agents.&nbsp;Use the starter toolkit to automatically create the IAM execution role, container image, and Amazon Elastic Container Registry repository to host an agent in AgentCore Runtime. You can define multiple tools available to your agent. In this example, we use the Strands Agent powered by Embed 4: 
 
 # Using bedrock-agentcore&lt;=0.1.5 and bedrock-agentcore-starter-toolkit==0.1.14
from bedrock_agentcore_starter_toolkit import Runtime
from boto3.session import Session
boto_session = Session()
region = boto_session.region_name

agentcore_runtime = Runtime()
agent_name = "search_agent"
response = agentcore_runtime.configure(
    entrypoint="example.py", # Replace with your custom agent and tools
    auto_create_execution_role=True,
    auto_create_ecr=True,
    requirements_file="requirements.txt",
    region=region,
    agent_name=agent_name
)
response
launch_result = agentcore_runtime.launch()
invoke_response = agentcore_runtime.invoke({‚Äúprompt‚Äù: ‚ÄúCompare earnings growth rates mentioned in the documents‚Äù})  
 
Clean up 
To avoid incurring unnecessary costs when you‚Äôre done, empty and delete the S3 Vector buckets created, applications that can make requests to the Amazon Bedrock APIs, the launched AgentCore Runtimes and associated ECR repositories. 
For more information, see this documentation to delete a vector index and this documentation to delete a vector bucket, and see this step for removing resources created by the Bedrock AgentCore starter toolkit. 
Conclusion 
Embed 4 on Amazon Bedrock is beneficial for enterprises aiming to unlock the value of their unstructured, multimodal data. With support for up to 128,000 tokens, compressed embeddings for cost efficiency, and multilingual capabilities across 100+ languages, Embed 4 provides the scalability and precision required for enterprise search at scale. 
Embed 4 has advanced capabilities that are optimized with domain specific understanding of data from regulated industries such as finance, healthcare, and manufacturing. When combined with S3 Vectors for cost-optimized storage, Strands Agents for agent orchestration, and Bedrock AgentCore for deployment, organizations can build secure, high-performing agentic workflows without the overhead of managing infrastructure. Check the full Region list for future updates. 
To learn more, check out the Cohere in Amazon Bedrock product page and the Amazon Bedrock pricing page. If you‚Äôre interested in diving deeper check out the code sample and the Cohere on AWS GitHub repository. 
 
About the authors 
 James Yi is a Senior AI/ML Partner Solutions Architect at AWS. He spearheads AWS‚Äôs strategic partnerships in Emerging Technologies, guiding engineering teams to design and develop cutting-edge joint solutions in generative AI. He enables field and technical teams to seamlessly deploy, operate, secure, and integrate partner solutions on AWS. James collaborates closely with business leaders to define and execute joint Go-To-Market strategies, driving cloud-based business growth. Outside of work, he enjoys playing soccer, traveling, and spending time with his family. 
Nirmal Kumar&nbsp;is Sr. Product Manager for the Amazon SageMaker service. Committed to broadening access to AI/ML, he steers the development of no-code and low-code ML solutions. Outside work, he enjoys travelling and reading non-fiction. 
Hugo Tse is a Solutions Architect at AWS, with a focus on Generative AI and Storage solutions. He is dedicated to empowering customers to overcome challenges and unlock new business opportunities using technology. He holds a Bachelor of Arts in Economics from the University of Chicago and a Master of Science in Information Technology from Arizona State University. 
Mehran Najafi, PhD, serves as AWS Principal Solutions Architect and leads the Generative AI Solution Architects team for AWS Canada. His expertise lies in ensuring the scalability, optimization, and production deployment of multi-tenant generative AI solutions for enterprise customers. 
Sagar Murthy&nbsp;is an agentic AI GTM leader at AWS who enjoys collaborating with frontier foundation model partners, agentic frameworks, startups, and enterprise customers to evangelize AI and data innovations, open source solutions, and enable impactful partnerships and launches, while building scalable GTM motions. Sagar brings a blend of technical solution and business acumen, holding a BE in Electronics Engineering from the University of Mumbai, MS in Computer Science from Rochester Institute of Technology, and an MBA from UCLA Anderson School of Management. 
Payal Singh&nbsp;is a Solutions Architect at Cohere with over 15 years of cross-domain expertise in DevOps, Cloud, Security, SDN, Data Center Architecture, and Virtualization. She drives partnerships at Cohere and helps customers with complex GenAI solution integrations.
‚Ä¢ A guide to building AI agents in GxP environments
  Healthcare and life sciences organizations are transforming drug discovery, medical devices, and patient care with generative AI agents. In regulated industries, any system that impacts product quality or patient safety must comply with GxP (Good Practice) regulations, such as Good Clinical Practice (GxP), Good Laboratory Practice (GLP), Good Manufacturing Practice (GMP). Organizations must demonstrate to regulatory authorities that their AI agents are safe, effective, and meet quality standards. Building AI agents for these GxP environments requires a strategic approach that balances innovation, speed, and regulatory requirements. 
AI agents can be built for GxP environments: The key lies in understanding how to build them appropriately based on their risk profiles. Gen AI introduces unique challenges around explainability, probabilistic outputs, and continuous learning that require thoughtful risk assessment rather than blanket validation approaches. The disconnect between traditional GxP compliance methods and modern AI capabilities creates barriers to implementation, increases validation costs, slows innovation speed, and limits the potential benefits for product quality and patient care. 
The regulatory landscape for GxP compliance is evolving to address the unique characteristics of AI. Traditional Computer System Validation (CSV) approaches, often with uniform validation strategies, are being supplemented by Computer Software Assurance (CSA) frameworks that emphasize flexible risk-based validation methods tailored to each system‚Äôs actual impact and complexity (FDA latest guidance). 
In this post, we cover a risk-based implementation, practical implementation considerations across different risk levels, the AWS shared responsibility model for compliance, and concrete examples of risk mitigation strategies. 
Risk based implementation framework 
Effective GxP compliance for agentic AI systems require assessing risk based on operational context rather than technology features alone. To support risk classification, the FDA‚Äôs CSA Draft Guidance recommends evaluating intended uses across three factors: severity of potential harm, probability of occurrence, and detectability of failures. 
In Figure 1, this assessment model combines traditional operational roles with modern risk-based levels. Organizations should assess how AI agents function within workflows and their potential impact on regulated processes. 

 
 Figure 1.  GxP compliance for AI agents combines traditional Role-based with CSA‚Äôs modern risk-based levels
 
The same AI agent capability can warrant dramatically different validation approaches depending on how it is being deployed. How is the agentic AI being consumed and within existing GxP processes? What is the level of human oversight or human-in-the-loop controls? Is the AI agent itself being added as an additional control? What is the potential impact of AI failures on product quality, data integrity, or patient safety? 
Consider an AI agent for scientific literature review. When creating literature summaries for internal team meetings, it presents low risk, requiring minimal controls. When scientists use these insights to guide research direction, it becomes medium risk, needing structured controls, such as human review checkpoints. When supporting regulatory submissions for drug approval, it becomes high risk and requires comprehensive controls because outputs directly impact regulatory decisions and patient safety. 
This risk-based methodology allows organizations to balance innovation with compliance by tailoring validation efforts to actual risk levels rather than applying uniform controls across all AI implementations. 
Implementation considerations 
Successful AI agent designs require common controls that apply consistently across risk levels for quality and safety. Organizations should maintain clear records of AI decisions, prove data has not been altered, reproduce results when needed, and manage system updates safely. AWS supports these requirements through qualified infrastructure and various compliance certifications such as ISO, SOC, and NIST. For a more complete list, see our Healthcare &amp; Life Sciences Compliance page. Detailed compliance validation information for Amazon Bedrock AgentCore is available in the compliance documentation. To implement these controls effectively, organizations can refer to the National Institute of Standards and Technology (NIST) AI Risk Management Framework for AI-risk guidance and ALCOA+ principles to promote data integrity. 
Shared responsibility model 
Successful generative AI cloud-implementation in GxP environments requires understanding the shared division of responsibilities between customers and AWS, as outlined in the Shared responsibility model, to allow organizations to focus on delivering effective and compliance-aligned solutions. 
As AWS helps protect the infrastructure that runs the services offered in the AWS Cloud, Table 1 provides practical examples of how AWS can support customers in validating their agentic AI systems. 
 
  
   
   Focus 
   Customer responsibilities 
   How AWS supports 
   
   
   Validation strategy 
   Design risk-appropriate validation approaches using AWS services for GxP compliance. Establish acceptance criteria and validation protocols based on intended use. 
    Inherit compliance controls with AWS services such as Amazon Bedrock‚Äôs ISO 27001, SOC 1/2/3, FedRAMP, and GDPR/HIPAA eligibility. Support your GxP training requirements through AWS Skill Builder for artificial intelligence and machine learning (AI/ML) and AWS Certified Machine Learning ‚Äì Specialty. Use infrastructure as code through AWS CloudFormation to support on demand validations and deployments that provide repeatable IQ for your agentic workloads. 
   
   
   GxP procedures 
   Develop SOPs that integrate AWS capabilities with existing quality management systems. Establish documented procedures for system operation and maintenance. 
    Build GxP agentic systems with HCLS Landing Zones, designed to align for highly regulated workloads, this capability can augment and support your standard procedure requirements. Augment risk management procedures with Amazon Bedrock AgentCore supporting end-to-end visibility and runtime requirements for complex multi-step tasks. Use AWS Certified SysOps Administrator and AWS Certified DevOps Engineering certifications for training requirements and to make sure teams can operationalize and govern procedural compliance on AWS. 
   
   
   User management 
   Configure IAM roles and permissions aligned with GxP user access requirements. Maintain user access documentation and training records. 
   Secure AI agents access with AWS IAM and Amazon Bedrock AgentCore Identity to establish fine-grained permissions and enterprise identity integration and use IAM Identity Center to streamline workforce user access. 
   
   
   Performance criteria 
   Define acceptance criteria and monitoring thresholds for gen AI applications. Establish performance monitoring protocols. 
    Use Amazon Bedrock Provision Throughput plan for agentic workflows that require consistent and guaranteed performance requirements. Monitor performance with Amazon Bedrock AgentCore Observability and with Amazon CloudWatch with customizable alerts and dashboards for end-to-end visibility. 
   
   
   Documentation 
   Create validation documentation demonstrating how AWS services support GxP compliance. Maintain quality system records. 
   Use AWS Config to help generate compliance reports of your agentic deployments with conformance packs for HIPAA, 21 CFR Part 11, and GxP EU Annex 11.Store your GxP data with Amazon Simple Storage Service (Amazon S3), which offers enterprise-grade 11 nines of durability with support for versioning and user defined retention policies. 
   
   
   Provenance 
   Monitor model versions while maintaining validated snapshots. Version-control prompt templates to facilitate consistent AI interactions, track changes, and maintain records for audit trails version-control prompt templates. Lock tool dependencies in validated environment. 
    Control models and data with Amazon Bedrock configurable data residency and immutable model versioning. AWS Config executes automated configuration tracking and validation. AWS CloudTrail captures comprehensive audit logging. Deploy reproducibility of AI behaviors using model versioning in AWS CodePipeline, AWS CodeCommit, and Amazon Bedrock. 
   
  
 
The following is an example of what customers might need to implement and what AWS provides when building AI agents (Figure 2): 

 
 Figure 2. Gen AI implementation in GxP environments requires understanding the division of responsibilities between customers and AWS.
 
Let‚Äôs demonstrate how these shared responsibilities translate into actual implementation. 
Provenance and reproducibility 
AWS Supports the following: 
 
 Amazon Bedrock ‚Äì Provides immutable model versioning, facilitating reproducible AI behavior across the system lifecycle. 
 AWS Config ‚Äì Automatically tracks and validates system configurations, continuously monitoring for drift from validated baselines. 
 AWS CloudTrail ‚Äì Generates audit trails with cryptographic integrity, capturing model invocations with complete metadata including timestamps, user identities, and model versions. Infrastructure as Code support through AWS CloudFormation enables version-controlled, repeatable deployments. 
 
Customer responsibility: Organizations must version-control their infrastructure deployments, their prompt templates to make sure there is consistent AI behavior and maintain audit trails of prompt changes. Tool dependencies must be tracked and locked to specific versions in validated environments to help prevent unintended updates that could affect AI outputs. 
Observability and performance metrics 
AWS supports the following: 
 
 Amazon Bedrock AgentCore ‚Äì Provides a comprehensive solution for the unique risks that agentic AI introduces, including end-to-end visibility into complex multi-step agent tasks and runtime requirements for orchestrating reasoning chains. Amazon Bedrock AgentCore Observability captures the complete chain of decisions and tool invocations, so that you can inspect an agent‚Äôs execution path, audit intermediate outputs, and inspect failures. The Bedrock Retrieval API for Amazon Bedrock Knowledge Bases enables traceability from retrieved documents to AI-generated outputs. 
 Amazon CloudWatch ‚Äì Delivers real-time monitoring with customizable alerts and dashboards, aggregating performance metrics across the agent invocations. Organizations can configure logging levels based on risk, such as basic CloudTrail logging for low-risk applications, detailed AgentCore traces for medium risk, and complete provenance chains for high-risk regulatory submissions. 
 
Customer responsibility: Organizations define acceptance criteria and monitoring thresholds appropriate to their risk level‚Äîfor example, citation accuracy requirements for our literature review agent. Teams must decide when human-in-the-loop triggers are required, such as mandatory expert review before AI recommendations influence research decisions or regulatory submissions. 
User management, session isolation, and security 
AWS Supports the following: 
 
 Amazon Bedrock AgentCore ‚Äì Provides session isolation using dedicated microVMs, that help prevent cross-contamination between different projects or regulatory submissions. The service supports VPC endpoints to establish private connections between your Amazon VPC and Amazon Bedrock AgentCore resources, allowing for inter-network traffic privacy. All communication with Amazon Bedrock AgentCore endpoints uses HTTPS exclusively across all supported regions, with no HTTP support, so that all communications are digitally signed for authentication and integrity. 
 
Amazon Bedrock AgentCore maintains robust encryption standards with TLS 1.2 minimum requirements (TLS 1.3 recommended) for all API endpoints. Both control plane and data plane traffic are encrypted with TLS protocols and restricted to minimum TLS 1.2 with no unencrypted communication permitted. Amazon Bedrock AgentCore Identity addresses identity complexity with a secure token vault for credentials management, providing fine-grained permissions and enterprise identity integration. 
AWS Identity and Access Management (IAM) enables organizations to configure role-based access controls with least-privilege principles. Built-in encryption facilitates data protection both in transit and at rest, while network isolation and compliance certifications (SOC, ISO 27001, HIPAA) support regulatory requirements. Amazon Bedrock offers configurable data residency, allowing organizations to specify regions for data processing. 
Customer responsibility: Organizations configure IAM roles and policies aligned with GxP user access requirements, facilitating least-privilege access and proper segregation of duties. Access controls must be documented and maintained as part of the quality management system. 
GxP controls for AI agents 
The implementation of GxP risk controls for AI agents can be considered through three key phases. 
Risk Assessment evaluates the GxP workload against the organization‚Äôs risk-based validation framework. Continual quality assurance is maintained through structured feedback loops, ranging from real-time verification (see Continuous Validation) to bi-annual reviews. This process makes sure reviewers are trained against the evolving AI landscape, adapt to user feedback, and apply appropriate intervention criteria. In practice, risk assessments define risk categories and triggers for reassessment. 
Control Selection is carefully selecting minimum required controls based on the 1. risk classification, 2. the specific design attributes, and 3. operational context of the AI agents. This targeted, risk-adjusted approach, makes sure controls align with both technical requirements and compliance objectives. In practice, risk categories drive required and selectable controls. An example of medium risk might require Agent and Prompt Governance controls along with two or more Detective Controls, while a high risk might require Traditional Testing (IQ, OQ, PQ) control, and two additional corrective controls. 
Continuous Validation is an approach that includes the traditional fit-for-intended-use validation and subsequent process that leverages real-world data (RWD), such as operational logs and/or user feedback, to create supplemental real-world evidence (RWE) that the system maintains a validated state. As a control mechanism itself, the Continuous Validation approach helps address modern cloud-based designs including SaaS models, model drifts, and evolving cloud infrastructure. Through ongoing monitoring of performance and functionality, this approach helps maintain system GxP compliance while supporting regulatory inspections. In practice, for low-risk categories, this might be a user compliance-aligned portal that tracks user issue trends to high-risk systems that incorporate periodic self-tests with compliance reports. 
The following table provides examples of Preventive, Corrective, and Detective Controls for agentic AI systems that could be incorporated in a modern GxP validation framework. 
 
  
   
   Control element 
   Supporting AWS services 
   
   
   Preventive Controls 
   
   
   Agent Behavior Specification 
   Use Amazon Bedrock Model Catalog to find the models that help meet your specific requirements and use AWS service quotas (limits) and documentation on service features to define supported and verifiable agent capabilities. 
   
   
   Threat Modeling 
   Use AWS Well-Architected Framework (Security Pillar) tools and AWS service security documentation to proactively identify AI-specific threats like Prompt Injection, Data Poisoning, and Model Inversion, and help design preventive mitigations using AWS services. 
   
   
   Response Content and Relevance Control 
   Use Amazon Bedrock Guardrails to implement real-time safety policies for large language models (LLMs) to deny harmful inputs or responses. Guardrails can also define denylists and filter for PII. Use Amazon Bedrock Knowledge Bases or AWS purpose-built vector databases for RAG to provide controlled, current, and relevant information to help prevent factual drift. 
   
   
   Bias Mitigation in Datasets 
   Amazon SageMaker Clarify provides tools to run pre-training bias analysis of your datasets. For agents, this helps make sure the foundational data doesn‚Äôt lead to biased decision-making paths or tool usage. 
   
   
   Agent &amp; Prompt Governance 
   Amazon Bedrock agents and prompt management features support lifecycle processes including creation, evaluation, versioning, and optimization. The features also support advanced prompt templates, content filters, automated reasoning checks, and integration with Amazon Bedrock Flows for more secure and controlled agentic workflows. 
   
   
   Configuration Management 
   AWS provides an industry leading suite of configuration management services such as AWS Config and AWS Audit Manager, which can be used to continuously validate agentic GxP system configurations. AWS SageMaker Model Registry manages and versions trained machine learning (ML) models for controlled deployments. 
   
   
   Secure AI Development 
   Amazon Q Developer and Amazon Kiro provide AI-powered code assistance that incorporate security best practices and AWS Well-Architected principals for building and maintaining agentic workloads securely from the start. 
   
   
   AI Agents as Secondary Controls 
   Use Amazon Bedrock AgentCore and your data to quickly incorporate AI agents into existing GxP workflows as secondary preventative controls to add capabilities like trend analysis, automated inspections, and systems flow analysis that can trigger preventative workflow events. 
   
   
   Detective Controls 
   
   
   Traditional Testing (IQ, OQ, PQ) 
   Use AWS Config and AWS CloudFormation for IQ validation by tracking resource deployment configurations. Use AWS CloudTrail and AWS CloudWatch for sourcing events, metrics, and log test results for OQ/PQ validation. 
   
   
   Explainability Audits &amp; Trajectory Reviews 
   Amazon SageMaker Clarify generates explainability reports for custom models. Amazon Bedrock Invocation Logs can be used to review reasoning or chain of thought to find flaws in an agent‚Äôs logic. Utilize Amazon AgentCore Observability to look at agent invocation sessions, traces and spans. 
   
   
   Model &amp; I/O Drift Detection 
   For custom models, Amazon SageMaker Model Monitor, can detect drift in data and model quality. For AI agents using commercial LLMs, use the observability service of Amazon Bedrock AgentCore to design monitoring of Inputs (prompts) and Outputs (responses) to detect concept drift. Use Amazon CloudWatch alarms to manage compliance notifications. 
   
   
   Performance Monitoring 
   Agentic workloads can use Amazon Bedrock metrics, AgentCore Observability and AWS CloudWatch metrics to include monitoring for Token Usage, Cost per Interaction, and Tool Execution Latency to detect performance and cost anomalies. 
   
   
   Log and Event Monitoring (SIEM) 
   For agentic workload, Amazon GuardDuty provides intelligent threat detection that analyzes Amazon Bedrock API calls to detect anomalous or potentially malicious use of the agent or LLMs. 
   
   
   Code &amp; Model Risk Scanning 
   Amazon CodeGuru and Amazon Inspector scans agent code and operational environment for vulnerabilities. These tools can‚Äôt assess model weights for risk, however AWS does provide Amazon SageMaker Model Card support that can be used to build Model Risk scanning controls. 
   
   
   Adversarial Testing (Red Teaming) &amp; Critic/Grader Model 
   The evaluation tools of Amazon Bedrock help assess model fitness. Amazon Bedrock supports leading model providers allowing GxP systems to use multiple models for secondary and tertiary validation. 
   
   
   Internal Audits 
   AWS Audit Manager automates the collection of evidence for compliance and audits and AWS CloudTrail provides a streamlined way to review agent actions and facilitate procedural adherence. 
   
   
   Corrective Controls 
   
   
   Model &amp; Prompt Rollback 
   Use AWS CodePipeline and AWS CloudFormation to quickly revert to a previous, known-good version of a model or Prompt Template when a problem is detected. 
   
   
   System Fallback 
   AWS Step Functions can help orchestrate a fallback to a streamlined, more constrained model or a human-only workflow if the primary agent fails. 
   
   
   Human-in-the-Loop &amp; Escalation Management 
   AWS Step Functions, Amazon Simple Notification Service (SNS) and Amazon Bedrock Prompt Flow can orchestrate workflows that can pause and wait for human approval, including dynamic approvals based on low agent confidence scores or detected anomalies. 
   
   
   CAPA Process 
   AWS Systems Manager OpsCenter provides a central place to manage operational issues, which can be used to track the root cause analysis of an agent‚Äôs failure. 
   
   
   Incident Response Plan 
   AWS Security Hub and AWS Systems Manager Incident Manager can automate response plans for AI security incidents (for example, major jailbreak and data leakage) and provide a central dashboard to manage them. 
   
   
   Disaster Recovery Plan (DRP) 
   AWS Elastic Disaster Recovery (DRS) and AWS Backup provides tools to replicate and recover the entire AI application stack, including deploying to different AWS Regions. 
   
  
 
Conclusion 
Healthcare and life sciences organizations can build GxP-compliant AI agents by adopting a risk-based framework that balances innovation with regulatory requirements. Success requires proper risk classification, scaled controls matching system impact, and understanding the AWS shared responsibility model. AWS provides qualified infrastructure and comprehensive services, while organizations configure appropriate controls, maintain version management, and implement risk mitigation strategies tailored to their validation needs. 
We encourage organizations to explore building GxP-compliant AI agents with AWS services. For more information about implementing compliance-aligned AI systems in regulated environments, contact your AWS account team or visit our Healthcare and Life Sciences Solutions page. 
 
About the authors 
Pierre de Malliard is a Senior AI/ML Solutions Architect at Amazon Web Services and supports customers in the Healthcare and Life Sciences Industry. 
Ian Sutcliffe&nbsp;is a Global Solution Architect with 25+ years of experience in IT, primarily in the Life Sciences Industry. A thought leader in the area of regulated cloud computing, one of his areas of focus is IT operating models and process optimization and automation with the intent of helping customers become Regulated Cloud Natives 
Kristin Ambrosini is a Generative AI Specialist at Amazon Web Services. She drives adoption of scalable GenAI solutions across healthcare and life sciences to transform drug discovery and improve patient outcomes. Kristin blends scientific expertise, technical acumen, and business strategy. She holds a Ph.D. in Biological Sciences. 
Ben Xavier is a MedTech Specialist with over 25 years of experience in Medical Device R&amp;D. He is a passionate leader focused on modernizing the MedTech industry through technology and best practices to accelerate innovation and improve patient outcomes.

‚∏ª